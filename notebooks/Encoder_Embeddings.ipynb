{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Codons using the trained Encoder model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import Tensor\n",
    "import math\n",
    "\n",
    "sys.path.append('../scripts')\n",
    "import ml_helper as mlh\n",
    "import Classifier as Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps device\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "        18, 19, 20], device='mps:0')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amino_acids = ['A', 'R', 'N', 'D', 'C', 'Q', 'E', 'G', 'H', 'I', 'L', 'K', 'M', 'F', 'P', 'S', 'T', 'W', 'Y', 'V', '*']\n",
    "\n",
    "aminoacids_to_integer = dict((a, i) for i, a in enumerate(amino_acids))\n",
    "\n",
    "amino_acids_int = torch.tensor([aminoacids_to_integer[aa] for aa in amino_acids]).to(device)\n",
    "amino_acids_int"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 500):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(max_len, 1, d_model)\n",
    "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            x: Tensor, shape ``[seq_len, batch_size, embedding_dim]``\n",
    "        \"\"\"\n",
    "        x = x + self.pe[:x.size(0)]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderClassifier(nn.Module):\n",
    "    def __init__(self, embed_dim, num_layers, num_heads, dropout=0.2, pos_enc=False):\n",
    "        super(EncoderClassifier, self).__init__()\n",
    "\n",
    "        emb_size = embed_dim\n",
    "        if SPEEDS_ADDED:\n",
    "            emb_size -= 1\n",
    "        self.emb = nn.Embedding(len(amino_acids), emb_size, padding_idx=len(amino_acids)-1)\n",
    "        self.pos_enc = pos_enc\n",
    "        self.pos_encoder = PositionalEncoding(embed_dim, dropout)\n",
    "\n",
    "        self.encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=embed_dim,\n",
    "            nhead=num_heads,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.encoder = nn.TransformerEncoder(\n",
    "            encoder_layer=self.encoder_layer,\n",
    "            num_layers=num_layers,\n",
    "        )\n",
    "        self.linear = nn.Linear(embed_dim, len(codons))\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.long()\n",
    "        if SPEEDS_ADDED:\n",
    "            x1 = self.emb(x[:, :, 0])\n",
    "            x2 = x[:, :, 1].unsqueeze(-1)\n",
    "            x = torch.cat((x1, x2), dim=-1)  # Concatenate along the feature dimension\n",
    "        else:\n",
    "            x = self.emb(x)\n",
    "\n",
    "        if self.pos_enc:\n",
    "            x = x.transpose(0, 1)\n",
    "            x = self.pos_encoder(x)  # Add positional encoding\n",
    "            x = x.transpose(0, 1)\n",
    "        x = self.encoder(x)\n",
    "        x = self.dropout(x)\n",
    "        out = self.linear(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "organism Homo.Sapiens\n",
      "Model loaded: 20240603201950_encoder_64em_4l_4h_posenc_02dr_80ep.pt\n"
     ]
    }
   ],
   "source": [
    "organisms = [\"E.Coli\", \"Drosophila.Melanogaster\", \"Homo.Sapiens\"]\n",
    "organism = organisms[2]\n",
    "print(\"organism\", organism)\n",
    "\n",
    "model = mlh.load_model('encoder', organism, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Embedding Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embedder(nn.Module):\n",
    "    def __init__(self, model_with_weights: EncoderClassifier):\n",
    "        super(Embedder, self).__init__()\n",
    "        self.emb = nn.Embedding.from_pretrained(model_with_weights.emb.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.emb(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedder(\n",
       "  (emb): Embedding(22, 64)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedder = Embedder(model).to(device)\n",
    "embedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape (21, 64)\n",
      "[[ 1.1042241   0.8326001   0.15882942 ...  0.1425863  -0.9600666\n",
      "   0.11301643]\n",
      " [ 1.0352929   0.6260455   1.4370686  ... -1.5619731   0.71031946\n",
      "  -1.4426522 ]\n",
      " [ 1.5754012   0.7523007  -1.2519578  ... -1.4231119   0.69422084\n",
      "  -0.14460011]\n",
      " ...\n",
      " [-1.6650704   0.03668799  0.69063514 ... -1.7696711   0.8733255\n",
      "  -1.4260384 ]\n",
      " [ 0.3931166   0.9061415   0.94544387 ... -1.3964047  -0.76329756\n",
      "  -1.3973165 ]\n",
      " [-0.29485354 -0.27986267  1.0837125  ...  2.0561688  -0.2347232\n",
      "  -1.3456243 ]]\n"
     ]
    }
   ],
   "source": [
    "embedding = embedder(amino_acids_int).cpu().detach().numpy()\n",
    "print(\"shape\", embedding.shape)\n",
    "print(embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter()\n",
    "writer.add_embedding(embedding, amino_acids)\n",
    "writer.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tensor baord starten mit\n",
    "```zsh\n",
    "tensorboard --logdir=notebooks/runs\n",
    "```\n",
    "evtl Pfad anpassen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir runs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
