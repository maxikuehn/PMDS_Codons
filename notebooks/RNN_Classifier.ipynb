{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# RNN Classifier",
   "id": "c769c947119d606e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-04T10:12:05.395535Z",
     "start_time": "2024-05-04T10:12:05.383803Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "id": "dd2db30860a62993",
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-04T11:18:56.131933Z",
     "start_time": "2024-05-04T11:18:56.110312Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from scripts.ml_helper import CodonDataset, amino_acids, codons, codon_from_output"
   ],
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Data Preparation",
   "id": "8d8f8988585e60c1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-04T11:19:39.575187Z",
     "start_time": "2024-05-04T11:19:39.500114Z"
    }
   },
   "cell_type": "code",
   "source": [
    "n_amino_acids = len(amino_acids)\n",
    "n_codons = len(codons)"
   ],
   "id": "5c47253bc9eefc57",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-04T10:19:52.052233Z",
     "start_time": "2024-05-04T10:19:51.932324Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ecoli_dataset = CodonDataset(\"E.Coli\")\n",
    "generator = torch.Generator().manual_seed(42)\n",
    "ecoli_train_set, ecoli_val_set = torch.utils.data.random_split(ecoli_dataset, [0.8, 0.2], generator=generator)"
   ],
   "id": "aa87419358258bf0",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-04T10:19:52.165339Z",
     "start_time": "2024-05-04T10:19:52.148799Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(len(ecoli_train_set))\n",
    "print(len(ecoli_val_set))"
   ],
   "id": "31c118f57606e690",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3085\n",
      "771\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-04T11:14:52.449702Z",
     "start_time": "2024-05-04T11:14:52.273555Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataloader = DataLoader(ecoli_dataset, batch_size=1, shuffle=True, num_workers=0)\n",
    "\n",
    "for i_batch, sample_batched in enumerate(dataloader):\n",
    "    print(i_batch, sample_batched)\n",
    "\n",
    "    # observe 4th batch and stop.\n",
    "    if i_batch == 3:\n",
    "        break"
   ],
   "id": "49bcd0733d66ca05",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [tensor([[[0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 1]]]), tensor([[35,  4, 24, 38, 33, 28, 56, 42, 27, 42, 19, 42, 55, 28, 53, 44, 43, 32,\n",
      "         27, 61, 27, 49, 51, 55, 17, 43, 42, 35, 17, 57, 59, 23, 25, 58, 13, 52,\n",
      "         54, 48,  2, 26, 27, 32, 52, 52, 33, 28, 61, 55, 50, 41, 60, 19, 35, 31,\n",
      "         58, 51, 32, 42, 60, 24, 19, 39, 58, 25, 33, 48, 25, 27, 63, 56, 59, 18,\n",
      "         42, 28, 58, 58, 56, 19, 56, 49, 48, 19, 43, 51, 19, 56,  6,  8, 33, 42,\n",
      "         10]])]\n",
      "1 [tensor([[[0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 1, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 1]]]), tensor([[35, 28, 58, 26, 33, 42, 27, 56, 33, 56, 19, 32, 59, 32,  2,  0,  8, 19,\n",
      "         43, 42, 43, 32, 28, 48, 33, 16,  0, 32, 35, 52, 34, 12, 35, 52, 35, 51,\n",
      "         19,  3,  0, 19,  8, 33, 40, 42, 57, 40, 34, 42, 51, 32,  9, 45, 18, 42,\n",
      "         34, 41, 27, 38, 39, 22, 60, 34, 16, 48, 45, 12, 56, 45, 40, 40, 40,  0,\n",
      "         53, 12, 27, 36, 38, 35, 36, 58, 56, 48, 32, 27, 30, 32, 36, 38,  0,  0,\n",
      "         25, 37, 45, 22, 56, 49, 43, 41, 46, 58, 34, 47, 19, 58, 15,  6, 62, 56,\n",
      "         43, 46, 52,  2, 22, 36, 52, 58, 59, 58, 34,  4, 29, 51, 27, 53,  4, 32,\n",
      "         33, 42, 15,  8, 55,  6, 58,  8, 24, 40, 61, 47, 26, 48, 17, 56, 59, 34,\n",
      "         26, 39, 20,  6, 54, 32, 41, 44, 59, 16,  8, 38, 42, 35, 34,  9, 19, 37,\n",
      "         47, 41, 15,  6,  3,  8, 23, 41, 60, 56, 61, 12, 50, 36, 34, 45,  6, 22,\n",
      "         58, 34, 42, 40, 42,  9, 20, 52, 53, 32, 13, 19, 52, 19, 62,  0,  0, 18,\n",
      "         45, 32, 50, 32,  4, 50, 35,  0, 13, 16, 49, 42, 42, 35, 50, 56, 58,  9,\n",
      "         26, 26, 41,  4, 63, 27, 10]])]\n",
      "2 [tensor([[[0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 1,  ..., 0, 0, 0],\n",
      "         [0, 0, 1,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [0, 1, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 1]]]), tensor([[35, 40, 40,  2, 23, 50, 48, 28,  7, 21, 15, 31, 32, 51, 32,  3, 19, 19,\n",
      "         61,  0, 37,  0, 17,  9, 55, 22, 35, 19, 35, 19, 48, 33,  8,  7,  0, 41,\n",
      "         45,  7, 43, 19, 51, 39, 51, 15, 53, 61, 15,  6, 39, 29, 15,  8, 60, 59,\n",
      "          2,  3, 29, 56, 57, 55, 35, 35, 44, 55, 48, 60,  2, 44, 19, 38, 32, 55,\n",
      "         53, 12, 55, 55, 39, 55, 55, 55, 33, 17, 62, 36, 32, 55, 55, 51, 51, 19,\n",
      "         51, 29,  0, 61, 47,  0, 29, 62,  6, 40, 61,  0, 53,  0, 35, 33, 37, 55,\n",
      "         23, 19, 50, 35, 22, 56, 49, 33, 39, 61,  3,  7, 19,  3,  2,  2,  1, 49,\n",
      "         55, 16, 52, 24, 53, 32, 61, 15, 20, 55, 57, 29, 60, 35, 17, 37, 33, 15,\n",
      "         19, 55, 24, 49, 36,  0, 12, 39, 52,  8, 51, 55, 49, 48, 32,  4,  6, 46,\n",
      "          3, 31, 58, 19, 56, 29,  7, 34, 58, 58, 54, 55, 35, 56, 17, 60, 55, 39,\n",
      "         23, 19, 42, 51,  0,  1, 49, 32, 39, 18, 23, 35, 33, 35, 21, 55, 33, 32,\n",
      "          4, 61, 15,  2, 19, 52,  0, 36,  3,  7, 16, 56, 56, 19, 51, 33, 53, 45,\n",
      "          0, 48,  5, 63, 23, 62, 53, 37, 39,  2, 23, 35, 19, 49,  0,  5, 45, 51,\n",
      "         31, 35, 63, 51, 40, 23, 58, 33, 41, 53, 19, 54, 38,  3, 33, 17, 61, 55,\n",
      "         49, 62, 32, 49, 62,  0, 33, 53, 15,  8, 19, 35, 52, 29, 54, 58, 42, 27,\n",
      "         31, 34, 29, 57, 33, 27, 28, 54, 46, 28, 61, 14]])]\n",
      "3 [tensor([[[0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 1]]]), tensor([[35, 26, 43, 26, 52, 59,  3,  8, 28, 60, 42, 55, 42, 37, 50,  9, 45, 39,\n",
      "         58, 41, 23, 57, 19,  3, 51, 17, 58,  1, 29, 40, 56, 39,  6, 54, 63, 56,\n",
      "         61, 55, 29, 32, 59, 27,  0, 56, 29, 42, 60, 35, 51, 41, 41, 43,  1, 41,\n",
      "          9,  1, 32, 35, 45, 42, 19, 52, 58, 55, 60, 33, 23, 36, 26, 35, 59, 28,\n",
      "         19, 17,  5, 56, 37, 58, 12, 19, 51, 42, 43, 19, 56, 35, 51, 23, 48, 59,\n",
      "         12, 49, 51, 28, 41, 28, 52, 52, 61,  4, 19, 51, 42, 28, 16, 62, 33, 58,\n",
      "         58, 60, 32, 59, 19, 41, 23, 23, 19,  1, 56, 19,  1, 19, 42, 41, 57, 53,\n",
      "         35, 25, 56, 23, 35, 49, 41, 58,  4,  9, 13, 58, 37,  0, 61, 15, 51, 45,\n",
      "         42, 59, 41, 19, 55, 28, 35, 42, 59, 19, 37,  9, 42, 55, 41, 57, 51, 19,\n",
      "         42, 42, 19,  1, 56, 56, 52, 60, 19, 32, 19, 49, 57,  1, 43, 19, 58,  0,\n",
      "         60, 19,  9, 42, 61, 58, 51, 50, 19, 60, 56, 59,  1,  5, 23, 57, 60, 45,\n",
      "         29, 19, 15, 57, 42, 58, 39, 19, 59, 42, 35, 57, 42, 57, 28,  1, 29, 27,\n",
      "         45, 17, 60, 61, 19, 33, 58, 53,  8, 58, 53, 49, 53, 29, 29, 19, 60, 50,\n",
      "         27, 19, 57, 14]])]\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Creating the Network",
   "id": "ff0b66bcd08d7662"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-04T11:21:18.510318Z",
     "start_time": "2024-05-04T11:21:18.484356Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.i2h = nn.Linear(input_size, hidden_size)\n",
    "        self.h2h = nn.Linear(hidden_size, hidden_size)\n",
    "        self.h2o = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        hidden = F.tanh(self.i2h(input) + self.h2h(hidden))\n",
    "        output = self.h2o(hidden)\n",
    "        output = self.softmax(output)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, self.hidden_size)\n",
    "\n",
    "\n",
    "n_hidden = 128\n",
    "rnn = RNN(n_amino_acids, n_hidden, n_codons)"
   ],
   "id": "a3597811f1d82258",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-04T11:27:14.973418Z",
     "start_time": "2024-05-04T11:27:14.952923Z"
    }
   },
   "cell_type": "code",
   "source": [
    "aa, c = ecoli_train_set[0]\n",
    "hidden = rnn.initHidden()\n",
    "output, next_hidden = rnn(aa, hidden)\n",
    "output"
   ],
   "id": "beda04a593796ed3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-4.1084, -4.0406, -4.0875,  ..., -4.1056, -4.0902, -4.2256],\n",
       "        [-4.1635, -4.1685, -4.1552,  ..., -4.3154, -4.0351, -4.1656],\n",
       "        [-4.0903, -4.0890, -4.0503,  ..., -4.2119, -4.0961, -4.1502],\n",
       "        ...,\n",
       "        [-4.2334, -4.1264, -4.0462,  ..., -4.2003, -4.2030, -4.2022],\n",
       "        [-4.2334, -4.1264, -4.0462,  ..., -4.2003, -4.2030, -4.2022],\n",
       "        [-4.0909, -4.2354, -4.0652,  ..., -4.2347, -4.1591, -4.1950]],\n",
       "       grad_fn=<LogSoftmaxBackward0>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Training",
   "id": "7ff5d1f444f3ad99"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-04T11:33:50.581874Z",
     "start_time": "2024-05-04T11:33:50.546653Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import random\n",
    "\n",
    "\n",
    "def randomChoice(l):\n",
    "    return l[random.randint(0, len(l) - 1)]\n",
    "\n",
    "def randomTrainingExample():\n",
    "    aa, c = randomChoice(ecoli_train_set)\n",
    "    return aa, c"
   ],
   "id": "9843e907490e4523",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-04T11:33:50.899898Z",
     "start_time": "2024-05-04T11:33:50.881514Z"
    }
   },
   "cell_type": "code",
   "source": [
    "criterion = nn.NLLLoss()\n",
    "learning_rate = 0.005  # If you set this too high, it might explode. If too low, it might not learn\n",
    "\n",
    "\n",
    "def train(codon_tensor, aa_tensor):\n",
    "    hidden = rnn.initHidden()\n",
    "\n",
    "    rnn.zero_grad()\n",
    "\n",
    "    for i in range(aa_tensor.size()[0]):\n",
    "        output, hidden = rnn(aa_tensor[i], hidden)\n",
    "\n",
    "    loss = criterion(output, codon_tensor)\n",
    "    loss.backward()\n",
    "\n",
    "    # Add parameters' gradients to their values, multiplied by learning rate\n",
    "    for p in rnn.parameters():\n",
    "        p.data.add_(p.grad.data, alpha=-learning_rate)\n",
    "\n",
    "    return output, loss.item()"
   ],
   "id": "d85c038ece1a471f",
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-04T11:35:03.139799Z",
     "start_time": "2024-05-04T11:35:03.075523Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "n_iters = 100_000\n",
    "print_every = 5000\n",
    "plot_every = 1000\n",
    "\n",
    "# Keep track of losses for plotting\n",
    "current_loss = 0\n",
    "all_losses = []\n",
    "\n",
    "\n",
    "def timeSince(since):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for iter in range(1, n_iters + 1):\n",
    "    aa, c = randomTrainingExample()\n",
    "    output, loss = train(c, aa)\n",
    "    current_loss += loss\n",
    "\n",
    "    # Print ``iter`` number, loss, name and guess\n",
    "    if iter % print_every == 0:\n",
    "        guess, guess_i = codon_from_output(output)\n",
    "        correct = '✓' if guess == c else '✗ (%s)' % c\n",
    "        print(\n",
    "            '%d %d%% (%s) %.4f %s / %s %s' % (iter, iter / n_iters * 100, timeSince(start), loss    , guess, correct))\n",
    "\n",
    "    # Add current loss avg to list of losses\n",
    "    if iter % plot_every == 0:\n",
    "        all_losses.append(current_loss / plot_every)\n",
    "        current_loss = 0"
   ],
   "id": "a861bd44a3b52502",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected input batch_size (1) to match target batch_size (404).",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[37], line 25\u001B[0m\n\u001B[1;32m     23\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m \u001B[38;5;28miter\u001B[39m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m1\u001B[39m, n_iters \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m):\n\u001B[1;32m     24\u001B[0m     aa, c \u001B[38;5;241m=\u001B[39m randomTrainingExample()\n\u001B[0;32m---> 25\u001B[0m     output, loss \u001B[38;5;241m=\u001B[39m train(c, aa)\n\u001B[1;32m     26\u001B[0m     current_loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m loss\n\u001B[1;32m     28\u001B[0m     \u001B[38;5;66;03m# Print ``iter`` number, loss, name and guess\u001B[39;00m\n",
      "Cell \u001B[0;32mIn[34], line 13\u001B[0m, in \u001B[0;36mtrain\u001B[0;34m(codon_tensor, aa_tensor)\u001B[0m\n\u001B[1;32m     10\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(aa_tensor\u001B[38;5;241m.\u001B[39msize()[\u001B[38;5;241m0\u001B[39m]):\n\u001B[1;32m     11\u001B[0m     output, hidden \u001B[38;5;241m=\u001B[39m rnn(aa_tensor[i], hidden)\n\u001B[0;32m---> 13\u001B[0m loss \u001B[38;5;241m=\u001B[39m criterion(output, codon_tensor)\n\u001B[1;32m     14\u001B[0m loss\u001B[38;5;241m.\u001B[39mbackward()\n\u001B[1;32m     16\u001B[0m \u001B[38;5;66;03m# Add parameters' gradients to their values, multiplied by learning rate\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/envs/pmds_codon_crawler/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/anaconda3/envs/pmds_codon_crawler/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/envs/pmds_codon_crawler/lib/python3.11/site-packages/torch/nn/modules/loss.py:216\u001B[0m, in \u001B[0;36mNLLLoss.forward\u001B[0;34m(self, input, target)\u001B[0m\n\u001B[1;32m    215\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor, target: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[0;32m--> 216\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m F\u001B[38;5;241m.\u001B[39mnll_loss(\u001B[38;5;28minput\u001B[39m, target, weight\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mweight, ignore_index\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mignore_index, reduction\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreduction)\n",
      "File \u001B[0;32m~/anaconda3/envs/pmds_codon_crawler/lib/python3.11/site-packages/torch/nn/functional.py:2760\u001B[0m, in \u001B[0;36mnll_loss\u001B[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001B[0m\n\u001B[1;32m   2758\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m size_average \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m reduce \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   2759\u001B[0m     reduction \u001B[38;5;241m=\u001B[39m _Reduction\u001B[38;5;241m.\u001B[39mlegacy_get_string(size_average, reduce)\n\u001B[0;32m-> 2760\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m torch\u001B[38;5;241m.\u001B[39m_C\u001B[38;5;241m.\u001B[39m_nn\u001B[38;5;241m.\u001B[39mnll_loss_nd(\u001B[38;5;28minput\u001B[39m, target, weight, _Reduction\u001B[38;5;241m.\u001B[39mget_enum(reduction), ignore_index)\n",
      "\u001B[0;31mValueError\u001B[0m: Expected input batch_size (1) to match target batch_size (404)."
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "c4b9ed2fcb16e472"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
