{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# RNN Classifier",
   "id": "c769c947119d606e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-08T16:50:41.787968Z",
     "start_time": "2024-05-08T16:50:41.776058Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "id": "dd2db30860a62993",
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-08T16:50:42.776277Z",
     "start_time": "2024-05-08T16:50:41.789193Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "from scripts.ml_helper import CodonDataset, amino_acids, codons, codon_from_output"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-08T16:50:42.830944Z",
     "start_time": "2024-05-08T16:50:42.776965Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ],
   "id": "3c7187a43dc55642",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Creating the Network",
   "id": "ff0b66bcd08d7662"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-08T16:50:42.845334Z",
     "start_time": "2024-05-08T16:50:42.831606Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size: int, hidden_size: int, output_size: int, batch_size=1) -> None:\n",
    "        \"\"\"\n",
    "        input_size: Number of features of your input vector\n",
    "        hidden_size: Number of hidden neurons\n",
    "        output_size: Number of features of your output vector\n",
    "        \"\"\"\n",
    "        super(RNN, self).__init__()\n",
    "\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.i2h = nn.Linear(input_size, hidden_size, bias=False)\n",
    "        self.h2h = nn.Linear(hidden_size, hidden_size)\n",
    "        self.h2o = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden_state) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Returns computed output and tanh(i2h + h2h)\n",
    "        Inputs\n",
    "        ------\n",
    "        input: Input vector\n",
    "        hidden_state: Previous hidden state\n",
    "        Outputs\n",
    "        -------\n",
    "        out: Linear output (without activation because of how pytorch works)\n",
    "        hidden_state: New hidden state matrix\n",
    "        \"\"\"\n",
    "        input = self.i2h(input)\n",
    "\n",
    "        hidden_state = self.h2h(hidden_state)\n",
    "\n",
    "        hidden_state = F.tanh(input + hidden_state)\n",
    "        out = self.h2o(hidden_state)\n",
    "        out = self.softmax(out)\n",
    "        return out, hidden_state\n",
    "\n",
    "    def init_hidden(self) -> torch.Tensor:\n",
    "        return torch.zeros(self.batch_size, self.hidden_size, requires_grad=False)\n"
   ],
   "id": "c3f9c3bcfa0ea02b",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-08T16:50:42.860384Z",
     "start_time": "2024-05-08T16:50:42.846685Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train(model: RNN, data: DataLoader, epochs: int, optimizer: optim.Optimizer, loss_fn: nn.Module) -> None:\n",
    "    \"\"\"\n",
    "    Trains the model for the specified number of epochs\n",
    "    Inputs\n",
    "    ------\n",
    "    model: RNN model to train\n",
    "    data: Iterable DataLoader\n",
    "    epochs: Number of epochs to train the model\n",
    "    optimizer: Optimizer to use for each epoch\n",
    "    loss_fn: Function to calculate loss\n",
    "    \"\"\"\n",
    "    train_losses = {}\n",
    "    model.to(device)\n",
    "\n",
    "    model.train()\n",
    "    print(\"=> Starting training\")\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        epoch_losses = list()\n",
    "        num_data = 0\n",
    "        for aa_sequence, codon_sequence in data:\n",
    "            num_data += 1\n",
    "            if num_data % int(len(data) / 4) == 0:\n",
    "                percentage = 5 * round(int(num_data / len(data) * 100) / 5)\n",
    "                print(f'{percentage}%')\n",
    "\n",
    "            hidden = model.init_hidden()\n",
    "\n",
    "            # send tensors to device\n",
    "            aa_sequence, codon_sequence, hidden = aa_sequence.to(device), codon_sequence.to(device), hidden.to(device)\n",
    "            # clear gradients\n",
    "            model.zero_grad()\n",
    "            loss = 0\n",
    "            for i in range(aa_sequence.shape[1]):\n",
    "                input = aa_sequence[:, i].reshape(aa_sequence.shape[0], aa_sequence.shape[2])\n",
    "                out, hidden = model(input, hidden)\n",
    "\n",
    "                l = loss_fn(out, codon_sequence[:, i].long())\n",
    "                loss += l\n",
    "            # Complete gradients\n",
    "            loss.backward()\n",
    "            # Adjust learnable parameters\n",
    "            # clip as well to avoid vanishing and exploding gradients\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), 3)\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_losses.append(loss.detach().item() / aa_sequence.shape[1])\n",
    "        train_losses[epoch] = torch.tensor(epoch_losses).mean()\n",
    "        print(f'=> epoch: {epoch + 1}, loss: {train_losses[epoch]}')"
   ],
   "id": "98123ede54a351aa",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Training",
   "id": "7ff5d1f444f3ad99"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-08T16:50:44.460665Z",
     "start_time": "2024-05-08T16:50:42.860971Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Data Prep\n",
    "organism = \"E.Coli\"\n",
    "batch_size = 1\n",
    "min_length = None\n",
    "max_length = 600\n",
    "\n",
    "train_dataset = CodonDataset(organism=organism, split=\"train\", min_length=min_length, max_length=max_length)\n",
    "test_dataset = CodonDataset(organism=organism, split=\"test\", min_length=min_length, max_length=max_length)\n",
    "\n",
    "print(len(train_dataset))\n",
    "print(len(test_dataset))\n",
    "\n",
    "train_loader = DataLoader(train_dataset, shuffle=True, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_dataset, shuffle=True, batch_size=batch_size)"
   ],
   "id": "c4a940351fe6b0a7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839\n",
      "712\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-08T16:50:44.882494Z",
     "start_time": "2024-05-08T16:50:44.461359Z"
    }
   },
   "cell_type": "code",
   "source": [
    "    # Model\n",
    "input_dim = len(amino_acids)\n",
    "output_dim = len(codons)\n",
    "n_hidden = 128\n",
    "\n",
    "rnnModel = RNN(input_size=input_dim, hidden_size=n_hidden, output_size=output_dim, batch_size=batch_size)\n",
    "print(rnnModel)\n",
    "\n",
    "# Train variables\n",
    "epochs = 5\n",
    "learning_rate = 0.001\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = optim.RMSprop(rnnModel.parameters(), lr=learning_rate)"
   ],
   "id": "a7b24cfa4796351c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN(\n",
      "  (i2h): Linear(in_features=22, out_features=128, bias=False)\n",
      "  (h2h): Linear(in_features=128, out_features=128, bias=True)\n",
      "  (h2o): Linear(in_features=128, out_features=65, bias=True)\n",
      "  (softmax): LogSoftmax(dim=1)\n",
      ")\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-08T17:07:44.476803Z",
     "start_time": "2024-05-08T16:50:44.883185Z"
    }
   },
   "cell_type": "code",
   "source": "train(rnnModel, train_loader, epochs, optimizer, loss)",
   "id": "b4146a47e4f268e6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Starting training\n",
      "25%\n",
      "50%\n",
      "75%\n",
      "100%\n",
      "=> epoch: 1, loss: 0.49895545840263367\n",
      "25%\n",
      "50%\n",
      "75%\n",
      "100%\n",
      "=> epoch: 2, loss: 0.4632096588611603\n",
      "25%\n",
      "50%\n",
      "75%\n",
      "100%\n",
      "=> epoch: 3, loss: 0.46253812313079834\n",
      "25%\n",
      "50%\n",
      "75%\n",
      "100%\n",
      "=> epoch: 4, loss: 0.4622006416320801\n",
      "25%\n",
      "50%\n",
      "75%\n",
      "100%\n",
      "=> epoch: 5, loss: 0.4619610905647278\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-08T17:07:44.478810Z",
     "start_time": "2024-05-08T17:07:44.477358Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "8ddfa5af35a9bc1",
   "outputs": [],
   "execution_count": 8
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
