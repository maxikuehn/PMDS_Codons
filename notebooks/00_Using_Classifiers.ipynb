{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the best classifiers of each ML model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload\n",
    "\n",
    "import pandas as pd\n",
    "import sys\n",
    "import torch\n",
    "\n",
    "sys.path.append('../scripts')\n",
    "import ml_helper as mlh\n",
    "import ml_evaluation as mle\n",
    "import Baseline_classifiers as bc\n",
    "import encoder as e\n",
    "import Tcn as tcn\n",
    "import rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "organisms = [\"E.Coli\", \"Drosophila.Melanogaster\", \"Homo.Sapiens\"]\n",
    "models = [\"Max CUB\", \"RNN\", \"Encoder\", \"TCN\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = {}\n",
    "usage_biases = {}\n",
    "\n",
    "def group_codons(sequence):\n",
    "    return [''.join(sequence[i:i+3]) for i in range(0, len(sequence), 3)]\n",
    "\n",
    "for organism in organisms:\n",
    "    dfs[organism] = pd.read_pickle(f\"../data/{organism}/cleanedData_test.pkl\")\n",
    "    dfs[organism]['codons'] = dfs[organism]['sequence'].apply(group_codons)\n",
    "    usage_biases[organism] = pd.read_pickle(f\"../data/{organism}/usageBias.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# amino_sequences as list of lists\n",
    "def predict_codons(amino_sequences, organism, model):\n",
    "    codon_preds = None\n",
    "\n",
    "    if model == \"Max CUB\":\n",
    "        max_weighted_bc = bc.Max_Bias_Baseline_Classifier(usage_biases[organism])\n",
    "        codon_preds = max_weighted_bc.predict_codons(amino_sequences)\n",
    "        codon_preds = codon_preds.tolist()\n",
    "        codon_preds = [[item for item in sublist if item != ''] for sublist in codon_preds]\n",
    "    elif model == \"RNN\":\n",
    "        e.organism = organism\n",
    "        model = mlh.load_model('rnn', organism, device=device)\n",
    "        rnn_classifier = rnn.RNN_Classifier(model)\n",
    "        codon_preds = rnn_classifier.predict_codons(amino_sequences)\n",
    "        new_codon_preds = []\n",
    "        for list in codon_preds:\n",
    "            new_codon_preds.append([mlh.integer_to_codons[pred] for pred in list])\n",
    "        codon_preds = new_codon_preds\n",
    "    elif model == \"Encoder\":\n",
    "        e.organism = organism\n",
    "        model = mlh.load_model('encoder', organism, device=device)\n",
    "        encoder_classifier = e.Encoder_Classifier(model)\n",
    "        codon_preds = encoder_classifier.predict_codons(amino_sequences)\n",
    "        codon_preds = codon_preds.tolist()\n",
    "        codon_preds = [[item for item in sublist if item != ''] for sublist in codon_preds]\n",
    "    elif model == \"TCN\":\n",
    "        e.organism = organism\n",
    "        model = mlh.load_model('tcn', organism, device=device)\n",
    "        tcn_classifier = tcn.Tcn_Classifier(model)\n",
    "        codon_preds = tcn_classifier.predict_codons(amino_sequences)\n",
    "    \n",
    "    return codon_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing on new data\n",
    "- Option 1:\n",
    "    - Run Notebook 01 with the new organism and the new fasta file to receive the needed cleanData file\n",
    "- Option 2:\n",
    "    - Enter the amino sequences manually in this script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1: Use new cleanedData.pkl file\n",
    "new_organism = \"new organism\" # Add name here\n",
    "df_new = pd.read_pickle(f\"../data/{new_organism}/cleanedData.pkl\")\n",
    "\n",
    "amino_sequences = list(df_new['translation'].apply(lambda seq: list(seq)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 2: Define amnio_sequences manually\n",
    "amino_sequences = [\n",
    "    ['M', 'A', 'L'],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_organism = \"E.Coli\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "['ATG', 'GCG', 'CTG']\n"
     ]
    }
   ],
   "source": [
    "max_cub_preds = predict_codons(amino_sequences, trained_organism, \"Max CUB\")\n",
    "print(len(max_cub_preds))\n",
    "print(max_cub_preds[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded: 20240627091800_encoder_64em_2l_4h_05dr_400ep.pt\n",
      "1\n",
      "['ATG', 'GCG', 'CTG']\n"
     ]
    }
   ],
   "source": [
    "enocder_preds = predict_codons(amino_sequences, trained_organism, \"Encoder\")\n",
    "print(len(enocder_preds))\n",
    "print(enocder_preds[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'Tcnn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m tcn_preds \u001b[38;5;241m=\u001b[39m \u001b[43mpredict_codons\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamino_sequences\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrained_organism\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTCN\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(tcn_preds))\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(tcn_preds[\u001b[38;5;241m0\u001b[39m])\n",
      "Cell \u001b[1;32mIn[7], line 24\u001b[0m, in \u001b[0;36mpredict_codons\u001b[1;34m(amino_sequences, organism, model)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m model \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTCN\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     23\u001b[0m     e\u001b[38;5;241m.\u001b[39morganism \u001b[38;5;241m=\u001b[39m organism\n\u001b[1;32m---> 24\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mmlh\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtcn\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morganism\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m     tcn_classifier \u001b[38;5;241m=\u001b[39m tcn\u001b[38;5;241m.\u001b[39mTcn_Classifier(model)\n\u001b[0;32m     26\u001b[0m     codon_preds \u001b[38;5;241m=\u001b[39m tcn_classifier\u001b[38;5;241m.\u001b[39mpredict_codons(amino_sequences)\n",
      "File \u001b[1;32mc:\\Users\\insab\\OneDrive\\_Dokumente\\Studium\\Master\\Vorlesungen\\SS24\\PMDS\\Codons Repo\\notebooks\\../scripts\\ml_helper.py:311\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(model_name, organism, device, get_all, not_relevant, path_model_dir)\u001b[0m\n\u001b[0;32m    309\u001b[0m \u001b[38;5;66;03m# get newest model\u001b[39;00m\n\u001b[0;32m    310\u001b[0m newest_model \u001b[38;5;241m=\u001b[39m models[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m--> 311\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mpath_model_dir\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43morganism\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnot_relevant/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;250;43m \u001b[39;49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[38;5;250;43m \u001b[39;49m\u001b[43mnot_relevant\u001b[49m\u001b[38;5;250;43m \u001b[39;49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[38;5;250;43m \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mnewest_model\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    312\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel loaded: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnewest_model\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    313\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[1;32mc:\\Users\\insab\\anaconda3\\Lib\\site-packages\\torch\\serialization.py:1025\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[0;32m   1023\u001b[0m             \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1024\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError(UNSAFE_MESSAGE \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(e)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1025\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1026\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1027\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1028\u001b[0m \u001b[43m                     \u001b[49m\u001b[43moverall_storage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverall_storage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1029\u001b[0m \u001b[43m                     \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpickle_load_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1030\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mmap:\n\u001b[0;32m   1031\u001b[0m     f_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(f, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\insab\\anaconda3\\Lib\\site-packages\\torch\\serialization.py:1446\u001b[0m, in \u001b[0;36m_load\u001b[1;34m(zip_file, map_location, pickle_module, pickle_file, overall_storage, **pickle_load_args)\u001b[0m\n\u001b[0;32m   1444\u001b[0m unpickler \u001b[38;5;241m=\u001b[39m UnpicklerWrapper(data_file, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args)\n\u001b[0;32m   1445\u001b[0m unpickler\u001b[38;5;241m.\u001b[39mpersistent_load \u001b[38;5;241m=\u001b[39m persistent_load\n\u001b[1;32m-> 1446\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43munpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1448\u001b[0m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_validate_loaded_sparse_tensors()\n\u001b[0;32m   1449\u001b[0m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_log_api_usage_metadata(\n\u001b[0;32m   1450\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch.load.metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mserialization_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: zip_file\u001b[38;5;241m.\u001b[39mserialization_id()}\n\u001b[0;32m   1451\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\insab\\anaconda3\\Lib\\site-packages\\torch\\serialization.py:1439\u001b[0m, in \u001b[0;36m_load.<locals>.UnpicklerWrapper.find_class\u001b[1;34m(self, mod_name, name)\u001b[0m\n\u001b[0;32m   1437\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m   1438\u001b[0m mod_name \u001b[38;5;241m=\u001b[39m load_module_mapping\u001b[38;5;241m.\u001b[39mget(mod_name, mod_name)\n\u001b[1;32m-> 1439\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfind_class(mod_name, name)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'Tcnn'"
     ]
    }
   ],
   "source": [
    "tcn_preds = predict_codons(amino_sequences, trained_organism, \"TCN\")\n",
    "print(len(tcn_preds))\n",
    "print(tcn_preds[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded: 20240521135840_rnn_hidden128_epochs10_lr0.001_optimSGD.pt\n",
      "1\n",
      "['ATG', 'GCG', 'CTG']\n"
     ]
    }
   ],
   "source": [
    "rnn_preds = predict_codons(amino_sequences, trained_organism, \"RNN\")\n",
    "print(len(rnn_preds))\n",
    "print(rnn_preds[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
