{"cells":[{"cell_type":"markdown","metadata":{"id":"dvibukPbQ7Zg"},"source":["# Encoder-only Transformer Architektur"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":5081,"status":"ok","timestamp":1715688676256,"user":{"displayName":"Insa Belter","userId":"09408038895575287386"},"user_tz":-120},"id":"ev_KN7VqQ7Zm"},"outputs":[],"source":["%load_ext autoreload\n","%autoreload\n","\n","import sys\n","import torch\n","from torch.utils.data import DataLoader\n","\n","sys.path.append('../scripts')\n","#sys.path.append('/content/drive/MyDrive/PMDS/Notebooks')\n","import ml_helper as mlh\n","import encoder as e"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1715688676256,"user":{"displayName":"Insa Belter","userId":"09408038895575287386"},"user_tz":-120},"id":"9eRDLHmaS7Im"},"outputs":[{"name":"stdout","output_type":"stream","text":["cuda:1\n"]}],"source":["data_path = '../data'\n","device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n","print(device)"]},{"cell_type":"markdown","metadata":{"id":"6UP5EBpZQ7Zx"},"source":["## Define the encoder-only model"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Länge train_dataset: 3555\n","Länge valid_dataset: 420\n"]}],"source":["e.load_train_valid_data(\"E.Coli\")"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1715688701504,"user":{"displayName":"Insa Belter","userId":"09408038895575287386"},"user_tz":-120},"id":"2u2Dbb0rQ7Zy"},"outputs":[],"source":["EMBED_DIM = 256\n","NUM_ENCODER_LAYERS = 4\n","NUM_HEADS = 4\n","DROP_OUT = 0.2"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1715688702540,"user":{"displayName":"Insa Belter","userId":"09408038895575287386"},"user_tz":-120},"id":"33ksA3YLQ7Zy","outputId":"559e6f1f-4377-402d-fe71-a0adf4a7a70f"},"outputs":[{"name":"stdout","output_type":"stream","text":["EncoderClassifier(\n","  (emb): Embedding(22, 256, padding_idx=21)\n","  (pos_encoder): PositionalEncoding(\n","    (dropout): Dropout(p=0.2, inplace=False)\n","  )\n","  (encoder_layer): TransformerEncoderLayer(\n","    (self_attn): MultiheadAttention(\n","      (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n","    )\n","    (linear1): Linear(in_features=256, out_features=2048, bias=True)\n","    (dropout): Dropout(p=0.1, inplace=False)\n","    (linear2): Linear(in_features=2048, out_features=256, bias=True)\n","    (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","    (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","    (dropout1): Dropout(p=0.1, inplace=False)\n","    (dropout2): Dropout(p=0.1, inplace=False)\n","  )\n","  (encoder): TransformerEncoder(\n","    (layers): ModuleList(\n","      (0-3): 4 x TransformerEncoderLayer(\n","        (self_attn): MultiheadAttention(\n","          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n","        )\n","        (linear1): Linear(in_features=256, out_features=2048, bias=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","        (linear2): Linear(in_features=2048, out_features=256, bias=True)\n","        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","        (dropout1): Dropout(p=0.1, inplace=False)\n","        (dropout2): Dropout(p=0.1, inplace=False)\n","      )\n","    )\n","  )\n","  (linear): Linear(in_features=256, out_features=65, bias=True)\n","  (dropout): Dropout(p=0.2, inplace=False)\n",")\n"]}],"source":["model = e.EncoderClassifier(\n","    embed_dim=EMBED_DIM,\n","    num_layers=NUM_ENCODER_LAYERS,\n","    num_heads=NUM_HEADS,\n","    dropout=DROP_OUT,\n","    pos_enc=True\n",").to(device)\n","print(model)"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1715688702799,"user":{"displayName":"Insa Belter","userId":"09408038895575287386"},"user_tz":-120},"id":"DLRNk1mnQ7Zz"},"outputs":[],"source":["# Total parameters and trainable parameters.\n","def print_parameters(model):\n","    total_params = sum(p.numel() for p in model.parameters())\n","    print(f\"{total_params:,} total parameters.\")\n","    total_trainable_params = sum(\n","        p.numel() for p in model.parameters() if p.requires_grad)\n","    print(f\"{total_trainable_params:,} training parameters.\")"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1715688703433,"user":{"displayName":"Insa Belter","userId":"09408038895575287386"},"user_tz":-120},"id":"Ua_2VN3NQ7Zz","outputId":"472c69d7-94cb-40cd-bd7e-8e1e75c00415"},"outputs":[{"name":"stdout","output_type":"stream","text":["6,597,697 total parameters.\n","6,597,697 training parameters.\n"]}],"source":["print_parameters(model)"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1715688704233,"user":{"displayName":"Insa Belter","userId":"09408038895575287386"},"user_tz":-120},"id":"6SEl0FSxQ7Zz"},"outputs":[],"source":["def test_forward_pass(model, data_loader):\n","  batch_data, batch_label = next(iter(data_loader))\n","  print(f\"input dim: {batch_data.shape}\")\n","  output, attn_weights = model(batch_data, attn_weights_needed=True)\n","  output = model(batch_data)\n","  print(f\"output dim: {output.shape}\")\n","  print(f\"attn_weights dim: {attn_weights}\")"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1152,"status":"ok","timestamp":1715688705880,"user":{"displayName":"Insa Belter","userId":"09408038895575287386"},"user_tz":-120},"id":"X9OgGtB6Q7Z0","outputId":"52e399fa-b185-4c52-c314-91c772f4e98f"},"outputs":[{"name":"stdout","output_type":"stream","text":["input dim: torch.Size([32, 500])\n","output dim: torch.Size([32, 500, 65])\n","attn_weights dim: [tensor([[[[0.0000, 0.0010, 0.0004,  ..., 0.0000, 0.0014, 0.0017],\n","          [0.0015, 0.0000, 0.0020,  ..., 0.0013, 0.0015, 0.0021],\n","          [0.0013, 0.0014, 0.0009,  ..., 0.0011, 0.0008, 0.0019],\n","          ...,\n","          [0.0022, 0.0020, 0.0012,  ..., 0.0023, 0.0023, 0.0024],\n","          [0.0023, 0.0000, 0.0019,  ..., 0.0022, 0.0025, 0.0026],\n","          [0.0024, 0.0016, 0.0000,  ..., 0.0027, 0.0029, 0.0034]],\n","\n","         [[0.0023, 0.0030, 0.0039,  ..., 0.0025, 0.0016, 0.0018],\n","          [0.0018, 0.0227, 0.0129,  ..., 0.0026, 0.0030, 0.0024],\n","          [0.0019, 0.0000, 0.0000,  ..., 0.0000, 0.0032, 0.0018],\n","          ...,\n","          [0.0011, 0.0037, 0.0030,  ..., 0.0028, 0.0026, 0.0000],\n","          [0.0010, 0.0050, 0.0030,  ..., 0.0023, 0.0020, 0.0024],\n","          [0.0015, 0.0028, 0.0014,  ..., 0.0028, 0.0018, 0.0023]],\n","\n","         [[0.0026, 0.0013, 0.0000,  ..., 0.0010, 0.0016, 0.0000],\n","          [0.0011, 0.0028, 0.0032,  ..., 0.0011, 0.0010, 0.0010],\n","          [0.0011, 0.0014, 0.0013,  ..., 0.0018, 0.0018, 0.0018],\n","          ...,\n","          [0.0029, 0.0012, 0.0020,  ..., 0.0011, 0.0013, 0.0014],\n","          [0.0027, 0.0015, 0.0021,  ..., 0.0015, 0.0016, 0.0021],\n","          [0.0022, 0.0012, 0.0000,  ..., 0.0011, 0.0013, 0.0017]],\n","\n","         [[0.0023, 0.0009, 0.0008,  ..., 0.0014, 0.0026, 0.0016],\n","          [0.0007, 0.0004, 0.0005,  ..., 0.0011, 0.0016, 0.0019],\n","          [0.0006, 0.0000, 0.0007,  ..., 0.0018, 0.0025, 0.0029],\n","          ...,\n","          [0.0044, 0.0028, 0.0014,  ..., 0.0000, 0.0031, 0.0028],\n","          [0.0025, 0.0046, 0.0026,  ..., 0.0016, 0.0023, 0.0020],\n","          [0.0019, 0.0026, 0.0013,  ..., 0.0000, 0.0029, 0.0023]]],\n","\n","\n","        [[[0.0026, 0.0013, 0.0022,  ..., 0.0016, 0.0021, 0.0023],\n","          [0.0006, 0.0079, 0.0012,  ..., 0.0005, 0.0016, 0.0024],\n","          [0.0035, 0.0044, 0.0010,  ..., 0.0019, 0.0018, 0.0032],\n","          ...,\n","          [0.0017, 0.0021, 0.0000,  ..., 0.0000, 0.0017, 0.0020],\n","          [0.0023, 0.0024, 0.0051,  ..., 0.0022, 0.0028, 0.0027],\n","          [0.0026, 0.0044, 0.0031,  ..., 0.0019, 0.0029, 0.0031]],\n","\n","         [[0.0010, 0.0069, 0.0015,  ..., 0.0032, 0.0026, 0.0022],\n","          [0.0029, 0.0044, 0.0013,  ..., 0.0019, 0.0025, 0.0000],\n","          [0.0010, 0.0024, 0.0027,  ..., 0.0019, 0.0040, 0.0034],\n","          ...,\n","          [0.0014, 0.0035, 0.0000,  ..., 0.0000, 0.0024, 0.0021],\n","          [0.0019, 0.0040, 0.0038,  ..., 0.0021, 0.0000, 0.0021],\n","          [0.0009, 0.0028, 0.0038,  ..., 0.0014, 0.0019, 0.0017]],\n","\n","         [[0.0044, 0.0121, 0.0011,  ..., 0.0012, 0.0032, 0.0024],\n","          [0.0000, 0.0000, 0.0004,  ..., 0.0018, 0.0027, 0.0025],\n","          [0.0000, 0.0054, 0.0017,  ..., 0.0012, 0.0015, 0.0020],\n","          ...,\n","          [0.0045, 0.0046, 0.0023,  ..., 0.0014, 0.0016, 0.0000],\n","          [0.0024, 0.0041, 0.0011,  ..., 0.0014, 0.0000, 0.0000],\n","          [0.0031, 0.0031, 0.0025,  ..., 0.0000, 0.0000, 0.0021]],\n","\n","         [[0.0015, 0.0052, 0.0011,  ..., 0.0028, 0.0025, 0.0018],\n","          [0.0010, 0.0003, 0.0000,  ..., 0.0017, 0.0012, 0.0009],\n","          [0.0025, 0.0010, 0.0017,  ..., 0.0033, 0.0039, 0.0036],\n","          ...,\n","          [0.0024, 0.0018, 0.0010,  ..., 0.0017, 0.0024, 0.0022],\n","          [0.0000, 0.0009, 0.0009,  ..., 0.0022, 0.0000, 0.0019],\n","          [0.0024, 0.0012, 0.0011,  ..., 0.0018, 0.0019, 0.0017]]],\n","\n","\n","        [[[0.0022, 0.0000, 0.0011,  ..., 0.0013, 0.0015, 0.0020],\n","          [0.0005, 0.0208, 0.0011,  ..., 0.0010, 0.0010, 0.0015],\n","          [0.0016, 0.0062, 0.0064,  ..., 0.0029, 0.0000, 0.0019],\n","          ...,\n","          [0.0039, 0.0028, 0.0037,  ..., 0.0023, 0.0023, 0.0031],\n","          [0.0028, 0.0032, 0.0042,  ..., 0.0025, 0.0023, 0.0000],\n","          [0.0026, 0.0025, 0.0040,  ..., 0.0024, 0.0021, 0.0030]],\n","\n","         [[0.0042, 0.0008, 0.0023,  ..., 0.0028, 0.0021, 0.0029],\n","          [0.0031, 0.0017, 0.0010,  ..., 0.0025, 0.0023, 0.0030],\n","          [0.0077, 0.0045, 0.0064,  ..., 0.0015, 0.0015, 0.0011],\n","          ...,\n","          [0.0011, 0.0035, 0.0005,  ..., 0.0021, 0.0021, 0.0022],\n","          [0.0013, 0.0034, 0.0007,  ..., 0.0022, 0.0023, 0.0025],\n","          [0.0017, 0.0034, 0.0008,  ..., 0.0022, 0.0023, 0.0026]],\n","\n","         [[0.0038, 0.0115, 0.0020,  ..., 0.0023, 0.0000, 0.0033],\n","          [0.0023, 0.0031, 0.0003,  ..., 0.0018, 0.0015, 0.0000],\n","          [0.0008, 0.0059, 0.0000,  ..., 0.0010, 0.0008, 0.0008],\n","          ...,\n","          [0.0012, 0.0030, 0.0015,  ..., 0.0015, 0.0012, 0.0019],\n","          [0.0015, 0.0000, 0.0010,  ..., 0.0018, 0.0015, 0.0019],\n","          [0.0016, 0.0011, 0.0008,  ..., 0.0015, 0.0011, 0.0017]],\n","\n","         [[0.0022, 0.0033, 0.0021,  ..., 0.0014, 0.0000, 0.0025],\n","          [0.0179, 0.0005, 0.0027,  ..., 0.0000, 0.0019, 0.0013],\n","          [0.0000, 0.0032, 0.0048,  ..., 0.0023, 0.0017, 0.0016],\n","          ...,\n","          [0.0044, 0.0021, 0.0022,  ..., 0.0021, 0.0019, 0.0022],\n","          [0.0026, 0.0000, 0.0011,  ..., 0.0014, 0.0015, 0.0013],\n","          [0.0022, 0.0009, 0.0013,  ..., 0.0013, 0.0016, 0.0015]]],\n","\n","\n","        ...,\n","\n","\n","        [[[0.0057, 0.0015, 0.0007,  ..., 0.0004, 0.0012, 0.0005],\n","          [0.0026, 0.0013, 0.0034,  ..., 0.0010, 0.0020, 0.0011],\n","          [0.0000, 0.0041, 0.0026,  ..., 0.0020, 0.0003, 0.0015],\n","          ...,\n","          [0.0030, 0.0026, 0.0058,  ..., 0.0052, 0.0011, 0.0012],\n","          [0.0026, 0.0015, 0.0042,  ..., 0.0017, 0.0018, 0.0046],\n","          [0.0042, 0.0006, 0.0027,  ..., 0.0027, 0.0027, 0.0000]],\n","\n","         [[0.0000, 0.0016, 0.0020,  ..., 0.0052, 0.0017, 0.0000],\n","          [0.0012, 0.0070, 0.0009,  ..., 0.0046, 0.0035, 0.0000],\n","          [0.0029, 0.0024, 0.0066,  ..., 0.0048, 0.0008, 0.0072],\n","          ...,\n","          [0.0010, 0.0033, 0.0000,  ..., 0.0026, 0.0034, 0.0045],\n","          [0.0005, 0.0005, 0.0015,  ..., 0.0027, 0.0071, 0.0035],\n","          [0.0012, 0.0061, 0.0031,  ..., 0.0016, 0.0014, 0.0000]],\n","\n","         [[0.0021, 0.0002, 0.0011,  ..., 0.0007, 0.0014, 0.0015],\n","          [0.0006, 0.0012, 0.0030,  ..., 0.0016, 0.0011, 0.0012],\n","          [0.0019, 0.0041, 0.0000,  ..., 0.0006, 0.0003, 0.0014],\n","          ...,\n","          [0.0023, 0.0012, 0.0012,  ..., 0.0019, 0.0007, 0.0004],\n","          [0.0017, 0.0009, 0.0018,  ..., 0.0014, 0.0005, 0.0013],\n","          [0.0038, 0.0004, 0.0004,  ..., 0.0007, 0.0008, 0.0002]],\n","\n","         [[0.0137, 0.0006, 0.0003,  ..., 0.0004, 0.0016, 0.0009],\n","          [0.0029, 0.0022, 0.0025,  ..., 0.0067, 0.0007, 0.0000],\n","          [0.0006, 0.0006, 0.0008,  ..., 0.0015, 0.0009, 0.0029],\n","          ...,\n","          [0.0006, 0.0003, 0.0010,  ..., 0.0006, 0.0005, 0.0023],\n","          [0.0010, 0.0003, 0.0033,  ..., 0.0016, 0.0005, 0.0005],\n","          [0.0015, 0.0007, 0.0019,  ..., 0.0027, 0.0010, 0.0016]]],\n","\n","\n","        [[[0.0170, 0.0015, 0.0027,  ..., 0.0022, 0.0036, 0.0024],\n","          [0.0038, 0.0009, 0.0025,  ..., 0.0019, 0.0034, 0.0028],\n","          [0.0036, 0.0008, 0.0020,  ..., 0.0030, 0.0000, 0.0024],\n","          ...,\n","          [0.0000, 0.0006, 0.0019,  ..., 0.0023, 0.0000, 0.0000],\n","          [0.0027, 0.0011, 0.0017,  ..., 0.0027, 0.0032, 0.0030],\n","          [0.0025, 0.0015, 0.0047,  ..., 0.0023, 0.0026, 0.0028]],\n","\n","         [[0.0020, 0.0018, 0.0017,  ..., 0.0026, 0.0020, 0.0018],\n","          [0.0018, 0.0012, 0.0013,  ..., 0.0015, 0.0021, 0.0000],\n","          [0.0062, 0.0011, 0.0107,  ..., 0.0000, 0.0030, 0.0023],\n","          ...,\n","          [0.0000, 0.0025, 0.0010,  ..., 0.0032, 0.0022, 0.0024],\n","          [0.0017, 0.0026, 0.0007,  ..., 0.0027, 0.0000, 0.0023],\n","          [0.0025, 0.0034, 0.0015,  ..., 0.0023, 0.0023, 0.0020]],\n","\n","         [[0.0091, 0.0024, 0.0020,  ..., 0.0000, 0.0024, 0.0028],\n","          [0.0008, 0.0011, 0.0007,  ..., 0.0018, 0.0023, 0.0017],\n","          [0.0000, 0.0007, 0.0005,  ..., 0.0000, 0.0009, 0.0013],\n","          ...,\n","          [0.0019, 0.0017, 0.0000,  ..., 0.0014, 0.0022, 0.0000],\n","          [0.0020, 0.0000, 0.0011,  ..., 0.0017, 0.0025, 0.0022],\n","          [0.0023, 0.0031, 0.0019,  ..., 0.0015, 0.0021, 0.0018]],\n","\n","         [[0.0035, 0.0020, 0.0017,  ..., 0.0015, 0.0025, 0.0000],\n","          [0.0017, 0.0025, 0.0007,  ..., 0.0014, 0.0011, 0.0008],\n","          [0.0134, 0.0016, 0.0030,  ..., 0.0017, 0.0029, 0.0030],\n","          ...,\n","          [0.0036, 0.0014, 0.0000,  ..., 0.0021, 0.0017, 0.0019],\n","          [0.0032, 0.0014, 0.0000,  ..., 0.0021, 0.0000, 0.0014],\n","          [0.0037, 0.0012, 0.0019,  ..., 0.0016, 0.0000, 0.0012]]],\n","\n","\n","        [[[0.0050, 0.0010, 0.0036,  ..., 0.0013, 0.0014, 0.0015],\n","          [0.0000, 0.0005, 0.0007,  ..., 0.0016, 0.0018, 0.0014],\n","          [0.0020, 0.0003, 0.0018,  ..., 0.0022, 0.0017, 0.0012],\n","          ...,\n","          [0.0031, 0.0010, 0.0019,  ..., 0.0030, 0.0031, 0.0030],\n","          [0.0030, 0.0009, 0.0015,  ..., 0.0026, 0.0026, 0.0000],\n","          [0.0040, 0.0011, 0.0019,  ..., 0.0037, 0.0037, 0.0041]],\n","\n","         [[0.0017, 0.0018, 0.0006,  ..., 0.0024, 0.0019, 0.0020],\n","          [0.0020, 0.0010, 0.0011,  ..., 0.0026, 0.0041, 0.0038],\n","          [0.0031, 0.0017, 0.0017,  ..., 0.0023, 0.0022, 0.0000],\n","          ...,\n","          [0.0018, 0.0020, 0.0021,  ..., 0.0000, 0.0000, 0.0031],\n","          [0.0012, 0.0020, 0.0031,  ..., 0.0017, 0.0018, 0.0028],\n","          [0.0000, 0.0015, 0.0039,  ..., 0.0018, 0.0016, 0.0029]],\n","\n","         [[0.0027, 0.0015, 0.0078,  ..., 0.0025, 0.0032, 0.0024],\n","          [0.0017, 0.0025, 0.0027,  ..., 0.0020, 0.0030, 0.0026],\n","          [0.0016, 0.0009, 0.0022,  ..., 0.0014, 0.0013, 0.0010],\n","          ...,\n","          [0.0036, 0.0013, 0.0121,  ..., 0.0013, 0.0014, 0.0000],\n","          [0.0018, 0.0016, 0.0081,  ..., 0.0000, 0.0014, 0.0017],\n","          [0.0000, 0.0012, 0.0065,  ..., 0.0014, 0.0015, 0.0022]],\n","\n","         [[0.0000, 0.0021, 0.0024,  ..., 0.0019, 0.0023, 0.0012],\n","          [0.0007, 0.0021, 0.0000,  ..., 0.0037, 0.0000, 0.0020],\n","          [0.0028, 0.0032, 0.0006,  ..., 0.0041, 0.0000, 0.0018],\n","          ...,\n","          [0.0023, 0.0015, 0.0013,  ..., 0.0029, 0.0025, 0.0028],\n","          [0.0022, 0.0026, 0.0015,  ..., 0.0023, 0.0018, 0.0019],\n","          [0.0012, 0.0013, 0.0007,  ..., 0.0000, 0.0016, 0.0021]]]],\n","       device='cuda:1', grad_fn=<ViewBackward0>), tensor([[[[0.0027, 0.0014, 0.0009,  ..., 0.0012, 0.0000, 0.0010],\n","          [0.0000, 0.0037, 0.0020,  ..., 0.0009, 0.0013, 0.0015],\n","          [0.0020, 0.0018, 0.0014,  ..., 0.0010, 0.0012, 0.0018],\n","          ...,\n","          [0.0020, 0.0017, 0.0011,  ..., 0.0020, 0.0016, 0.0016],\n","          [0.0021, 0.0024, 0.0022,  ..., 0.0016, 0.0018, 0.0000],\n","          [0.0018, 0.0015, 0.0017,  ..., 0.0022, 0.0019, 0.0025]],\n","\n","         [[0.0020, 0.0000, 0.0026,  ..., 0.0025, 0.0022, 0.0018],\n","          [0.0012, 0.0090, 0.0050,  ..., 0.0029, 0.0038, 0.0025],\n","          [0.0015, 0.0052, 0.0000,  ..., 0.0030, 0.0041, 0.0025],\n","          ...,\n","          [0.0007, 0.0031, 0.0028,  ..., 0.0034, 0.0034, 0.0031],\n","          [0.0006, 0.0053, 0.0033,  ..., 0.0030, 0.0029, 0.0000],\n","          [0.0009, 0.0025, 0.0014,  ..., 0.0033, 0.0017, 0.0023]],\n","\n","         [[0.0028, 0.0021, 0.0017,  ..., 0.0014, 0.0015, 0.0011],\n","          [0.0022, 0.0000, 0.0000,  ..., 0.0000, 0.0020, 0.0028],\n","          [0.0024, 0.0024, 0.0020,  ..., 0.0028, 0.0028, 0.0040],\n","          ...,\n","          [0.0038, 0.0013, 0.0017,  ..., 0.0011, 0.0010, 0.0017],\n","          [0.0026, 0.0000, 0.0021,  ..., 0.0018, 0.0016, 0.0042],\n","          [0.0027, 0.0014, 0.0017,  ..., 0.0011, 0.0013, 0.0031]],\n","\n","         [[0.0018, 0.0012, 0.0013,  ..., 0.0015, 0.0032, 0.0018],\n","          [0.0009, 0.0009, 0.0011,  ..., 0.0015, 0.0022, 0.0020],\n","          [0.0006, 0.0000, 0.0012,  ..., 0.0025, 0.0033, 0.0027],\n","          ...,\n","          [0.0032, 0.0029, 0.0017,  ..., 0.0039, 0.0049, 0.0034],\n","          [0.0021, 0.0038, 0.0026,  ..., 0.0023, 0.0036, 0.0021],\n","          [0.0019, 0.0019, 0.0010,  ..., 0.0000, 0.0042, 0.0024]]],\n","\n","\n","        [[[0.0019, 0.0000, 0.0021,  ..., 0.0008, 0.0012, 0.0014],\n","          [0.0014, 0.0070, 0.0018,  ..., 0.0003, 0.0010, 0.0014],\n","          [0.0029, 0.0027, 0.0000,  ..., 0.0012, 0.0015, 0.0029],\n","          ...,\n","          [0.0014, 0.0016, 0.0017,  ..., 0.0009, 0.0000, 0.0013],\n","          [0.0019, 0.0018, 0.0037,  ..., 0.0000, 0.0022, 0.0000],\n","          [0.0017, 0.0035, 0.0022,  ..., 0.0007, 0.0000, 0.0000]],\n","\n","         [[0.0000, 0.0028, 0.0011,  ..., 0.0036, 0.0026, 0.0021],\n","          [0.0016, 0.0000, 0.0012,  ..., 0.0023, 0.0031, 0.0025],\n","          [0.0010, 0.0023, 0.0017,  ..., 0.0015, 0.0034, 0.0022],\n","          ...,\n","          [0.0006, 0.0000, 0.0011,  ..., 0.0023, 0.0028, 0.0027],\n","          [0.0010, 0.0026, 0.0022,  ..., 0.0026, 0.0030, 0.0023],\n","          [0.0004, 0.0022, 0.0020,  ..., 0.0016, 0.0023, 0.0000]],\n","\n","         [[0.0024, 0.0052, 0.0025,  ..., 0.0014, 0.0041, 0.0027],\n","          [0.0039, 0.0016, 0.0013,  ..., 0.0021, 0.0022, 0.0034],\n","          [0.0018, 0.0038, 0.0023,  ..., 0.0012, 0.0012, 0.0019],\n","          ...,\n","          [0.0048, 0.0030, 0.0000,  ..., 0.0012, 0.0018, 0.0033],\n","          [0.0026, 0.0025, 0.0010,  ..., 0.0012, 0.0018, 0.0033],\n","          [0.0033, 0.0017, 0.0000,  ..., 0.0014, 0.0014, 0.0029]],\n","\n","         [[0.0000, 0.0033, 0.0012,  ..., 0.0025, 0.0016, 0.0015],\n","          [0.0016, 0.0008, 0.0015,  ..., 0.0012, 0.0008, 0.0011],\n","          [0.0029, 0.0014, 0.0018,  ..., 0.0027, 0.0024, 0.0027],\n","          ...,\n","          [0.0018, 0.0000, 0.0006,  ..., 0.0014, 0.0023, 0.0026],\n","          [0.0016, 0.0010, 0.0007,  ..., 0.0019, 0.0000, 0.0022],\n","          [0.0020, 0.0011, 0.0010,  ..., 0.0016, 0.0017, 0.0019]]],\n","\n","\n","        [[[0.0021, 0.0034, 0.0012,  ..., 0.0009, 0.0010, 0.0023],\n","          [0.0010, 0.0111, 0.0015,  ..., 0.0009, 0.0007, 0.0014],\n","          [0.0019, 0.0045, 0.0033,  ..., 0.0019, 0.0011, 0.0018],\n","          ...,\n","          [0.0042, 0.0021, 0.0037,  ..., 0.0017, 0.0013, 0.0031],\n","          [0.0021, 0.0026, 0.0041,  ..., 0.0018, 0.0012, 0.0022],\n","          [0.0028, 0.0029, 0.0036,  ..., 0.0000, 0.0009, 0.0024]],\n","\n","         [[0.0000, 0.0010, 0.0023,  ..., 0.0034, 0.0022, 0.0034],\n","          [0.0015, 0.0015, 0.0016,  ..., 0.0000, 0.0029, 0.0034],\n","          [0.0000, 0.0038, 0.0038,  ..., 0.0017, 0.0015, 0.0011],\n","          ...,\n","          [0.0006, 0.0025, 0.0008,  ..., 0.0024, 0.0020, 0.0027],\n","          [0.0007, 0.0026, 0.0011,  ..., 0.0022, 0.0022, 0.0026],\n","          [0.0006, 0.0025, 0.0010,  ..., 0.0026, 0.0027, 0.0036]],\n","\n","         [[0.0032, 0.0055, 0.0000,  ..., 0.0021, 0.0019, 0.0000],\n","          [0.0037, 0.0032, 0.0013,  ..., 0.0016, 0.0000, 0.0028],\n","          [0.0016, 0.0000, 0.0012,  ..., 0.0010, 0.0010, 0.0000],\n","          ...,\n","          [0.0000, 0.0000, 0.0018,  ..., 0.0012, 0.0009, 0.0021],\n","          [0.0016, 0.0015, 0.0011,  ..., 0.0015, 0.0011, 0.0017],\n","          [0.0020, 0.0007, 0.0008,  ..., 0.0013, 0.0007, 0.0016]],\n","\n","         [[0.0020, 0.0018, 0.0016,  ..., 0.0009, 0.0014, 0.0021],\n","          [0.0050, 0.0011, 0.0027,  ..., 0.0014, 0.0016, 0.0011],\n","          [0.0069, 0.0038, 0.0064,  ..., 0.0028, 0.0017, 0.0014],\n","          ...,\n","          [0.0035, 0.0016, 0.0016,  ..., 0.0016, 0.0013, 0.0020],\n","          [0.0022, 0.0009, 0.0011,  ..., 0.0011, 0.0012, 0.0012],\n","          [0.0018, 0.0005, 0.0009,  ..., 0.0011, 0.0014, 0.0017]]],\n","\n","\n","        ...,\n","\n","\n","        [[[0.0033, 0.0021, 0.0011,  ..., 0.0009, 0.0016, 0.0009],\n","          [0.0021, 0.0012, 0.0030,  ..., 0.0011, 0.0022, 0.0014],\n","          [0.0015, 0.0037, 0.0028,  ..., 0.0016, 0.0010, 0.0018],\n","          ...,\n","          [0.0023, 0.0024, 0.0052,  ..., 0.0000, 0.0019, 0.0017],\n","          [0.0023, 0.0020, 0.0034,  ..., 0.0019, 0.0017, 0.0029],\n","          [0.0000, 0.0012, 0.0026,  ..., 0.0016, 0.0025, 0.0059]],\n","\n","         [[0.0013, 0.0015, 0.0014,  ..., 0.0031, 0.0029, 0.0017],\n","          [0.0013, 0.0036, 0.0012,  ..., 0.0027, 0.0029, 0.0020],\n","          [0.0019, 0.0019, 0.0033,  ..., 0.0030, 0.0018, 0.0044],\n","          ...,\n","          [0.0013, 0.0000, 0.0013,  ..., 0.0023, 0.0028, 0.0000],\n","          [0.0000, 0.0010, 0.0022,  ..., 0.0034, 0.0039, 0.0035],\n","          [0.0013, 0.0036, 0.0026,  ..., 0.0019, 0.0014, 0.0025]],\n","\n","         [[0.0021, 0.0008, 0.0014,  ..., 0.0016, 0.0023, 0.0021],\n","          [0.0012, 0.0019, 0.0026,  ..., 0.0029, 0.0000, 0.0000],\n","          [0.0034, 0.0054, 0.0041,  ..., 0.0015, 0.0011, 0.0023],\n","          ...,\n","          [0.0028, 0.0015, 0.0016,  ..., 0.0000, 0.0016, 0.0009],\n","          [0.0017, 0.0018, 0.0017,  ..., 0.0021, 0.0016, 0.0014],\n","          [0.0047, 0.0012, 0.0000,  ..., 0.0022, 0.0027, 0.0008]],\n","\n","         [[0.0000, 0.0009, 0.0000,  ..., 0.0007, 0.0018, 0.0008],\n","          [0.0026, 0.0019, 0.0000,  ..., 0.0038, 0.0019, 0.0029],\n","          [0.0008, 0.0008, 0.0014,  ..., 0.0000, 0.0014, 0.0021],\n","          ...,\n","          [0.0009, 0.0007, 0.0018,  ..., 0.0011, 0.0013, 0.0020],\n","          [0.0015, 0.0008, 0.0031,  ..., 0.0025, 0.0016, 0.0012],\n","          [0.0000, 0.0011, 0.0022,  ..., 0.0025, 0.0017, 0.0017]]],\n","\n","\n","        [[[0.0054, 0.0021, 0.0018,  ..., 0.0012, 0.0022, 0.0020],\n","          [0.0023, 0.0020, 0.0000,  ..., 0.0011, 0.0021, 0.0024],\n","          [0.0025, 0.0017, 0.0017,  ..., 0.0000, 0.0000, 0.0015],\n","          ...,\n","          [0.0023, 0.0008, 0.0017,  ..., 0.0013, 0.0015, 0.0018],\n","          [0.0027, 0.0014, 0.0015,  ..., 0.0015, 0.0021, 0.0025],\n","          [0.0025, 0.0016, 0.0039,  ..., 0.0012, 0.0018, 0.0026]],\n","\n","         [[0.0017, 0.0021, 0.0032,  ..., 0.0030, 0.0019, 0.0019],\n","          [0.0017, 0.0015, 0.0018,  ..., 0.0016, 0.0019, 0.0031],\n","          [0.0035, 0.0017, 0.0044,  ..., 0.0028, 0.0027, 0.0023],\n","          ...,\n","          [0.0006, 0.0020, 0.0012,  ..., 0.0037, 0.0019, 0.0023],\n","          [0.0009, 0.0016, 0.0000,  ..., 0.0036, 0.0016, 0.0000],\n","          [0.0015, 0.0026, 0.0022,  ..., 0.0026, 0.0019, 0.0018]],\n","\n","         [[0.0041, 0.0037, 0.0023,  ..., 0.0019, 0.0018, 0.0029],\n","          [0.0014, 0.0021, 0.0011,  ..., 0.0020, 0.0020, 0.0020],\n","          [0.0014, 0.0000, 0.0011,  ..., 0.0016, 0.0010, 0.0014],\n","          ...,\n","          [0.0016, 0.0016, 0.0016,  ..., 0.0013, 0.0020, 0.0013],\n","          [0.0016, 0.0022, 0.0011,  ..., 0.0014, 0.0021, 0.0022],\n","          [0.0023, 0.0029, 0.0021,  ..., 0.0013, 0.0000, 0.0018]],\n","\n","         [[0.0022, 0.0015, 0.0015,  ..., 0.0012, 0.0000, 0.0030],\n","          [0.0016, 0.0023, 0.0011,  ..., 0.0012, 0.0010, 0.0008],\n","          [0.0101, 0.0021, 0.0051,  ..., 0.0012, 0.0025, 0.0025],\n","          ...,\n","          [0.0024, 0.0011, 0.0018,  ..., 0.0018, 0.0013, 0.0018],\n","          [0.0022, 0.0013, 0.0016,  ..., 0.0017, 0.0000, 0.0010],\n","          [0.0024, 0.0011, 0.0020,  ..., 0.0014, 0.0008, 0.0010]]],\n","\n","\n","        [[[0.0036, 0.0030, 0.0043,  ..., 0.0009, 0.0012, 0.0010],\n","          [0.0000, 0.0019, 0.0012,  ..., 0.0013, 0.0017, 0.0009],\n","          [0.0018, 0.0022, 0.0024,  ..., 0.0012, 0.0012, 0.0007],\n","          ...,\n","          [0.0029, 0.0015, 0.0023,  ..., 0.0022, 0.0000, 0.0031],\n","          [0.0025, 0.0017, 0.0018,  ..., 0.0018, 0.0020, 0.0018],\n","          [0.0028, 0.0019, 0.0020,  ..., 0.0028, 0.0037, 0.0039]],\n","\n","         [[0.0014, 0.0020, 0.0006,  ..., 0.0030, 0.0024, 0.0024],\n","          [0.0018, 0.0014, 0.0009,  ..., 0.0025, 0.0033, 0.0037],\n","          [0.0027, 0.0022, 0.0017,  ..., 0.0000, 0.0016, 0.0013],\n","          ...,\n","          [0.0000, 0.0021, 0.0016,  ..., 0.0019, 0.0015, 0.0000],\n","          [0.0006, 0.0021, 0.0016,  ..., 0.0017, 0.0018, 0.0044],\n","          [0.0007, 0.0012, 0.0020,  ..., 0.0019, 0.0016, 0.0053]],\n","\n","         [[0.0024, 0.0021, 0.0032,  ..., 0.0025, 0.0036, 0.0027],\n","          [0.0020, 0.0029, 0.0014,  ..., 0.0018, 0.0026, 0.0025],\n","          [0.0000, 0.0000, 0.0017,  ..., 0.0021, 0.0017, 0.0015],\n","          ...,\n","          [0.0050, 0.0014, 0.0071,  ..., 0.0012, 0.0000, 0.0023],\n","          [0.0028, 0.0017, 0.0062,  ..., 0.0013, 0.0012, 0.0020],\n","          [0.0041, 0.0013, 0.0044,  ..., 0.0014, 0.0013, 0.0027]],\n","\n","         [[0.0000, 0.0018, 0.0020,  ..., 0.0016, 0.0020, 0.0012],\n","          [0.0013, 0.0025, 0.0022,  ..., 0.0025, 0.0026, 0.0021],\n","          [0.0025, 0.0028, 0.0013,  ..., 0.0025, 0.0025, 0.0016],\n","          ...,\n","          [0.0025, 0.0011, 0.0013,  ..., 0.0034, 0.0031, 0.0000],\n","          [0.0025, 0.0017, 0.0014,  ..., 0.0023, 0.0017, 0.0023],\n","          [0.0013, 0.0009, 0.0009,  ..., 0.0028, 0.0017, 0.0031]]]],\n","       device='cuda:1', grad_fn=<ViewBackward0>), tensor([[[[0.0027, 0.0014, 0.0014,  ..., 0.0010, 0.0011, 0.0008],\n","          [0.0017, 0.0000, 0.0019,  ..., 0.0000, 0.0016, 0.0014],\n","          [0.0023, 0.0017, 0.0014,  ..., 0.0011, 0.0016, 0.0017],\n","          ...,\n","          [0.0016, 0.0017, 0.0014,  ..., 0.0016, 0.0015, 0.0013],\n","          [0.0018, 0.0025, 0.0028,  ..., 0.0000, 0.0013, 0.0014],\n","          [0.0013, 0.0016, 0.0024,  ..., 0.0016, 0.0013, 0.0015]],\n","\n","         [[0.0017, 0.0017, 0.0000,  ..., 0.0000, 0.0024, 0.0026],\n","          [0.0013, 0.0063, 0.0044,  ..., 0.0031, 0.0036, 0.0033],\n","          [0.0013, 0.0051, 0.0026,  ..., 0.0035, 0.0037, 0.0030],\n","          ...,\n","          [0.0007, 0.0027, 0.0029,  ..., 0.0043, 0.0000, 0.0042],\n","          [0.0000, 0.0039, 0.0037,  ..., 0.0036, 0.0033, 0.0046],\n","          [0.0007, 0.0025, 0.0018,  ..., 0.0035, 0.0018, 0.0027]],\n","\n","         [[0.0023, 0.0023, 0.0018,  ..., 0.0016, 0.0011, 0.0000],\n","          [0.0029, 0.0038, 0.0030,  ..., 0.0000, 0.0018, 0.0031],\n","          [0.0031, 0.0028, 0.0022,  ..., 0.0025, 0.0000, 0.0037],\n","          ...,\n","          [0.0040, 0.0016, 0.0014,  ..., 0.0015, 0.0013, 0.0018],\n","          [0.0025, 0.0000, 0.0018,  ..., 0.0023, 0.0020, 0.0039],\n","          [0.0029, 0.0017, 0.0015,  ..., 0.0016, 0.0017, 0.0032]],\n","\n","         [[0.0018, 0.0015, 0.0013,  ..., 0.0019, 0.0029, 0.0022],\n","          [0.0010, 0.0014, 0.0013,  ..., 0.0023, 0.0027, 0.0023],\n","          [0.0006, 0.0011, 0.0013,  ..., 0.0034, 0.0039, 0.0030],\n","          ...,\n","          [0.0025, 0.0024, 0.0017,  ..., 0.0051, 0.0047, 0.0041],\n","          [0.0018, 0.0000, 0.0021,  ..., 0.0037, 0.0040, 0.0029],\n","          [0.0018, 0.0016, 0.0009,  ..., 0.0042, 0.0050, 0.0033]]],\n","\n","\n","        [[[0.0014, 0.0015, 0.0018,  ..., 0.0009, 0.0010, 0.0011],\n","          [0.0012, 0.0056, 0.0000,  ..., 0.0004, 0.0008, 0.0007],\n","          [0.0024, 0.0024, 0.0010,  ..., 0.0011, 0.0010, 0.0021],\n","          ...,\n","          [0.0012, 0.0014, 0.0014,  ..., 0.0000, 0.0009, 0.0008],\n","          [0.0016, 0.0015, 0.0000,  ..., 0.0008, 0.0015, 0.0010],\n","          [0.0014, 0.0027, 0.0016,  ..., 0.0006, 0.0013, 0.0012]],\n","\n","         [[0.0008, 0.0021, 0.0000,  ..., 0.0042, 0.0033, 0.0026],\n","          [0.0012, 0.0015, 0.0012,  ..., 0.0032, 0.0040, 0.0030],\n","          [0.0000, 0.0024, 0.0016,  ..., 0.0018, 0.0034, 0.0019],\n","          ...,\n","          [0.0006, 0.0000, 0.0011,  ..., 0.0033, 0.0034, 0.0034],\n","          [0.0008, 0.0021, 0.0015,  ..., 0.0044, 0.0035, 0.0032],\n","          [0.0004, 0.0019, 0.0014,  ..., 0.0029, 0.0026, 0.0032]],\n","\n","         [[0.0022, 0.0052, 0.0029,  ..., 0.0015, 0.0037, 0.0019],\n","          [0.0035, 0.0000, 0.0011,  ..., 0.0022, 0.0018, 0.0000],\n","          [0.0023, 0.0032, 0.0024,  ..., 0.0014, 0.0000, 0.0019],\n","          ...,\n","          [0.0051, 0.0029, 0.0023,  ..., 0.0016, 0.0018, 0.0037],\n","          [0.0028, 0.0025, 0.0012,  ..., 0.0018, 0.0018, 0.0038],\n","          [0.0040, 0.0019, 0.0019,  ..., 0.0019, 0.0017, 0.0027]],\n","\n","         [[0.0023, 0.0029, 0.0011,  ..., 0.0029, 0.0000, 0.0000],\n","          [0.0000, 0.0012, 0.0014,  ..., 0.0013, 0.0011, 0.0016],\n","          [0.0023, 0.0015, 0.0017,  ..., 0.0026, 0.0022, 0.0026],\n","          ...,\n","          [0.0017, 0.0014, 0.0006,  ..., 0.0020, 0.0028, 0.0036],\n","          [0.0013, 0.0011, 0.0005,  ..., 0.0022, 0.0023, 0.0033],\n","          [0.0018, 0.0013, 0.0010,  ..., 0.0023, 0.0026, 0.0030]]],\n","\n","\n","        [[[0.0020, 0.0036, 0.0012,  ..., 0.0000, 0.0010, 0.0029],\n","          [0.0010, 0.0098, 0.0012,  ..., 0.0009, 0.0007, 0.0014],\n","          [0.0000, 0.0044, 0.0000,  ..., 0.0000, 0.0009, 0.0020],\n","          ...,\n","          [0.0036, 0.0016, 0.0030,  ..., 0.0016, 0.0000, 0.0028],\n","          [0.0000, 0.0027, 0.0032,  ..., 0.0014, 0.0000, 0.0018],\n","          [0.0027, 0.0028, 0.0029,  ..., 0.0011, 0.0006, 0.0021]],\n","\n","         [[0.0019, 0.0011, 0.0023,  ..., 0.0000, 0.0039, 0.0000],\n","          [0.0011, 0.0015, 0.0019,  ..., 0.0051, 0.0042, 0.0045],\n","          [0.0023, 0.0038, 0.0037,  ..., 0.0025, 0.0022, 0.0015],\n","          ...,\n","          [0.0005, 0.0023, 0.0010,  ..., 0.0042, 0.0033, 0.0034],\n","          [0.0006, 0.0000, 0.0000,  ..., 0.0030, 0.0000, 0.0025],\n","          [0.0006, 0.0023, 0.0015,  ..., 0.0040, 0.0040, 0.0037]],\n","\n","         [[0.0023, 0.0046, 0.0024,  ..., 0.0017, 0.0016, 0.0032],\n","          [0.0029, 0.0027, 0.0017,  ..., 0.0014, 0.0011, 0.0000],\n","          [0.0017, 0.0038, 0.0016,  ..., 0.0010, 0.0000, 0.0015],\n","          ...,\n","          [0.0017, 0.0015, 0.0030,  ..., 0.0015, 0.0000, 0.0025],\n","          [0.0018, 0.0016, 0.0020,  ..., 0.0015, 0.0013, 0.0019],\n","          [0.0000, 0.0008, 0.0013,  ..., 0.0000, 0.0009, 0.0019]],\n","\n","         [[0.0000, 0.0014, 0.0015,  ..., 0.0009, 0.0014, 0.0029],\n","          [0.0038, 0.0014, 0.0021,  ..., 0.0014, 0.0019, 0.0015],\n","          [0.0062, 0.0035, 0.0056,  ..., 0.0000, 0.0017, 0.0018],\n","          ...,\n","          [0.0041, 0.0017, 0.0017,  ..., 0.0018, 0.0016, 0.0000],\n","          [0.0000, 0.0010, 0.0015,  ..., 0.0016, 0.0015, 0.0024],\n","          [0.0023, 0.0007, 0.0009,  ..., 0.0019, 0.0021, 0.0033]]],\n","\n","\n","        ...,\n","\n","\n","        [[[0.0000, 0.0020, 0.0009,  ..., 0.0010, 0.0015, 0.0010],\n","          [0.0024, 0.0011, 0.0041,  ..., 0.0012, 0.0020, 0.0013],\n","          [0.0000, 0.0033, 0.0031,  ..., 0.0017, 0.0013, 0.0000],\n","          ...,\n","          [0.0019, 0.0022, 0.0055,  ..., 0.0032, 0.0020, 0.0017],\n","          [0.0019, 0.0024, 0.0030,  ..., 0.0019, 0.0000, 0.0024],\n","          [0.0000, 0.0011, 0.0024,  ..., 0.0000, 0.0022, 0.0042]],\n","\n","         [[0.0011, 0.0014, 0.0010,  ..., 0.0028, 0.0033, 0.0021],\n","          [0.0014, 0.0030, 0.0012,  ..., 0.0025, 0.0022, 0.0027],\n","          [0.0016, 0.0018, 0.0030,  ..., 0.0037, 0.0025, 0.0047],\n","          ...,\n","          [0.0014, 0.0019, 0.0013,  ..., 0.0023, 0.0032, 0.0055],\n","          [0.0007, 0.0016, 0.0021,  ..., 0.0034, 0.0037, 0.0051],\n","          [0.0012, 0.0000, 0.0025,  ..., 0.0022, 0.0013, 0.0029]],\n","\n","         [[0.0017, 0.0011, 0.0013,  ..., 0.0017, 0.0025, 0.0000],\n","          [0.0014, 0.0020, 0.0027,  ..., 0.0000, 0.0027, 0.0015],\n","          [0.0035, 0.0047, 0.0042,  ..., 0.0022, 0.0017, 0.0023],\n","          ...,\n","          [0.0032, 0.0017, 0.0016,  ..., 0.0031, 0.0000, 0.0009],\n","          [0.0023, 0.0020, 0.0019,  ..., 0.0021, 0.0020, 0.0013],\n","          [0.0050, 0.0013, 0.0019,  ..., 0.0028, 0.0000, 0.0009]],\n","\n","         [[0.0060, 0.0010, 0.0010,  ..., 0.0008, 0.0020, 0.0010],\n","          [0.0000, 0.0018, 0.0028,  ..., 0.0038, 0.0024, 0.0022],\n","          [0.0010, 0.0008, 0.0000,  ..., 0.0015, 0.0000, 0.0026],\n","          ...,\n","          [0.0008, 0.0008, 0.0018,  ..., 0.0013, 0.0016, 0.0021],\n","          [0.0000, 0.0000, 0.0021,  ..., 0.0032, 0.0025, 0.0020],\n","          [0.0017, 0.0010, 0.0000,  ..., 0.0028, 0.0025, 0.0018]]],\n","\n","\n","        [[[0.0045, 0.0025, 0.0019,  ..., 0.0011, 0.0017, 0.0023],\n","          [0.0023, 0.0028, 0.0022,  ..., 0.0008, 0.0018, 0.0023],\n","          [0.0022, 0.0029, 0.0017,  ..., 0.0012, 0.0016, 0.0015],\n","          ...,\n","          [0.0021, 0.0015, 0.0019,  ..., 0.0010, 0.0013, 0.0017],\n","          [0.0025, 0.0024, 0.0017,  ..., 0.0011, 0.0015, 0.0022],\n","          [0.0025, 0.0027, 0.0029,  ..., 0.0009, 0.0016, 0.0000]],\n","\n","         [[0.0015, 0.0000, 0.0040,  ..., 0.0045, 0.0032, 0.0000],\n","          [0.0014, 0.0015, 0.0019,  ..., 0.0025, 0.0022, 0.0038],\n","          [0.0031, 0.0016, 0.0036,  ..., 0.0033, 0.0032, 0.0028],\n","          ...,\n","          [0.0007, 0.0015, 0.0000,  ..., 0.0042, 0.0026, 0.0000],\n","          [0.0008, 0.0012, 0.0015,  ..., 0.0043, 0.0022, 0.0043],\n","          [0.0013, 0.0017, 0.0000,  ..., 0.0033, 0.0024, 0.0025]],\n","\n","         [[0.0000, 0.0040, 0.0000,  ..., 0.0014, 0.0013, 0.0019],\n","          [0.0016, 0.0000, 0.0010,  ..., 0.0000, 0.0020, 0.0018],\n","          [0.0013, 0.0033, 0.0012,  ..., 0.0016, 0.0011, 0.0013],\n","          ...,\n","          [0.0016, 0.0021, 0.0020,  ..., 0.0016, 0.0017, 0.0014],\n","          [0.0016, 0.0028, 0.0000,  ..., 0.0016, 0.0019, 0.0022],\n","          [0.0021, 0.0029, 0.0024,  ..., 0.0017, 0.0019, 0.0021]],\n","\n","         [[0.0018, 0.0000, 0.0000,  ..., 0.0016, 0.0000, 0.0000],\n","          [0.0020, 0.0026, 0.0011,  ..., 0.0020, 0.0018, 0.0011],\n","          [0.0000, 0.0023, 0.0052,  ..., 0.0014, 0.0027, 0.0023],\n","          ...,\n","          [0.0018, 0.0012, 0.0016,  ..., 0.0026, 0.0018, 0.0028],\n","          [0.0017, 0.0000, 0.0014,  ..., 0.0021, 0.0000, 0.0015],\n","          [0.0019, 0.0010, 0.0016,  ..., 0.0024, 0.0000, 0.0017]]],\n","\n","\n","        [[[0.0031, 0.0000, 0.0000,  ..., 0.0009, 0.0010, 0.0000],\n","          [0.0017, 0.0020, 0.0011,  ..., 0.0013, 0.0016, 0.0009],\n","          [0.0018, 0.0027, 0.0021,  ..., 0.0010, 0.0011, 0.0007],\n","          ...,\n","          [0.0000, 0.0016, 0.0024,  ..., 0.0018, 0.0022, 0.0027],\n","          [0.0021, 0.0019, 0.0018,  ..., 0.0016, 0.0018, 0.0019],\n","          [0.0022, 0.0022, 0.0022,  ..., 0.0019, 0.0026, 0.0028]],\n","\n","         [[0.0014, 0.0016, 0.0004,  ..., 0.0042, 0.0030, 0.0031],\n","          [0.0018, 0.0015, 0.0006,  ..., 0.0029, 0.0036, 0.0041],\n","          [0.0029, 0.0022, 0.0010,  ..., 0.0026, 0.0018, 0.0015],\n","          ...,\n","          [0.0012, 0.0022, 0.0011,  ..., 0.0022, 0.0000, 0.0042],\n","          [0.0007, 0.0020, 0.0010,  ..., 0.0024, 0.0024, 0.0049],\n","          [0.0008, 0.0014, 0.0013,  ..., 0.0025, 0.0022, 0.0056]],\n","\n","         [[0.0023, 0.0029, 0.0029,  ..., 0.0018, 0.0029, 0.0018],\n","          [0.0020, 0.0033, 0.0013,  ..., 0.0018, 0.0020, 0.0020],\n","          [0.0023, 0.0028, 0.0016,  ..., 0.0021, 0.0019, 0.0014],\n","          ...,\n","          [0.0042, 0.0019, 0.0057,  ..., 0.0014, 0.0015, 0.0021],\n","          [0.0029, 0.0027, 0.0000,  ..., 0.0016, 0.0016, 0.0018],\n","          [0.0039, 0.0020, 0.0035,  ..., 0.0017, 0.0018, 0.0026]],\n","\n","         [[0.0027, 0.0015, 0.0019,  ..., 0.0021, 0.0025, 0.0016],\n","          [0.0014, 0.0020, 0.0015,  ..., 0.0026, 0.0028, 0.0025],\n","          [0.0021, 0.0020, 0.0013,  ..., 0.0030, 0.0032, 0.0023],\n","          ...,\n","          [0.0020, 0.0009, 0.0010,  ..., 0.0000, 0.0000, 0.0053],\n","          [0.0023, 0.0012, 0.0012,  ..., 0.0033, 0.0027, 0.0037],\n","          [0.0014, 0.0008, 0.0010,  ..., 0.0033, 0.0023, 0.0042]]]],\n","       device='cuda:1', grad_fn=<ViewBackward0>), tensor([[[[0.0023, 0.0016, 0.0015,  ..., 0.0008, 0.0000, 0.0008],\n","          [0.0013, 0.0029, 0.0018,  ..., 0.0000, 0.0017, 0.0013],\n","          [0.0021, 0.0019, 0.0015,  ..., 0.0010, 0.0019, 0.0016],\n","          ...,\n","          [0.0014, 0.0017, 0.0014,  ..., 0.0014, 0.0014, 0.0013],\n","          [0.0015, 0.0025, 0.0028,  ..., 0.0000, 0.0012, 0.0014],\n","          [0.0010, 0.0000, 0.0025,  ..., 0.0012, 0.0010, 0.0013]],\n","\n","         [[0.0018, 0.0018, 0.0028,  ..., 0.0031, 0.0027, 0.0025],\n","          [0.0014, 0.0039, 0.0000,  ..., 0.0000, 0.0041, 0.0034],\n","          [0.0013, 0.0034, 0.0022,  ..., 0.0038, 0.0043, 0.0040],\n","          ...,\n","          [0.0008, 0.0021, 0.0025,  ..., 0.0045, 0.0033, 0.0000],\n","          [0.0007, 0.0027, 0.0029,  ..., 0.0041, 0.0000, 0.0043],\n","          [0.0008, 0.0023, 0.0020,  ..., 0.0034, 0.0000, 0.0029]],\n","\n","         [[0.0022, 0.0019, 0.0018,  ..., 0.0015, 0.0011, 0.0013],\n","          [0.0036, 0.0035, 0.0033,  ..., 0.0021, 0.0018, 0.0032],\n","          [0.0036, 0.0029, 0.0024,  ..., 0.0023, 0.0028, 0.0000],\n","          ...,\n","          [0.0039, 0.0000, 0.0014,  ..., 0.0018, 0.0017, 0.0021],\n","          [0.0026, 0.0019, 0.0016,  ..., 0.0024, 0.0023, 0.0034],\n","          [0.0035, 0.0000, 0.0015,  ..., 0.0022, 0.0025, 0.0037]],\n","\n","         [[0.0000, 0.0015, 0.0013,  ..., 0.0025, 0.0032, 0.0023],\n","          [0.0013, 0.0000, 0.0000,  ..., 0.0029, 0.0000, 0.0024],\n","          [0.0006, 0.0000, 0.0015,  ..., 0.0033, 0.0037, 0.0025],\n","          ...,\n","          [0.0023, 0.0019, 0.0020,  ..., 0.0048, 0.0000, 0.0042],\n","          [0.0020, 0.0023, 0.0021,  ..., 0.0043, 0.0044, 0.0031],\n","          [0.0020, 0.0013, 0.0011,  ..., 0.0047, 0.0052, 0.0040]]],\n","\n","\n","        [[[0.0011, 0.0012, 0.0000,  ..., 0.0009, 0.0011, 0.0010],\n","          [0.0009, 0.0038, 0.0013,  ..., 0.0005, 0.0009, 0.0005],\n","          [0.0021, 0.0019, 0.0000,  ..., 0.0009, 0.0000, 0.0017],\n","          ...,\n","          [0.0010, 0.0012, 0.0014,  ..., 0.0007, 0.0010, 0.0008],\n","          [0.0000, 0.0011, 0.0000,  ..., 0.0007, 0.0015, 0.0008],\n","          [0.0011, 0.0020, 0.0012,  ..., 0.0006, 0.0013, 0.0009]],\n","\n","         [[0.0000, 0.0020, 0.0011,  ..., 0.0039, 0.0036, 0.0029],\n","          [0.0000, 0.0017, 0.0012,  ..., 0.0035, 0.0043, 0.0000],\n","          [0.0010, 0.0000, 0.0017,  ..., 0.0024, 0.0030, 0.0019],\n","          ...,\n","          [0.0007, 0.0016, 0.0012,  ..., 0.0040, 0.0042, 0.0043],\n","          [0.0009, 0.0022, 0.0000,  ..., 0.0048, 0.0040, 0.0037],\n","          [0.0006, 0.0021, 0.0013,  ..., 0.0034, 0.0000, 0.0037]],\n","\n","         [[0.0023, 0.0050, 0.0029,  ..., 0.0015, 0.0034, 0.0014],\n","          [0.0026, 0.0018, 0.0011,  ..., 0.0020, 0.0017, 0.0019],\n","          [0.0028, 0.0037, 0.0022,  ..., 0.0019, 0.0016, 0.0016],\n","          ...,\n","          [0.0042, 0.0032, 0.0023,  ..., 0.0020, 0.0000, 0.0024],\n","          [0.0030, 0.0024, 0.0000,  ..., 0.0023, 0.0019, 0.0000],\n","          [0.0039, 0.0018, 0.0021,  ..., 0.0023, 0.0019, 0.0022]],\n","\n","         [[0.0021, 0.0031, 0.0012,  ..., 0.0034, 0.0020, 0.0025],\n","          [0.0000, 0.0016, 0.0000,  ..., 0.0019, 0.0012, 0.0019],\n","          [0.0026, 0.0021, 0.0015,  ..., 0.0029, 0.0000, 0.0000],\n","          ...,\n","          [0.0021, 0.0015, 0.0007,  ..., 0.0023, 0.0028, 0.0040],\n","          [0.0000, 0.0000, 0.0006,  ..., 0.0024, 0.0028, 0.0000],\n","          [0.0023, 0.0017, 0.0010,  ..., 0.0028, 0.0031, 0.0036]]],\n","\n","\n","        [[[0.0000, 0.0033, 0.0000,  ..., 0.0011, 0.0010, 0.0031],\n","          [0.0013, 0.0083, 0.0012,  ..., 0.0000, 0.0000, 0.0017],\n","          [0.0017, 0.0039, 0.0021,  ..., 0.0013, 0.0010, 0.0022],\n","          ...,\n","          [0.0032, 0.0017, 0.0026,  ..., 0.0015, 0.0009, 0.0000],\n","          [0.0000, 0.0026, 0.0025,  ..., 0.0012, 0.0008, 0.0019],\n","          [0.0025, 0.0025, 0.0027,  ..., 0.0012, 0.0007, 0.0020]],\n","\n","         [[0.0016, 0.0014, 0.0024,  ..., 0.0068, 0.0045, 0.0049],\n","          [0.0000, 0.0019, 0.0024,  ..., 0.0060, 0.0046, 0.0044],\n","          [0.0017, 0.0040, 0.0035,  ..., 0.0033, 0.0000, 0.0017],\n","          ...,\n","          [0.0007, 0.0025, 0.0000,  ..., 0.0062, 0.0048, 0.0039],\n","          [0.0008, 0.0027, 0.0020,  ..., 0.0043, 0.0000, 0.0026],\n","          [0.0007, 0.0025, 0.0015,  ..., 0.0057, 0.0048, 0.0039]],\n","\n","         [[0.0024, 0.0034, 0.0025,  ..., 0.0016, 0.0016, 0.0027],\n","          [0.0026, 0.0025, 0.0019,  ..., 0.0016, 0.0011, 0.0000],\n","          [0.0021, 0.0032, 0.0019,  ..., 0.0013, 0.0014, 0.0022],\n","          ...,\n","          [0.0018, 0.0015, 0.0034,  ..., 0.0000, 0.0015, 0.0031],\n","          [0.0022, 0.0015, 0.0025,  ..., 0.0018, 0.0017, 0.0023],\n","          [0.0000, 0.0010, 0.0016,  ..., 0.0019, 0.0015, 0.0026]],\n","\n","         [[0.0026, 0.0012, 0.0014,  ..., 0.0014, 0.0016, 0.0000],\n","          [0.0032, 0.0020, 0.0018,  ..., 0.0016, 0.0000, 0.0022],\n","          [0.0058, 0.0035, 0.0040,  ..., 0.0033, 0.0000, 0.0021],\n","          ...,\n","          [0.0044, 0.0000, 0.0013,  ..., 0.0022, 0.0018, 0.0039],\n","          [0.0032, 0.0012, 0.0013,  ..., 0.0023, 0.0019, 0.0029],\n","          [0.0028, 0.0010, 0.0009,  ..., 0.0030, 0.0022, 0.0038]]],\n","\n","\n","        ...,\n","\n","\n","        [[[0.0026, 0.0021, 0.0011,  ..., 0.0013, 0.0014, 0.0012],\n","          [0.0025, 0.0012, 0.0040,  ..., 0.0014, 0.0021, 0.0016],\n","          [0.0000, 0.0031, 0.0000,  ..., 0.0017, 0.0017, 0.0018],\n","          ...,\n","          [0.0018, 0.0019, 0.0049,  ..., 0.0028, 0.0026, 0.0023],\n","          [0.0019, 0.0022, 0.0027,  ..., 0.0019, 0.0019, 0.0000],\n","          [0.0000, 0.0013, 0.0023,  ..., 0.0011, 0.0000, 0.0038]],\n","\n","         [[0.0013, 0.0016, 0.0011,  ..., 0.0026, 0.0034, 0.0027],\n","          [0.0017, 0.0030, 0.0012,  ..., 0.0023, 0.0020, 0.0027],\n","          [0.0017, 0.0018, 0.0026,  ..., 0.0036, 0.0029, 0.0052],\n","          ...,\n","          [0.0016, 0.0023, 0.0015,  ..., 0.0000, 0.0031, 0.0056],\n","          [0.0009, 0.0000, 0.0019,  ..., 0.0031, 0.0035, 0.0050],\n","          [0.0000, 0.0030, 0.0000,  ..., 0.0022, 0.0012, 0.0028]],\n","\n","         [[0.0022, 0.0015, 0.0012,  ..., 0.0021, 0.0024, 0.0022],\n","          [0.0019, 0.0022, 0.0024,  ..., 0.0039, 0.0030, 0.0014],\n","          [0.0042, 0.0036, 0.0031,  ..., 0.0026, 0.0000, 0.0000],\n","          ...,\n","          [0.0000, 0.0018, 0.0014,  ..., 0.0035, 0.0020, 0.0010],\n","          [0.0027, 0.0023, 0.0016,  ..., 0.0021, 0.0024, 0.0014],\n","          [0.0053, 0.0013, 0.0019,  ..., 0.0038, 0.0040, 0.0011]],\n","\n","         [[0.0044, 0.0011, 0.0013,  ..., 0.0010, 0.0022, 0.0011],\n","          [0.0030, 0.0018, 0.0022,  ..., 0.0032, 0.0025, 0.0019],\n","          [0.0014, 0.0008, 0.0016,  ..., 0.0019, 0.0022, 0.0000],\n","          ...,\n","          [0.0010, 0.0009, 0.0019,  ..., 0.0017, 0.0019, 0.0019],\n","          [0.0023, 0.0000, 0.0018,  ..., 0.0034, 0.0028, 0.0021],\n","          [0.0022, 0.0010, 0.0018,  ..., 0.0029, 0.0032, 0.0000]]],\n","\n","\n","        [[[0.0040, 0.0034, 0.0019,  ..., 0.0010, 0.0019, 0.0023],\n","          [0.0022, 0.0032, 0.0023,  ..., 0.0008, 0.0019, 0.0023],\n","          [0.0021, 0.0040, 0.0018,  ..., 0.0011, 0.0016, 0.0017],\n","          ...,\n","          [0.0022, 0.0000, 0.0021,  ..., 0.0009, 0.0014, 0.0017],\n","          [0.0024, 0.0029, 0.0000,  ..., 0.0010, 0.0015, 0.0020],\n","          [0.0024, 0.0030, 0.0026,  ..., 0.0000, 0.0015, 0.0023]],\n","\n","         [[0.0018, 0.0014, 0.0039,  ..., 0.0057, 0.0000, 0.0028],\n","          [0.0016, 0.0000, 0.0023,  ..., 0.0038, 0.0030, 0.0037],\n","          [0.0033, 0.0017, 0.0029,  ..., 0.0000, 0.0035, 0.0025],\n","          ...,\n","          [0.0010, 0.0014, 0.0020,  ..., 0.0047, 0.0000, 0.0032],\n","          [0.0011, 0.0013, 0.0019,  ..., 0.0048, 0.0027, 0.0037],\n","          [0.0016, 0.0014, 0.0031,  ..., 0.0039, 0.0029, 0.0026]],\n","\n","         [[0.0024, 0.0039, 0.0017,  ..., 0.0014, 0.0015, 0.0020],\n","          [0.0016, 0.0025, 0.0010,  ..., 0.0017, 0.0020, 0.0021],\n","          [0.0015, 0.0041, 0.0010,  ..., 0.0017, 0.0015, 0.0016],\n","          ...,\n","          [0.0017, 0.0026, 0.0022,  ..., 0.0017, 0.0000, 0.0019],\n","          [0.0015, 0.0028, 0.0012,  ..., 0.0000, 0.0016, 0.0021],\n","          [0.0018, 0.0030, 0.0000,  ..., 0.0018, 0.0018, 0.0024]],\n","\n","         [[0.0000, 0.0014, 0.0013,  ..., 0.0019, 0.0027, 0.0024],\n","          [0.0020, 0.0031, 0.0012,  ..., 0.0027, 0.0022, 0.0015],\n","          [0.0061, 0.0023, 0.0042,  ..., 0.0016, 0.0029, 0.0000],\n","          ...,\n","          [0.0015, 0.0015, 0.0016,  ..., 0.0029, 0.0022, 0.0028],\n","          [0.0017, 0.0014, 0.0011,  ..., 0.0026, 0.0018, 0.0019],\n","          [0.0000, 0.0011, 0.0012,  ..., 0.0033, 0.0018, 0.0021]]],\n","\n","\n","        [[[0.0025, 0.0032, 0.0032,  ..., 0.0009, 0.0011, 0.0011],\n","          [0.0015, 0.0020, 0.0013,  ..., 0.0012, 0.0015, 0.0010],\n","          [0.0022, 0.0034, 0.0020,  ..., 0.0011, 0.0012, 0.0009],\n","          ...,\n","          [0.0020, 0.0019, 0.0025,  ..., 0.0018, 0.0018, 0.0021],\n","          [0.0017, 0.0022, 0.0019,  ..., 0.0015, 0.0016, 0.0018],\n","          [0.0017, 0.0025, 0.0022,  ..., 0.0015, 0.0000, 0.0020]],\n","\n","         [[0.0016, 0.0012, 0.0003,  ..., 0.0046, 0.0036, 0.0042],\n","          [0.0018, 0.0015, 0.0004,  ..., 0.0031, 0.0038, 0.0038],\n","          [0.0028, 0.0016, 0.0007,  ..., 0.0029, 0.0021, 0.0018],\n","          ...,\n","          [0.0012, 0.0018, 0.0008,  ..., 0.0021, 0.0017, 0.0044],\n","          [0.0008, 0.0017, 0.0008,  ..., 0.0023, 0.0024, 0.0051],\n","          [0.0009, 0.0013, 0.0009,  ..., 0.0023, 0.0023, 0.0054]],\n","\n","         [[0.0000, 0.0032, 0.0028,  ..., 0.0015, 0.0017, 0.0013],\n","          [0.0023, 0.0027, 0.0016,  ..., 0.0018, 0.0018, 0.0017],\n","          [0.0027, 0.0032, 0.0018,  ..., 0.0000, 0.0000, 0.0016],\n","          ...,\n","          [0.0038, 0.0025, 0.0044,  ..., 0.0017, 0.0014, 0.0016],\n","          [0.0030, 0.0031, 0.0047,  ..., 0.0016, 0.0016, 0.0015],\n","          [0.0039, 0.0025, 0.0032,  ..., 0.0018, 0.0018, 0.0021]],\n","\n","         [[0.0027, 0.0016, 0.0018,  ..., 0.0024, 0.0026, 0.0016],\n","          [0.0018, 0.0021, 0.0015,  ..., 0.0024, 0.0024, 0.0023],\n","          [0.0023, 0.0020, 0.0013,  ..., 0.0000, 0.0029, 0.0024],\n","          ...,\n","          [0.0018, 0.0009, 0.0011,  ..., 0.0052, 0.0049, 0.0051],\n","          [0.0025, 0.0014, 0.0014,  ..., 0.0031, 0.0029, 0.0037],\n","          [0.0017, 0.0010, 0.0011,  ..., 0.0033, 0.0025, 0.0041]]]],\n","       device='cuda:1', grad_fn=<ViewBackward0>)]\n"]}],"source":["test_forward_pass(model, e.train_loader)"]},{"cell_type":"markdown","metadata":{"id":"w60mTX5nQ7Z1"},"source":["## Training the model"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1715688892531,"user":{"displayName":"Insa Belter","userId":"09408038895575287386"},"user_tz":-120},"id":"Vr8Ge8QYQ7Z2"},"outputs":[{"name":"stdout","output_type":"stream","text":["849,089 total parameters.\n","849,089 training parameters.\n"]}],"source":["e.set_seed()\n","EMBED_DIM = 64\n","NUM_ENCODER_LAYERS = 2\n","NUM_HEADS = 4\n","DROPOUT = 0.5\n","\n","model = e.EncoderClassifier(\n","    embed_dim=EMBED_DIM,\n","    num_layers=NUM_ENCODER_LAYERS,\n","    num_heads=NUM_HEADS,\n","    dropout=DROPOUT,\n","    pos_enc=False\n",").to(device)\n","print_parameters(model)"]},{"cell_type":"code","execution_count":48,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":452,"status":"ok","timestamp":1715688894105,"user":{"displayName":"Insa Belter","userId":"09408038895575287386"},"user_tz":-120},"id":"8G-AucPcQ7Z2","outputId":"8483db98-2a68-47ee-eaa2-b7d3c55e90f7"},"outputs":[{"name":"stdout","output_type":"stream","text":["----- Start Training -----\n","Epoch [1/50], Loss: 1.7964, Eval Accuracy: 0.5155, Took 1.16 s\n","Epoch [2/50], Loss: 1.2462, Eval Accuracy: 0.5146, Took 1.15 s\n","Epoch [3/50], Loss: 1.1489, Eval Accuracy: 0.5153, Took 1.15 s\n","Epoch [4/50], Loss: 1.1064, Eval Accuracy: 0.5166, Took 1.15 s\n","Epoch [5/50], Loss: 1.083, Eval Accuracy: 0.5186, Took 1.15 s\n","Epoch [6/50], Loss: 1.0689, Eval Accuracy: 0.5166, Took 1.16 s\n","Epoch [7/50], Loss: 1.0594, Eval Accuracy: 0.5176, Took 1.16 s\n","Epoch [8/50], Loss: 1.0536, Eval Accuracy: 0.5196, Took 1.15 s\n","Epoch [9/50], Loss: 1.0486, Eval Accuracy: 0.5204, Took 1.15 s\n","Epoch [10/50], Loss: 1.0456, Eval Accuracy: 0.522, Took 1.17 s\n","Epoch [11/50], Loss: 1.0435, Eval Accuracy: 0.5184, Took 1.18 s\n","Epoch [12/50], Loss: 1.0409, Eval Accuracy: 0.5198, Took 1.18 s\n","Epoch [13/50], Loss: 1.0407, Eval Accuracy: 0.5218, Took 1.18 s\n","Epoch [14/50], Loss: 1.0382, Eval Accuracy: 0.5218, Took 1.19 s\n","Epoch [15/50], Loss: 1.0381, Eval Accuracy: 0.5199, Took 1.19 s\n","Epoch [16/50], Loss: 1.0368, Eval Accuracy: 0.5222, Took 1.17 s\n","Epoch [17/50], Loss: 1.0367, Eval Accuracy: 0.5226, Took 1.16 s\n","Epoch [18/50], Loss: 1.0349, Eval Accuracy: 0.5226, Took 1.16 s\n","Epoch [19/50], Loss: 1.0345, Eval Accuracy: 0.5231, Took 1.17 s\n","Epoch [20/50], Loss: 1.0347, Eval Accuracy: 0.5209, Took 1.16 s\n","Epoch [21/50], Loss: 1.035, Eval Accuracy: 0.5225, Took 1.16 s\n","Stopped early after epoch 21 as validation accuracy was lower than average of the last 7 accuracies.\n","Last Loss: 1.035, Last Eval Accuracy: 0.5225, Took 24.47 s\n"]},{"data":{"text/plain":["(1.035, 0.5225, 21)"]},"execution_count":48,"metadata":{},"output_type":"execute_result"}],"source":["EPOCHS = 100\n","print(\"----- Start Training -----\")\n","e.train_model(model, EPOCHS)"]},{"cell_type":"code","execution_count":50,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Model saved as 20240616081217_encoder_64em_2l_4h_05dr_21ep.pt\n"]}],"source":["mlh.save_model(model, f'encoder_64em_2l_4h_05dr_21ep', e.organism)"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[],"source":["#model = mlh.load_model(f'encoder_256em_4l_4h_03dr_10ep', organism)"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[],"source":["criterion = torch.nn.CrossEntropyLoss(ignore_index=mlh.codons_to_integer['___'])\n","#evaluate_model(model, criterion)"]},{"cell_type":"markdown","metadata":{},"source":["## Hyperparameter tuning"]},{"cell_type":"markdown","metadata":{},"source":["### E.Coli"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Länge train_dataset: 3555\n","Länge valid_dataset: 420\n"]}],"source":["organism = \"E.Coli\"\n","e.load_train_valid_data(organism)"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["----- Start Training: 64 emb, 2 layers, 4 heads, 0.5 dropout, positional encoding: False, 400 epochs -----\n"]},{"name":"stderr","output_type":"stream","text":["/home/mkuehn/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [1/400], Loss: 1.7964, Eval Accuracy: 0.5155, Took 1.56 s\n","Epoch [2/400], Loss: 1.2462, Eval Accuracy: 0.5146, Took 1.14 s\n","Epoch [3/400], Loss: 1.1489, Eval Accuracy: 0.5153, Took 1.15 s\n","Epoch [4/400], Loss: 1.1064, Eval Accuracy: 0.5166, Took 1.14 s\n","Epoch [5/400], Loss: 1.083, Eval Accuracy: 0.5186, Took 1.14 s\n","Epoch [6/400], Loss: 1.0689, Eval Accuracy: 0.5166, Took 1.16 s\n","Epoch [7/400], Loss: 1.0594, Eval Accuracy: 0.5176, Took 1.16 s\n","Epoch [8/400], Loss: 1.0536, Eval Accuracy: 0.5196, Took 1.16 s\n","Epoch [9/400], Loss: 1.0486, Eval Accuracy: 0.5204, Took 1.13 s\n","Epoch [10/400], Loss: 1.0456, Eval Accuracy: 0.522, Took 1.13 s\n","Epoch [11/400], Loss: 1.0435, Eval Accuracy: 0.5184, Took 1.14 s\n","Epoch [12/400], Loss: 1.0409, Eval Accuracy: 0.5198, Took 1.15 s\n","Epoch [13/400], Loss: 1.0407, Eval Accuracy: 0.5218, Took 1.14 s\n","Epoch [14/400], Loss: 1.0382, Eval Accuracy: 0.5218, Took 1.14 s\n","Epoch [15/400], Loss: 1.0381, Eval Accuracy: 0.5199, Took 1.14 s\n","Epoch [16/400], Loss: 1.0368, Eval Accuracy: 0.5222, Took 1.14 s\n","Epoch [17/400], Loss: 1.0367, Eval Accuracy: 0.5226, Took 1.14 s\n","Epoch [18/400], Loss: 1.0349, Eval Accuracy: 0.5226, Took 1.14 s\n","Epoch [19/400], Loss: 1.0345, Eval Accuracy: 0.5231, Took 1.14 s\n","Epoch [20/400], Loss: 1.0347, Eval Accuracy: 0.5209, Took 1.14 s\n","Epoch [21/400], Loss: 1.035, Eval Accuracy: 0.5225, Took 1.14 s\n","Epoch [22/400], Loss: 1.0327, Eval Accuracy: 0.5219, Took 1.14 s\n","Epoch [23/400], Loss: 1.0345, Eval Accuracy: 0.5224, Took 1.14 s\n","Epoch [24/400], Loss: 1.0331, Eval Accuracy: 0.523, Took 1.14 s\n","Epoch [25/400], Loss: 1.0329, Eval Accuracy: 0.5221, Took 1.15 s\n","Epoch [26/400], Loss: 1.0334, Eval Accuracy: 0.5242, Took 1.15 s\n","Epoch [27/400], Loss: 1.0328, Eval Accuracy: 0.5229, Took 1.14 s\n","Epoch [28/400], Loss: 1.0324, Eval Accuracy: 0.5223, Took 1.14 s\n","Epoch [29/400], Loss: 1.0327, Eval Accuracy: 0.524, Took 1.14 s\n","Epoch [30/400], Loss: 1.0321, Eval Accuracy: 0.5242, Took 1.14 s\n","Epoch [31/400], Loss: 1.032, Eval Accuracy: 0.523, Took 1.14 s\n","Epoch [32/400], Loss: 1.0314, Eval Accuracy: 0.5222, Took 1.14 s\n","Epoch [33/400], Loss: 1.0313, Eval Accuracy: 0.5237, Took 1.14 s\n","Epoch [34/400], Loss: 1.0303, Eval Accuracy: 0.5234, Took 1.14 s\n","Epoch [35/400], Loss: 1.0311, Eval Accuracy: 0.5236, Took 1.14 s\n","Epoch [36/400], Loss: 1.0317, Eval Accuracy: 0.5236, Took 1.14 s\n","Epoch [37/400], Loss: 1.0303, Eval Accuracy: 0.5226, Took 1.14 s\n","Epoch [38/400], Loss: 1.0292, Eval Accuracy: 0.5237, Took 1.14 s\n","Epoch [39/400], Loss: 1.0297, Eval Accuracy: 0.5232, Took 1.14 s\n","Epoch [40/400], Loss: 1.0304, Eval Accuracy: 0.5206, Took 1.14 s\n","Epoch [41/400], Loss: 1.0294, Eval Accuracy: 0.524, Took 1.14 s\n","Epoch [42/400], Loss: 1.0298, Eval Accuracy: 0.5228, Took 1.14 s\n","Epoch [43/400], Loss: 1.0291, Eval Accuracy: 0.524, Took 1.14 s\n","Epoch [44/400], Loss: 1.0294, Eval Accuracy: 0.5232, Took 1.14 s\n","Epoch [45/400], Loss: 1.0295, Eval Accuracy: 0.524, Took 1.15 s\n","Epoch [46/400], Loss: 1.0288, Eval Accuracy: 0.5232, Took 1.14 s\n","Epoch [47/400], Loss: 1.029, Eval Accuracy: 0.5231, Took 1.14 s\n","Epoch [48/400], Loss: 1.0297, Eval Accuracy: 0.5227, Took 1.14 s\n","Epoch [49/400], Loss: 1.0292, Eval Accuracy: 0.524, Took 1.14 s\n","Epoch [50/400], Loss: 1.0293, Eval Accuracy: 0.5229, Took 1.14 s\n","Epoch [51/400], Loss: 1.0278, Eval Accuracy: 0.5229, Took 1.14 s\n","Epoch [52/400], Loss: 1.0283, Eval Accuracy: 0.5233, Took 1.14 s\n","Epoch [53/400], Loss: 1.0281, Eval Accuracy: 0.5229, Took 1.14 s\n","Epoch [54/400], Loss: 1.0291, Eval Accuracy: 0.5235, Took 1.14 s\n","Epoch [55/400], Loss: 1.0283, Eval Accuracy: 0.5205, Took 1.14 s\n","Epoch [56/400], Loss: 1.0281, Eval Accuracy: 0.5231, Took 1.14 s\n","Epoch [57/400], Loss: 1.0282, Eval Accuracy: 0.5229, Took 1.14 s\n","Epoch [58/400], Loss: 1.0271, Eval Accuracy: 0.5225, Took 1.14 s\n","Epoch [59/400], Loss: 1.0271, Eval Accuracy: 0.5217, Took 1.14 s\n","Epoch [60/400], Loss: 1.0267, Eval Accuracy: 0.5237, Took 1.14 s\n","Epoch [61/400], Loss: 1.0268, Eval Accuracy: 0.5236, Took 1.14 s\n","Epoch [62/400], Loss: 1.0271, Eval Accuracy: 0.525, Took 1.14 s\n","Epoch [63/400], Loss: 1.0267, Eval Accuracy: 0.521, Took 1.14 s\n","Epoch [64/400], Loss: 1.0274, Eval Accuracy: 0.5236, Took 1.14 s\n","Epoch [65/400], Loss: 1.0271, Eval Accuracy: 0.5232, Took 1.14 s\n","Epoch [66/400], Loss: 1.0263, Eval Accuracy: 0.5229, Took 1.14 s\n","Epoch [67/400], Loss: 1.027, Eval Accuracy: 0.5225, Took 1.14 s\n","Epoch [68/400], Loss: 1.0277, Eval Accuracy: 0.5217, Took 1.14 s\n","Epoch [69/400], Loss: 1.0258, Eval Accuracy: 0.5233, Took 1.14 s\n","Epoch [70/400], Loss: 1.0241, Eval Accuracy: 0.5234, Took 1.14 s\n","Epoch [71/400], Loss: 1.0256, Eval Accuracy: 0.5232, Took 1.14 s\n","Epoch [72/400], Loss: 1.0253, Eval Accuracy: 0.5236, Took 1.14 s\n","Epoch [73/400], Loss: 1.0253, Eval Accuracy: 0.5221, Took 1.14 s\n","Epoch [74/400], Loss: 1.0249, Eval Accuracy: 0.524, Took 1.15 s\n","Epoch [75/400], Loss: 1.0241, Eval Accuracy: 0.5228, Took 1.14 s\n","Epoch [76/400], Loss: 1.0255, Eval Accuracy: 0.522, Took 1.14 s\n","Epoch [77/400], Loss: 1.0253, Eval Accuracy: 0.5232, Took 1.14 s\n","Epoch [78/400], Loss: 1.0244, Eval Accuracy: 0.5228, Took 1.14 s\n","Epoch [79/400], Loss: 1.0236, Eval Accuracy: 0.5222, Took 1.14 s\n","Epoch [80/400], Loss: 1.0243, Eval Accuracy: 0.5239, Took 1.14 s\n","Epoch [81/400], Loss: 1.0234, Eval Accuracy: 0.5229, Took 1.14 s\n","Epoch [82/400], Loss: 1.0236, Eval Accuracy: 0.5217, Took 1.14 s\n","Epoch [83/400], Loss: 1.024, Eval Accuracy: 0.5234, Took 1.14 s\n","Epoch [84/400], Loss: 1.0238, Eval Accuracy: 0.5216, Took 1.15 s\n","Epoch [85/400], Loss: 1.0225, Eval Accuracy: 0.5237, Took 1.14 s\n","Epoch [86/400], Loss: 1.0232, Eval Accuracy: 0.5232, Took 1.14 s\n","Epoch [87/400], Loss: 1.0225, Eval Accuracy: 0.5216, Took 1.15 s\n","Epoch [88/400], Loss: 1.0225, Eval Accuracy: 0.5241, Took 1.15 s\n","Epoch [89/400], Loss: 1.0223, Eval Accuracy: 0.5238, Took 1.14 s\n","Epoch [90/400], Loss: 1.022, Eval Accuracy: 0.5228, Took 1.14 s\n","Epoch [91/400], Loss: 1.0215, Eval Accuracy: 0.5232, Took 1.14 s\n","Epoch [92/400], Loss: 1.0212, Eval Accuracy: 0.5221, Took 1.14 s\n","Epoch [93/400], Loss: 1.0204, Eval Accuracy: 0.5211, Took 1.14 s\n","Epoch [94/400], Loss: 1.0211, Eval Accuracy: 0.5205, Took 1.15 s\n","Epoch [95/400], Loss: 1.0212, Eval Accuracy: 0.5209, Took 1.14 s\n","Epoch [96/400], Loss: 1.021, Eval Accuracy: 0.5234, Took 1.14 s\n","Epoch [97/400], Loss: 1.0198, Eval Accuracy: 0.5239, Took 1.16 s\n","Epoch [98/400], Loss: 1.0197, Eval Accuracy: 0.5229, Took 1.17 s\n","Epoch [99/400], Loss: 1.0202, Eval Accuracy: 0.5215, Took 1.17 s\n","Epoch [100/400], Loss: 1.0191, Eval Accuracy: 0.5226, Took 1.17 s\n","Epoch [101/400], Loss: 1.0186, Eval Accuracy: 0.5212, Took 1.17 s\n","Epoch [102/400], Loss: 1.0184, Eval Accuracy: 0.5216, Took 1.17 s\n","Epoch [103/400], Loss: 1.0186, Eval Accuracy: 0.52, Took 1.15 s\n","Epoch [104/400], Loss: 1.0175, Eval Accuracy: 0.5205, Took 1.14 s\n","Epoch [105/400], Loss: 1.0184, Eval Accuracy: 0.5199, Took 1.14 s\n","Epoch [106/400], Loss: 1.0182, Eval Accuracy: 0.5203, Took 1.14 s\n","Epoch [107/400], Loss: 1.0176, Eval Accuracy: 0.5203, Took 1.14 s\n","Epoch [108/400], Loss: 1.0191, Eval Accuracy: 0.5193, Took 1.15 s\n","Epoch [109/400], Loss: 1.0175, Eval Accuracy: 0.5205, Took 1.17 s\n","Epoch [110/400], Loss: 1.0171, Eval Accuracy: 0.5205, Took 1.17 s\n","Epoch [111/400], Loss: 1.0158, Eval Accuracy: 0.5205, Took 1.17 s\n","Epoch [112/400], Loss: 1.0155, Eval Accuracy: 0.5182, Took 1.17 s\n","Epoch [113/400], Loss: 1.0154, Eval Accuracy: 0.5181, Took 1.14 s\n","Epoch [114/400], Loss: 1.0158, Eval Accuracy: 0.5209, Took 1.14 s\n","Epoch [115/400], Loss: 1.0154, Eval Accuracy: 0.5194, Took 1.14 s\n","Epoch [116/400], Loss: 1.0155, Eval Accuracy: 0.5221, Took 1.14 s\n","Epoch [117/400], Loss: 1.0152, Eval Accuracy: 0.5183, Took 1.15 s\n","Epoch [118/400], Loss: 1.0142, Eval Accuracy: 0.5194, Took 1.14 s\n","Epoch [119/400], Loss: 1.0145, Eval Accuracy: 0.5164, Took 1.14 s\n","Epoch [120/400], Loss: 1.0142, Eval Accuracy: 0.5169, Took 1.15 s\n","Epoch [121/400], Loss: 1.0137, Eval Accuracy: 0.5188, Took 1.15 s\n","Epoch [122/400], Loss: 1.013, Eval Accuracy: 0.5179, Took 1.14 s\n","Epoch [123/400], Loss: 1.0139, Eval Accuracy: 0.5177, Took 1.14 s\n","Epoch [124/400], Loss: 1.0133, Eval Accuracy: 0.5188, Took 1.14 s\n","Epoch [125/400], Loss: 1.0127, Eval Accuracy: 0.5172, Took 1.14 s\n","Epoch [126/400], Loss: 1.0113, Eval Accuracy: 0.5175, Took 1.15 s\n","Epoch [127/400], Loss: 1.0123, Eval Accuracy: 0.5169, Took 1.14 s\n","Epoch [128/400], Loss: 1.0109, Eval Accuracy: 0.5184, Took 1.15 s\n","Epoch [129/400], Loss: 1.0127, Eval Accuracy: 0.5144, Took 1.14 s\n","Epoch [130/400], Loss: 1.0106, Eval Accuracy: 0.5165, Took 1.14 s\n","Epoch [131/400], Loss: 1.0113, Eval Accuracy: 0.5157, Took 1.14 s\n","Epoch [132/400], Loss: 1.0103, Eval Accuracy: 0.5146, Took 1.15 s\n","Epoch [133/400], Loss: 1.01, Eval Accuracy: 0.5166, Took 1.14 s\n","Epoch [134/400], Loss: 1.0107, Eval Accuracy: 0.5155, Took 1.14 s\n","Epoch [135/400], Loss: 1.0105, Eval Accuracy: 0.5144, Took 1.14 s\n","Epoch [136/400], Loss: 1.0096, Eval Accuracy: 0.5164, Took 1.14 s\n","Epoch [137/400], Loss: 1.0093, Eval Accuracy: 0.5169, Took 1.14 s\n","Epoch [138/400], Loss: 1.0083, Eval Accuracy: 0.5168, Took 1.14 s\n","Epoch [139/400], Loss: 1.0085, Eval Accuracy: 0.5145, Took 1.14 s\n","Epoch [140/400], Loss: 1.0081, Eval Accuracy: 0.5144, Took 1.14 s\n","Epoch [141/400], Loss: 1.0104, Eval Accuracy: 0.5168, Took 1.14 s\n","Epoch [142/400], Loss: 1.0074, Eval Accuracy: 0.5162, Took 1.14 s\n","Epoch [143/400], Loss: 1.0085, Eval Accuracy: 0.5147, Took 1.14 s\n","Epoch [144/400], Loss: 1.0111, Eval Accuracy: 0.515, Took 1.14 s\n","Epoch [145/400], Loss: 1.0075, Eval Accuracy: 0.5151, Took 1.15 s\n","Epoch [146/400], Loss: 1.0068, Eval Accuracy: 0.5135, Took 1.15 s\n","Epoch [147/400], Loss: 1.0063, Eval Accuracy: 0.5147, Took 1.14 s\n","Epoch [148/400], Loss: 1.0072, Eval Accuracy: 0.5144, Took 1.14 s\n","Epoch [149/400], Loss: 1.0073, Eval Accuracy: 0.5128, Took 1.14 s\n","Epoch [150/400], Loss: 1.0063, Eval Accuracy: 0.5117, Took 1.14 s\n","Epoch [151/400], Loss: 1.005, Eval Accuracy: 0.5157, Took 1.14 s\n","Epoch [152/400], Loss: 1.0065, Eval Accuracy: 0.5142, Took 1.14 s\n","Epoch [153/400], Loss: 1.0048, Eval Accuracy: 0.5137, Took 1.14 s\n","Epoch [154/400], Loss: 1.0049, Eval Accuracy: 0.5139, Took 1.14 s\n","Epoch [155/400], Loss: 1.0046, Eval Accuracy: 0.5113, Took 1.15 s\n","Epoch [156/400], Loss: 1.0043, Eval Accuracy: 0.5108, Took 1.14 s\n","Epoch [157/400], Loss: 1.0039, Eval Accuracy: 0.5126, Took 1.14 s\n","Epoch [158/400], Loss: 1.0039, Eval Accuracy: 0.5131, Took 1.15 s\n","Epoch [159/400], Loss: 1.0044, Eval Accuracy: 0.5081, Took 1.14 s\n","Epoch [160/400], Loss: 1.0034, Eval Accuracy: 0.5126, Took 1.14 s\n","Epoch [161/400], Loss: 1.0037, Eval Accuracy: 0.5139, Took 1.14 s\n","Epoch [162/400], Loss: 1.0021, Eval Accuracy: 0.5126, Took 1.14 s\n","Epoch [163/400], Loss: 1.0029, Eval Accuracy: 0.5083, Took 1.14 s\n","Epoch [164/400], Loss: 1.0021, Eval Accuracy: 0.5099, Took 1.14 s\n","Epoch [165/400], Loss: 1.0041, Eval Accuracy: 0.5109, Took 1.14 s\n","Epoch [166/400], Loss: 1.0015, Eval Accuracy: 0.5092, Took 1.14 s\n","Epoch [167/400], Loss: 1.0029, Eval Accuracy: 0.5097, Took 1.14 s\n","Epoch [168/400], Loss: 1.0017, Eval Accuracy: 0.5104, Took 1.14 s\n","Epoch [169/400], Loss: 1.0011, Eval Accuracy: 0.5114, Took 1.14 s\n","Epoch [170/400], Loss: 1.0012, Eval Accuracy: 0.509, Took 1.14 s\n","Epoch [171/400], Loss: 1.0006, Eval Accuracy: 0.5121, Took 1.14 s\n","Epoch [172/400], Loss: 1.0008, Eval Accuracy: 0.5102, Took 1.14 s\n","Epoch [173/400], Loss: 1.0016, Eval Accuracy: 0.509, Took 1.14 s\n","Epoch [174/400], Loss: 0.9999, Eval Accuracy: 0.5111, Took 1.14 s\n","Epoch [175/400], Loss: 0.9999, Eval Accuracy: 0.5114, Took 1.14 s\n","Epoch [176/400], Loss: 1.0002, Eval Accuracy: 0.5066, Took 1.14 s\n","Epoch [177/400], Loss: 0.9997, Eval Accuracy: 0.5099, Took 1.14 s\n","Epoch [178/400], Loss: 0.9992, Eval Accuracy: 0.5084, Took 1.14 s\n","Epoch [179/400], Loss: 0.9995, Eval Accuracy: 0.5096, Took 1.14 s\n","Epoch [180/400], Loss: 0.999, Eval Accuracy: 0.5087, Took 1.14 s\n","Epoch [181/400], Loss: 0.999, Eval Accuracy: 0.5101, Took 1.14 s\n","Epoch [182/400], Loss: 0.9976, Eval Accuracy: 0.5097, Took 1.14 s\n","Epoch [183/400], Loss: 0.9985, Eval Accuracy: 0.5088, Took 1.14 s\n","Epoch [184/400], Loss: 0.9981, Eval Accuracy: 0.5076, Took 1.14 s\n","Epoch [185/400], Loss: 1.0005, Eval Accuracy: 0.5084, Took 1.14 s\n","Epoch [186/400], Loss: 0.9983, Eval Accuracy: 0.5101, Took 1.14 s\n","Epoch [187/400], Loss: 0.997, Eval Accuracy: 0.5067, Took 1.14 s\n","Epoch [188/400], Loss: 0.9984, Eval Accuracy: 0.5093, Took 1.14 s\n","Epoch [189/400], Loss: 0.9966, Eval Accuracy: 0.5078, Took 1.14 s\n","Epoch [190/400], Loss: 0.9969, Eval Accuracy: 0.5084, Took 1.14 s\n","Epoch [191/400], Loss: 0.9962, Eval Accuracy: 0.5093, Took 1.15 s\n","Epoch [192/400], Loss: 0.9956, Eval Accuracy: 0.5086, Took 1.14 s\n","Epoch [193/400], Loss: 0.997, Eval Accuracy: 0.5074, Took 1.14 s\n","Epoch [194/400], Loss: 0.9961, Eval Accuracy: 0.5102, Took 1.14 s\n","Epoch [195/400], Loss: 0.9961, Eval Accuracy: 0.5087, Took 1.14 s\n","Epoch [196/400], Loss: 0.9957, Eval Accuracy: 0.5072, Took 1.14 s\n","Epoch [197/400], Loss: 0.9961, Eval Accuracy: 0.5098, Took 1.14 s\n","Epoch [198/400], Loss: 0.9957, Eval Accuracy: 0.5082, Took 1.14 s\n","Epoch [199/400], Loss: 0.9946, Eval Accuracy: 0.5064, Took 1.14 s\n","Epoch [200/400], Loss: 0.9944, Eval Accuracy: 0.507, Took 1.14 s\n","Epoch [201/400], Loss: 0.9953, Eval Accuracy: 0.5058, Took 1.15 s\n","Epoch [202/400], Loss: 0.9947, Eval Accuracy: 0.5089, Took 1.14 s\n","Epoch [203/400], Loss: 0.9941, Eval Accuracy: 0.5058, Took 1.14 s\n","Epoch [204/400], Loss: 0.9939, Eval Accuracy: 0.5053, Took 1.14 s\n","Epoch [205/400], Loss: 0.9944, Eval Accuracy: 0.5033, Took 1.14 s\n","Epoch [206/400], Loss: 0.9933, Eval Accuracy: 0.5063, Took 1.14 s\n","Epoch [207/400], Loss: 0.9946, Eval Accuracy: 0.5068, Took 1.14 s\n","Epoch [208/400], Loss: 0.9939, Eval Accuracy: 0.5045, Took 1.14 s\n","Epoch [209/400], Loss: 0.9929, Eval Accuracy: 0.5092, Took 1.14 s\n","Epoch [210/400], Loss: 0.9932, Eval Accuracy: 0.5082, Took 1.15 s\n","Epoch [211/400], Loss: 0.9923, Eval Accuracy: 0.508, Took 1.14 s\n","Epoch [212/400], Loss: 0.9918, Eval Accuracy: 0.5048, Took 1.14 s\n","Epoch [213/400], Loss: 0.992, Eval Accuracy: 0.5045, Took 1.14 s\n","Epoch [214/400], Loss: 0.9923, Eval Accuracy: 0.5078, Took 1.14 s\n","Epoch [215/400], Loss: 0.9901, Eval Accuracy: 0.505, Took 1.14 s\n","Epoch [216/400], Loss: 0.9916, Eval Accuracy: 0.5055, Took 1.14 s\n","Epoch [217/400], Loss: 0.9916, Eval Accuracy: 0.5065, Took 1.14 s\n","Epoch [218/400], Loss: 0.9911, Eval Accuracy: 0.5083, Took 1.14 s\n","Epoch [219/400], Loss: 0.9915, Eval Accuracy: 0.5056, Took 1.14 s\n","Epoch [220/400], Loss: 0.9917, Eval Accuracy: 0.5073, Took 1.15 s\n","Epoch [221/400], Loss: 0.9911, Eval Accuracy: 0.5075, Took 1.14 s\n","Epoch [222/400], Loss: 0.9909, Eval Accuracy: 0.5058, Took 1.14 s\n","Epoch [223/400], Loss: 0.991, Eval Accuracy: 0.5084, Took 1.15 s\n","Epoch [224/400], Loss: 0.9909, Eval Accuracy: 0.5053, Took 1.17 s\n","Epoch [225/400], Loss: 0.9897, Eval Accuracy: 0.5052, Took 1.17 s\n","Epoch [226/400], Loss: 0.99, Eval Accuracy: 0.5045, Took 1.17 s\n","Epoch [227/400], Loss: 0.9902, Eval Accuracy: 0.5048, Took 1.17 s\n","Epoch [228/400], Loss: 0.9905, Eval Accuracy: 0.5034, Took 1.15 s\n","Epoch [229/400], Loss: 0.9898, Eval Accuracy: 0.5029, Took 1.14 s\n","Epoch [230/400], Loss: 0.9894, Eval Accuracy: 0.5021, Took 1.14 s\n","Epoch [231/400], Loss: 0.9895, Eval Accuracy: 0.505, Took 1.14 s\n","Epoch [232/400], Loss: 0.9895, Eval Accuracy: 0.5035, Took 1.14 s\n","Epoch [233/400], Loss: 0.989, Eval Accuracy: 0.5043, Took 1.14 s\n","Epoch [234/400], Loss: 0.9886, Eval Accuracy: 0.5038, Took 1.14 s\n","Epoch [235/400], Loss: 0.9873, Eval Accuracy: 0.5056, Took 1.14 s\n","Epoch [236/400], Loss: 0.9871, Eval Accuracy: 0.5051, Took 1.14 s\n","Epoch [237/400], Loss: 0.9882, Eval Accuracy: 0.5057, Took 1.14 s\n","Epoch [238/400], Loss: 0.9895, Eval Accuracy: 0.5056, Took 1.14 s\n","Epoch [239/400], Loss: 0.9889, Eval Accuracy: 0.5064, Took 1.14 s\n","Epoch [240/400], Loss: 0.9872, Eval Accuracy: 0.5041, Took 1.16 s\n","Epoch [241/400], Loss: 0.9874, Eval Accuracy: 0.5038, Took 1.17 s\n","Epoch [242/400], Loss: 0.9859, Eval Accuracy: 0.5047, Took 1.17 s\n","Epoch [243/400], Loss: 0.9888, Eval Accuracy: 0.5062, Took 1.16 s\n","Epoch [244/400], Loss: 0.9861, Eval Accuracy: 0.5045, Took 1.17 s\n","Epoch [245/400], Loss: 0.987, Eval Accuracy: 0.5047, Took 1.17 s\n","Epoch [246/400], Loss: 0.9868, Eval Accuracy: 0.5047, Took 1.17 s\n","Epoch [247/400], Loss: 0.9868, Eval Accuracy: 0.5049, Took 1.17 s\n","Epoch [248/400], Loss: 0.9859, Eval Accuracy: 0.5026, Took 1.17 s\n","Epoch [249/400], Loss: 0.9874, Eval Accuracy: 0.5018, Took 1.14 s\n","Epoch [250/400], Loss: 0.9871, Eval Accuracy: 0.5013, Took 1.14 s\n","Epoch [251/400], Loss: 0.9861, Eval Accuracy: 0.505, Took 1.14 s\n","Epoch [252/400], Loss: 0.9863, Eval Accuracy: 0.5044, Took 1.14 s\n","Epoch [253/400], Loss: 0.9852, Eval Accuracy: 0.502, Took 1.14 s\n","Epoch [254/400], Loss: 0.9854, Eval Accuracy: 0.5053, Took 1.14 s\n","Epoch [255/400], Loss: 0.9855, Eval Accuracy: 0.5051, Took 1.14 s\n","Epoch [256/400], Loss: 0.9852, Eval Accuracy: 0.5017, Took 1.14 s\n","Epoch [257/400], Loss: 0.9858, Eval Accuracy: 0.5034, Took 1.14 s\n","Epoch [258/400], Loss: 0.9835, Eval Accuracy: 0.5046, Took 1.14 s\n","Epoch [259/400], Loss: 0.9861, Eval Accuracy: 0.5029, Took 1.14 s\n","Epoch [260/400], Loss: 0.9848, Eval Accuracy: 0.5022, Took 1.14 s\n","Epoch [261/400], Loss: 0.9844, Eval Accuracy: 0.501, Took 1.14 s\n","Epoch [262/400], Loss: 0.9846, Eval Accuracy: 0.5016, Took 1.14 s\n","Epoch [263/400], Loss: 0.9846, Eval Accuracy: 0.5015, Took 1.14 s\n","Epoch [264/400], Loss: 0.9851, Eval Accuracy: 0.5034, Took 1.14 s\n","Epoch [265/400], Loss: 0.9835, Eval Accuracy: 0.5006, Took 1.14 s\n","Epoch [266/400], Loss: 0.9838, Eval Accuracy: 0.5032, Took 1.14 s\n","Epoch [267/400], Loss: 0.9832, Eval Accuracy: 0.5023, Took 1.14 s\n","Epoch [268/400], Loss: 0.9833, Eval Accuracy: 0.5018, Took 1.14 s\n","Epoch [269/400], Loss: 0.9841, Eval Accuracy: 0.5038, Took 1.14 s\n","Epoch [270/400], Loss: 0.9831, Eval Accuracy: 0.5053, Took 1.14 s\n","Epoch [271/400], Loss: 0.982, Eval Accuracy: 0.503, Took 1.14 s\n","Epoch [272/400], Loss: 0.9819, Eval Accuracy: 0.5039, Took 1.15 s\n","Epoch [273/400], Loss: 0.9831, Eval Accuracy: 0.5009, Took 1.14 s\n","Epoch [274/400], Loss: 0.9816, Eval Accuracy: 0.5001, Took 1.14 s\n","Epoch [275/400], Loss: 0.9837, Eval Accuracy: 0.5009, Took 1.14 s\n","Epoch [276/400], Loss: 0.9821, Eval Accuracy: 0.5003, Took 1.14 s\n","Epoch [277/400], Loss: 0.9818, Eval Accuracy: 0.5017, Took 1.14 s\n","Epoch [278/400], Loss: 0.9813, Eval Accuracy: 0.5014, Took 1.14 s\n","Epoch [279/400], Loss: 0.9812, Eval Accuracy: 0.5016, Took 1.14 s\n","Epoch [280/400], Loss: 0.9817, Eval Accuracy: 0.5032, Took 1.14 s\n","Epoch [281/400], Loss: 0.9813, Eval Accuracy: 0.5017, Took 1.14 s\n","Epoch [282/400], Loss: 0.9817, Eval Accuracy: 0.5022, Took 1.14 s\n","Epoch [283/400], Loss: 0.9819, Eval Accuracy: 0.5013, Took 1.14 s\n","Epoch [284/400], Loss: 0.982, Eval Accuracy: 0.5, Took 1.14 s\n","Epoch [285/400], Loss: 0.9803, Eval Accuracy: 0.5009, Took 1.14 s\n","Epoch [286/400], Loss: 0.9807, Eval Accuracy: 0.5009, Took 1.14 s\n","Epoch [287/400], Loss: 0.9807, Eval Accuracy: 0.5012, Took 1.14 s\n","Epoch [288/400], Loss: 0.9821, Eval Accuracy: 0.5021, Took 1.14 s\n","Epoch [289/400], Loss: 0.9811, Eval Accuracy: 0.5042, Took 1.14 s\n","Epoch [290/400], Loss: 0.98, Eval Accuracy: 0.5021, Took 1.14 s\n","Epoch [291/400], Loss: 0.9803, Eval Accuracy: 0.5019, Took 1.15 s\n","Epoch [292/400], Loss: 0.9818, Eval Accuracy: 0.5032, Took 1.17 s\n","Epoch [293/400], Loss: 0.9803, Eval Accuracy: 0.5019, Took 1.17 s\n","Epoch [294/400], Loss: 0.9807, Eval Accuracy: 0.5017, Took 1.17 s\n","Epoch [295/400], Loss: 0.9797, Eval Accuracy: 0.4997, Took 1.17 s\n","Epoch [296/400], Loss: 0.9806, Eval Accuracy: 0.5025, Took 1.17 s\n","Epoch [297/400], Loss: 0.9795, Eval Accuracy: 0.5025, Took 1.16 s\n","Epoch [298/400], Loss: 0.9813, Eval Accuracy: 0.5026, Took 1.14 s\n","Epoch [299/400], Loss: 0.9801, Eval Accuracy: 0.5005, Took 1.14 s\n","Epoch [300/400], Loss: 0.98, Eval Accuracy: 0.5032, Took 1.14 s\n","Epoch [301/400], Loss: 0.9795, Eval Accuracy: 0.5009, Took 1.14 s\n","Epoch [302/400], Loss: 0.9784, Eval Accuracy: 0.5024, Took 1.14 s\n","Epoch [303/400], Loss: 0.9792, Eval Accuracy: 0.5019, Took 1.14 s\n","Epoch [304/400], Loss: 0.9779, Eval Accuracy: 0.5007, Took 1.14 s\n","Epoch [305/400], Loss: 0.9804, Eval Accuracy: 0.4982, Took 1.14 s\n","Epoch [306/400], Loss: 0.9806, Eval Accuracy: 0.5014, Took 1.14 s\n","Epoch [307/400], Loss: 0.9791, Eval Accuracy: 0.5019, Took 1.14 s\n","Epoch [308/400], Loss: 0.9787, Eval Accuracy: 0.503, Took 1.15 s\n","Epoch [309/400], Loss: 0.9789, Eval Accuracy: 0.5026, Took 1.14 s\n","Epoch [310/400], Loss: 0.9786, Eval Accuracy: 0.4999, Took 1.14 s\n","Epoch [311/400], Loss: 0.9786, Eval Accuracy: 0.5018, Took 1.14 s\n","Epoch [312/400], Loss: 0.978, Eval Accuracy: 0.4994, Took 1.14 s\n","Epoch [313/400], Loss: 0.9785, Eval Accuracy: 0.4998, Took 1.14 s\n","Epoch [314/400], Loss: 0.9775, Eval Accuracy: 0.5012, Took 1.14 s\n","Epoch [315/400], Loss: 0.976, Eval Accuracy: 0.4986, Took 1.14 s\n","Epoch [316/400], Loss: 0.9785, Eval Accuracy: 0.4999, Took 1.14 s\n","Epoch [317/400], Loss: 0.9779, Eval Accuracy: 0.5004, Took 1.14 s\n","Epoch [318/400], Loss: 0.9776, Eval Accuracy: 0.4992, Took 1.16 s\n","Epoch [319/400], Loss: 0.9769, Eval Accuracy: 0.5009, Took 1.17 s\n","Epoch [320/400], Loss: 0.9781, Eval Accuracy: 0.5025, Took 1.17 s\n","Epoch [321/400], Loss: 0.975, Eval Accuracy: 0.4982, Took 1.15 s\n","Epoch [322/400], Loss: 0.9765, Eval Accuracy: 0.4992, Took 1.14 s\n","Epoch [323/400], Loss: 0.9772, Eval Accuracy: 0.4987, Took 1.14 s\n","Epoch [324/400], Loss: 0.9763, Eval Accuracy: 0.5014, Took 1.14 s\n","Epoch [325/400], Loss: 0.9762, Eval Accuracy: 0.4987, Took 1.14 s\n","Epoch [326/400], Loss: 0.9763, Eval Accuracy: 0.5017, Took 1.15 s\n","Epoch [327/400], Loss: 0.976, Eval Accuracy: 0.5019, Took 1.15 s\n","Epoch [328/400], Loss: 0.9767, Eval Accuracy: 0.5012, Took 1.14 s\n","Epoch [329/400], Loss: 0.978, Eval Accuracy: 0.5016, Took 1.14 s\n","Epoch [330/400], Loss: 0.975, Eval Accuracy: 0.4995, Took 1.15 s\n","Epoch [331/400], Loss: 0.9773, Eval Accuracy: 0.5, Took 1.14 s\n","Epoch [332/400], Loss: 0.9772, Eval Accuracy: 0.4997, Took 1.14 s\n","Epoch [333/400], Loss: 0.9759, Eval Accuracy: 0.4991, Took 1.14 s\n","Epoch [334/400], Loss: 0.9765, Eval Accuracy: 0.501, Took 1.14 s\n","Epoch [335/400], Loss: 0.9754, Eval Accuracy: 0.5019, Took 1.14 s\n","Epoch [336/400], Loss: 0.9783, Eval Accuracy: 0.5008, Took 1.14 s\n","Epoch [337/400], Loss: 0.9762, Eval Accuracy: 0.4992, Took 1.14 s\n","Epoch [338/400], Loss: 0.9749, Eval Accuracy: 0.5, Took 1.14 s\n","Epoch [339/400], Loss: 0.9758, Eval Accuracy: 0.5005, Took 1.14 s\n","Epoch [340/400], Loss: 0.9772, Eval Accuracy: 0.4995, Took 1.14 s\n","Epoch [341/400], Loss: 0.975, Eval Accuracy: 0.5019, Took 1.14 s\n","Epoch [342/400], Loss: 0.9747, Eval Accuracy: 0.499, Took 1.14 s\n","Epoch [343/400], Loss: 0.9748, Eval Accuracy: 0.5003, Took 1.14 s\n","Epoch [344/400], Loss: 0.9748, Eval Accuracy: 0.4987, Took 1.14 s\n","Epoch [345/400], Loss: 0.9753, Eval Accuracy: 0.5015, Took 1.14 s\n","Epoch [346/400], Loss: 0.9746, Eval Accuracy: 0.498, Took 1.14 s\n","Epoch [347/400], Loss: 0.9743, Eval Accuracy: 0.4989, Took 1.14 s\n","Epoch [348/400], Loss: 0.977, Eval Accuracy: 0.4979, Took 1.14 s\n","Epoch [349/400], Loss: 0.9738, Eval Accuracy: 0.4983, Took 1.14 s\n","Epoch [350/400], Loss: 0.9732, Eval Accuracy: 0.4983, Took 1.14 s\n","Epoch [351/400], Loss: 0.973, Eval Accuracy: 0.5012, Took 1.14 s\n","Epoch [352/400], Loss: 0.974, Eval Accuracy: 0.4984, Took 1.14 s\n","Epoch [353/400], Loss: 0.9748, Eval Accuracy: 0.4988, Took 1.14 s\n","Epoch [354/400], Loss: 0.9738, Eval Accuracy: 0.4987, Took 1.14 s\n","Epoch [355/400], Loss: 0.9738, Eval Accuracy: 0.4997, Took 1.14 s\n","Epoch [356/400], Loss: 0.9736, Eval Accuracy: 0.4985, Took 1.14 s\n","Epoch [357/400], Loss: 0.9732, Eval Accuracy: 0.5004, Took 1.14 s\n","Epoch [358/400], Loss: 0.9738, Eval Accuracy: 0.4996, Took 1.14 s\n","Epoch [359/400], Loss: 0.9741, Eval Accuracy: 0.499, Took 1.14 s\n","Epoch [360/400], Loss: 0.9726, Eval Accuracy: 0.5008, Took 1.14 s\n","Epoch [361/400], Loss: 0.9738, Eval Accuracy: 0.4992, Took 1.14 s\n","Epoch [362/400], Loss: 0.9736, Eval Accuracy: 0.4981, Took 1.14 s\n","Epoch [363/400], Loss: 0.9717, Eval Accuracy: 0.4981, Took 1.14 s\n","Epoch [364/400], Loss: 0.9742, Eval Accuracy: 0.4998, Took 1.14 s\n","Epoch [365/400], Loss: 0.9732, Eval Accuracy: 0.4977, Took 1.14 s\n","Epoch [366/400], Loss: 0.973, Eval Accuracy: 0.4969, Took 1.14 s\n","Epoch [367/400], Loss: 0.9726, Eval Accuracy: 0.4984, Took 1.14 s\n","Epoch [368/400], Loss: 0.973, Eval Accuracy: 0.4982, Took 1.14 s\n","Epoch [369/400], Loss: 0.9728, Eval Accuracy: 0.4985, Took 1.14 s\n","Epoch [370/400], Loss: 0.9728, Eval Accuracy: 0.5013, Took 1.14 s\n","Epoch [371/400], Loss: 0.973, Eval Accuracy: 0.4999, Took 1.14 s\n","Epoch [372/400], Loss: 0.9739, Eval Accuracy: 0.5008, Took 1.14 s\n","Epoch [373/400], Loss: 0.973, Eval Accuracy: 0.4982, Took 1.14 s\n","Epoch [374/400], Loss: 0.9722, Eval Accuracy: 0.4997, Took 1.14 s\n","Epoch [375/400], Loss: 0.9737, Eval Accuracy: 0.4988, Took 1.14 s\n","Epoch [376/400], Loss: 0.9722, Eval Accuracy: 0.4986, Took 1.15 s\n","Epoch [377/400], Loss: 0.9712, Eval Accuracy: 0.4974, Took 1.14 s\n","Epoch [378/400], Loss: 0.972, Eval Accuracy: 0.4987, Took 1.14 s\n","Epoch [379/400], Loss: 0.9722, Eval Accuracy: 0.4984, Took 1.14 s\n","Epoch [380/400], Loss: 0.9729, Eval Accuracy: 0.499, Took 1.14 s\n","Epoch [381/400], Loss: 0.973, Eval Accuracy: 0.499, Took 1.14 s\n","Epoch [382/400], Loss: 0.9728, Eval Accuracy: 0.4963, Took 1.14 s\n","Epoch [383/400], Loss: 0.9716, Eval Accuracy: 0.4972, Took 1.14 s\n","Epoch [384/400], Loss: 0.9712, Eval Accuracy: 0.4979, Took 1.15 s\n","Epoch [385/400], Loss: 0.9729, Eval Accuracy: 0.4996, Took 1.15 s\n","Epoch [386/400], Loss: 0.9722, Eval Accuracy: 0.4985, Took 1.15 s\n","Epoch [387/400], Loss: 0.9712, Eval Accuracy: 0.4976, Took 1.14 s\n","Epoch [388/400], Loss: 0.9718, Eval Accuracy: 0.4988, Took 1.15 s\n","Epoch [389/400], Loss: 0.9715, Eval Accuracy: 0.4978, Took 1.15 s\n","Epoch [390/400], Loss: 0.9718, Eval Accuracy: 0.4972, Took 1.15 s\n","Epoch [391/400], Loss: 0.9704, Eval Accuracy: 0.4978, Took 1.15 s\n","Epoch [392/400], Loss: 0.971, Eval Accuracy: 0.4977, Took 1.15 s\n","Epoch [393/400], Loss: 0.9715, Eval Accuracy: 0.4974, Took 1.15 s\n","Epoch [394/400], Loss: 0.9711, Eval Accuracy: 0.4993, Took 1.14 s\n","Epoch [395/400], Loss: 0.9712, Eval Accuracy: 0.4972, Took 1.14 s\n","Epoch [396/400], Loss: 0.9706, Eval Accuracy: 0.498, Took 1.15 s\n","Epoch [397/400], Loss: 0.9704, Eval Accuracy: 0.4994, Took 1.14 s\n","Epoch [398/400], Loss: 0.97, Eval Accuracy: 0.5002, Took 1.15 s\n","Epoch [399/400], Loss: 0.9695, Eval Accuracy: 0.4964, Took 1.14 s\n","Epoch [400/400], Loss: 0.9712, Eval Accuracy: 0.4985, Took 1.15 s\n","Average eval Loss: 1.024, Best Eval Accuracy: 0.525, Took 458.69 s\n","Model saved as 20240627091800_encoder_64em_2l_4h_05dr_400ep.pt\n","------------\n","Not saved as loss too high:\n","[]\n"]}],"source":["# Train single model without stopping\n","EMBED_DIM = [64]\n","NUM_ENCODER_LAYERS = [2]\n","NUM_HEADS = [4]\n","dropouts = [0.5]\n","POS_ENC = [False]\n","accuracies, all_accuracies, best_model_state = e.hyper_parameter_training(EMBED_DIM, NUM_ENCODER_LAYERS, NUM_HEADS, dropouts, POS_ENC, epochs=400, validation_stop=False)"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["training_results = {\n","    \"time\": 459,\n","    \"best_model_state\": best_model_state,\n","    \"all_accuracies\": all_accuracies['encoder_64em_2l_4h_05dr_400ep']\n","}"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["mlh.to_pickle(training_results, data_path+f'/{e.organism}/training_results_encoder.pkl')"]},{"cell_type":"markdown","metadata":{},"source":["#### Dropout"]},{"cell_type":"code","execution_count":34,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["----- Start Training: 256 emb, 4 layers, 4 heads, 0.1 dropout, positional encoding: False, 50 epochs -----\n","Epoch [1/50], Loss: 1.1639, Eval Accuracy: 0.4962, Took 3.68 s\n","Epoch [2/50], Loss: 1.0538, Eval Accuracy: 0.5166, Took 3.68 s\n","Epoch [3/50], Loss: 1.0461, Eval Accuracy: 0.5178, Took 3.69 s\n","Epoch [4/50], Loss: 1.0421, Eval Accuracy: 0.52, Took 3.68 s\n","Epoch [5/50], Loss: 1.0397, Eval Accuracy: 0.5076, Took 3.71 s\n","Epoch [6/50], Loss: 1.0378, Eval Accuracy: 0.5178, Took 3.71 s\n","Epoch [7/50], Loss: 1.0361, Eval Accuracy: 0.5162, Took 3.71 s\n","Epoch [8/50], Loss: 1.0355, Eval Accuracy: 0.5191, Took 3.71 s\n","Epoch [9/50], Loss: 1.0326, Eval Accuracy: 0.5233, Took 3.71 s\n","Epoch [10/50], Loss: 1.0331, Eval Accuracy: 0.5229, Took 3.71 s\n","Epoch [11/50], Loss: 1.0323, Eval Accuracy: 0.5174, Took 3.71 s\n","Epoch [12/50], Loss: 1.0308, Eval Accuracy: 0.5192, Took 3.72 s\n","Epoch [13/50], Loss: 1.031, Eval Accuracy: 0.5226, Took 3.72 s\n","Epoch [14/50], Loss: 1.0299, Eval Accuracy: 0.5203, Took 3.71 s\n","Epoch [15/50], Loss: 1.0305, Eval Accuracy: 0.5211, Took 3.72 s\n","Epoch [16/50], Loss: 1.0291, Eval Accuracy: 0.5183, Took 3.72 s\n","Stopped early after epoch 16 as validation accuracy was lower than average of the last 7 accuracies.\n","Last Loss: 1.0291, Last Eval Accuracy: 0.5183, Took 59.32 s\n","Model saved as 20240603142405_encoder_256em_4l_4h_01dr_16ep.pt\n","----- Start Training: 256 emb, 4 layers, 4 heads, 0.2 dropout, positional encoding: False, 50 epochs -----\n","Epoch [1/50], Loss: 1.173, Eval Accuracy: 0.497, Took 3.71 s\n","Epoch [2/50], Loss: 1.0587, Eval Accuracy: 0.5184, Took 3.72 s\n","Epoch [3/50], Loss: 1.0489, Eval Accuracy: 0.515, Took 3.72 s\n","Epoch [4/50], Loss: 1.0437, Eval Accuracy: 0.5206, Took 3.71 s\n","Epoch [5/50], Loss: 1.0405, Eval Accuracy: 0.5092, Took 3.72 s\n","Epoch [6/50], Loss: 1.0381, Eval Accuracy: 0.5177, Took 3.72 s\n","Epoch [7/50], Loss: 1.0362, Eval Accuracy: 0.5159, Took 3.71 s\n","Epoch [8/50], Loss: 1.0355, Eval Accuracy: 0.5185, Took 3.72 s\n","Epoch [9/50], Loss: 1.0329, Eval Accuracy: 0.5242, Took 3.72 s\n","Epoch [10/50], Loss: 1.0328, Eval Accuracy: 0.5236, Took 3.71 s\n","Epoch [11/50], Loss: 1.0319, Eval Accuracy: 0.5177, Took 3.72 s\n","Epoch [12/50], Loss: 1.0308, Eval Accuracy: 0.5194, Took 3.72 s\n","Epoch [13/50], Loss: 1.0311, Eval Accuracy: 0.523, Took 3.71 s\n","Epoch [14/50], Loss: 1.0297, Eval Accuracy: 0.5208, Took 3.73 s\n","Epoch [15/50], Loss: 1.0304, Eval Accuracy: 0.521, Took 3.72 s\n","Epoch [16/50], Loss: 1.0289, Eval Accuracy: 0.5189, Took 3.72 s\n","Stopped early after epoch 16 as validation accuracy was lower than average of the last 7 accuracies.\n","Last Loss: 1.0289, Last Eval Accuracy: 0.5189, Took 59.49 s\n","Model saved as 20240603142505_encoder_256em_4l_4h_02dr_16ep.pt\n","----- Start Training: 256 emb, 4 layers, 4 heads, 0.3 dropout, positional encoding: False, 50 epochs -----\n","Epoch [1/50], Loss: 1.1835, Eval Accuracy: 0.4922, Took 3.72 s\n","Epoch [2/50], Loss: 1.0628, Eval Accuracy: 0.5202, Took 3.72 s\n","Epoch [3/50], Loss: 1.0509, Eval Accuracy: 0.5133, Took 3.71 s\n","Epoch [4/50], Loss: 1.0445, Eval Accuracy: 0.5207, Took 3.72 s\n","Epoch [5/50], Loss: 1.0408, Eval Accuracy: 0.5116, Took 3.72 s\n","Epoch [6/50], Loss: 1.038, Eval Accuracy: 0.5179, Took 3.71 s\n","Epoch [7/50], Loss: 1.036, Eval Accuracy: 0.5158, Took 3.72 s\n","Epoch [8/50], Loss: 1.0355, Eval Accuracy: 0.5182, Took 3.72 s\n","Epoch [9/50], Loss: 1.0333, Eval Accuracy: 0.5239, Took 3.72 s\n","Epoch [10/50], Loss: 1.0329, Eval Accuracy: 0.5229, Took 3.72 s\n","Epoch [11/50], Loss: 1.032, Eval Accuracy: 0.5175, Took 3.72 s\n","Epoch [12/50], Loss: 1.031, Eval Accuracy: 0.519, Took 3.72 s\n","Epoch [13/50], Loss: 1.0313, Eval Accuracy: 0.5229, Took 3.72 s\n","Epoch [14/50], Loss: 1.0298, Eval Accuracy: 0.5211, Took 3.72 s\n","Epoch [15/50], Loss: 1.0304, Eval Accuracy: 0.5205, Took 3.72 s\n","Epoch [16/50], Loss: 1.0294, Eval Accuracy: 0.5182, Took 3.73 s\n","Stopped early after epoch 16 as validation accuracy was lower than average of the last 7 accuracies.\n","Last Loss: 1.0294, Last Eval Accuracy: 0.5182, Took 59.53 s\n","Model saved as 20240603142604_encoder_256em_4l_4h_03dr_16ep.pt\n","----- Start Training: 256 emb, 4 layers, 4 heads, 0.4 dropout, positional encoding: False, 50 epochs -----\n","Epoch [1/50], Loss: 1.1964, Eval Accuracy: 0.4949, Took 3.73 s\n","Epoch [2/50], Loss: 1.0667, Eval Accuracy: 0.5201, Took 3.72 s\n","Epoch [3/50], Loss: 1.0524, Eval Accuracy: 0.5146, Took 3.72 s\n","Epoch [4/50], Loss: 1.0448, Eval Accuracy: 0.5208, Took 3.72 s\n","Epoch [5/50], Loss: 1.0409, Eval Accuracy: 0.5145, Took 3.72 s\n","Epoch [6/50], Loss: 1.038, Eval Accuracy: 0.5182, Took 3.72 s\n","Epoch [7/50], Loss: 1.0362, Eval Accuracy: 0.5155, Took 3.72 s\n","Epoch [8/50], Loss: 1.0357, Eval Accuracy: 0.5181, Took 3.72 s\n","Epoch [9/50], Loss: 1.0337, Eval Accuracy: 0.524, Took 3.72 s\n","Epoch [10/50], Loss: 1.0332, Eval Accuracy: 0.5227, Took 3.72 s\n","Epoch [11/50], Loss: 1.0322, Eval Accuracy: 0.5175, Took 3.72 s\n","Epoch [12/50], Loss: 1.0313, Eval Accuracy: 0.519, Took 3.72 s\n","Epoch [13/50], Loss: 1.0317, Eval Accuracy: 0.5228, Took 3.72 s\n","Epoch [14/50], Loss: 1.0302, Eval Accuracy: 0.5219, Took 3.72 s\n","Epoch [15/50], Loss: 1.0309, Eval Accuracy: 0.5202, Took 3.72 s\n","Epoch [16/50], Loss: 1.0299, Eval Accuracy: 0.5182, Took 3.72 s\n","Stopped early after epoch 16 as validation accuracy was lower than average of the last 7 accuracies.\n","Last Loss: 1.0299, Last Eval Accuracy: 0.5182, Took 59.54 s\n","Model saved as 20240603142704_encoder_256em_4l_4h_04dr_16ep.pt\n","----- Start Training: 256 emb, 4 layers, 4 heads, 0.5 dropout, positional encoding: False, 50 epochs -----\n","Epoch [1/50], Loss: 1.2133, Eval Accuracy: 0.4983, Took 3.71 s\n","Epoch [2/50], Loss: 1.0712, Eval Accuracy: 0.5184, Took 3.71 s\n","Epoch [3/50], Loss: 1.054, Eval Accuracy: 0.5144, Took 3.7 s\n","Epoch [4/50], Loss: 1.0453, Eval Accuracy: 0.5207, Took 3.7 s\n","Epoch [5/50], Loss: 1.0413, Eval Accuracy: 0.5144, Took 3.69 s\n","Epoch [6/50], Loss: 1.0383, Eval Accuracy: 0.5177, Took 3.7 s\n","Epoch [7/50], Loss: 1.0366, Eval Accuracy: 0.5137, Took 3.7 s\n","Epoch [8/50], Loss: 1.0361, Eval Accuracy: 0.5183, Took 3.7 s\n","Epoch [9/50], Loss: 1.0345, Eval Accuracy: 0.524, Took 3.7 s\n","Epoch [10/50], Loss: 1.0337, Eval Accuracy: 0.5226, Took 3.7 s\n","Epoch [11/50], Loss: 1.0328, Eval Accuracy: 0.5177, Took 3.7 s\n","Epoch [12/50], Loss: 1.0318, Eval Accuracy: 0.519, Took 3.7 s\n","Epoch [13/50], Loss: 1.0322, Eval Accuracy: 0.5223, Took 3.7 s\n","Epoch [14/50], Loss: 1.0308, Eval Accuracy: 0.5222, Took 3.7 s\n","Epoch [15/50], Loss: 1.033, Eval Accuracy: 0.5225, Took 3.7 s\n","Epoch [16/50], Loss: 1.0315, Eval Accuracy: 0.5174, Took 3.71 s\n","Stopped early after epoch 16 as validation accuracy was lower than average of the last 7 accuracies.\n","Last Loss: 1.0315, Last Eval Accuracy: 0.5174, Took 59.23 s\n","Model saved as 20240603142803_encoder_256em_4l_4h_05dr_16ep.pt\n","------------\n","Not saved as loss too high:\n","[]\n"]},{"data":{"text/plain":["{'encoder_256em_4l_4h_01dr_50ep': 0.5183,\n"," 'encoder_256em_4l_4h_02dr_50ep': 0.5189,\n"," 'encoder_256em_4l_4h_03dr_50ep': 0.5182,\n"," 'encoder_256em_4l_4h_04dr_50ep': 0.5182,\n"," 'encoder_256em_4l_4h_05dr_50ep': 0.5174}"]},"execution_count":34,"metadata":{},"output_type":"execute_result"}],"source":["EMBED_DIM = [256]\n","NUM_ENCODER_LAYERS = [4]\n","NUM_HEADS = [4]\n","dropouts = [0.1, 0.2, 0.3, 0.4, 0.5]\n","POS_ENC = [False]\n","e.hyper_parameter_training(EMBED_DIM, NUM_ENCODER_LAYERS, NUM_HEADS, dropouts, POS_ENC)"]},{"cell_type":"markdown","metadata":{},"source":["#### Embedding Dimension"]},{"cell_type":"code","execution_count":35,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["----- Start Training: 16 emb, 4 layers, 4 heads, 0.5 dropout, positional encoding: False, 50 epochs -----\n","Epoch [1/50], Loss: 3.0332, Eval Accuracy: 0.5129, Took 2.03 s\n","Epoch [2/50], Loss: 2.3796, Eval Accuracy: 0.5145, Took 2.02 s\n","Epoch [3/50], Loss: 1.9794, Eval Accuracy: 0.5145, Took 2.02 s\n","Epoch [4/50], Loss: 1.7237, Eval Accuracy: 0.5155, Took 2.03 s\n","Epoch [5/50], Loss: 1.5641, Eval Accuracy: 0.5155, Took 2.02 s\n","Epoch [6/50], Loss: 1.4599, Eval Accuracy: 0.5145, Took 2.02 s\n","Epoch [7/50], Loss: 1.3854, Eval Accuracy: 0.5155, Took 2.02 s\n","Epoch [8/50], Loss: 1.3323, Eval Accuracy: 0.5155, Took 2.02 s\n","Epoch [9/50], Loss: 1.291, Eval Accuracy: 0.5155, Took 2.03 s\n","Epoch [10/50], Loss: 1.2609, Eval Accuracy: 0.5155, Took 2.03 s\n","Epoch [11/50], Loss: 1.2362, Eval Accuracy: 0.5155, Took 2.03 s\n","Epoch [12/50], Loss: 1.2157, Eval Accuracy: 0.5155, Took 2.03 s\n","Epoch [13/50], Loss: 1.2004, Eval Accuracy: 0.5155, Took 2.03 s\n","Epoch [14/50], Loss: 1.1867, Eval Accuracy: 0.5155, Took 2.03 s\n","Epoch [15/50], Loss: 1.1766, Eval Accuracy: 0.5155, Took 2.03 s\n","Epoch [16/50], Loss: 1.1675, Eval Accuracy: 0.5155, Took 2.03 s\n","Epoch [17/50], Loss: 1.1607, Eval Accuracy: 0.5155, Took 2.03 s\n","Epoch [18/50], Loss: 1.1536, Eval Accuracy: 0.5145, Took 2.03 s\n","Stopped early after epoch 18 as validation accuracy was lower than average of the last 7 accuracies.\n","Last Loss: 1.1536, Last Eval Accuracy: 0.5145, Took 36.47 s\n","Model saved as 20240603143100_encoder_16em_4l_4h_05dr_18ep.pt\n","----- Start Training: 32 emb, 4 layers, 4 heads, 0.5 dropout, positional encoding: False, 50 epochs -----\n","Epoch [1/50], Loss: 2.3956, Eval Accuracy: 0.5112, Took 2.07 s\n","Epoch [2/50], Loss: 1.641, Eval Accuracy: 0.5155, Took 2.07 s\n","Epoch [3/50], Loss: 1.3713, Eval Accuracy: 0.5155, Took 2.08 s\n","Epoch [4/50], Loss: 1.2538, Eval Accuracy: 0.5154, Took 2.07 s\n","Epoch [5/50], Loss: 1.1901, Eval Accuracy: 0.5152, Took 2.08 s\n","Epoch [6/50], Loss: 1.1515, Eval Accuracy: 0.516, Took 2.08 s\n","Epoch [7/50], Loss: 1.1238, Eval Accuracy: 0.5164, Took 2.08 s\n","Epoch [8/50], Loss: 1.1059, Eval Accuracy: 0.516, Took 2.08 s\n","Epoch [9/50], Loss: 1.0911, Eval Accuracy: 0.5164, Took 2.08 s\n","Epoch [10/50], Loss: 1.0817, Eval Accuracy: 0.516, Took 2.08 s\n","Epoch [11/50], Loss: 1.0745, Eval Accuracy: 0.5167, Took 2.08 s\n","Epoch [12/50], Loss: 1.0685, Eval Accuracy: 0.5172, Took 2.08 s\n","Epoch [13/50], Loss: 1.0655, Eval Accuracy: 0.5169, Took 2.08 s\n","Epoch [14/50], Loss: 1.0611, Eval Accuracy: 0.5173, Took 2.08 s\n","Epoch [15/50], Loss: 1.0591, Eval Accuracy: 0.5165, Took 2.08 s\n","Epoch [16/50], Loss: 1.0554, Eval Accuracy: 0.5179, Took 2.07 s\n","Epoch [17/50], Loss: 1.054, Eval Accuracy: 0.5175, Took 2.07 s\n","Epoch [18/50], Loss: 1.0515, Eval Accuracy: 0.5175, Took 2.07 s\n","Epoch [19/50], Loss: 1.0504, Eval Accuracy: 0.5187, Took 2.07 s\n","Epoch [20/50], Loss: 1.0492, Eval Accuracy: 0.5176, Took 2.07 s\n","Epoch [21/50], Loss: 1.049, Eval Accuracy: 0.5183, Took 2.07 s\n","Epoch [22/50], Loss: 1.0466, Eval Accuracy: 0.5178, Took 2.08 s\n","Epoch [23/50], Loss: 1.047, Eval Accuracy: 0.5181, Took 2.08 s\n","Epoch [24/50], Loss: 1.0454, Eval Accuracy: 0.5196, Took 2.08 s\n","Epoch [25/50], Loss: 1.0446, Eval Accuracy: 0.5222, Took 2.08 s\n","Epoch [26/50], Loss: 1.0447, Eval Accuracy: 0.5213, Took 2.08 s\n","Epoch [27/50], Loss: 1.0441, Eval Accuracy: 0.5198, Took 2.08 s\n","Epoch [28/50], Loss: 1.0431, Eval Accuracy: 0.5199, Took 2.08 s\n","Epoch [29/50], Loss: 1.0432, Eval Accuracy: 0.521, Took 2.08 s\n","Epoch [30/50], Loss: 1.0419, Eval Accuracy: 0.5203, Took 2.08 s\n","Epoch [31/50], Loss: 1.042, Eval Accuracy: 0.5199, Took 2.08 s\n","Stopped early after epoch 31 as validation accuracy was lower than average of the last 7 accuracies.\n","Last Loss: 1.042, Last Eval Accuracy: 0.5199, Took 64.43 s\n","Model saved as 20240603143205_encoder_32em_4l_4h_05dr_31ep.pt\n","----- Start Training: 64 emb, 4 layers, 4 heads, 0.5 dropout, positional encoding: False, 50 epochs -----\n","Epoch [1/50], Loss: 1.7575, Eval Accuracy: 0.5149, Took 2.2 s\n","Epoch [2/50], Loss: 1.2396, Eval Accuracy: 0.5146, Took 2.2 s\n","Epoch [3/50], Loss: 1.1453, Eval Accuracy: 0.5151, Took 2.2 s\n","Epoch [4/50], Loss: 1.1037, Eval Accuracy: 0.5177, Took 2.2 s\n","Epoch [5/50], Loss: 1.0812, Eval Accuracy: 0.5164, Took 2.21 s\n","Epoch [6/50], Loss: 1.0673, Eval Accuracy: 0.5163, Took 2.2 s\n","Epoch [7/50], Loss: 1.0583, Eval Accuracy: 0.5161, Took 2.2 s\n","Epoch [8/50], Loss: 1.0529, Eval Accuracy: 0.5177, Took 2.2 s\n","Epoch [9/50], Loss: 1.0481, Eval Accuracy: 0.521, Took 2.21 s\n","Epoch [10/50], Loss: 1.045, Eval Accuracy: 0.5228, Took 2.2 s\n","Epoch [11/50], Loss: 1.0425, Eval Accuracy: 0.5182, Took 2.2 s\n","Epoch [12/50], Loss: 1.0404, Eval Accuracy: 0.5198, Took 2.2 s\n","Epoch [13/50], Loss: 1.0405, Eval Accuracy: 0.5229, Took 2.21 s\n","Epoch [14/50], Loss: 1.0376, Eval Accuracy: 0.5228, Took 2.2 s\n","Epoch [15/50], Loss: 1.0374, Eval Accuracy: 0.5195, Took 2.2 s\n","Epoch [16/50], Loss: 1.0363, Eval Accuracy: 0.5231, Took 2.2 s\n","Epoch [17/50], Loss: 1.0359, Eval Accuracy: 0.5227, Took 2.21 s\n","Epoch [18/50], Loss: 1.0348, Eval Accuracy: 0.5212, Took 2.2 s\n","Epoch [19/50], Loss: 1.0344, Eval Accuracy: 0.5223, Took 2.2 s\n","Epoch [20/50], Loss: 1.0343, Eval Accuracy: 0.5219, Took 2.2 s\n","Stopped early after epoch 20 as validation accuracy was lower than average of the last 7 accuracies.\n","Last Loss: 1.0343, Last Eval Accuracy: 0.5219, Took 44.08 s\n","Model saved as 20240603143249_encoder_64em_4l_4h_05dr_20ep.pt\n","----- Start Training: 128 emb, 4 layers, 4 heads, 0.5 dropout, positional encoding: False, 50 epochs -----\n","Epoch [1/50], Loss: 1.3783, Eval Accuracy: 0.5171, Took 2.51 s\n","Epoch [2/50], Loss: 1.109, Eval Accuracy: 0.5169, Took 2.52 s\n","Epoch [3/50], Loss: 1.0744, Eval Accuracy: 0.5121, Took 2.51 s\n","Epoch [4/50], Loss: 1.0582, Eval Accuracy: 0.5202, Took 2.51 s\n","Epoch [5/50], Loss: 1.0496, Eval Accuracy: 0.5191, Took 2.51 s\n","Epoch [6/50], Loss: 1.0446, Eval Accuracy: 0.5169, Took 2.51 s\n","Epoch [7/50], Loss: 1.0412, Eval Accuracy: 0.5123, Took 2.51 s\n","Epoch [8/50], Loss: 1.0394, Eval Accuracy: 0.5195, Took 2.51 s\n","Stopped early after epoch 8 as validation accuracy was lower than average of the last 7 accuracies.\n","Last Loss: 1.0394, Last Eval Accuracy: 0.5195, Took 20.1 s\n","Model saved as 20240603143309_encoder_128em_4l_4h_05dr_8ep.pt\n","----- Start Training: 256 emb, 4 layers, 4 heads, 0.5 dropout, positional encoding: False, 50 epochs -----\n","Epoch [1/50], Loss: 1.2133, Eval Accuracy: 0.4983, Took 3.72 s\n","Epoch [2/50], Loss: 1.0712, Eval Accuracy: 0.5184, Took 3.72 s\n","Epoch [3/50], Loss: 1.054, Eval Accuracy: 0.5144, Took 3.72 s\n","Epoch [4/50], Loss: 1.0453, Eval Accuracy: 0.5207, Took 3.71 s\n","Epoch [5/50], Loss: 1.0413, Eval Accuracy: 0.5144, Took 3.72 s\n","Epoch [6/50], Loss: 1.0383, Eval Accuracy: 0.5177, Took 3.72 s\n","Epoch [7/50], Loss: 1.0366, Eval Accuracy: 0.5137, Took 3.72 s\n","Epoch [8/50], Loss: 1.0361, Eval Accuracy: 0.5183, Took 3.72 s\n","Epoch [9/50], Loss: 1.0345, Eval Accuracy: 0.524, Took 3.72 s\n","Epoch [10/50], Loss: 1.0337, Eval Accuracy: 0.5226, Took 3.72 s\n","Epoch [11/50], Loss: 1.0328, Eval Accuracy: 0.5177, Took 3.71 s\n","Epoch [12/50], Loss: 1.0318, Eval Accuracy: 0.519, Took 3.7 s\n","Epoch [13/50], Loss: 1.0322, Eval Accuracy: 0.5223, Took 3.69 s\n","Epoch [14/50], Loss: 1.0308, Eval Accuracy: 0.5222, Took 3.7 s\n","Epoch [15/50], Loss: 1.033, Eval Accuracy: 0.5225, Took 3.7 s\n","Epoch [16/50], Loss: 1.0315, Eval Accuracy: 0.5174, Took 3.7 s\n","Stopped early after epoch 16 as validation accuracy was lower than average of the last 7 accuracies.\n","Last Loss: 1.0315, Last Eval Accuracy: 0.5174, Took 59.38 s\n","Model saved as 20240603143408_encoder_256em_4l_4h_05dr_16ep.pt\n","----- Start Training: 512 emb, 4 layers, 4 heads, 0.5 dropout, positional encoding: False, 50 epochs -----\n","Epoch [1/50], Loss: 1.1683, Eval Accuracy: 0.4891, Took 6.86 s\n","Epoch [2/50], Loss: 1.0637, Eval Accuracy: 0.52, Took 6.86 s\n","Epoch [3/50], Loss: 1.0497, Eval Accuracy: 0.5158, Took 6.87 s\n","Epoch [4/50], Loss: 1.0434, Eval Accuracy: 0.5201, Took 6.86 s\n","Epoch [5/50], Loss: 1.0399, Eval Accuracy: 0.5002, Took 6.85 s\n","Epoch [6/50], Loss: 1.0382, Eval Accuracy: 0.5178, Took 6.87 s\n","Epoch [7/50], Loss: 1.0366, Eval Accuracy: 0.516, Took 6.88 s\n","Epoch [8/50], Loss: 1.036, Eval Accuracy: 0.5175, Took 6.89 s\n","Epoch [9/50], Loss: 1.0337, Eval Accuracy: 0.5241, Took 6.86 s\n","Epoch [10/50], Loss: 1.0339, Eval Accuracy: 0.5215, Took 6.86 s\n","Epoch [11/50], Loss: 1.0335, Eval Accuracy: 0.518, Took 6.87 s\n","Epoch [12/50], Loss: 1.0325, Eval Accuracy: 0.5218, Took 6.87 s\n","Epoch [13/50], Loss: 1.0328, Eval Accuracy: 0.5218, Took 6.88 s\n","Epoch [14/50], Loss: 1.0328, Eval Accuracy: 0.5203, Took 6.89 s\n","Epoch [15/50], Loss: 1.0351, Eval Accuracy: 0.5211, Took 6.87 s\n","Epoch [16/50], Loss: 1.0335, Eval Accuracy: 0.506, Took 6.9 s\n","Stopped early after epoch 16 as validation accuracy was lower than average of the last 7 accuracies.\n","Last Loss: 1.0335, Last Eval Accuracy: 0.506, Took 109.96 s\n","Model saved as 20240603143558_encoder_512em_4l_4h_05dr_16ep.pt\n","------------\n","Not saved as loss too high:\n","[]\n"]},{"data":{"text/plain":["{'encoder_16em_4l_4h_05dr_50ep': 0.5145,\n"," 'encoder_32em_4l_4h_05dr_50ep': 0.5199,\n"," 'encoder_64em_4l_4h_05dr_50ep': 0.5219,\n"," 'encoder_128em_4l_4h_05dr_50ep': 0.5195,\n"," 'encoder_256em_4l_4h_05dr_50ep': 0.5174,\n"," 'encoder_512em_4l_4h_05dr_50ep': 0.506}"]},"execution_count":35,"metadata":{},"output_type":"execute_result"}],"source":["embed_dims = [16, 32, 64, 128, 256, 512]\n","NUM_ENCODER_LAYERS = [4]\n","NUM_HEADS = [4]\n","DROPOUTS = [0.5]\n","POS_ENC = [False]\n","e.hyper_parameter_training(embed_dims, NUM_ENCODER_LAYERS, NUM_HEADS, DROPOUTS, POS_ENC)"]},{"cell_type":"markdown","metadata":{},"source":["#### Number Encoder Layers and Heads"]},{"cell_type":"code","execution_count":36,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/mkuehn/.local/lib/python3.10/site-packages/torch/nn/modules/transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n","  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"]},{"name":"stdout","output_type":"stream","text":["----- Start Training: 64 emb, 1 layers, 1 heads, 0.5 dropout, positional encoding: False, 50 epochs -----\n","Epoch [1/50], Loss: 1.8965, Eval Accuracy: 0.5156, Took 0.51 s\n","Epoch [2/50], Loss: 1.2653, Eval Accuracy: 0.5155, Took 0.51 s\n","Epoch [3/50], Loss: 1.1597, Eval Accuracy: 0.5155, Took 0.51 s\n","Epoch [4/50], Loss: 1.1151, Eval Accuracy: 0.5155, Took 0.51 s\n","Epoch [5/50], Loss: 1.0909, Eval Accuracy: 0.5166, Took 0.51 s\n","Epoch [6/50], Loss: 1.0769, Eval Accuracy: 0.5145, Took 0.5 s\n","Epoch [7/50], Loss: 1.0671, Eval Accuracy: 0.5152, Took 0.51 s\n","Epoch [8/50], Loss: 1.0622, Eval Accuracy: 0.5154, Took 0.51 s\n","Stopped early after epoch 8 as validation accuracy was lower than average of the last 7 accuracies.\n","Last Loss: 1.0622, Last Eval Accuracy: 0.5154, Took 4.05 s\n","Model saved as 20240603143811_encoder_64em_1l_1h_05dr_8ep.pt\n","----- Start Training: 64 emb, 1 layers, 2 heads, 0.5 dropout, positional encoding: False, 50 epochs -----\n","Epoch [1/50], Loss: 1.8958, Eval Accuracy: 0.5162, Took 0.55 s\n","Epoch [2/50], Loss: 1.2656, Eval Accuracy: 0.5155, Took 0.55 s\n","Epoch [3/50], Loss: 1.1588, Eval Accuracy: 0.5161, Took 0.55 s\n","Epoch [4/50], Loss: 1.1144, Eval Accuracy: 0.5157, Took 0.55 s\n","Epoch [5/50], Loss: 1.0906, Eval Accuracy: 0.5146, Took 0.55 s\n","Epoch [6/50], Loss: 1.0764, Eval Accuracy: 0.5146, Took 0.56 s\n","Epoch [7/50], Loss: 1.0666, Eval Accuracy: 0.5148, Took 0.55 s\n","Epoch [8/50], Loss: 1.0613, Eval Accuracy: 0.516, Took 0.55 s\n","Stopped early after epoch 8 as validation accuracy was lower than average of the last 7 accuracies.\n","Last Loss: 1.0613, Last Eval Accuracy: 0.516, Took 4.41 s\n","Model saved as 20240603143816_encoder_64em_1l_2h_05dr_8ep.pt\n","----- Start Training: 64 emb, 1 layers, 4 heads, 0.5 dropout, positional encoding: False, 50 epochs -----\n","Epoch [1/50], Loss: 1.896, Eval Accuracy: 0.5154, Took 0.62 s\n","Epoch [2/50], Loss: 1.265, Eval Accuracy: 0.5155, Took 0.62 s\n","Epoch [3/50], Loss: 1.1592, Eval Accuracy: 0.5156, Took 0.63 s\n","Epoch [4/50], Loss: 1.1132, Eval Accuracy: 0.5155, Took 0.63 s\n","Epoch [5/50], Loss: 1.0901, Eval Accuracy: 0.5167, Took 0.62 s\n","Epoch [6/50], Loss: 1.0757, Eval Accuracy: 0.515, Took 0.62 s\n","Epoch [7/50], Loss: 1.0654, Eval Accuracy: 0.5147, Took 0.63 s\n","Epoch [8/50], Loss: 1.06, Eval Accuracy: 0.5165, Took 0.63 s\n","Stopped early after epoch 8 as validation accuracy was lower than average of the last 7 accuracies.\n","Last Loss: 1.06, Last Eval Accuracy: 0.5165, Took 5.01 s\n","Model saved as 20240603143821_encoder_64em_1l_4h_05dr_8ep.pt\n","----- Start Training: 64 emb, 1 layers, 8 heads, 0.5 dropout, positional encoding: False, 50 epochs -----\n","Epoch [1/50], Loss: 1.8966, Eval Accuracy: 0.515, Took 0.78 s\n","Epoch [2/50], Loss: 1.265, Eval Accuracy: 0.5155, Took 0.78 s\n","Epoch [3/50], Loss: 1.1581, Eval Accuracy: 0.5156, Took 0.78 s\n","Epoch [4/50], Loss: 1.1135, Eval Accuracy: 0.5155, Took 0.78 s\n","Epoch [5/50], Loss: 1.0893, Eval Accuracy: 0.5152, Took 0.78 s\n","Epoch [6/50], Loss: 1.0751, Eval Accuracy: 0.5154, Took 0.78 s\n","Epoch [7/50], Loss: 1.0648, Eval Accuracy: 0.5142, Took 0.78 s\n","Epoch [8/50], Loss: 1.0595, Eval Accuracy: 0.5173, Took 0.78 s\n","Epoch [9/50], Loss: 1.0534, Eval Accuracy: 0.5184, Took 0.78 s\n","Epoch [10/50], Loss: 1.0505, Eval Accuracy: 0.5192, Took 0.78 s\n","Epoch [11/50], Loss: 1.0478, Eval Accuracy: 0.518, Took 0.78 s\n","Epoch [12/50], Loss: 1.0449, Eval Accuracy: 0.5183, Took 0.78 s\n","Epoch [13/50], Loss: 1.0445, Eval Accuracy: 0.5192, Took 0.78 s\n","Epoch [14/50], Loss: 1.0425, Eval Accuracy: 0.5175, Took 0.78 s\n","Epoch [15/50], Loss: 1.0414, Eval Accuracy: 0.5187, Took 0.78 s\n","Stopped early after epoch 15 as validation accuracy was lower than average of the last 7 accuracies.\n","Last Loss: 1.0414, Last Eval Accuracy: 0.5187, Took 11.73 s\n","Model saved as 20240603143832_encoder_64em_1l_8h_05dr_15ep.pt\n","----- Start Training: 64 emb, 2 layers, 1 heads, 0.5 dropout, positional encoding: False, 50 epochs -----\n","Epoch [1/50], Loss: 1.796, Eval Accuracy: 0.5147, Took 0.89 s\n","Epoch [2/50], Loss: 1.2471, Eval Accuracy: 0.5146, Took 0.89 s\n","Epoch [3/50], Loss: 1.1491, Eval Accuracy: 0.5161, Took 0.89 s\n","Epoch [4/50], Loss: 1.1068, Eval Accuracy: 0.5168, Took 0.89 s\n","Epoch [5/50], Loss: 1.0838, Eval Accuracy: 0.5191, Took 0.89 s\n","Epoch [6/50], Loss: 1.0693, Eval Accuracy: 0.5168, Took 0.89 s\n","Epoch [7/50], Loss: 1.0596, Eval Accuracy: 0.516, Took 0.89 s\n","Epoch [8/50], Loss: 1.0542, Eval Accuracy: 0.5203, Took 0.89 s\n","Epoch [9/50], Loss: 1.0492, Eval Accuracy: 0.5199, Took 0.9 s\n","Epoch [10/50], Loss: 1.0464, Eval Accuracy: 0.5208, Took 0.9 s\n","Epoch [11/50], Loss: 1.0442, Eval Accuracy: 0.5179, Took 0.9 s\n","Epoch [12/50], Loss: 1.0416, Eval Accuracy: 0.5193, Took 0.9 s\n","Epoch [13/50], Loss: 1.0411, Eval Accuracy: 0.5221, Took 0.9 s\n","Epoch [14/50], Loss: 1.0387, Eval Accuracy: 0.5224, Took 0.9 s\n","Epoch [15/50], Loss: 1.0387, Eval Accuracy: 0.5204, Took 0.9 s\n","Epoch [16/50], Loss: 1.0373, Eval Accuracy: 0.5225, Took 0.9 s\n","Epoch [17/50], Loss: 1.0371, Eval Accuracy: 0.5228, Took 0.9 s\n","Epoch [18/50], Loss: 1.0352, Eval Accuracy: 0.5232, Took 0.9 s\n","Epoch [19/50], Loss: 1.0349, Eval Accuracy: 0.5232, Took 0.9 s\n","Epoch [20/50], Loss: 1.0347, Eval Accuracy: 0.5217, Took 0.9 s\n","Epoch [21/50], Loss: 1.0354, Eval Accuracy: 0.5221, Took 0.9 s\n","Stopped early after epoch 21 as validation accuracy was lower than average of the last 7 accuracies.\n","Last Loss: 1.0354, Last Eval Accuracy: 0.5221, Took 18.8 s\n","Model saved as 20240603143851_encoder_64em_2l_1h_05dr_21ep.pt\n","----- Start Training: 64 emb, 2 layers, 2 heads, 0.5 dropout, positional encoding: False, 50 epochs -----\n","Epoch [1/50], Loss: 1.7955, Eval Accuracy: 0.5148, Took 0.98 s\n","Epoch [2/50], Loss: 1.2463, Eval Accuracy: 0.5146, Took 0.98 s\n","Epoch [3/50], Loss: 1.1496, Eval Accuracy: 0.516, Took 0.98 s\n","Epoch [4/50], Loss: 1.1062, Eval Accuracy: 0.5167, Took 0.98 s\n","Epoch [5/50], Loss: 1.083, Eval Accuracy: 0.52, Took 0.98 s\n","Epoch [6/50], Loss: 1.069, Eval Accuracy: 0.5163, Took 0.98 s\n","Epoch [7/50], Loss: 1.0589, Eval Accuracy: 0.5158, Took 0.98 s\n","Epoch [8/50], Loss: 1.0539, Eval Accuracy: 0.5208, Took 0.98 s\n","Epoch [9/50], Loss: 1.0487, Eval Accuracy: 0.5209, Took 0.98 s\n","Epoch [10/50], Loss: 1.0458, Eval Accuracy: 0.523, Took 0.98 s\n","Epoch [11/50], Loss: 1.0432, Eval Accuracy: 0.5177, Took 0.98 s\n","Epoch [12/50], Loss: 1.0413, Eval Accuracy: 0.5198, Took 0.98 s\n","Stopped early after epoch 12 as validation accuracy was lower than average of the last 7 accuracies.\n","Last Loss: 1.0413, Last Eval Accuracy: 0.5198, Took 11.77 s\n","Model saved as 20240603143903_encoder_64em_2l_2h_05dr_12ep.pt\n","----- Start Training: 64 emb, 2 layers, 4 heads, 0.5 dropout, positional encoding: False, 50 epochs -----\n","Epoch [1/50], Loss: 1.7964, Eval Accuracy: 0.5155, Took 1.14 s\n","Epoch [2/50], Loss: 1.2462, Eval Accuracy: 0.5146, Took 1.14 s\n","Epoch [3/50], Loss: 1.1489, Eval Accuracy: 0.5153, Took 1.14 s\n","Epoch [4/50], Loss: 1.1064, Eval Accuracy: 0.5166, Took 1.14 s\n","Epoch [5/50], Loss: 1.083, Eval Accuracy: 0.5186, Took 1.14 s\n","Epoch [6/50], Loss: 1.0689, Eval Accuracy: 0.5166, Took 1.15 s\n","Epoch [7/50], Loss: 1.0594, Eval Accuracy: 0.5176, Took 1.14 s\n","Epoch [8/50], Loss: 1.0536, Eval Accuracy: 0.5196, Took 1.14 s\n","Epoch [9/50], Loss: 1.0486, Eval Accuracy: 0.5204, Took 1.15 s\n","Epoch [10/50], Loss: 1.0456, Eval Accuracy: 0.522, Took 1.14 s\n","Epoch [11/50], Loss: 1.0435, Eval Accuracy: 0.5184, Took 1.14 s\n","Epoch [12/50], Loss: 1.0409, Eval Accuracy: 0.5198, Took 1.14 s\n","Epoch [13/50], Loss: 1.0407, Eval Accuracy: 0.5218, Took 1.14 s\n","Epoch [14/50], Loss: 1.0382, Eval Accuracy: 0.5218, Took 1.14 s\n","Epoch [15/50], Loss: 1.0381, Eval Accuracy: 0.5199, Took 1.14 s\n","Epoch [16/50], Loss: 1.0368, Eval Accuracy: 0.5222, Took 1.15 s\n","Epoch [17/50], Loss: 1.0367, Eval Accuracy: 0.5226, Took 1.14 s\n","Epoch [18/50], Loss: 1.0349, Eval Accuracy: 0.5226, Took 1.14 s\n","Epoch [19/50], Loss: 1.0345, Eval Accuracy: 0.5231, Took 1.15 s\n","Epoch [20/50], Loss: 1.0347, Eval Accuracy: 0.5209, Took 1.14 s\n","Epoch [21/50], Loss: 1.035, Eval Accuracy: 0.5225, Took 1.14 s\n","Stopped early after epoch 21 as validation accuracy was lower than average of the last 7 accuracies.\n","Last Loss: 1.035, Last Eval Accuracy: 0.5225, Took 24.03 s\n","Model saved as 20240603143927_encoder_64em_2l_4h_05dr_21ep.pt\n","----- Start Training: 64 emb, 2 layers, 8 heads, 0.5 dropout, positional encoding: False, 50 epochs -----\n","Epoch [1/50], Loss: 1.7956, Eval Accuracy: 0.5156, Took 1.48 s\n","Epoch [2/50], Loss: 1.2456, Eval Accuracy: 0.5145, Took 1.48 s\n","Epoch [3/50], Loss: 1.1489, Eval Accuracy: 0.516, Took 1.48 s\n","Epoch [4/50], Loss: 1.1066, Eval Accuracy: 0.5166, Took 1.49 s\n","Epoch [5/50], Loss: 1.0831, Eval Accuracy: 0.5198, Took 1.49 s\n","Epoch [6/50], Loss: 1.0687, Eval Accuracy: 0.5166, Took 1.48 s\n","Epoch [7/50], Loss: 1.0591, Eval Accuracy: 0.5159, Took 1.49 s\n","Epoch [8/50], Loss: 1.0537, Eval Accuracy: 0.5201, Took 1.5 s\n","Epoch [9/50], Loss: 1.0486, Eval Accuracy: 0.5213, Took 1.49 s\n","Epoch [10/50], Loss: 1.0451, Eval Accuracy: 0.5223, Took 1.5 s\n","Epoch [11/50], Loss: 1.0434, Eval Accuracy: 0.5193, Took 1.5 s\n","Epoch [12/50], Loss: 1.0406, Eval Accuracy: 0.5208, Took 1.49 s\n","Epoch [13/50], Loss: 1.0405, Eval Accuracy: 0.5227, Took 1.49 s\n","Epoch [14/50], Loss: 1.0381, Eval Accuracy: 0.5228, Took 1.5 s\n","Epoch [15/50], Loss: 1.0381, Eval Accuracy: 0.5203, Took 1.49 s\n","Epoch [16/50], Loss: 1.0369, Eval Accuracy: 0.5222, Took 1.49 s\n","Stopped early after epoch 16 as validation accuracy was lower than average of the last 7 accuracies.\n","Last Loss: 1.0369, Last Eval Accuracy: 0.5222, Took 23.84 s\n","Model saved as 20240603143951_encoder_64em_2l_8h_05dr_16ep.pt\n","----- Start Training: 64 emb, 4 layers, 1 heads, 0.5 dropout, positional encoding: False, 50 epochs -----\n","Epoch [1/50], Loss: 1.7575, Eval Accuracy: 0.5138, Took 1.72 s\n","Epoch [2/50], Loss: 1.2396, Eval Accuracy: 0.5151, Took 1.7 s\n","Epoch [3/50], Loss: 1.1461, Eval Accuracy: 0.5158, Took 1.7 s\n","Epoch [4/50], Loss: 1.1042, Eval Accuracy: 0.5167, Took 1.7 s\n","Epoch [5/50], Loss: 1.0809, Eval Accuracy: 0.5161, Took 1.7 s\n","Epoch [6/50], Loss: 1.0677, Eval Accuracy: 0.5158, Took 1.7 s\n","Epoch [7/50], Loss: 1.0582, Eval Accuracy: 0.5175, Took 1.69 s\n","Epoch [8/50], Loss: 1.0527, Eval Accuracy: 0.5193, Took 1.69 s\n","Epoch [9/50], Loss: 1.0482, Eval Accuracy: 0.5212, Took 1.7 s\n","Epoch [10/50], Loss: 1.0451, Eval Accuracy: 0.5224, Took 1.7 s\n","Epoch [11/50], Loss: 1.0428, Eval Accuracy: 0.5178, Took 1.71 s\n","Epoch [12/50], Loss: 1.0407, Eval Accuracy: 0.5183, Took 1.76 s\n","Epoch [13/50], Loss: 1.0406, Eval Accuracy: 0.5226, Took 1.76 s\n","Epoch [14/50], Loss: 1.0379, Eval Accuracy: 0.5229, Took 1.75 s\n","Epoch [15/50], Loss: 1.0381, Eval Accuracy: 0.52, Took 1.74 s\n","Epoch [16/50], Loss: 1.0364, Eval Accuracy: 0.5227, Took 1.74 s\n","Epoch [17/50], Loss: 1.0367, Eval Accuracy: 0.523, Took 1.74 s\n","Epoch [18/50], Loss: 1.0347, Eval Accuracy: 0.5219, Took 1.74 s\n","Epoch [19/50], Loss: 1.0344, Eval Accuracy: 0.5219, Took 1.75 s\n","Epoch [20/50], Loss: 1.0344, Eval Accuracy: 0.5214, Took 1.75 s\n","Stopped early after epoch 20 as validation accuracy was lower than average of the last 7 accuracies.\n","Last Loss: 1.0344, Last Eval Accuracy: 0.5214, Took 34.43 s\n","Model saved as 20240603144025_encoder_64em_4l_1h_05dr_20ep.pt\n","----- Start Training: 64 emb, 4 layers, 2 heads, 0.5 dropout, positional encoding: False, 50 epochs -----\n","Epoch [1/50], Loss: 1.7554, Eval Accuracy: 0.515, Took 1.9 s\n","Epoch [2/50], Loss: 1.2395, Eval Accuracy: 0.5145, Took 1.87 s\n","Epoch [3/50], Loss: 1.1458, Eval Accuracy: 0.517, Took 1.87 s\n","Epoch [4/50], Loss: 1.1043, Eval Accuracy: 0.5175, Took 1.87 s\n","Epoch [5/50], Loss: 1.0816, Eval Accuracy: 0.5184, Took 1.87 s\n","Epoch [6/50], Loss: 1.0679, Eval Accuracy: 0.5168, Took 1.87 s\n","Epoch [7/50], Loss: 1.0582, Eval Accuracy: 0.5165, Took 1.87 s\n","Epoch [8/50], Loss: 1.0527, Eval Accuracy: 0.5189, Took 1.87 s\n","Epoch [9/50], Loss: 1.0482, Eval Accuracy: 0.5218, Took 1.87 s\n","Epoch [10/50], Loss: 1.0446, Eval Accuracy: 0.5229, Took 1.87 s\n","Epoch [11/50], Loss: 1.0426, Eval Accuracy: 0.5186, Took 1.87 s\n","Epoch [12/50], Loss: 1.0404, Eval Accuracy: 0.519, Took 1.87 s\n","Epoch [13/50], Loss: 1.0406, Eval Accuracy: 0.5232, Took 1.87 s\n","Epoch [14/50], Loss: 1.0376, Eval Accuracy: 0.5228, Took 1.87 s\n","Epoch [15/50], Loss: 1.0377, Eval Accuracy: 0.5212, Took 1.87 s\n","Epoch [16/50], Loss: 1.0365, Eval Accuracy: 0.5232, Took 1.87 s\n","Epoch [17/50], Loss: 1.0363, Eval Accuracy: 0.523, Took 1.87 s\n","Epoch [18/50], Loss: 1.0348, Eval Accuracy: 0.5208, Took 1.87 s\n","Epoch [19/50], Loss: 1.0342, Eval Accuracy: 0.5228, Took 1.87 s\n","Stopped early after epoch 19 as validation accuracy was lower than average of the last 7 accuracies.\n","Last Loss: 1.0342, Last Eval Accuracy: 0.5228, Took 35.59 s\n","Model saved as 20240603144101_encoder_64em_4l_2h_05dr_19ep.pt\n","----- Start Training: 64 emb, 4 layers, 4 heads, 0.5 dropout, positional encoding: False, 50 epochs -----\n","Epoch [1/50], Loss: 1.7575, Eval Accuracy: 0.5149, Took 2.2 s\n","Epoch [2/50], Loss: 1.2396, Eval Accuracy: 0.5146, Took 2.2 s\n","Epoch [3/50], Loss: 1.1453, Eval Accuracy: 0.5151, Took 2.2 s\n","Epoch [4/50], Loss: 1.1037, Eval Accuracy: 0.5177, Took 2.2 s\n","Epoch [5/50], Loss: 1.0812, Eval Accuracy: 0.5164, Took 2.2 s\n","Epoch [6/50], Loss: 1.0673, Eval Accuracy: 0.5163, Took 2.21 s\n","Epoch [7/50], Loss: 1.0583, Eval Accuracy: 0.5161, Took 2.2 s\n","Epoch [8/50], Loss: 1.0529, Eval Accuracy: 0.5177, Took 2.2 s\n","Epoch [9/50], Loss: 1.0481, Eval Accuracy: 0.521, Took 2.2 s\n","Epoch [10/50], Loss: 1.045, Eval Accuracy: 0.5228, Took 2.2 s\n","Epoch [11/50], Loss: 1.0425, Eval Accuracy: 0.5182, Took 2.2 s\n","Epoch [12/50], Loss: 1.0404, Eval Accuracy: 0.5198, Took 2.21 s\n","Epoch [13/50], Loss: 1.0405, Eval Accuracy: 0.5229, Took 2.2 s\n","Epoch [14/50], Loss: 1.0376, Eval Accuracy: 0.5228, Took 2.2 s\n","Epoch [15/50], Loss: 1.0374, Eval Accuracy: 0.5195, Took 2.2 s\n","Epoch [16/50], Loss: 1.0363, Eval Accuracy: 0.5231, Took 2.21 s\n","Epoch [17/50], Loss: 1.0359, Eval Accuracy: 0.5227, Took 2.2 s\n","Epoch [18/50], Loss: 1.0348, Eval Accuracy: 0.5212, Took 2.21 s\n","Epoch [19/50], Loss: 1.0344, Eval Accuracy: 0.5223, Took 2.21 s\n","Epoch [20/50], Loss: 1.0343, Eval Accuracy: 0.5219, Took 2.21 s\n","Stopped early after epoch 20 as validation accuracy was lower than average of the last 7 accuracies.\n","Last Loss: 1.0343, Last Eval Accuracy: 0.5219, Took 44.1 s\n","Model saved as 20240603144145_encoder_64em_4l_4h_05dr_20ep.pt\n","----- Start Training: 64 emb, 4 layers, 8 heads, 0.5 dropout, positional encoding: False, 50 epochs -----\n","Epoch [1/50], Loss: 1.7566, Eval Accuracy: 0.514, Took 2.87 s\n","Epoch [2/50], Loss: 1.2394, Eval Accuracy: 0.5161, Took 2.87 s\n","Epoch [3/50], Loss: 1.1453, Eval Accuracy: 0.5157, Took 2.87 s\n","Epoch [4/50], Loss: 1.1034, Eval Accuracy: 0.5179, Took 2.87 s\n","Epoch [5/50], Loss: 1.0814, Eval Accuracy: 0.5189, Took 2.87 s\n","Epoch [6/50], Loss: 1.0675, Eval Accuracy: 0.5176, Took 2.87 s\n","Epoch [7/50], Loss: 1.058, Eval Accuracy: 0.5157, Took 2.87 s\n","Epoch [8/50], Loss: 1.0527, Eval Accuracy: 0.5187, Took 2.87 s\n","Epoch [9/50], Loss: 1.0478, Eval Accuracy: 0.5211, Took 2.87 s\n","Epoch [10/50], Loss: 1.0447, Eval Accuracy: 0.5232, Took 2.87 s\n","Epoch [11/50], Loss: 1.0424, Eval Accuracy: 0.5193, Took 2.87 s\n","Epoch [12/50], Loss: 1.0403, Eval Accuracy: 0.5194, Took 2.87 s\n","Epoch [13/50], Loss: 1.0405, Eval Accuracy: 0.5227, Took 2.9 s\n","Epoch [14/50], Loss: 1.0378, Eval Accuracy: 0.5227, Took 2.9 s\n","Epoch [15/50], Loss: 1.0375, Eval Accuracy: 0.5202, Took 2.9 s\n","Epoch [16/50], Loss: 1.0364, Eval Accuracy: 0.5235, Took 2.9 s\n","Epoch [17/50], Loss: 1.0363, Eval Accuracy: 0.5223, Took 2.9 s\n","Epoch [18/50], Loss: 1.0346, Eval Accuracy: 0.5217, Took 2.91 s\n","Epoch [19/50], Loss: 1.034, Eval Accuracy: 0.5224, Took 2.9 s\n","Epoch [20/50], Loss: 1.0344, Eval Accuracy: 0.5222, Took 2.89 s\n","Epoch [21/50], Loss: 1.0349, Eval Accuracy: 0.5231, Took 2.9 s\n","Epoch [22/50], Loss: 1.0328, Eval Accuracy: 0.5216, Took 2.9 s\n","Epoch [23/50], Loss: 1.0344, Eval Accuracy: 0.5219, Took 2.9 s\n","Stopped early after epoch 23 as validation accuracy was lower than average of the last 7 accuracies.\n","Last Loss: 1.0344, Last Eval Accuracy: 0.5219, Took 66.38 s\n","Model saved as 20240603144252_encoder_64em_4l_8h_05dr_23ep.pt\n","----- Start Training: 64 emb, 8 layers, 1 heads, 0.5 dropout, positional encoding: False, 50 epochs -----\n","Epoch [1/50], Loss: 1.8499, Eval Accuracy: 0.5151, Took 3.32 s\n","Epoch [2/50], Loss: 1.2472, Eval Accuracy: 0.5156, Took 3.31 s\n","Epoch [3/50], Loss: 1.1485, Eval Accuracy: 0.5148, Took 3.31 s\n","Epoch [4/50], Loss: 1.107, Eval Accuracy: 0.5171, Took 3.31 s\n","Epoch [5/50], Loss: 1.0826, Eval Accuracy: 0.5143, Took 3.31 s\n","Epoch [6/50], Loss: 1.0695, Eval Accuracy: 0.5185, Took 3.31 s\n","Epoch [7/50], Loss: 1.0589, Eval Accuracy: 0.5183, Took 3.31 s\n","Epoch [8/50], Loss: 1.0544, Eval Accuracy: 0.5185, Took 3.32 s\n","Epoch [9/50], Loss: 1.0487, Eval Accuracy: 0.5222, Took 3.31 s\n","Epoch [10/50], Loss: 1.0462, Eval Accuracy: 0.5221, Took 3.31 s\n","Epoch [11/50], Loss: 1.0438, Eval Accuracy: 0.5197, Took 3.31 s\n","Epoch [12/50], Loss: 1.041, Eval Accuracy: 0.5191, Took 3.31 s\n","Epoch [13/50], Loss: 1.041, Eval Accuracy: 0.5226, Took 3.31 s\n","Epoch [14/50], Loss: 1.0388, Eval Accuracy: 0.5214, Took 3.31 s\n","Epoch [15/50], Loss: 1.0383, Eval Accuracy: 0.5208, Took 3.31 s\n","Epoch [16/50], Loss: 1.0368, Eval Accuracy: 0.5228, Took 3.31 s\n","Epoch [17/50], Loss: 1.0373, Eval Accuracy: 0.522, Took 3.31 s\n","Epoch [18/50], Loss: 1.0357, Eval Accuracy: 0.5232, Took 3.31 s\n","Epoch [19/50], Loss: 1.0356, Eval Accuracy: 0.5211, Took 3.31 s\n","Epoch [20/50], Loss: 1.0351, Eval Accuracy: 0.5209, Took 3.31 s\n","Stopped early after epoch 20 as validation accuracy was lower than average of the last 7 accuracies.\n","Last Loss: 1.0351, Last Eval Accuracy: 0.5209, Took 66.28 s\n","Model saved as 20240603144358_encoder_64em_8l_1h_05dr_20ep.pt\n","----- Start Training: 64 emb, 8 layers, 2 heads, 0.5 dropout, positional encoding: False, 50 epochs -----\n","Epoch [1/50], Loss: 1.8548, Eval Accuracy: 0.5146, Took 3.68 s\n","Epoch [2/50], Loss: 1.2476, Eval Accuracy: 0.5137, Took 3.7 s\n","Epoch [3/50], Loss: 1.1492, Eval Accuracy: 0.5169, Took 3.67 s\n","Epoch [4/50], Loss: 1.1068, Eval Accuracy: 0.5174, Took 3.67 s\n","Epoch [5/50], Loss: 1.0834, Eval Accuracy: 0.5175, Took 3.67 s\n","Epoch [6/50], Loss: 1.0694, Eval Accuracy: 0.5194, Took 3.67 s\n","Epoch [7/50], Loss: 1.0596, Eval Accuracy: 0.518, Took 3.67 s\n","Epoch [8/50], Loss: 1.0541, Eval Accuracy: 0.5182, Took 3.67 s\n","Epoch [9/50], Loss: 1.0484, Eval Accuracy: 0.5227, Took 3.67 s\n","Epoch [10/50], Loss: 1.0467, Eval Accuracy: 0.5224, Took 3.66 s\n","Epoch [11/50], Loss: 1.0438, Eval Accuracy: 0.5188, Took 3.66 s\n","Epoch [12/50], Loss: 1.0414, Eval Accuracy: 0.5183, Took 3.66 s\n","Stopped early after epoch 12 as validation accuracy was lower than average of the last 7 accuracies.\n","Last Loss: 1.0414, Last Eval Accuracy: 0.5183, Took 44.05 s\n","Model saved as 20240603144442_encoder_64em_8l_2h_05dr_12ep.pt\n","----- Start Training: 64 emb, 8 layers, 4 heads, 0.5 dropout, positional encoding: False, 50 epochs -----\n","Epoch [1/50], Loss: 1.8542, Eval Accuracy: 0.5148, Took 4.33 s\n","Epoch [2/50], Loss: 1.2474, Eval Accuracy: 0.5158, Took 4.33 s\n","Epoch [3/50], Loss: 1.149, Eval Accuracy: 0.5158, Took 4.32 s\n","Epoch [4/50], Loss: 1.1065, Eval Accuracy: 0.5168, Took 4.33 s\n","Epoch [5/50], Loss: 1.0829, Eval Accuracy: 0.5156, Took 4.33 s\n","Epoch [6/50], Loss: 1.0693, Eval Accuracy: 0.5184, Took 4.34 s\n","Epoch [7/50], Loss: 1.0591, Eval Accuracy: 0.5184, Took 4.36 s\n","Epoch [8/50], Loss: 1.0538, Eval Accuracy: 0.5176, Took 4.36 s\n","Epoch [9/50], Loss: 1.0487, Eval Accuracy: 0.5223, Took 4.33 s\n","Epoch [10/50], Loss: 1.0467, Eval Accuracy: 0.5217, Took 4.33 s\n","Epoch [11/50], Loss: 1.044, Eval Accuracy: 0.518, Took 4.33 s\n","Epoch [12/50], Loss: 1.0414, Eval Accuracy: 0.5181, Took 4.33 s\n","Stopped early after epoch 12 as validation accuracy was lower than average of the last 7 accuracies.\n","Last Loss: 1.0414, Last Eval Accuracy: 0.5181, Took 52.01 s\n","Model saved as 20240603144534_encoder_64em_8l_4h_05dr_12ep.pt\n","----- Start Training: 64 emb, 8 layers, 8 heads, 0.5 dropout, positional encoding: False, 50 epochs -----\n","Epoch [1/50], Loss: 1.845, Eval Accuracy: 0.5145, Took 5.67 s\n","Epoch [2/50], Loss: 1.2461, Eval Accuracy: 0.5151, Took 5.68 s\n","Epoch [3/50], Loss: 1.1486, Eval Accuracy: 0.5099, Took 5.67 s\n","Epoch [4/50], Loss: 1.106, Eval Accuracy: 0.5171, Took 5.68 s\n","Epoch [5/50], Loss: 1.0826, Eval Accuracy: 0.514, Took 5.68 s\n","Epoch [6/50], Loss: 1.0688, Eval Accuracy: 0.5187, Took 5.68 s\n","Epoch [7/50], Loss: 1.0591, Eval Accuracy: 0.5182, Took 5.67 s\n","Epoch [8/50], Loss: 1.0539, Eval Accuracy: 0.5178, Took 5.68 s\n","Epoch [9/50], Loss: 1.0484, Eval Accuracy: 0.5222, Took 5.67 s\n","Epoch [10/50], Loss: 1.0463, Eval Accuracy: 0.5231, Took 5.68 s\n","Epoch [11/50], Loss: 1.0435, Eval Accuracy: 0.5183, Took 5.68 s\n","Epoch [12/50], Loss: 1.0409, Eval Accuracy: 0.5182, Took 5.68 s\n","Epoch [13/50], Loss: 1.041, Eval Accuracy: 0.5219, Took 5.67 s\n","Epoch [14/50], Loss: 1.0385, Eval Accuracy: 0.5216, Took 5.68 s\n","Epoch [15/50], Loss: 1.0381, Eval Accuracy: 0.5202, Took 5.68 s\n","Epoch [16/50], Loss: 1.0366, Eval Accuracy: 0.5227, Took 5.68 s\n","Epoch [17/50], Loss: 1.0367, Eval Accuracy: 0.5215, Took 5.68 s\n","Epoch [18/50], Loss: 1.0353, Eval Accuracy: 0.5217, Took 5.67 s\n","Epoch [19/50], Loss: 1.0352, Eval Accuracy: 0.5207, Took 5.68 s\n","Epoch [20/50], Loss: 1.0352, Eval Accuracy: 0.5218, Took 5.68 s\n","Stopped early after epoch 20 as validation accuracy was lower than average of the last 7 accuracies.\n","Last Loss: 1.0352, Last Eval Accuracy: 0.5218, Took 113.54 s\n","Model saved as 20240603144728_encoder_64em_8l_8h_05dr_20ep.pt\n","------------\n","Not saved as loss too high:\n","[]\n"]},{"data":{"text/plain":["{'encoder_64em_1l_1h_05dr_50ep': 0.5154,\n"," 'encoder_64em_1l_2h_05dr_50ep': 0.516,\n"," 'encoder_64em_1l_4h_05dr_50ep': 0.5165,\n"," 'encoder_64em_1l_8h_05dr_50ep': 0.5187,\n"," 'encoder_64em_2l_1h_05dr_50ep': 0.5221,\n"," 'encoder_64em_2l_2h_05dr_50ep': 0.5198,\n"," 'encoder_64em_2l_4h_05dr_50ep': 0.5225,\n"," 'encoder_64em_2l_8h_05dr_50ep': 0.5222,\n"," 'encoder_64em_4l_1h_05dr_50ep': 0.5214,\n"," 'encoder_64em_4l_2h_05dr_50ep': 0.5228,\n"," 'encoder_64em_4l_4h_05dr_50ep': 0.5219,\n"," 'encoder_64em_4l_8h_05dr_50ep': 0.5219,\n"," 'encoder_64em_8l_1h_05dr_50ep': 0.5209,\n"," 'encoder_64em_8l_2h_05dr_50ep': 0.5183,\n"," 'encoder_64em_8l_4h_05dr_50ep': 0.5181,\n"," 'encoder_64em_8l_8h_05dr_50ep': 0.5218}"]},"execution_count":36,"metadata":{},"output_type":"execute_result"}],"source":["EMBED_DIM = [64]\n","num_encoder_layers = [1, 2, 4, 8]\n","num_heads = [1, 2, 4, 8]\n","DROPOUTS = [0.5]\n","POS_ENC = [False]\n","e.hyper_parameter_training(EMBED_DIM, num_encoder_layers, num_heads, DROPOUTS, POS_ENC)"]},{"cell_type":"markdown","metadata":{},"source":["#### Positional Encoding"]},{"cell_type":"code","execution_count":39,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["----- Start Training: 64 emb, 2 layers, 4 heads, 0.5 dropout, positional encoding: True, 50 epochs -----\n","Epoch [1/50], Loss: 2.0597, Eval Accuracy: 0.5154, Took 1.17 s\n","Epoch [2/50], Loss: 1.2627, Eval Accuracy: 0.5155, Took 1.17 s\n","Epoch [3/50], Loss: 1.1491, Eval Accuracy: 0.5137, Took 1.16 s\n","Epoch [4/50], Loss: 1.1068, Eval Accuracy: 0.5155, Took 1.16 s\n","Epoch [5/50], Loss: 1.0852, Eval Accuracy: 0.5145, Took 1.17 s\n","Epoch [6/50], Loss: 1.0717, Eval Accuracy: 0.5153, Took 1.17 s\n","Epoch [7/50], Loss: 1.0629, Eval Accuracy: 0.5159, Took 1.17 s\n","Epoch [8/50], Loss: 1.0585, Eval Accuracy: 0.5163, Took 1.17 s\n","Epoch [9/50], Loss: 1.0538, Eval Accuracy: 0.517, Took 1.14 s\n","Epoch [10/50], Loss: 1.0511, Eval Accuracy: 0.5168, Took 1.14 s\n","Epoch [11/50], Loss: 1.0485, Eval Accuracy: 0.5164, Took 1.14 s\n","Epoch [12/50], Loss: 1.0462, Eval Accuracy: 0.5164, Took 1.15 s\n","Epoch [13/50], Loss: 1.0459, Eval Accuracy: 0.5161, Took 1.15 s\n","Stopped early after epoch 13 as validation accuracy was lower than average of the last 7 accuracies.\n","Last Loss: 1.0459, Last Eval Accuracy: 0.5161, Took 15.07 s\n","Model saved as 20240603145400_encoder_64em_2l_4h_05dr_posenc_13ep.pt\n","----- Start Training: 64 emb, 2 layers, 4 heads, 0.5 dropout, positional encoding: False, 50 epochs -----\n","Epoch [1/50], Loss: 1.7964, Eval Accuracy: 0.5155, Took 1.14 s\n","Epoch [2/50], Loss: 1.2462, Eval Accuracy: 0.5146, Took 1.14 s\n","Epoch [3/50], Loss: 1.1489, Eval Accuracy: 0.5153, Took 1.14 s\n","Epoch [4/50], Loss: 1.1064, Eval Accuracy: 0.5166, Took 1.14 s\n","Epoch [5/50], Loss: 1.083, Eval Accuracy: 0.5186, Took 1.14 s\n","Epoch [6/50], Loss: 1.0689, Eval Accuracy: 0.5166, Took 1.14 s\n","Epoch [7/50], Loss: 1.0594, Eval Accuracy: 0.5176, Took 1.14 s\n","Epoch [8/50], Loss: 1.0536, Eval Accuracy: 0.5196, Took 1.14 s\n","Epoch [9/50], Loss: 1.0486, Eval Accuracy: 0.5204, Took 1.14 s\n","Epoch [10/50], Loss: 1.0456, Eval Accuracy: 0.522, Took 1.14 s\n","Epoch [11/50], Loss: 1.0435, Eval Accuracy: 0.5184, Took 1.14 s\n","Epoch [12/50], Loss: 1.0409, Eval Accuracy: 0.5198, Took 1.14 s\n","Epoch [13/50], Loss: 1.0407, Eval Accuracy: 0.5218, Took 1.14 s\n","Epoch [14/50], Loss: 1.0382, Eval Accuracy: 0.5218, Took 1.14 s\n","Epoch [15/50], Loss: 1.0381, Eval Accuracy: 0.5199, Took 1.14 s\n","Epoch [16/50], Loss: 1.0368, Eval Accuracy: 0.5222, Took 1.14 s\n","Epoch [17/50], Loss: 1.0367, Eval Accuracy: 0.5226, Took 1.14 s\n","Epoch [18/50], Loss: 1.0349, Eval Accuracy: 0.5226, Took 1.14 s\n","Epoch [19/50], Loss: 1.0345, Eval Accuracy: 0.5231, Took 1.14 s\n","Epoch [20/50], Loss: 1.0347, Eval Accuracy: 0.5209, Took 1.14 s\n","Epoch [21/50], Loss: 1.035, Eval Accuracy: 0.5225, Took 1.15 s\n","Stopped early after epoch 21 as validation accuracy was lower than average of the last 7 accuracies.\n","Last Loss: 1.035, Last Eval Accuracy: 0.5225, Took 23.97 s\n","Model saved as 20240603145424_encoder_64em_2l_4h_05dr_21ep.pt\n","------------\n","Not saved as loss too high:\n","[]\n"]},{"data":{"text/plain":["{'encoder_64em_2l_4h_05dr_posenc_50ep': 0.5161,\n"," 'encoder_64em_2l_4h_05dr_50ep': 0.5225}"]},"execution_count":39,"metadata":{},"output_type":"execute_result"}],"source":["EMBED_DIM = [64]\n","NUM_ENCODER_LAYERS = [2]\n","NUM_HEADS = [4]\n","DROPOUTS = [0.5]\n","pos_enc = [True, False]\n","e.hyper_parameter_training(EMBED_DIM, NUM_ENCODER_LAYERS, NUM_HEADS, DROPOUTS, pos_enc)"]},{"cell_type":"markdown","metadata":{},"source":["### Drosophila.Melanogaster"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Länge train_dataset: 33040\n","Länge valid_dataset: 4073\n"]}],"source":["organism = \"Drosophila.Melanogaster\"\n","e.load_train_valid_data(organism)"]},{"cell_type":"code","execution_count":44,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["----- Start Training: 64 emb, 2 layers, 2 heads, 0.2 dropout, positional encoding: False, 10 epochs -----\n","Epoch [1/10], Loss: 1.1824, Eval Accuracy: 0.4967, Took 9.54 s\n","Epoch [2/10], Loss: 1.081, Eval Accuracy: 0.497, Took 9.79 s\n","Epoch [3/10], Loss: 1.076, Eval Accuracy: 0.4977, Took 9.09 s\n","Epoch [4/10], Loss: 1.0746, Eval Accuracy: 0.498, Took 9.1 s\n","Epoch [5/10], Loss: 1.0737, Eval Accuracy: 0.4975, Took 9.1 s\n","Epoch [6/10], Loss: 1.073, Eval Accuracy: 0.4972, Took 9.11 s\n","Epoch [7/10], Loss: 1.0725, Eval Accuracy: 0.4987, Took 9.1 s\n","Epoch [8/10], Loss: 1.0719, Eval Accuracy: 0.4989, Took 9.1 s\n","Epoch [9/10], Loss: 1.0715, Eval Accuracy: 0.4982, Took 10.15 s\n","Epoch [10/10], Loss: 1.071, Eval Accuracy: 0.4991, Took 9.1 s\n","Last Loss: 1.071, Last Eval Accuracy: 0.4991, Took 93.17 s\n","Model saved as 20240603150541_encoder_64em_2l_2h_02dr_10ep.pt\n","----- Start Training: 64 emb, 2 layers, 2 heads, 0.5 dropout, positional encoding: False, 10 epochs -----\n","Epoch [1/10], Loss: 1.2169, Eval Accuracy: 0.4961, Took 9.1 s\n","Epoch [2/10], Loss: 1.0838, Eval Accuracy: 0.4968, Took 9.1 s\n","Epoch [3/10], Loss: 1.0788, Eval Accuracy: 0.4974, Took 9.1 s\n","Epoch [4/10], Loss: 1.0772, Eval Accuracy: 0.4977, Took 9.1 s\n","Epoch [5/10], Loss: 1.0761, Eval Accuracy: 0.4973, Took 9.09 s\n","Epoch [6/10], Loss: 1.0753, Eval Accuracy: 0.4973, Took 9.1 s\n","Epoch [7/10], Loss: 1.0746, Eval Accuracy: 0.4982, Took 9.1 s\n","Epoch [8/10], Loss: 1.074, Eval Accuracy: 0.4986, Took 9.1 s\n","Epoch [9/10], Loss: 1.0736, Eval Accuracy: 0.498, Took 9.1 s\n","Epoch [10/10], Loss: 1.0732, Eval Accuracy: 0.4987, Took 9.09 s\n","Last Loss: 1.0732, Last Eval Accuracy: 0.4987, Took 90.98 s\n","Model saved as 20240603150712_encoder_64em_2l_2h_05dr_10ep.pt\n","----- Start Training: 64 emb, 2 layers, 4 heads, 0.2 dropout, positional encoding: False, 10 epochs -----\n","Epoch [1/10], Loss: 1.1823, Eval Accuracy: 0.4966, Took 10.65 s\n","Epoch [2/10], Loss: 1.0809, Eval Accuracy: 0.4968, Took 10.65 s\n","Epoch [3/10], Loss: 1.076, Eval Accuracy: 0.4976, Took 10.63 s\n","Epoch [4/10], Loss: 1.0745, Eval Accuracy: 0.4978, Took 10.64 s\n","Epoch [5/10], Loss: 1.0735, Eval Accuracy: 0.4974, Took 10.63 s\n","Epoch [6/10], Loss: 1.0729, Eval Accuracy: 0.4977, Took 10.63 s\n","Epoch [7/10], Loss: 1.0723, Eval Accuracy: 0.4985, Took 10.63 s\n","Epoch [8/10], Loss: 1.0717, Eval Accuracy: 0.499, Took 10.63 s\n","Epoch [9/10], Loss: 1.0713, Eval Accuracy: 0.4985, Took 10.64 s\n","Epoch [10/10], Loss: 1.0708, Eval Accuracy: 0.4993, Took 10.63 s\n","Last Loss: 1.0708, Last Eval Accuracy: 0.4993, Took 106.38 s\n","Model saved as 20240603150858_encoder_64em_2l_4h_02dr_10ep.pt\n","----- Start Training: 64 emb, 2 layers, 4 heads, 0.5 dropout, positional encoding: False, 10 epochs -----\n","Epoch [1/10], Loss: 1.2168, Eval Accuracy: 0.4962, Took 10.66 s\n","Epoch [2/10], Loss: 1.0837, Eval Accuracy: 0.4965, Took 10.66 s\n","Epoch [3/10], Loss: 1.0787, Eval Accuracy: 0.4971, Took 10.65 s\n","Epoch [4/10], Loss: 1.0771, Eval Accuracy: 0.4975, Took 10.64 s\n","Epoch [5/10], Loss: 1.076, Eval Accuracy: 0.4971, Took 10.65 s\n","Epoch [6/10], Loss: 1.0753, Eval Accuracy: 0.497, Took 10.63 s\n","Epoch [7/10], Loss: 1.0745, Eval Accuracy: 0.498, Took 10.64 s\n","Epoch [8/10], Loss: 1.0739, Eval Accuracy: 0.4983, Took 10.63 s\n","Epoch [9/10], Loss: 1.0734, Eval Accuracy: 0.4978, Took 10.63 s\n","Epoch [10/10], Loss: 1.073, Eval Accuracy: 0.4989, Took 10.64 s\n","Last Loss: 1.073, Last Eval Accuracy: 0.4989, Took 106.43 s\n","Model saved as 20240603151045_encoder_64em_2l_4h_05dr_10ep.pt\n","----- Start Training: 64 emb, 4 layers, 2 heads, 0.2 dropout, positional encoding: False, 10 epochs -----\n","Epoch [1/10], Loss: 1.1771, Eval Accuracy: 0.496, Took 17.41 s\n","Epoch [2/10], Loss: 1.0809, Eval Accuracy: 0.4962, Took 17.4 s\n","Epoch [3/10], Loss: 1.0765, Eval Accuracy: 0.4977, Took 17.42 s\n","Epoch [4/10], Loss: 1.0746, Eval Accuracy: 0.4978, Took 17.41 s\n","Epoch [5/10], Loss: 1.0736, Eval Accuracy: 0.4972, Took 17.44 s\n","Epoch [6/10], Loss: 1.0729, Eval Accuracy: 0.497, Took 17.43 s\n","Epoch [7/10], Loss: 1.0722, Eval Accuracy: 0.4984, Took 17.41 s\n","Epoch [8/10], Loss: 1.0716, Eval Accuracy: 0.4988, Took 17.39 s\n","Epoch [9/10], Loss: 1.0712, Eval Accuracy: 0.4983, Took 17.52 s\n","Epoch [10/10], Loss: 1.0711, Eval Accuracy: 0.4994, Took 17.56 s\n","Last Loss: 1.0711, Last Eval Accuracy: 0.4994, Took 174.37 s\n","Model saved as 20240603151339_encoder_64em_4l_2h_02dr_10ep.pt\n","----- Start Training: 64 emb, 4 layers, 2 heads, 0.5 dropout, positional encoding: False, 10 epochs -----\n","Epoch [1/10], Loss: 1.2105, Eval Accuracy: 0.4968, Took 17.4 s\n","Epoch [2/10], Loss: 1.0834, Eval Accuracy: 0.4955, Took 17.42 s\n","Epoch [3/10], Loss: 1.0788, Eval Accuracy: 0.4972, Took 17.43 s\n","Epoch [4/10], Loss: 1.0771, Eval Accuracy: 0.4978, Took 17.42 s\n","Epoch [5/10], Loss: 1.0761, Eval Accuracy: 0.4974, Took 17.44 s\n","Epoch [6/10], Loss: 1.0754, Eval Accuracy: 0.4969, Took 17.46 s\n","Epoch [7/10], Loss: 1.0745, Eval Accuracy: 0.4985, Took 17.6 s\n","Epoch [8/10], Loss: 1.074, Eval Accuracy: 0.4985, Took 17.63 s\n","Epoch [9/10], Loss: 1.0734, Eval Accuracy: 0.498, Took 17.64 s\n","Epoch [10/10], Loss: 1.073, Eval Accuracy: 0.4989, Took 17.63 s\n","Last Loss: 1.073, Last Eval Accuracy: 0.4989, Took 175.08 s\n","Model saved as 20240603151634_encoder_64em_4l_2h_05dr_10ep.pt\n","----- Start Training: 64 emb, 4 layers, 4 heads, 0.2 dropout, positional encoding: False, 10 epochs -----\n","Epoch [1/10], Loss: 1.1768, Eval Accuracy: 0.4964, Took 20.46 s\n","Epoch [2/10], Loss: 1.0809, Eval Accuracy: 0.4962, Took 20.5 s\n","Epoch [3/10], Loss: 1.0759, Eval Accuracy: 0.4978, Took 20.48 s\n","Epoch [4/10], Loss: 1.0744, Eval Accuracy: 0.498, Took 20.46 s\n","Epoch [5/10], Loss: 1.0738, Eval Accuracy: 0.4971, Took 20.49 s\n","Epoch [6/10], Loss: 1.0727, Eval Accuracy: 0.4968, Took 20.67 s\n","Epoch [7/10], Loss: 1.0719, Eval Accuracy: 0.4984, Took 20.46 s\n","Epoch [8/10], Loss: 1.0712, Eval Accuracy: 0.4991, Took 20.51 s\n","Epoch [9/10], Loss: 1.0712, Eval Accuracy: 0.4979, Took 20.71 s\n","Epoch [10/10], Loss: 1.0706, Eval Accuracy: 0.4993, Took 20.71 s\n","Last Loss: 1.0706, Last Eval Accuracy: 0.4993, Took 205.45 s\n","Model saved as 20240603152000_encoder_64em_4l_4h_02dr_10ep.pt\n","----- Start Training: 64 emb, 4 layers, 4 heads, 0.5 dropout, positional encoding: False, 10 epochs -----\n","Epoch [1/10], Loss: 1.2103, Eval Accuracy: 0.497, Took 20.77 s\n","Epoch [2/10], Loss: 1.0833, Eval Accuracy: 0.4962, Took 20.5 s\n","Epoch [3/10], Loss: 1.0785, Eval Accuracy: 0.4972, Took 20.5 s\n","Epoch [4/10], Loss: 1.0769, Eval Accuracy: 0.4975, Took 20.5 s\n","Epoch [5/10], Loss: 1.0759, Eval Accuracy: 0.4969, Took 20.52 s\n","Epoch [6/10], Loss: 1.0753, Eval Accuracy: 0.4964, Took 20.46 s\n","Epoch [7/10], Loss: 1.0744, Eval Accuracy: 0.4983, Took 20.52 s\n","Epoch [8/10], Loss: 1.0736, Eval Accuracy: 0.4987, Took 20.52 s\n","Epoch [9/10], Loss: 1.0731, Eval Accuracy: 0.4981, Took 20.49 s\n","Epoch [10/10], Loss: 1.0725, Eval Accuracy: 0.4989, Took 20.51 s\n","Last Loss: 1.0725, Last Eval Accuracy: 0.4989, Took 205.28 s\n","Model saved as 20240603152325_encoder_64em_4l_4h_05dr_10ep.pt\n","----- Start Training: 128 emb, 2 layers, 2 heads, 0.2 dropout, positional encoding: False, 10 epochs -----\n","Epoch [1/10], Loss: 1.124, Eval Accuracy: 0.4957, Took 10.7 s\n","Epoch [2/10], Loss: 1.0772, Eval Accuracy: 0.4965, Took 10.69 s\n","Epoch [3/10], Loss: 1.0744, Eval Accuracy: 0.4982, Took 10.72 s\n","Epoch [4/10], Loss: 1.0734, Eval Accuracy: 0.4975, Took 10.69 s\n","Epoch [5/10], Loss: 1.0727, Eval Accuracy: 0.4968, Took 10.67 s\n","Epoch [6/10], Loss: 1.0724, Eval Accuracy: 0.4964, Took 10.67 s\n","Epoch [7/10], Loss: 1.0721, Eval Accuracy: 0.4981, Took 10.66 s\n","Epoch [8/10], Loss: 1.0713, Eval Accuracy: 0.499, Took 10.67 s\n","Epoch [9/10], Loss: 1.0708, Eval Accuracy: 0.4983, Took 10.67 s\n","Epoch [10/10], Loss: 1.0714, Eval Accuracy: 0.4992, Took 10.66 s\n","Last Loss: 1.0714, Last Eval Accuracy: 0.4992, Took 106.81 s\n","Model saved as 20240603152512_encoder_128em_2l_2h_02dr_10ep.pt\n","----- Start Training: 128 emb, 2 layers, 2 heads, 0.5 dropout, positional encoding: False, 10 epochs -----\n","Epoch [1/10], Loss: 1.1385, Eval Accuracy: 0.4967, Took 10.73 s\n","Epoch [2/10], Loss: 1.0783, Eval Accuracy: 0.4967, Took 10.94 s\n","Epoch [3/10], Loss: 1.0758, Eval Accuracy: 0.498, Took 10.72 s\n","Epoch [4/10], Loss: 1.0751, Eval Accuracy: 0.4974, Took 10.71 s\n","Epoch [5/10], Loss: 1.0742, Eval Accuracy: 0.4968, Took 10.71 s\n","Epoch [6/10], Loss: 1.0737, Eval Accuracy: 0.4956, Took 10.74 s\n","Epoch [7/10], Loss: 1.0734, Eval Accuracy: 0.4981, Took 10.69 s\n","Epoch [8/10], Loss: 1.0727, Eval Accuracy: 0.4989, Took 10.81 s\n","Epoch [9/10], Loss: 1.0722, Eval Accuracy: 0.4979, Took 10.7 s\n","Epoch [10/10], Loss: 1.0718, Eval Accuracy: 0.4993, Took 10.7 s\n","Last Loss: 1.0718, Last Eval Accuracy: 0.4993, Took 107.44 s\n","Model saved as 20240603152659_encoder_128em_2l_2h_05dr_10ep.pt\n","----- Start Training: 128 emb, 2 layers, 4 heads, 0.2 dropout, positional encoding: False, 10 epochs -----\n","Epoch [1/10], Loss: 1.1237, Eval Accuracy: 0.4958, Took 12.06 s\n","Epoch [2/10], Loss: 1.077, Eval Accuracy: 0.4965, Took 12.05 s\n","Epoch [3/10], Loss: 1.0742, Eval Accuracy: 0.498, Took 12.12 s\n","Epoch [4/10], Loss: 1.0734, Eval Accuracy: 0.4973, Took 12.09 s\n","Epoch [5/10], Loss: 1.0725, Eval Accuracy: 0.4965, Took 12.04 s\n","Epoch [6/10], Loss: 1.072, Eval Accuracy: 0.4967, Took 12.03 s\n","Epoch [7/10], Loss: 1.072, Eval Accuracy: 0.4983, Took 12.08 s\n","Epoch [8/10], Loss: 1.0708, Eval Accuracy: 0.499, Took 12.02 s\n","Epoch [9/10], Loss: 1.0703, Eval Accuracy: 0.4982, Took 12.07 s\n","Epoch [10/10], Loss: 1.0698, Eval Accuracy: 0.4992, Took 12.06 s\n","Last Loss: 1.0698, Last Eval Accuracy: 0.4992, Took 120.62 s\n","Model saved as 20240603152900_encoder_128em_2l_4h_02dr_10ep.pt\n","----- Start Training: 128 emb, 2 layers, 4 heads, 0.5 dropout, positional encoding: False, 10 epochs -----\n","Epoch [1/10], Loss: 1.1381, Eval Accuracy: 0.4964, Took 12.1 s\n","Epoch [2/10], Loss: 1.0782, Eval Accuracy: 0.4967, Took 12.05 s\n","Epoch [3/10], Loss: 1.0757, Eval Accuracy: 0.4979, Took 12.04 s\n","Epoch [4/10], Loss: 1.075, Eval Accuracy: 0.4973, Took 12.05 s\n","Epoch [5/10], Loss: 1.074, Eval Accuracy: 0.4966, Took 12.04 s\n","Epoch [6/10], Loss: 1.0735, Eval Accuracy: 0.4963, Took 12.04 s\n","Epoch [7/10], Loss: 1.0732, Eval Accuracy: 0.4985, Took 12.02 s\n","Epoch [8/10], Loss: 1.0722, Eval Accuracy: 0.4991, Took 12.05 s\n","Epoch [9/10], Loss: 1.0718, Eval Accuracy: 0.4982, Took 12.2 s\n","Epoch [10/10], Loss: 1.0715, Eval Accuracy: 0.4989, Took 12.27 s\n","Last Loss: 1.0715, Last Eval Accuracy: 0.4989, Took 120.87 s\n","Model saved as 20240603153101_encoder_128em_2l_4h_05dr_10ep.pt\n","----- Start Training: 128 emb, 4 layers, 2 heads, 0.2 dropout, positional encoding: False, 10 epochs -----\n","Epoch [1/10], Loss: 1.1206, Eval Accuracy: 0.4959, Took 20.59 s\n","Epoch [2/10], Loss: 1.0771, Eval Accuracy: 0.4966, Took 20.59 s\n","Epoch [3/10], Loss: 1.0751, Eval Accuracy: 0.4977, Took 20.59 s\n","Epoch [4/10], Loss: 1.0735, Eval Accuracy: 0.4976, Took 20.58 s\n","Epoch [5/10], Loss: 1.0741, Eval Accuracy: 0.4967, Took 20.58 s\n","Epoch [6/10], Loss: 1.0729, Eval Accuracy: 0.496, Took 20.53 s\n","Epoch [7/10], Loss: 1.0723, Eval Accuracy: 0.4982, Took 20.51 s\n","Epoch [8/10], Loss: 1.0713, Eval Accuracy: 0.4988, Took 20.81 s\n","Epoch [9/10], Loss: 1.0711, Eval Accuracy: 0.4977, Took 20.57 s\n","Epoch [10/10], Loss: 1.0711, Eval Accuracy: 0.4986, Took 20.81 s\n","Last Loss: 1.0711, Last Eval Accuracy: 0.4986, Took 206.16 s\n","Model saved as 20240603153427_encoder_128em_4l_2h_02dr_10ep.pt\n","----- Start Training: 128 emb, 4 layers, 2 heads, 0.5 dropout, positional encoding: False, 10 epochs -----\n","Epoch [1/10], Loss: 1.1341, Eval Accuracy: 0.4962, Took 20.87 s\n","Epoch [2/10], Loss: 1.0781, Eval Accuracy: 0.4965, Took 20.75 s\n","Epoch [3/10], Loss: 1.0767, Eval Accuracy: 0.4975, Took 20.59 s\n","Epoch [4/10], Loss: 1.0751, Eval Accuracy: 0.4977, Took 20.57 s\n","Epoch [5/10], Loss: 1.0745, Eval Accuracy: 0.4967, Took 20.52 s\n","Epoch [6/10], Loss: 1.0742, Eval Accuracy: 0.4967, Took 20.5 s\n","Epoch [7/10], Loss: 1.0737, Eval Accuracy: 0.4954, Took 20.53 s\n","Epoch [8/10], Loss: 1.0734, Eval Accuracy: 0.4984, Took 20.51 s\n","Stopped early after epoch 8 as validation accuracy was lower than average of the last 7 accuracies.\n","Last Loss: 1.0734, Last Eval Accuracy: 0.4984, Took 164.86 s\n","Model saved as 20240603153712_encoder_128em_4l_2h_05dr_8ep.pt\n","----- Start Training: 128 emb, 4 layers, 4 heads, 0.2 dropout, positional encoding: False, 10 epochs -----\n","Epoch [1/10], Loss: 1.1203, Eval Accuracy: 0.4958, Took 23.34 s\n","Epoch [2/10], Loss: 1.077, Eval Accuracy: 0.4964, Took 23.35 s\n","Epoch [3/10], Loss: 1.0744, Eval Accuracy: 0.4977, Took 23.32 s\n","Epoch [4/10], Loss: 1.0733, Eval Accuracy: 0.4976, Took 23.27 s\n","Epoch [5/10], Loss: 1.0728, Eval Accuracy: 0.4969, Took 23.25 s\n","Epoch [6/10], Loss: 1.0726, Eval Accuracy: 0.4963, Took 23.23 s\n","Epoch [7/10], Loss: 1.0718, Eval Accuracy: 0.497, Took 23.32 s\n","Epoch [8/10], Loss: 1.0714, Eval Accuracy: 0.4992, Took 23.26 s\n","Epoch [9/10], Loss: 1.0701, Eval Accuracy: 0.4988, Took 23.27 s\n","Epoch [10/10], Loss: 1.07, Eval Accuracy: 0.4983, Took 23.24 s\n","Last Loss: 1.07, Last Eval Accuracy: 0.4983, Took 232.85 s\n","Model saved as 20240603154105_encoder_128em_4l_4h_02dr_10ep.pt\n","----- Start Training: 128 emb, 4 layers, 4 heads, 0.5 dropout, positional encoding: False, 10 epochs -----\n","Epoch [1/10], Loss: 1.1341, Eval Accuracy: 0.4955, Took 23.32 s\n","Epoch [2/10], Loss: 1.078, Eval Accuracy: 0.4963, Took 23.32 s\n","Epoch [3/10], Loss: 1.0759, Eval Accuracy: 0.4966, Took 23.3 s\n","Epoch [4/10], Loss: 1.0752, Eval Accuracy: 0.4977, Took 23.25 s\n","Epoch [5/10], Loss: 1.0743, Eval Accuracy: 0.4965, Took 23.27 s\n","Epoch [6/10], Loss: 1.0746, Eval Accuracy: 0.4964, Took 23.26 s\n","Epoch [7/10], Loss: 1.073, Eval Accuracy: 0.4982, Took 23.24 s\n","Epoch [8/10], Loss: 1.0726, Eval Accuracy: 0.4989, Took 23.25 s\n","Epoch [9/10], Loss: 1.0719, Eval Accuracy: 0.4986, Took 23.29 s\n","Epoch [10/10], Loss: 1.0717, Eval Accuracy: 0.4987, Took 23.42 s\n","Last Loss: 1.0717, Last Eval Accuracy: 0.4987, Took 232.92 s\n","Model saved as 20240603154458_encoder_128em_4l_4h_05dr_10ep.pt\n","------------\n","Not saved as loss too high:\n","[]\n"]}],"source":["embed_dims = [64, 128]\n","num_encoder_layers = [2, 4]\n","num_heads = [2, 4]\n","DROPOUTS = [0.2, 0.5]\n","POS_ENC = [False]\n","accuracies = e.hyper_parameter_training(embed_dims, num_encoder_layers, num_heads, DROPOUTS, POS_ENC, epochs=10, print_epochs=True)"]},{"cell_type":"code","execution_count":45,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["----- Start Training: 64 emb, 4 layers, 4 heads, 0.2 dropout, positional encoding: False, 100 epochs -----\n","Epoch [1/100], Loss: 1.1768, Eval Accuracy: 0.4964, Took 20.78 s\n","Epoch [2/100], Loss: 1.0809, Eval Accuracy: 0.4962, Took 20.48 s\n","Epoch [3/100], Loss: 1.0759, Eval Accuracy: 0.4978, Took 20.5 s\n","Epoch [4/100], Loss: 1.0744, Eval Accuracy: 0.498, Took 20.51 s\n","Epoch [5/100], Loss: 1.0738, Eval Accuracy: 0.4971, Took 20.5 s\n","Epoch [6/100], Loss: 1.0727, Eval Accuracy: 0.4968, Took 20.45 s\n","Epoch [7/100], Loss: 1.0719, Eval Accuracy: 0.4984, Took 20.78 s\n","Epoch [8/100], Loss: 1.0712, Eval Accuracy: 0.4991, Took 20.79 s\n","Epoch [9/100], Loss: 1.0712, Eval Accuracy: 0.4979, Took 20.52 s\n","Epoch [10/100], Loss: 1.0706, Eval Accuracy: 0.4993, Took 20.53 s\n","Epoch [11/100], Loss: 1.0698, Eval Accuracy: 0.4988, Took 20.77 s\n","Epoch [12/100], Loss: 1.0691, Eval Accuracy: 0.4987, Took 20.72 s\n","Epoch [13/100], Loss: 1.0687, Eval Accuracy: 0.4993, Took 20.61 s\n","Epoch [14/100], Loss: 1.0678, Eval Accuracy: 0.5002, Took 20.47 s\n","Epoch [15/100], Loss: 1.0677, Eval Accuracy: 0.4998, Took 20.51 s\n","Epoch [16/100], Loss: 1.0667, Eval Accuracy: 0.4986, Took 20.52 s\n","Epoch [17/100], Loss: 1.0659, Eval Accuracy: 0.5004, Took 20.52 s\n","Epoch [18/100], Loss: 1.0655, Eval Accuracy: 0.4995, Took 20.45 s\n","Epoch [19/100], Loss: 1.0646, Eval Accuracy: 0.5004, Took 20.52 s\n","Epoch [20/100], Loss: 1.0639, Eval Accuracy: 0.5004, Took 20.46 s\n","Epoch [21/100], Loss: 1.0631, Eval Accuracy: 0.5015, Took 20.47 s\n","Epoch [22/100], Loss: 1.0625, Eval Accuracy: 0.5016, Took 20.48 s\n","Epoch [23/100], Loss: 1.0615, Eval Accuracy: 0.499, Took 20.49 s\n","Epoch [24/100], Loss: 1.0608, Eval Accuracy: 0.5002, Took 20.44 s\n","Stopped early after epoch 24 as validation accuracy was lower than average of the last 7 accuracies.\n","Last Loss: 1.0608, Last Eval Accuracy: 0.5002, Took 493.3 s\n","Model saved as 20240603162032_encoder_64em_4l_4h_02dr_24ep.pt\n","----- Start Training: 64 emb, 4 layers, 4 heads, 0.2 dropout, positional encoding: True, 100 epochs -----\n","Epoch [1/100], Loss: 1.1862, Eval Accuracy: 0.4965, Took 20.5 s\n","Epoch [2/100], Loss: 1.0814, Eval Accuracy: 0.4959, Took 20.6 s\n","Epoch [3/100], Loss: 1.0763, Eval Accuracy: 0.4972, Took 20.82 s\n","Epoch [4/100], Loss: 1.0751, Eval Accuracy: 0.4978, Took 20.53 s\n","Epoch [5/100], Loss: 1.0738, Eval Accuracy: 0.497, Took 20.51 s\n","Epoch [6/100], Loss: 1.0729, Eval Accuracy: 0.4975, Took 20.54 s\n","Epoch [7/100], Loss: 1.0722, Eval Accuracy: 0.4983, Took 20.53 s\n","Epoch [8/100], Loss: 1.0715, Eval Accuracy: 0.499, Took 20.64 s\n","Epoch [9/100], Loss: 1.071, Eval Accuracy: 0.4982, Took 20.81 s\n","Epoch [10/100], Loss: 1.0703, Eval Accuracy: 0.4989, Took 20.58 s\n","Epoch [11/100], Loss: 1.0694, Eval Accuracy: 0.4988, Took 20.66 s\n","Epoch [12/100], Loss: 1.069, Eval Accuracy: 0.4989, Took 20.52 s\n","Epoch [13/100], Loss: 1.0686, Eval Accuracy: 0.4991, Took 20.76 s\n","Epoch [14/100], Loss: 1.0677, Eval Accuracy: 0.4998, Took 20.76 s\n","Epoch [15/100], Loss: 1.0673, Eval Accuracy: 0.5004, Took 20.78 s\n","Epoch [16/100], Loss: 1.0667, Eval Accuracy: 0.499, Took 20.68 s\n","Epoch [17/100], Loss: 1.0661, Eval Accuracy: 0.5008, Took 20.56 s\n","Epoch [18/100], Loss: 1.0656, Eval Accuracy: 0.4999, Took 20.56 s\n","Epoch [19/100], Loss: 1.0648, Eval Accuracy: 0.5008, Took 20.49 s\n","Epoch [20/100], Loss: 1.0643, Eval Accuracy: 0.5014, Took 20.49 s\n","Epoch [21/100], Loss: 1.0635, Eval Accuracy: 0.5022, Took 20.51 s\n","Epoch [22/100], Loss: 1.0628, Eval Accuracy: 0.5013, Took 20.53 s\n","Epoch [23/100], Loss: 1.062, Eval Accuracy: 0.5015, Took 20.55 s\n","Epoch [24/100], Loss: 1.0614, Eval Accuracy: 0.5021, Took 20.5 s\n","Epoch [25/100], Loss: 1.0607, Eval Accuracy: 0.5026, Took 20.53 s\n","Epoch [26/100], Loss: 1.0599, Eval Accuracy: 0.503, Took 20.51 s\n","Epoch [27/100], Loss: 1.059, Eval Accuracy: 0.503, Took 20.49 s\n","Epoch [28/100], Loss: 1.0582, Eval Accuracy: 0.5037, Took 20.77 s\n","Epoch [29/100], Loss: 1.0574, Eval Accuracy: 0.5027, Took 20.77 s\n","Epoch [30/100], Loss: 1.0566, Eval Accuracy: 0.5042, Took 20.76 s\n","Epoch [31/100], Loss: 1.056, Eval Accuracy: 0.5048, Took 20.55 s\n","Epoch [32/100], Loss: 1.0552, Eval Accuracy: 0.5052, Took 20.52 s\n","Epoch [33/100], Loss: 1.0542, Eval Accuracy: 0.5051, Took 20.54 s\n","Epoch [34/100], Loss: 1.0533, Eval Accuracy: 0.5054, Took 20.52 s\n","Epoch [35/100], Loss: 1.0526, Eval Accuracy: 0.5069, Took 20.52 s\n","Epoch [36/100], Loss: 1.0517, Eval Accuracy: 0.506, Took 20.54 s\n","Epoch [37/100], Loss: 1.0512, Eval Accuracy: 0.5067, Took 20.51 s\n","Epoch [38/100], Loss: 1.0501, Eval Accuracy: 0.5079, Took 20.51 s\n","Epoch [39/100], Loss: 1.0495, Eval Accuracy: 0.5076, Took 20.53 s\n","Epoch [40/100], Loss: 1.0488, Eval Accuracy: 0.507, Took 20.54 s\n","Epoch [41/100], Loss: 1.048, Eval Accuracy: 0.5085, Took 20.56 s\n","Epoch [42/100], Loss: 1.0473, Eval Accuracy: 0.5082, Took 20.51 s\n","Epoch [43/100], Loss: 1.0465, Eval Accuracy: 0.5094, Took 20.54 s\n","Epoch [44/100], Loss: 1.0459, Eval Accuracy: 0.5094, Took 20.54 s\n","Epoch [45/100], Loss: 1.0453, Eval Accuracy: 0.5093, Took 20.53 s\n","Epoch [46/100], Loss: 1.0446, Eval Accuracy: 0.5096, Took 20.72 s\n","Epoch [47/100], Loss: 1.0439, Eval Accuracy: 0.5098, Took 20.81 s\n","Epoch [48/100], Loss: 1.0433, Eval Accuracy: 0.5107, Took 20.66 s\n","Epoch [49/100], Loss: 1.0428, Eval Accuracy: 0.5095, Took 20.54 s\n","Epoch [50/100], Loss: 1.0422, Eval Accuracy: 0.5093, Took 20.57 s\n","Stopped early after epoch 50 as validation accuracy was lower than average of the last 7 accuracies.\n","Last Loss: 1.0422, Last Eval Accuracy: 0.5093, Took 1029.54 s\n","Model saved as 20240603163741_encoder_64em_4l_4h_02dr_posenc_50ep.pt\n","------------\n","Not saved as loss too high:\n","[]\n"]}],"source":["# Train best suited models for longer\n","embed_dims = [64]\n","num_encoder_layers = [4]\n","num_heads = [4]\n","DROPOUTS = [0.2]\n","POS_ENC = [False, True]\n","accuracies, _, _ = e.hyper_parameter_training(embed_dims, num_encoder_layers, num_heads, DROPOUTS, POS_ENC, epochs=100, print_epochs=True)"]},{"cell_type":"code","execution_count":42,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["----- Start Training: 64 emb, 4 layers, 4 heads, 0.2 dropout, positional encoding: True, 400 epochs -----\n","Epoch [301/400], Loss: 0.9997, Eval Accuracy: 0.5293, Took 20.6 s\n","Epoch [302/400], Loss: 0.9994, Eval Accuracy: 0.5291, Took 20.61 s\n","Epoch [303/400], Loss: 0.9994, Eval Accuracy: 0.5288, Took 20.69 s\n","Epoch [304/400], Loss: 0.9993, Eval Accuracy: 0.5279, Took 20.45 s\n","Epoch [305/400], Loss: 0.9994, Eval Accuracy: 0.5287, Took 20.45 s\n","Epoch [306/400], Loss: 0.9991, Eval Accuracy: 0.5288, Took 20.47 s\n","Epoch [307/400], Loss: 0.9992, Eval Accuracy: 0.53, Took 20.48 s\n","Epoch [308/400], Loss: 0.9991, Eval Accuracy: 0.528, Took 20.57 s\n","Epoch [309/400], Loss: 0.9989, Eval Accuracy: 0.5275, Took 20.46 s\n","Epoch [310/400], Loss: 0.9989, Eval Accuracy: 0.5279, Took 20.48 s\n","Epoch [311/400], Loss: 0.9991, Eval Accuracy: 0.5296, Took 20.46 s\n","Epoch [312/400], Loss: 0.9987, Eval Accuracy: 0.5298, Took 20.49 s\n","Epoch [313/400], Loss: 0.9987, Eval Accuracy: 0.5298, Took 20.47 s\n","Epoch [314/400], Loss: 0.9989, Eval Accuracy: 0.5294, Took 20.47 s\n","Epoch [315/400], Loss: 0.9984, Eval Accuracy: 0.529, Took 20.49 s\n","Epoch [316/400], Loss: 0.9985, Eval Accuracy: 0.5287, Took 20.47 s\n","Epoch [317/400], Loss: 0.9986, Eval Accuracy: 0.5298, Took 20.46 s\n","Epoch [318/400], Loss: 0.9984, Eval Accuracy: 0.5285, Took 20.45 s\n","Epoch [319/400], Loss: 0.9981, Eval Accuracy: 0.5293, Took 20.46 s\n","Epoch [320/400], Loss: 0.9984, Eval Accuracy: 0.5299, Took 20.48 s\n","Epoch [321/400], Loss: 0.9983, Eval Accuracy: 0.5284, Took 20.47 s\n","Epoch [322/400], Loss: 0.9982, Eval Accuracy: 0.53, Took 20.47 s\n","Epoch [323/400], Loss: 0.9982, Eval Accuracy: 0.5289, Took 20.46 s\n","Epoch [324/400], Loss: 0.9981, Eval Accuracy: 0.5297, Took 20.64 s\n","Epoch [325/400], Loss: 0.998, Eval Accuracy: 0.5301, Took 20.46 s\n","Epoch [326/400], Loss: 0.9978, Eval Accuracy: 0.5298, Took 20.48 s\n","Epoch [327/400], Loss: 0.9979, Eval Accuracy: 0.5302, Took 20.74 s\n","Epoch [328/400], Loss: 0.9978, Eval Accuracy: 0.5295, Took 20.73 s\n","Epoch [329/400], Loss: 0.9978, Eval Accuracy: 0.53, Took 20.72 s\n","Epoch [330/400], Loss: 0.9977, Eval Accuracy: 0.5299, Took 20.49 s\n","Epoch [331/400], Loss: 0.9976, Eval Accuracy: 0.5305, Took 20.45 s\n","Epoch [332/400], Loss: 0.9975, Eval Accuracy: 0.5292, Took 20.47 s\n","Epoch [333/400], Loss: 0.9977, Eval Accuracy: 0.5293, Took 20.47 s\n","Epoch [334/400], Loss: 0.9974, Eval Accuracy: 0.5295, Took 20.48 s\n","Epoch [335/400], Loss: 0.9972, Eval Accuracy: 0.5302, Took 20.49 s\n","Epoch [336/400], Loss: 0.9975, Eval Accuracy: 0.5295, Took 20.46 s\n","Epoch [337/400], Loss: 0.9972, Eval Accuracy: 0.5273, Took 20.46 s\n","Epoch [338/400], Loss: 0.9972, Eval Accuracy: 0.5297, Took 20.48 s\n","Epoch [339/400], Loss: 0.9972, Eval Accuracy: 0.5303, Took 20.45 s\n","Epoch [340/400], Loss: 0.9972, Eval Accuracy: 0.5286, Took 20.47 s\n","Epoch [341/400], Loss: 0.9968, Eval Accuracy: 0.5305, Took 20.47 s\n","Epoch [342/400], Loss: 0.9972, Eval Accuracy: 0.5293, Took 20.5 s\n","Epoch [343/400], Loss: 0.997, Eval Accuracy: 0.5302, Took 20.47 s\n","Epoch [344/400], Loss: 0.997, Eval Accuracy: 0.5298, Took 20.49 s\n","Epoch [345/400], Loss: 0.9968, Eval Accuracy: 0.5298, Took 20.51 s\n","Epoch [346/400], Loss: 0.9969, Eval Accuracy: 0.5304, Took 20.48 s\n","Epoch [347/400], Loss: 0.9967, Eval Accuracy: 0.5307, Took 20.5 s\n","Epoch [348/400], Loss: 0.9967, Eval Accuracy: 0.5302, Took 20.46 s\n","Epoch [349/400], Loss: 0.9966, Eval Accuracy: 0.5295, Took 20.74 s\n","Epoch [350/400], Loss: 0.9966, Eval Accuracy: 0.5291, Took 20.73 s\n","Epoch [351/400], Loss: 0.9966, Eval Accuracy: 0.531, Took 20.72 s\n","Epoch [352/400], Loss: 0.9965, Eval Accuracy: 0.5298, Took 20.46 s\n","Epoch [353/400], Loss: 0.9965, Eval Accuracy: 0.529, Took 20.46 s\n","Epoch [354/400], Loss: 0.9961, Eval Accuracy: 0.5301, Took 20.48 s\n","Epoch [355/400], Loss: 0.9962, Eval Accuracy: 0.5296, Took 20.45 s\n","Epoch [356/400], Loss: 0.9964, Eval Accuracy: 0.5313, Took 20.48 s\n","Epoch [357/400], Loss: 0.9963, Eval Accuracy: 0.5309, Took 20.71 s\n","Epoch [358/400], Loss: 0.9961, Eval Accuracy: 0.5291, Took 20.75 s\n","Epoch [359/400], Loss: 0.9961, Eval Accuracy: 0.5298, Took 20.75 s\n","Epoch [360/400], Loss: 0.9962, Eval Accuracy: 0.5305, Took 20.51 s\n","Epoch [361/400], Loss: 0.996, Eval Accuracy: 0.5301, Took 20.46 s\n","Epoch [362/400], Loss: 0.9959, Eval Accuracy: 0.5305, Took 20.45 s\n","Epoch [363/400], Loss: 0.9961, Eval Accuracy: 0.5312, Took 20.62 s\n","Epoch [364/400], Loss: 0.9959, Eval Accuracy: 0.5305, Took 20.74 s\n","Epoch [365/400], Loss: 0.9957, Eval Accuracy: 0.5301, Took 20.56 s\n","Epoch [366/400], Loss: 0.9956, Eval Accuracy: 0.5302, Took 20.46 s\n","Epoch [367/400], Loss: 0.9957, Eval Accuracy: 0.5297, Took 20.47 s\n","Epoch [368/400], Loss: 0.9955, Eval Accuracy: 0.5293, Took 20.46 s\n","Epoch [369/400], Loss: 0.9955, Eval Accuracy: 0.5307, Took 20.47 s\n","Epoch [370/400], Loss: 0.9955, Eval Accuracy: 0.5289, Took 20.48 s\n","Epoch [371/400], Loss: 0.9955, Eval Accuracy: 0.5295, Took 20.46 s\n","Epoch [372/400], Loss: 0.9955, Eval Accuracy: 0.5308, Took 20.46 s\n","Epoch [373/400], Loss: 0.9953, Eval Accuracy: 0.5303, Took 20.46 s\n","Epoch [374/400], Loss: 0.9954, Eval Accuracy: 0.5307, Took 20.47 s\n","Epoch [375/400], Loss: 0.9953, Eval Accuracy: 0.5306, Took 20.47 s\n","Epoch [376/400], Loss: 0.9951, Eval Accuracy: 0.5312, Took 20.56 s\n","Epoch [377/400], Loss: 0.9949, Eval Accuracy: 0.5303, Took 20.74 s\n","Epoch [378/400], Loss: 0.9953, Eval Accuracy: 0.5298, Took 20.46 s\n","Epoch [379/400], Loss: 0.9951, Eval Accuracy: 0.5304, Took 20.46 s\n","Epoch [380/400], Loss: 0.995, Eval Accuracy: 0.5309, Took 20.46 s\n","Epoch [381/400], Loss: 0.995, Eval Accuracy: 0.5292, Took 20.47 s\n","Epoch [382/400], Loss: 0.9948, Eval Accuracy: 0.5315, Took 20.47 s\n","Epoch [383/400], Loss: 0.9949, Eval Accuracy: 0.5293, Took 20.46 s\n","Epoch [384/400], Loss: 0.9947, Eval Accuracy: 0.53, Took 21.88 s\n","Epoch [385/400], Loss: 0.9948, Eval Accuracy: 0.5312, Took 22.68 s\n","Epoch [386/400], Loss: 0.9947, Eval Accuracy: 0.5303, Took 22.68 s\n","Epoch [387/400], Loss: 0.9947, Eval Accuracy: 0.5305, Took 22.69 s\n","Epoch [388/400], Loss: 0.9946, Eval Accuracy: 0.5314, Took 22.66 s\n","Epoch [389/400], Loss: 0.9946, Eval Accuracy: 0.5315, Took 21.99 s\n","Epoch [390/400], Loss: 0.9947, Eval Accuracy: 0.5309, Took 22.23 s\n","Epoch [391/400], Loss: 0.9943, Eval Accuracy: 0.5312, Took 22.68 s\n","Epoch [392/400], Loss: 0.9944, Eval Accuracy: 0.5298, Took 22.71 s\n","Epoch [393/400], Loss: 0.9943, Eval Accuracy: 0.5307, Took 22.68 s\n","Epoch [394/400], Loss: 0.9941, Eval Accuracy: 0.5319, Took 22.7 s\n","Epoch [395/400], Loss: 0.9944, Eval Accuracy: 0.5291, Took 22.69 s\n","Epoch [396/400], Loss: 0.9943, Eval Accuracy: 0.5317, Took 22.65 s\n","Epoch [397/400], Loss: 0.9941, Eval Accuracy: 0.5303, Took 20.61 s\n","Epoch [398/400], Loss: 0.9941, Eval Accuracy: 0.5294, Took 20.75 s\n","Epoch [399/400], Loss: 0.9941, Eval Accuracy: 0.5299, Took 20.52 s\n","Epoch [400/400], Loss: 0.9939, Eval Accuracy: 0.5309, Took 20.61 s\n","Average eval Loss: 1.0188, Best Eval Accuracy: 0.5319, Took 2079.65 s\n","Model saved as 20240626115352_encoder_64em_4l_4h_posenc_02dr_400ep.pt\n","------------\n","Not saved as loss too high:\n","[]\n"]}],"source":["# Train best model for longer\n","embed_dims = [64]\n","num_encoder_layers = [4]\n","num_heads = [4]\n","DROPOUTS = [0.2]\n","POS_ENC = [True]\n","accuracies, all_accuracies, best_model_state = e.hyper_parameter_training(embed_dims, num_encoder_layers, num_heads, DROPOUTS, POS_ENC, epochs=400, validation_stop=False, start_epoch=0, current_best_model_state=None, existing_model=None)"]},{"cell_type":"markdown","metadata":{},"source":["time: 4146 + 2060 + 2080"]},{"cell_type":"code","execution_count":43,"metadata":{},"outputs":[],"source":["training_results = {\n","    \"time\": 4146 + 2060 + 2080,\n","    \"best_model_state\": best_model_state,\n","    \"all_accuracies\": all_accuracies['encoder_64em_4l_4h_posenc_02dr_400ep']\n","}"]},{"cell_type":"code","execution_count":45,"metadata":{},"outputs":[],"source":["mlh.to_pickle(training_results, data_path+f'/{e.organism}/training_results_encoder.pkl')"]},{"cell_type":"markdown","metadata":{},"source":["### Homo.Sapiens"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Länge train_dataset: 140711\n","Länge valid_dataset: 17784\n","CPU times: user 2min 10s, sys: 551 ms, total: 2min 10s\n","Wall time: 2min 10s\n"]}],"source":["%%time\n","\n","organism = \"Homo.Sapiens\"\n","e.load_train_valid_data(organism)"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["----- Start Training: 64 emb, 4 layers, 4 heads, 0.2 dropout, positional encoding: True, 100 epochs -----\n"]},{"name":"stderr","output_type":"stream","text":["/home/mkuehn/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [1/100], Loss: 1.1145, Eval Accuracy: 0.4759, Took 88.67 s\n","Epoch [2/100], Loss: 1.0813, Eval Accuracy: 0.4778, Took 87.75 s\n","Epoch [3/100], Loss: 1.0784, Eval Accuracy: 0.4809, Took 88.37 s\n","Epoch [4/100], Loss: 1.0759, Eval Accuracy: 0.4834, Took 87.4 s\n","Epoch [5/100], Loss: 1.0738, Eval Accuracy: 0.4837, Took 87.3 s\n","Epoch [6/100], Loss: 1.0719, Eval Accuracy: 0.4875, Took 87.73 s\n","Epoch [7/100], Loss: 1.0701, Eval Accuracy: 0.4889, Took 87.27 s\n","Epoch [8/100], Loss: 1.0681, Eval Accuracy: 0.4886, Took 87.55 s\n","Epoch [9/100], Loss: 1.0661, Eval Accuracy: 0.4922, Took 87.25 s\n","Epoch [10/100], Loss: 1.0642, Eval Accuracy: 0.4936, Took 87.25 s\n","Epoch [11/100], Loss: 1.0622, Eval Accuracy: 0.4928, Took 87.27 s\n","Epoch [12/100], Loss: 1.0605, Eval Accuracy: 0.496, Took 87.29 s\n","Epoch [13/100], Loss: 1.0588, Eval Accuracy: 0.4975, Took 87.23 s\n","Epoch [14/100], Loss: 1.057, Eval Accuracy: 0.4985, Took 87.34 s\n","Epoch [15/100], Loss: 1.0554, Eval Accuracy: 0.5002, Took 87.46 s\n","Epoch [16/100], Loss: 1.0538, Eval Accuracy: 0.4975, Took 87.29 s\n","Epoch [17/100], Loss: 1.0523, Eval Accuracy: 0.5015, Took 87.32 s\n","Epoch [18/100], Loss: 1.0511, Eval Accuracy: 0.5022, Took 87.31 s\n","Epoch [19/100], Loss: 1.0496, Eval Accuracy: 0.503, Took 87.31 s\n","Epoch [20/100], Loss: 1.0484, Eval Accuracy: 0.5039, Took 87.31 s\n","Epoch [21/100], Loss: 1.0471, Eval Accuracy: 0.5046, Took 87.35 s\n","Epoch [22/100], Loss: 1.0461, Eval Accuracy: 0.5066, Took 87.34 s\n","Epoch [23/100], Loss: 1.045, Eval Accuracy: 0.5064, Took 87.35 s\n","Epoch [24/100], Loss: 1.0439, Eval Accuracy: 0.5081, Took 87.38 s\n","Epoch [25/100], Loss: 1.0429, Eval Accuracy: 0.5075, Took 87.91 s\n","Epoch [26/100], Loss: 1.042, Eval Accuracy: 0.5088, Took 88.52 s\n","Epoch [27/100], Loss: 1.041, Eval Accuracy: 0.5097, Took 87.31 s\n","Epoch [28/100], Loss: 1.0402, Eval Accuracy: 0.5096, Took 87.58 s\n","Epoch [29/100], Loss: 1.0393, Eval Accuracy: 0.5114, Took 87.36 s\n","Epoch [30/100], Loss: 1.0385, Eval Accuracy: 0.5095, Took 87.37 s\n","Epoch [31/100], Loss: 1.0378, Eval Accuracy: 0.5104, Took 88.03 s\n","Epoch [32/100], Loss: 1.037, Eval Accuracy: 0.5112, Took 87.41 s\n","Epoch [33/100], Loss: 1.0363, Eval Accuracy: 0.5125, Took 88.22 s\n","Epoch [34/100], Loss: 1.0356, Eval Accuracy: 0.5127, Took 87.51 s\n","Epoch [35/100], Loss: 1.0349, Eval Accuracy: 0.5134, Took 87.37 s\n","Epoch [36/100], Loss: 1.0343, Eval Accuracy: 0.5138, Took 87.37 s\n","Epoch [37/100], Loss: 1.0338, Eval Accuracy: 0.5142, Took 88.24 s\n","Epoch [38/100], Loss: 1.0332, Eval Accuracy: 0.515, Took 87.41 s\n","Epoch [39/100], Loss: 1.0327, Eval Accuracy: 0.5152, Took 87.35 s\n","Epoch [40/100], Loss: 1.0322, Eval Accuracy: 0.5146, Took 87.53 s\n","Epoch [41/100], Loss: 1.0317, Eval Accuracy: 0.5157, Took 88.37 s\n","Epoch [42/100], Loss: 1.0311, Eval Accuracy: 0.5147, Took 87.34 s\n","Epoch [43/100], Loss: 1.0307, Eval Accuracy: 0.5162, Took 87.34 s\n","Epoch [44/100], Loss: 1.0303, Eval Accuracy: 0.5153, Took 87.33 s\n","Epoch [45/100], Loss: 1.0297, Eval Accuracy: 0.5163, Took 87.47 s\n","Epoch [46/100], Loss: 1.0293, Eval Accuracy: 0.5167, Took 87.33 s\n","Epoch [47/100], Loss: 1.0289, Eval Accuracy: 0.5177, Took 87.46 s\n","Epoch [48/100], Loss: 1.0285, Eval Accuracy: 0.5178, Took 87.34 s\n","Epoch [49/100], Loss: 1.028, Eval Accuracy: 0.518, Took 87.35 s\n","Epoch [50/100], Loss: 1.0276, Eval Accuracy: 0.5176, Took 87.45 s\n","Epoch [51/100], Loss: 1.0273, Eval Accuracy: 0.5178, Took 87.75 s\n","Epoch [52/100], Loss: 1.0269, Eval Accuracy: 0.5182, Took 87.86 s\n","Epoch [53/100], Loss: 1.0266, Eval Accuracy: 0.519, Took 87.87 s\n","Epoch [54/100], Loss: 1.0262, Eval Accuracy: 0.5187, Took 87.68 s\n","Epoch [55/100], Loss: 1.0259, Eval Accuracy: 0.5194, Took 88.06 s\n","Epoch [56/100], Loss: 1.0256, Eval Accuracy: 0.5194, Took 87.35 s\n","Epoch [57/100], Loss: 1.0253, Eval Accuracy: 0.5197, Took 87.95 s\n","Epoch [58/100], Loss: 1.0249, Eval Accuracy: 0.5194, Took 87.7 s\n","Epoch [59/100], Loss: 1.0246, Eval Accuracy: 0.5193, Took 88.43 s\n","Epoch [60/100], Loss: 1.0243, Eval Accuracy: 0.5194, Took 87.62 s\n","Epoch [61/100], Loss: 1.0241, Eval Accuracy: 0.5197, Took 87.44 s\n","Epoch [62/100], Loss: 1.0237, Eval Accuracy: 0.5197, Took 87.35 s\n","Epoch [63/100], Loss: 1.0235, Eval Accuracy: 0.52, Took 87.52 s\n","Epoch [64/100], Loss: 1.0233, Eval Accuracy: 0.5207, Took 87.39 s\n","Epoch [65/100], Loss: 1.023, Eval Accuracy: 0.5203, Took 87.35 s\n","Epoch [66/100], Loss: 1.0227, Eval Accuracy: 0.5214, Took 87.39 s\n","Epoch [67/100], Loss: 1.0225, Eval Accuracy: 0.5204, Took 87.45 s\n","Epoch [68/100], Loss: 1.0223, Eval Accuracy: 0.5212, Took 88.43 s\n","Epoch [69/100], Loss: 1.022, Eval Accuracy: 0.5218, Took 87.43 s\n","Epoch [70/100], Loss: 1.0218, Eval Accuracy: 0.5201, Took 87.53 s\n","Epoch [71/100], Loss: 1.0216, Eval Accuracy: 0.5213, Took 87.62 s\n","Stopped early after epoch 71 as validation accuracy was lower than average of the last 7 accuracies.\n","Last Loss: 1.0216, Last Eval Accuracy: 0.5213, Took 6217.62 s\n","Model saved as 20240616111205_encoder_64em_4l_4h_posenc_02dr_71ep.pt\n","------------\n","Not saved as loss too high:\n","[]\n"]},{"data":{"text/plain":["{'encoder_64em_4l_4h_posenc_02dr_100ep': 0.5213}"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["embed_dims = [64]\n","num_encoder_layers = [4]\n","num_heads = [4]\n","DROPOUTS = [0.2]\n","POS_ENC = [True, False]\n","e.hyper_parameter_training(embed_dims, num_encoder_layers, num_heads, DROPOUTS, POS_ENC, epochs=100)"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["----- Start Training: 64 emb, 4 layers, 4 heads, 0.2 dropout, positional encoding: True, 400 epochs -----\n"]},{"name":"stderr","output_type":"stream","text":["/home/mkuehn/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [301/400], Loss: 1.0051, Eval Accuracy: 0.5313, Took 87.27 s\n","Epoch [302/400], Loss: 1.0049, Eval Accuracy: 0.5315, Took 87.05 s\n","Epoch [303/400], Loss: 1.005, Eval Accuracy: 0.5316, Took 87.22 s\n","Epoch [304/400], Loss: 1.005, Eval Accuracy: 0.5314, Took 87.19 s\n","Epoch [305/400], Loss: 1.0048, Eval Accuracy: 0.5316, Took 87.35 s\n","Epoch [306/400], Loss: 1.0049, Eval Accuracy: 0.5319, Took 87.17 s\n","Epoch [307/400], Loss: 1.0048, Eval Accuracy: 0.5309, Took 87.11 s\n","Epoch [308/400], Loss: 1.0049, Eval Accuracy: 0.5321, Took 87.17 s\n","Epoch [309/400], Loss: 1.0047, Eval Accuracy: 0.5321, Took 87.18 s\n","Epoch [310/400], Loss: 1.0047, Eval Accuracy: 0.5316, Took 87.16 s\n","Epoch [311/400], Loss: 1.0046, Eval Accuracy: 0.5314, Took 87.33 s\n","Epoch [312/400], Loss: 1.0048, Eval Accuracy: 0.532, Took 87.19 s\n","Epoch [313/400], Loss: 1.0046, Eval Accuracy: 0.5315, Took 87.22 s\n","Epoch [314/400], Loss: 1.0046, Eval Accuracy: 0.5315, Took 87.22 s\n","Epoch [315/400], Loss: 1.0045, Eval Accuracy: 0.5315, Took 87.15 s\n","Epoch [316/400], Loss: 1.0044, Eval Accuracy: 0.5318, Took 87.07 s\n","Epoch [317/400], Loss: 1.0045, Eval Accuracy: 0.5315, Took 87.16 s\n","Epoch [318/400], Loss: 1.0045, Eval Accuracy: 0.5319, Took 87.2 s\n","Epoch [319/400], Loss: 1.0044, Eval Accuracy: 0.5314, Took 87.27 s\n","Epoch [320/400], Loss: 1.0044, Eval Accuracy: 0.5318, Took 87.42 s\n","Epoch [321/400], Loss: 1.0043, Eval Accuracy: 0.5314, Took 87.38 s\n","Epoch [322/400], Loss: 1.0044, Eval Accuracy: 0.5322, Took 87.7 s\n","Epoch [323/400], Loss: 1.0043, Eval Accuracy: 0.5318, Took 87.18 s\n","Epoch [324/400], Loss: 1.0043, Eval Accuracy: 0.5319, Took 87.43 s\n","Epoch [325/400], Loss: 1.0042, Eval Accuracy: 0.5315, Took 87.2 s\n","Epoch [326/400], Loss: 1.0042, Eval Accuracy: 0.5321, Took 87.27 s\n","Epoch [327/400], Loss: 1.0042, Eval Accuracy: 0.5317, Took 87.19 s\n","Epoch [328/400], Loss: 1.0041, Eval Accuracy: 0.5323, Took 87.23 s\n","Epoch [329/400], Loss: 1.0041, Eval Accuracy: 0.5316, Took 87.33 s\n","Epoch [330/400], Loss: 1.004, Eval Accuracy: 0.5315, Took 87.59 s\n","Epoch [331/400], Loss: 1.0041, Eval Accuracy: 0.5319, Took 87.22 s\n","Epoch [332/400], Loss: 1.004, Eval Accuracy: 0.5319, Took 87.4 s\n","Epoch [333/400], Loss: 1.004, Eval Accuracy: 0.5321, Took 87.14 s\n","Epoch [334/400], Loss: 1.0039, Eval Accuracy: 0.5323, Took 87.19 s\n","Epoch [335/400], Loss: 1.0039, Eval Accuracy: 0.5319, Took 87.06 s\n","Epoch [336/400], Loss: 1.004, Eval Accuracy: 0.5323, Took 87.08 s\n","Epoch [337/400], Loss: 1.0038, Eval Accuracy: 0.5322, Took 87.7 s\n","Epoch [338/400], Loss: 1.0038, Eval Accuracy: 0.5323, Took 87.29 s\n","Epoch [339/400], Loss: 1.0038, Eval Accuracy: 0.5322, Took 87.42 s\n","Epoch [340/400], Loss: 1.0039, Eval Accuracy: 0.5321, Took 87.51 s\n","Epoch [341/400], Loss: 1.0037, Eval Accuracy: 0.5311, Took 87.14 s\n","Epoch [342/400], Loss: 1.0037, Eval Accuracy: 0.5315, Took 87.15 s\n","Epoch [343/400], Loss: 1.0037, Eval Accuracy: 0.5322, Took 87.12 s\n","Epoch [344/400], Loss: 1.0037, Eval Accuracy: 0.5321, Took 87.2 s\n","Epoch [345/400], Loss: 1.0036, Eval Accuracy: 0.5321, Took 87.12 s\n","Epoch [346/400], Loss: 1.0036, Eval Accuracy: 0.5317, Took 87.29 s\n","Epoch [347/400], Loss: 1.0035, Eval Accuracy: 0.5319, Took 87.14 s\n","Epoch [348/400], Loss: 1.0036, Eval Accuracy: 0.5319, Took 87.51 s\n","Epoch [349/400], Loss: 1.0035, Eval Accuracy: 0.532, Took 87.22 s\n","Epoch [350/400], Loss: 1.0035, Eval Accuracy: 0.5321, Took 87.32 s\n","Epoch [351/400], Loss: 1.0034, Eval Accuracy: 0.5323, Took 87.13 s\n","Epoch [352/400], Loss: 1.0034, Eval Accuracy: 0.5321, Took 87.56 s\n","Epoch [353/400], Loss: 1.0034, Eval Accuracy: 0.532, Took 87.4 s\n","Epoch [354/400], Loss: 1.0033, Eval Accuracy: 0.5322, Took 87.21 s\n","Epoch [355/400], Loss: 1.0034, Eval Accuracy: 0.5317, Took 87.16 s\n","Epoch [356/400], Loss: 1.0033, Eval Accuracy: 0.5326, Took 87.31 s\n","Epoch [357/400], Loss: 1.0032, Eval Accuracy: 0.5319, Took 87.17 s\n","Epoch [358/400], Loss: 1.0033, Eval Accuracy: 0.5323, Took 87.24 s\n","Epoch [359/400], Loss: 1.0032, Eval Accuracy: 0.5323, Took 87.45 s\n","Epoch [360/400], Loss: 1.0032, Eval Accuracy: 0.5324, Took 87.1 s\n","Epoch [361/400], Loss: 1.0031, Eval Accuracy: 0.5327, Took 87.07 s\n","Epoch [362/400], Loss: 1.0032, Eval Accuracy: 0.5325, Took 87.27 s\n","Epoch [363/400], Loss: 1.0032, Eval Accuracy: 0.5322, Took 87.1 s\n","Epoch [364/400], Loss: 1.003, Eval Accuracy: 0.5314, Took 87.47 s\n","Epoch [365/400], Loss: 1.0031, Eval Accuracy: 0.5317, Took 87.13 s\n"]}],"source":["# Train best model \n","embed_dims = [64]\n","num_encoder_layers = [4]\n","num_heads = [4]\n","DROPOUTS = [0.2]\n","POS_ENC = [True]\n","accuracies, all_accuracies, best_model_state = e.hyper_parameter_training(embed_dims, num_encoder_layers, num_heads, DROPOUTS, POS_ENC, epochs=400, validation_stop=False, start_epoch=300, current_best_model_state=training_results_1[\"best_model_state\"], existing_model=model)"]},{"cell_type":"markdown","metadata":{},"source":["time: 4435 + 13280 + 5089 + 4376 + 8752"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["training_results = {\n","    \"time\": 4435 + 13280 + 5089 + 4376 + 8752,\n","    \"best_model_state\": best_model_state,\n","    \"all_accuracies\": all_accuracies['encoder_64em_4l_4h_posenc_02dr_400ep']\n","}"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["mlh.to_pickle(training_results, data_path+f'/Homo.Sapiens/training_results_encoder.pkl')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":0}
