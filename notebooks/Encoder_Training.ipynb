{"cells":[{"cell_type":"markdown","metadata":{"id":"dvibukPbQ7Zg"},"source":["# Encoder-only Transformer Architektur"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20842,"status":"ok","timestamp":1715688662385,"user":{"displayName":"Insa Belter","userId":"09408038895575287386"},"user_tz":-120},"id":"fXeUV5wCRtUz","outputId":"2bb0af2b-b2a5-4f6e-c9d6-addcb643a568"},"outputs":[],"source":["#from google.colab import drive\n","#drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8804,"status":"ok","timestamp":1715688671184,"user":{"displayName":"Insa Belter","userId":"09408038895575287386"},"user_tz":-120},"id":"3yudZ4edSJEQ","outputId":"d4151a0c-b418-4144-d13b-0f4aef17b8a7"},"outputs":[{"name":"stdout","output_type":"stream","text":["Defaulting to user installation because normal site-packages is not writeable\n","Requirement already satisfied: biopython in /home/mkuehn/.local/lib/python3.10/site-packages (1.83)\n","Requirement already satisfied: numpy in /home/mkuehn/.local/lib/python3.10/site-packages (from biopython) (1.26.4)\n"]}],"source":["!pip install biopython"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":5081,"status":"ok","timestamp":1715688676256,"user":{"displayName":"Insa Belter","userId":"09408038895575287386"},"user_tz":-120},"id":"ev_KN7VqQ7Zm"},"outputs":[],"source":["import sys\n","import random\n","import numpy as np\n","import pandas as pd\n","import ast\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader\n","from torch import Tensor\n","from torch.nn import TransformerEncoderLayer\n","import time\n","import math\n","\n","sys.path.append('../scripts')\n","#sys.path.append('/content/drive/MyDrive/PMDS/Notebooks')\n","import ml_helper\n","import custom_transformer_encoder as custom_te"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1715688676256,"user":{"displayName":"Insa Belter","userId":"09408038895575287386"},"user_tz":-120},"id":"9eRDLHmaS7Im"},"outputs":[],"source":["#data_path = '/content/drive/MyDrive/PMDS/Data'\n","data_path = '../data'"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1715688676256,"user":{"displayName":"Insa Belter","userId":"09408038895575287386"},"user_tz":-120},"id":"0ayA8mz2Q7Zp"},"outputs":[],"source":["SEED = 42\n","def set_seed(SEED=SEED):\n","    random.seed(SEED)\n","    np.random.seed(SEED)\n","    torch.manual_seed(SEED)\n","    torch.cuda.manual_seed(SEED)\n","set_seed()"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":566,"status":"ok","timestamp":1715688676819,"user":{"displayName":"Insa Belter","userId":"09408038895575287386"},"user_tz":-120},"id":"5hFAHJ8hRE8p","outputId":"6c9d739b-7b72-447c-878a-a0291901b15d"},"outputs":[{"name":"stdout","output_type":"stream","text":["cpu\n"]}],"source":["device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n","print(device)"]},{"cell_type":"markdown","metadata":{"id":"1iTm60N3Q7Zr"},"source":["## Prepare Valid and Training Data Loader"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1715688680014,"user":{"displayName":"Insa Belter","userId":"09408038895575287386"},"user_tz":-120},"id":"iZLLB2yhQ7Zs"},"outputs":[],"source":["amino_acids = ['A', 'R', 'N', 'D', 'C', 'Q', 'E', 'G', 'H', 'I', 'L', 'K', 'M', 'F', 'P', 'S', 'T', 'W', 'Y', 'V', '*',\n","               '_']\n","\n","aminoacids_to_integer = dict((a, i) for i, a in enumerate(amino_acids))\n","integer_to_aminoacids = dict((i, a) for i, a in enumerate(amino_acids))\n","\n","codons = ['TTT', 'TTC', 'TTA', 'TTG', 'TCT', 'TCC', 'TCA', 'TCG', 'TAT', 'TAC', 'TAA', 'TAG', 'TGT', 'TGC', 'TGA',\n","          'TGG', 'CTT', 'CTC', 'CTA', 'CTG', 'CCT', 'CCC', 'CCA', 'CCG', 'CAT', 'CAC', 'CAA', 'CAG', 'CGT', 'CGC',\n","          'CGA', 'CGG', 'ATT', 'ATC', 'ATA', 'ATG', 'ACT', 'ACC', 'ACA', 'ACG', 'AAT', 'AAC', 'AAA', 'AAG', 'AGT',\n","          'AGC', 'AGA', 'AGG', 'GTT', 'GTC', 'GTA', 'GTG', 'GCT', 'GCC', 'GCA', 'GCG', 'GAT', 'GAC', 'GAA', 'GAG',\n","          'GGT', 'GGC', 'GGA', 'GGG', '___']\n","\n","codons_to_integer = dict((c, i) for i, c in enumerate(codons))\n","integer_to_codons = dict((i, c) for i, c in enumerate(codons))"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14935,"status":"ok","timestamp":1715688695565,"user":{"displayName":"Insa Belter","userId":"09408038895575287386"},"user_tz":-120},"id":"8w1wA5dDQ7Zt","outputId":"f67d1129-17d1-4a11-f6b0-83a4f973ba75"},"outputs":[{"name":"stdout","output_type":"stream","text":["Länge train_dataset: 3555\n","Länge valid_dataset: 420\n"]}],"source":["organism = \"E.Coli\"\n","min_length = None\n","max_length = 500\n","\n","SPEEDS_ADDED = False\n","\n","train_dataset = ml_helper.CodonDataset(organism, \"train\", min_length, max_length, add_speeds=SPEEDS_ADDED, cut_data=True, one_hot_aa=False, data_path=data_path, device=device)\n","print(f\"Länge train_dataset: {len(train_dataset)}\")\n","valid_dataset = ml_helper.CodonDataset(organism, \"valid\", min_length, max_length, add_speeds=SPEEDS_ADDED, cut_data=True, one_hot_aa=False, data_path=data_path, device=device)\n","print(f\"Länge valid_dataset: {len(valid_dataset)}\")"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":369,"status":"ok","timestamp":1715688695930,"user":{"displayName":"Insa Belter","userId":"09408038895575287386"},"user_tz":-120},"id":"TDq7AeaFQ7Zv","outputId":"1b96196c-89a7-4031-b63e-6a9358f7aa09"},"outputs":[{"name":"stdout","output_type":"stream","text":["(tensor([12, 16, 18,  0, 19,  6, 13,  3,  2, 19, 15,  1, 10, 18,  7,  3, 19,  1,\n","         0, 19,  3,  7, 19, 15,  9,  0,  9, 11,  3,  7,  6, 13, 13, 15, 12, 10,\n","         7, 14, 15,  7, 15,  7, 11, 16, 16,  4, 10,  1, 10,  9,  0,  7, 13,  6,\n","         5, 10, 15,  7,  7,  0,  9, 15,  9, 13,  7, 11, 14,  0, 15,  2, 10, 14,\n","        14, 17,  6,  1,  3, 19,  2, 16, 19, 13,  5,  3, 18,  0, 10, 13, 14,  8,\n","        12, 15,  9, 10,  3,  2, 19,  0, 18,  7, 10, 12, 19, 11,  7, 19,  2, 11,\n","        11,  5,  1,  8,  0, 12,  0,  5,  6,  0, 10,  6, 11, 19,  0, 10,  7, 13,\n","        19,  8,  5,  1, 11, 14, 15,  5, 10, 15,  7,  7,  5,  1,  5,  1, 19,  0,\n","         9,  0,  1,  0, 10, 19,  2,  6, 14,  1, 19, 10, 10, 10,  3,  6, 14, 10,\n","         7,  0, 10,  3, 10, 11, 10,  1,  6,  5, 12,  5, 10,  6, 10, 11, 11, 10,\n","         5,  5, 15, 10,  7,  9, 16, 13,  9, 13, 19, 16,  8,  3,  5,  7,  6,  0,\n","        10, 15, 12, 15,  3,  1, 19,  0, 19, 13,  2,  2,  7,  1,  9,  6,  5, 19,\n","         3, 15, 14,  1,  3, 10, 18, 12,  1, 14,  1, 16, 14, 13, 19,  0,  7, 13,\n","        19,  7, 16, 15,  2, 19, 13,  3,  7, 10, 12,  0,  6, 11, 10,  4,  7, 12,\n","        16,  7, 15, 13,  0, 10,  1, 14,  6,  8,  9,  1, 10,  2, 16, 14,  7,  6,\n","        10,  5,  0,  2,  7, 16,  9,  5,  0, 19,  5, 18,  5,  7,  0,  0, 16,  1,\n","        13,  6, 10, 11, 10,  2,  7,  7,  6, 11, 10, 10, 19, 15,  5,  0,  2, 12,\n","        16,  7,  6,  6, 10, 14,  0, 16, 10, 16, 14,  7,  5,  5, 19, 12, 19, 15,\n","        17, 15,  1,  3, 19, 12, 19, 14, 10, 19,  6,  6,  1, 21, 21, 21, 21, 21,\n","        21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21,\n","        21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21,\n","        21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21,\n","        21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21,\n","        21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21,\n","        21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21,\n","        21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21,\n","        21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21,\n","        21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21],\n","       dtype=torch.int32), tensor([35., 39.,  9., 54., 51., 59.,  0., 57., 41., 49.,  7., 31.,  3.,  9.,\n","        60., 57., 51., 29., 54., 50., 56., 61., 49., 44., 32., 55., 34., 42.,\n","        56., 60., 59.,  1.,  1.,  4., 35., 19., 63., 23.,  5., 61.,  5., 61.,\n","        42., 37., 37., 13., 19., 29., 19., 32., 52., 61.,  1., 58., 27., 16.,\n","         5., 61., 63., 52., 33.,  4., 33.,  0., 60., 42., 21., 53., 45., 40.,\n","        19., 22., 23., 15., 59., 31., 57., 51., 40., 36., 49.,  0., 27., 57.,\n","         9., 55., 18.,  0., 23., 24., 35.,  7., 32., 16., 57., 40., 49., 53.,\n","         8., 63., 19., 35., 49., 42., 61., 51., 40., 42., 43., 27., 31., 25.,\n","        54., 35., 55., 26., 59., 55., 19., 59., 42., 51., 55.,  3., 63.,  0.,\n","        50., 24., 26., 28., 42., 23.,  6., 26., 16.,  4., 60., 60., 27., 29.,\n","        27., 31., 48., 52., 33., 53., 46., 54.,  3., 51., 40., 58., 23., 29.,\n","        50.,  3., 19.,  3., 56., 58., 23., 17., 61., 54., 19., 56., 17., 42.,\n","         3., 28., 59., 27., 35., 27., 19., 58., 19., 42., 42., 19., 26., 27.,\n","         4., 17., 60., 33., 36.,  0., 33.,  1., 48., 37., 25., 56., 27., 61.,\n","        58., 55.,  2.,  7., 35.,  5., 56., 28., 51., 55., 48.,  1., 40., 40.,\n","        62., 29., 32., 59., 27., 49., 56.,  5., 23., 29., 56., 17.,  8., 35.,\n","        29., 23., 29., 39., 23.,  0., 48., 53., 63.,  1., 48., 60., 38.,  7.,\n","        40., 48.,  0., 56., 62., 19., 35., 54., 59., 42., 16., 12., 61., 35.,\n","        39., 62., 45.,  1., 53., 19., 30., 23., 58., 24., 33., 29., 17., 41.,\n","        37., 20., 60., 58., 19., 27., 53., 40., 61., 39., 33., 27., 55., 51.,\n","        26.,  8., 27., 61., 55., 54., 36., 28.,  0., 58., 19., 42.,  3., 41.,\n","        61., 60., 58., 42., 19., 16., 51., 44., 27., 53., 40., 35., 38., 61.,\n","        58., 58., 19., 20., 53., 39., 17., 39., 21., 62., 26., 27., 51., 35.,\n","        48.,  5., 15.,  7., 28., 56., 51., 35., 51., 23., 19., 48., 59., 59.,\n","        47., 64., 64., 64., 64., 64., 64., 64., 64., 64., 64., 64., 64., 64.,\n","        64., 64., 64., 64., 64., 64., 64., 64., 64., 64., 64., 64., 64., 64.,\n","        64., 64., 64., 64., 64., 64., 64., 64., 64., 64., 64., 64., 64., 64.,\n","        64., 64., 64., 64., 64., 64., 64., 64., 64., 64., 64., 64., 64., 64.,\n","        64., 64., 64., 64., 64., 64., 64., 64., 64., 64., 64., 64., 64., 64.,\n","        64., 64., 64., 64., 64., 64., 64., 64., 64., 64., 64., 64., 64., 64.,\n","        64., 64., 64., 64., 64., 64., 64., 64., 64., 64., 64., 64., 64., 64.,\n","        64., 64., 64., 64., 64., 64., 64., 64., 64., 64., 64., 64., 64., 64.,\n","        64., 64., 64., 64., 64., 64., 64., 64., 64., 64., 64., 64., 64., 64.,\n","        64., 64., 64., 64., 64., 64., 64., 64., 64., 64., 64., 64., 64., 64.,\n","        64., 64., 64., 64., 64., 64., 64., 64., 64., 64., 64., 64., 64., 64.,\n","        64., 64., 64., 64., 64., 64., 64., 64., 64., 64.]))\n","torch.Size([500])\n","torch.Size([500])\n"]}],"source":["print(train_dataset[3])\n","print(train_dataset[3][0].shape)\n","print(train_dataset[3][1].shape)"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1715688695930,"user":{"displayName":"Insa Belter","userId":"09408038895575287386"},"user_tz":-120},"id":"MQvx476IQ7Zw"},"outputs":[],"source":["BATCH_SIZE = 32\n","train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n","valid_loader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False)"]},{"cell_type":"markdown","metadata":{"id":"6UP5EBpZQ7Zx"},"source":["## Define the encoder-only model"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["class PositionalEncoding(nn.Module):\n","\n","    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 500):\n","        super().__init__()\n","        self.dropout = nn.Dropout(p=dropout)\n","\n","        position = torch.arange(max_len).unsqueeze(1)\n","        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n","        pe = torch.zeros(max_len, 1, d_model)\n","        pe[:, 0, 0::2] = torch.sin(position * div_term)\n","        pe[:, 0, 1::2] = torch.cos(position * div_term)\n","        self.register_buffer('pe', pe)\n","\n","    def forward(self, x: Tensor) -> Tensor:\n","        \"\"\"\n","        Arguments:\n","            x: Tensor, shape ``[seq_len, batch_size, embedding_dim]``\n","        \"\"\"\n","        x = x + self.pe[:x.size(0)]\n","        return self.dropout(x)"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":272,"status":"ok","timestamp":1715688700989,"user":{"displayName":"Insa Belter","userId":"09408038895575287386"},"user_tz":-120},"id":"DmAoTz7sQ7Zx"},"outputs":[],"source":["class EncoderClassifier(nn.Module):\n","    def __init__(self, embed_dim, num_layers, num_heads, dropout=0.2, pos_enc=False):\n","        super(EncoderClassifier, self).__init__()\n","\n","        emb_size = embed_dim\n","        if SPEEDS_ADDED:\n","            emb_size -= 1\n","        self.emb = nn.Embedding(len(amino_acids), emb_size, padding_idx=len(amino_acids)-1)\n","        self.pos_enc = pos_enc\n","        self.pos_encoder = PositionalEncoding(embed_dim, dropout)\n","\n","        self.encoder_layer = custom_te.CustomTransformerEncoderLayer(\n","            d_model=embed_dim,\n","            nhead=num_heads,\n","            batch_first=True\n","        )\n","        self.encoder = custom_te.CustomTransformerEncoder(\n","            encoder_layer=self.encoder_layer,\n","            num_layers=num_layers,\n","        )\n","\n","        self.linear = nn.Linear(embed_dim, len(codons))\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, x, attn_weights_needed=False):\n","        x = x.long()\n","        if SPEEDS_ADDED:\n","            x1 = self.emb(x[:, :, 0])\n","            x2 = x[:, :, 1].unsqueeze(-1)\n","            x = torch.cat((x1, x2), dim=-1)  # Concatenate along the feature dimension\n","        else:\n","            x = self.emb(x)\n","\n","        if self.pos_enc:\n","            x = x.transpose(0, 1)\n","            x = self.pos_encoder(x)  # Add positional encoding\n","            x = x.transpose(0, 1)\n","        \n","        if attn_weights_needed:\n","            x, attn_weights = self.encoder(x, attn_weights_needed=attn_weights_needed)\n","            x = self.dropout(x)\n","            out = self.linear(x)\n","            return out, attn_weights\n","        else:\n","            x = self.encoder(x, attn_weights_needed=attn_weights_needed)\n","            x = self.dropout(x)\n","            out = self.linear(x)\n","            return out\n"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1715688701504,"user":{"displayName":"Insa Belter","userId":"09408038895575287386"},"user_tz":-120},"id":"2u2Dbb0rQ7Zy"},"outputs":[],"source":["EMBED_DIM = 256\n","NUM_ENCODER_LAYERS = 4\n","NUM_HEADS = 4\n","DROP_OUT = 0.2"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1715688702540,"user":{"displayName":"Insa Belter","userId":"09408038895575287386"},"user_tz":-120},"id":"33ksA3YLQ7Zy","outputId":"559e6f1f-4377-402d-fe71-a0adf4a7a70f"},"outputs":[{"name":"stdout","output_type":"stream","text":["EncoderClassifier(\n","  (emb): Embedding(22, 256, padding_idx=21)\n","  (pos_encoder): PositionalEncoding(\n","    (dropout): Dropout(p=0.2, inplace=False)\n","  )\n","  (encoder_layer): CustomTransformerEncoderLayer(\n","    (self_attn): MultiheadAttention(\n","      (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n","    )\n","    (linear1): Linear(in_features=256, out_features=2048, bias=True)\n","    (dropout): Dropout(p=0.1, inplace=False)\n","    (linear2): Linear(in_features=2048, out_features=256, bias=True)\n","    (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","    (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","    (dropout1): Dropout(p=0.1, inplace=False)\n","    (dropout2): Dropout(p=0.1, inplace=False)\n","  )\n","  (encoder): CustomTransformerEncoder(\n","    (layers): ModuleList(\n","      (0-3): 4 x CustomTransformerEncoderLayer(\n","        (self_attn): MultiheadAttention(\n","          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n","        )\n","        (linear1): Linear(in_features=256, out_features=2048, bias=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","        (linear2): Linear(in_features=2048, out_features=256, bias=True)\n","        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","        (dropout1): Dropout(p=0.1, inplace=False)\n","        (dropout2): Dropout(p=0.1, inplace=False)\n","      )\n","    )\n","  )\n","  (linear): Linear(in_features=256, out_features=65, bias=True)\n","  (dropout): Dropout(p=0.2, inplace=False)\n",")\n"]}],"source":["model = EncoderClassifier(\n","    embed_dim=EMBED_DIM,\n","    num_layers=NUM_ENCODER_LAYERS,\n","    num_heads=NUM_HEADS,\n","    dropout=DROP_OUT,\n","    pos_enc=True\n",").to(device)\n","print(model)"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1715688702799,"user":{"displayName":"Insa Belter","userId":"09408038895575287386"},"user_tz":-120},"id":"DLRNk1mnQ7Zz"},"outputs":[],"source":["# Total parameters and trainable parameters.\n","def print_parameters(model):\n","    total_params = sum(p.numel() for p in model.parameters())\n","    print(f\"{total_params:,} total parameters.\")\n","    total_trainable_params = sum(\n","        p.numel() for p in model.parameters() if p.requires_grad)\n","    print(f\"{total_trainable_params:,} training parameters.\")"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1715688703433,"user":{"displayName":"Insa Belter","userId":"09408038895575287386"},"user_tz":-120},"id":"Ua_2VN3NQ7Zz","outputId":"472c69d7-94cb-40cd-bd7e-8e1e75c00415"},"outputs":[{"name":"stdout","output_type":"stream","text":["6,597,697 total parameters.\n","6,597,697 training parameters.\n"]}],"source":["print_parameters(model)"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1715688704233,"user":{"displayName":"Insa Belter","userId":"09408038895575287386"},"user_tz":-120},"id":"6SEl0FSxQ7Zz"},"outputs":[],"source":["def test_forward_pass(model, data_loader):\n","  batch_data, batch_label = next(iter(data_loader))\n","  print(f\"input dim: {batch_data.shape}\")\n","  output, attn_weights = model(batch_data, attn_weights_needed=True)\n","  print(f\"output dim: {output.shape}\")\n","  print(f\"attr_weights dim: {attn_weights}\")"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1152,"status":"ok","timestamp":1715688705880,"user":{"displayName":"Insa Belter","userId":"09408038895575287386"},"user_tz":-120},"id":"X9OgGtB6Q7Z0","outputId":"52e399fa-b185-4c52-c314-91c772f4e98f"},"outputs":[{"name":"stdout","output_type":"stream","text":["input dim: torch.Size([32, 500])\n","output dim: torch.Size([32, 500, 65])\n","attr_weights dim: [tensor([[[0.0019, 0.0040, 0.0026,  ..., 0.0020, 0.0024, 0.0015],\n","         [0.0024, 0.0024, 0.0016,  ..., 0.0015, 0.0017, 0.0012],\n","         [0.0034, 0.0020, 0.0034,  ..., 0.0015, 0.0012, 0.0018],\n","         ...,\n","         [0.0022, 0.0006, 0.0026,  ..., 0.0021, 0.0013, 0.0024],\n","         [0.0026, 0.0029, 0.0011,  ..., 0.0017, 0.0021, 0.0024],\n","         [0.0023, 0.0026, 0.0022,  ..., 0.0016, 0.0016, 0.0022]],\n","\n","        [[0.0012, 0.0018, 0.0019,  ..., 0.0020, 0.0024, 0.0016],\n","         [0.0028, 0.0039, 0.0053,  ..., 0.0023, 0.0026, 0.0015],\n","         [0.0033, 0.0060, 0.0041,  ..., 0.0021, 0.0018, 0.0007],\n","         ...,\n","         [0.0017, 0.0024, 0.0020,  ..., 0.0022, 0.0022, 0.0024],\n","         [0.0014, 0.0023, 0.0017,  ..., 0.0022, 0.0025, 0.0026],\n","         [0.0026, 0.0024, 0.0025,  ..., 0.0022, 0.0024, 0.0023]],\n","\n","        [[0.0044, 0.0039, 0.0030,  ..., 0.0034, 0.0036, 0.0013],\n","         [0.0042, 0.0034, 0.0030,  ..., 0.0017, 0.0033, 0.0024],\n","         [0.0028, 0.0027, 0.0036,  ..., 0.0025, 0.0023, 0.0021],\n","         ...,\n","         [0.0043, 0.0019, 0.0042,  ..., 0.0061, 0.0049, 0.0040],\n","         [0.0032, 0.0025, 0.0027,  ..., 0.0011, 0.0038, 0.0008],\n","         [0.0015, 0.0021, 0.0014,  ..., 0.0074, 0.0028, 0.0039]],\n","\n","        ...,\n","\n","        [[0.0040, 0.0035, 0.0029,  ..., 0.0027, 0.0033, 0.0026],\n","         [0.0044, 0.0044, 0.0045,  ..., 0.0014, 0.0018, 0.0021],\n","         [0.0018, 0.0020, 0.0048,  ..., 0.0018, 0.0005, 0.0022],\n","         ...,\n","         [0.0020, 0.0017, 0.0021,  ..., 0.0018, 0.0019, 0.0023],\n","         [0.0023, 0.0029, 0.0021,  ..., 0.0021, 0.0029, 0.0019],\n","         [0.0016, 0.0027, 0.0015,  ..., 0.0016, 0.0021, 0.0023]],\n","\n","        [[0.0024, 0.0042, 0.0038,  ..., 0.0024, 0.0023, 0.0025],\n","         [0.0031, 0.0010, 0.0018,  ..., 0.0017, 0.0016, 0.0020],\n","         [0.0034, 0.0018, 0.0024,  ..., 0.0019, 0.0019, 0.0018],\n","         ...,\n","         [0.0018, 0.0020, 0.0024,  ..., 0.0024, 0.0025, 0.0023],\n","         [0.0025, 0.0010, 0.0012,  ..., 0.0018, 0.0025, 0.0024],\n","         [0.0022, 0.0004, 0.0031,  ..., 0.0012, 0.0026, 0.0024]],\n","\n","        [[0.0037, 0.0032, 0.0030,  ..., 0.0029, 0.0025, 0.0017],\n","         [0.0021, 0.0015, 0.0069,  ..., 0.0021, 0.0022, 0.0027],\n","         [0.0040, 0.0031, 0.0021,  ..., 0.0027, 0.0032, 0.0023],\n","         ...,\n","         [0.0021, 0.0021, 0.0019,  ..., 0.0019, 0.0030, 0.0022],\n","         [0.0020, 0.0015, 0.0026,  ..., 0.0027, 0.0027, 0.0021],\n","         [0.0013, 0.0015, 0.0027,  ..., 0.0024, 0.0010, 0.0023]]],\n","       grad_fn=<MeanBackward1>), tensor([[[0.0020, 0.0021, 0.0020,  ..., 0.0023, 0.0017, 0.0022],\n","         [0.0025, 0.0011, 0.0022,  ..., 0.0023, 0.0022, 0.0018],\n","         [0.0026, 0.0020, 0.0020,  ..., 0.0022, 0.0021, 0.0019],\n","         ...,\n","         [0.0028, 0.0021, 0.0021,  ..., 0.0023, 0.0017, 0.0017],\n","         [0.0017, 0.0022, 0.0019,  ..., 0.0023, 0.0022, 0.0022],\n","         [0.0027, 0.0022, 0.0020,  ..., 0.0024, 0.0023, 0.0018]],\n","\n","        [[0.0023, 0.0020, 0.0015,  ..., 0.0021, 0.0022, 0.0019],\n","         [0.0023, 0.0022, 0.0015,  ..., 0.0021, 0.0022, 0.0021],\n","         [0.0022, 0.0017, 0.0020,  ..., 0.0015, 0.0016, 0.0015],\n","         ...,\n","         [0.0023, 0.0022, 0.0011,  ..., 0.0020, 0.0023, 0.0019],\n","         [0.0017, 0.0022, 0.0021,  ..., 0.0021, 0.0016, 0.0020],\n","         [0.0023, 0.0023, 0.0021,  ..., 0.0020, 0.0017, 0.0021]],\n","\n","        [[0.0021, 0.0022, 0.0027,  ..., 0.0021, 0.0020, 0.0016],\n","         [0.0014, 0.0020, 0.0025,  ..., 0.0020, 0.0010, 0.0024],\n","         [0.0023, 0.0025, 0.0028,  ..., 0.0020, 0.0017, 0.0024],\n","         ...,\n","         [0.0015, 0.0018, 0.0027,  ..., 0.0017, 0.0021, 0.0016],\n","         [0.0016, 0.0021, 0.0026,  ..., 0.0022, 0.0012, 0.0018],\n","         [0.0010, 0.0023, 0.0020,  ..., 0.0023, 0.0011, 0.0018]],\n","\n","        ...,\n","\n","        [[0.0023, 0.0022, 0.0010,  ..., 0.0024, 0.0023, 0.0022],\n","         [0.0018, 0.0023, 0.0022,  ..., 0.0024, 0.0023, 0.0016],\n","         [0.0017, 0.0016, 0.0021,  ..., 0.0018, 0.0023, 0.0016],\n","         ...,\n","         [0.0017, 0.0022, 0.0022,  ..., 0.0025, 0.0024, 0.0022],\n","         [0.0021, 0.0022, 0.0017,  ..., 0.0024, 0.0013, 0.0022],\n","         [0.0016, 0.0021, 0.0016,  ..., 0.0025, 0.0023, 0.0021]],\n","\n","        [[0.0017, 0.0012, 0.0026,  ..., 0.0022, 0.0021, 0.0014],\n","         [0.0012, 0.0023, 0.0024,  ..., 0.0011, 0.0021, 0.0017],\n","         [0.0022, 0.0022, 0.0014,  ..., 0.0017, 0.0016, 0.0020],\n","         ...,\n","         [0.0017, 0.0023, 0.0020,  ..., 0.0021, 0.0020, 0.0016],\n","         [0.0015, 0.0023, 0.0021,  ..., 0.0023, 0.0016, 0.0016],\n","         [0.0022, 0.0024, 0.0013,  ..., 0.0021, 0.0021, 0.0022]],\n","\n","        [[0.0022, 0.0021, 0.0022,  ..., 0.0023, 0.0020, 0.0020],\n","         [0.0011, 0.0020, 0.0022,  ..., 0.0016, 0.0016, 0.0020],\n","         [0.0021, 0.0022, 0.0016,  ..., 0.0022, 0.0019, 0.0020],\n","         ...,\n","         [0.0020, 0.0020, 0.0017,  ..., 0.0022, 0.0015, 0.0019],\n","         [0.0016, 0.0022, 0.0022,  ..., 0.0022, 0.0020, 0.0016],\n","         [0.0020, 0.0020, 0.0022,  ..., 0.0022, 0.0015, 0.0020]]],\n","       grad_fn=<MeanBackward1>), tensor([[[0.0026, 0.0020, 0.0022,  ..., 0.0013, 0.0015, 0.0022],\n","         [0.0027, 0.0019, 0.0020,  ..., 0.0023, 0.0008, 0.0017],\n","         [0.0028, 0.0019, 0.0022,  ..., 0.0023, 0.0018, 0.0023],\n","         ...,\n","         [0.0013, 0.0020, 0.0016,  ..., 0.0017, 0.0019, 0.0018],\n","         [0.0027, 0.0012, 0.0022,  ..., 0.0023, 0.0019, 0.0023],\n","         [0.0027, 0.0019, 0.0021,  ..., 0.0023, 0.0015, 0.0023]],\n","\n","        [[0.0021, 0.0016, 0.0022,  ..., 0.0017, 0.0022, 0.0025],\n","         [0.0019, 0.0016, 0.0022,  ..., 0.0018, 0.0022, 0.0018],\n","         [0.0021, 0.0020, 0.0017,  ..., 0.0023, 0.0022, 0.0025],\n","         ...,\n","         [0.0019, 0.0014, 0.0022,  ..., 0.0023, 0.0017, 0.0024],\n","         [0.0013, 0.0021, 0.0023,  ..., 0.0023, 0.0019, 0.0025],\n","         [0.0016, 0.0015, 0.0022,  ..., 0.0023, 0.0022, 0.0018]],\n","\n","        [[0.0013, 0.0021, 0.0021,  ..., 0.0024, 0.0015, 0.0010],\n","         [0.0026, 0.0015, 0.0021,  ..., 0.0017, 0.0014, 0.0015],\n","         [0.0026, 0.0011, 0.0022,  ..., 0.0025, 0.0014, 0.0022],\n","         ...,\n","         [0.0021, 0.0021, 0.0021,  ..., 0.0023, 0.0020, 0.0016],\n","         [0.0028, 0.0021, 0.0021,  ..., 0.0017, 0.0015, 0.0017],\n","         [0.0026, 0.0021, 0.0022,  ..., 0.0024, 0.0019, 0.0015]],\n","\n","        ...,\n","\n","        [[0.0023, 0.0019, 0.0020,  ..., 0.0019, 0.0016, 0.0020],\n","         [0.0011, 0.0024, 0.0020,  ..., 0.0019, 0.0022, 0.0020],\n","         [0.0016, 0.0020, 0.0020,  ..., 0.0019, 0.0022, 0.0016],\n","         ...,\n","         [0.0022, 0.0025, 0.0016,  ..., 0.0018, 0.0022, 0.0015],\n","         [0.0022, 0.0024, 0.0014,  ..., 0.0019, 0.0022, 0.0021],\n","         [0.0023, 0.0018, 0.0015,  ..., 0.0013, 0.0017, 0.0016]],\n","\n","        [[0.0023, 0.0023, 0.0023,  ..., 0.0018, 0.0023, 0.0023],\n","         [0.0018, 0.0017, 0.0023,  ..., 0.0019, 0.0023, 0.0023],\n","         [0.0023, 0.0023, 0.0016,  ..., 0.0020, 0.0023, 0.0017],\n","         ...,\n","         [0.0023, 0.0016, 0.0018,  ..., 0.0018, 0.0018, 0.0023],\n","         [0.0023, 0.0017, 0.0024,  ..., 0.0019, 0.0022, 0.0012],\n","         [0.0017, 0.0016, 0.0024,  ..., 0.0018, 0.0022, 0.0023]],\n","\n","        [[0.0023, 0.0024, 0.0023,  ..., 0.0025, 0.0026, 0.0015],\n","         [0.0016, 0.0022, 0.0018,  ..., 0.0013, 0.0017, 0.0021],\n","         [0.0022, 0.0016, 0.0023,  ..., 0.0019, 0.0025, 0.0020],\n","         ...,\n","         [0.0022, 0.0023, 0.0024,  ..., 0.0017, 0.0026, 0.0019],\n","         [0.0023, 0.0022, 0.0017,  ..., 0.0023, 0.0026, 0.0021],\n","         [0.0022, 0.0018, 0.0024,  ..., 0.0025, 0.0025, 0.0021]]],\n","       grad_fn=<MeanBackward1>), tensor([[[0.0026, 0.0025, 0.0022,  ..., 0.0013, 0.0012, 0.0021],\n","         [0.0026, 0.0025, 0.0023,  ..., 0.0015, 0.0023, 0.0019],\n","         [0.0019, 0.0016, 0.0024,  ..., 0.0015, 0.0017, 0.0021],\n","         ...,\n","         [0.0026, 0.0023, 0.0019,  ..., 0.0019, 0.0023, 0.0010],\n","         [0.0018, 0.0017, 0.0018,  ..., 0.0014, 0.0023, 0.0021],\n","         [0.0025, 0.0023, 0.0018,  ..., 0.0019, 0.0017, 0.0014]],\n","\n","        [[0.0019, 0.0020, 0.0025,  ..., 0.0024, 0.0024, 0.0021],\n","         [0.0018, 0.0010, 0.0024,  ..., 0.0023, 0.0018, 0.0022],\n","         [0.0018, 0.0020, 0.0024,  ..., 0.0024, 0.0017, 0.0022],\n","         ...,\n","         [0.0018, 0.0020, 0.0025,  ..., 0.0024, 0.0024, 0.0022],\n","         [0.0018, 0.0016, 0.0025,  ..., 0.0019, 0.0018, 0.0022],\n","         [0.0019, 0.0014, 0.0023,  ..., 0.0025, 0.0019, 0.0021]],\n","\n","        [[0.0022, 0.0018, 0.0023,  ..., 0.0021, 0.0023, 0.0023],\n","         [0.0022, 0.0023, 0.0023,  ..., 0.0022, 0.0016, 0.0023],\n","         [0.0022, 0.0024, 0.0018,  ..., 0.0020, 0.0013, 0.0023],\n","         ...,\n","         [0.0021, 0.0018, 0.0022,  ..., 0.0016, 0.0023, 0.0022],\n","         [0.0021, 0.0025, 0.0011,  ..., 0.0015, 0.0019, 0.0023],\n","         [0.0022, 0.0019, 0.0023,  ..., 0.0022, 0.0022, 0.0012]],\n","\n","        ...,\n","\n","        [[0.0015, 0.0024, 0.0024,  ..., 0.0023, 0.0024, 0.0025],\n","         [0.0023, 0.0025, 0.0024,  ..., 0.0022, 0.0024, 0.0024],\n","         [0.0022, 0.0019, 0.0024,  ..., 0.0012, 0.0024, 0.0017],\n","         ...,\n","         [0.0023, 0.0020, 0.0026,  ..., 0.0022, 0.0018, 0.0025],\n","         [0.0022, 0.0016, 0.0018,  ..., 0.0022, 0.0019, 0.0011],\n","         [0.0010, 0.0024, 0.0024,  ..., 0.0022, 0.0018, 0.0022]],\n","\n","        [[0.0022, 0.0022, 0.0023,  ..., 0.0026, 0.0016, 0.0021],\n","         [0.0021, 0.0017, 0.0023,  ..., 0.0016, 0.0015, 0.0020],\n","         [0.0020, 0.0018, 0.0017,  ..., 0.0019, 0.0022, 0.0015],\n","         ...,\n","         [0.0020, 0.0023, 0.0016,  ..., 0.0022, 0.0015, 0.0020],\n","         [0.0015, 0.0022, 0.0019,  ..., 0.0010, 0.0021, 0.0021],\n","         [0.0016, 0.0023, 0.0022,  ..., 0.0023, 0.0015, 0.0021]],\n","\n","        [[0.0018, 0.0016, 0.0018,  ..., 0.0021, 0.0021, 0.0020],\n","         [0.0022, 0.0022, 0.0023,  ..., 0.0021, 0.0021, 0.0014],\n","         [0.0017, 0.0022, 0.0017,  ..., 0.0015, 0.0021, 0.0020],\n","         ...,\n","         [0.0022, 0.0022, 0.0024,  ..., 0.0021, 0.0018, 0.0010],\n","         [0.0023, 0.0021, 0.0015,  ..., 0.0022, 0.0016, 0.0020],\n","         [0.0022, 0.0021, 0.0023,  ..., 0.0021, 0.0015, 0.0021]]],\n","       grad_fn=<MeanBackward1>)]\n"]}],"source":["test_forward_pass(model, train_loader)"]},{"cell_type":"markdown","metadata":{},"source":["## Define the evaluation methods to calculate metrics"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[],"source":["def count_correct_predictions(predictions, labels):\n","    predictions = np.argmax(predictions, axis=1)\n","\n","    # Find indices where labels are not equal to the padding value\n","    non_padding_indices = labels != codons_to_integer['___']\n","\n","    # Filter out predictions and labels where the label is not padding\n","    filtered_predictions = predictions[non_padding_indices]\n","    filtered_labels = labels[non_padding_indices]\n","\n","    codon_num = filtered_labels.shape[0]\n","    correct_codons = (filtered_predictions == filtered_labels).sum().item()\n","    return codon_num, correct_codons"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[],"source":["def evaluate_model(model, criterion, print_scores=True, loss_without_pad=False):\n","    model.eval()  # Set the model to evaluation mode\n","\n","    total_loss = 0.0\n","\n","    with torch.no_grad():\n","        codon_num = 0\n","        correct_codon_num = 0\n","        for batch_idx, batch in enumerate(valid_loader):\n","             # Forward pass\n","            input_data, labels = batch\n","\n","            output = model(input_data)  # (batch_size, seq_len, num_classes)\n","            output = output.view(-1, len(codons)) # (batch_size * seq_len, num_classes)\n","\n","            labels = labels.view(-1).long() # (batch_size, seq_len) -> (batch_size * seq_len)\n","\n","            # Calculate loss\n","            loss = criterion(output, labels)\n","\n","            # Compute total loss\n","            total_loss += loss.item()\n","\n","            # Count codons and correct codon predictions\n","            codon_num_batch, correct_codons_batch = count_correct_predictions(output.cpu(), labels.cpu())\n","            codon_num += codon_num_batch\n","            correct_codon_num += correct_codons_batch\n","\n","    # Compute average loss\n","    avg_loss = total_loss / len(valid_loader)\n","\n","    # Compute accuracy\n","    accuracy = round(correct_codon_num / codon_num, 4)\n","\n","    if print_scores:\n","        print(f'Average Batch Loss: {avg_loss:.4f}')\n","        print(f'Accuracy: {accuracy:.4f}')\n","\n","    return avg_loss, accuracy"]},{"cell_type":"markdown","metadata":{"id":"6DIXDxybQ7Z0"},"source":["## Define the training methods"]},{"cell_type":"code","execution_count":33,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1715688705880,"user":{"displayName":"Insa Belter","userId":"09408038895575287386"},"user_tz":-120},"id":"B8_PCftyQ7Z0"},"outputs":[],"source":["def train_model(model, num_epochs, loss_ignore_pad=True, learning_rate=0.0005, validation_stop=True, validation_stop_area=7, print_batches=0, print_epochs=True):\n","    criterion = torch.nn.CrossEntropyLoss()\n","    if loss_ignore_pad:\n","        criterion = torch.nn.CrossEntropyLoss(ignore_index=codons_to_integer['___'])\n","    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","    \n","    start_time = time.time()\n","    last_loss = None\n","    saved_accuracies = []\n","    epoch_num = 0\n","    for epoch in range(num_epochs):\n","        epoch_num += 1\n","        set_seed(epoch)\n","        model.train()\n","\n","        epoch_start_time = time.time()\n","        batch_start_time = time.time()\n","        epoch_loss = 0\n","        for batch_idx, batch in enumerate(train_loader):\n","            # Clear gradients\n","            optimizer.zero_grad()\n","\n","            # Forward pass\n","            input_data, labels = batch\n","\n","            output = model(input_data)  # (batch_size, seq_len, num_classes)\n","            output = output.view(-1, len(codons)) # (batch_size * seq_len, num_classes)\n","\n","            labels = labels.view(-1).long() # (batch_size, seq_len) -> (batch_size * seq_len)\n","\n","            # Calculate loss\n","            loss = criterion(output, labels)\n","            epoch_loss += loss.item()\n","\n","            # Backward pass\n","            loss.backward()\n","\n","            # Update model parameters\n","            optimizer.step()\n","\n","            if print_batches != 0 and batch_idx % print_batches == (print_batches-1):\n","                batch_time =  round(time.time() - batch_start_time,2)\n","                print(f'Batch [{batch_idx+1}/{len(train_loader)}], Loss: {loss.item():.4f}, Time since last batch print: {batch_time} s')\n","                batch_start_time = time.time()\n","        \n","        epoch_loss = round(epoch_loss / len(train_loader),4)\n","        last_loss = epoch_loss\n","        \n","        avg_eval_loss, accuracy = evaluate_model(model, criterion, print_scores=False)\n","        \n","        epoch_time = round(time.time() - epoch_start_time,2)\n","        if print_epochs:\n","            print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss}, Eval Accuracy: {accuracy}, Took {epoch_time} s')\n","         \n","        if validation_stop:\n","            saved_accuracies.append(accuracy)  \n","            if len(saved_accuracies) == validation_stop_area+1:\n","                # compare accuracy to average of saved_accuracies\n","                # if accuracy is lower: stop early\n","                if np.average(np.array(saved_accuracies[validation_stop_area-1:validation_stop_area+1])) < np.average(np.array(saved_accuracies[0:validation_stop_area-2])):\n","                    print(f'Stopped early after epoch {epoch+1} as validation accuracy was lower than average of the last {validation_stop_area} accuracies.')\n","                    break\n","                saved_accuracies.pop(0)\n","               \n","    total_time = round(time.time() - start_time,2)\n","    print(f'Last Loss: {last_loss}, Last Eval Accuracy: {accuracy}, Took {total_time} s')\n","    return last_loss, accuracy, epoch_num"]},{"cell_type":"markdown","metadata":{"id":"w60mTX5nQ7Z1"},"source":["## Training the model"]},{"cell_type":"code","execution_count":21,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1715688892531,"user":{"displayName":"Insa Belter","userId":"09408038895575287386"},"user_tz":-120},"id":"Vr8Ge8QYQ7Z2"},"outputs":[{"name":"stdout","output_type":"stream","text":["6,597,697 total parameters.\n","6,597,697 training parameters.\n"]}],"source":["set_seed()\n","EMBED_DIM = 256\n","NUM_ENCODER_LAYERS = 4\n","NUM_HEADS = 4\n","DROPOUT = 0.3\n","\n","model = EncoderClassifier(\n","    embed_dim=EMBED_DIM,\n","    num_layers=NUM_ENCODER_LAYERS,\n","    num_heads=NUM_HEADS,\n","    dropout=DROPOUT,\n","    pos_enc=False\n",").to(device)\n","print_parameters(model)"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":452,"status":"ok","timestamp":1715688894105,"user":{"displayName":"Insa Belter","userId":"09408038895575287386"},"user_tz":-120},"id":"8G-AucPcQ7Z2","outputId":"8483db98-2a68-47ee-eaa2-b7d3c55e90f7"},"outputs":[{"name":"stdout","output_type":"stream","text":["----- Start Training -----\n"]}],"source":["EPOCHS = 50\n","print(\"----- Start Training -----\")\n","#train_model(model, EPOCHS)"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[],"source":["#ml_helper.save_model(model, f'encoder_256em_4l_4h_03dr_10ep', organism)"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[],"source":["#model = ml_helper.load_model(f'encoder_256em_4l_4h_03dr_10ep', organism)"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[],"source":["criterion = torch.nn.CrossEntropyLoss(ignore_index=codons_to_integer['___'])\n","#evaluate_model(model, criterion)"]},{"cell_type":"markdown","metadata":{},"source":["## Hyperparameter tuning"]},{"cell_type":"code","execution_count":46,"metadata":{},"outputs":[],"source":["def train_parameter_model(embed_dim, num_encoder_layers, num_heads, dropout, pos_enc, num_epochs, print_epochs):\n","    set_seed()\n","    \n","    model = EncoderClassifier(\n","        embed_dim=embed_dim,\n","        num_layers=num_encoder_layers,\n","        num_heads=num_heads,\n","        dropout=dropout,\n","        pos_enc=pos_enc\n","    ).to(device)\n","    #print_parameters(model)\n","\n","    print(f\"----- Start Training: {embed_dim} emb, {num_encoder_layers} layers, {num_heads} heads, {dropout} dropout, positional encoding: {pos_enc}, {num_epochs} epochs -----\")\n","    last_loss, accuracy, epoch_num = train_model(model, num_epochs, print_epochs=print_epochs)\n","\n","    saved = False\n","    if last_loss >= 2:\n","        print(f\"Did not save following model as loss was too high:\")\n","        print(f'encoder_{embed_dim}em_{num_encoder_layers}l_{num_heads}h{\"_posenc\" if pos_enc else \"\"}_{str(dropout).replace(\".\",\"\")}dr_{epoch_num}ep')\n","    else:\n","        saved = True\n","        ml_helper.save_model(model, f'encoder_{embed_dim}em_{num_encoder_layers}l_{num_heads}h{\"_posenc\" if pos_enc else \"\"}_{str(dropout).replace(\".\",\"\")}dr_{epoch_num}ep', organism)\n","    return saved, accuracy"]},{"cell_type":"code","execution_count":47,"metadata":{},"outputs":[],"source":["def hyper_parameter_training(embed_dims, num_encoder_layers, num_heads, dropouts, pos_enc, epochs=50, print_epochs=True):\n","    not_saved = []\n","    accuracies = {}\n","    for EMBED_DIM in embed_dims:\n","        for NUM_ENCODER_LAYERS in num_encoder_layers:\n","            for NUM_HEADS in num_heads:\n","                for DROPOUT in dropouts:\n","                    for POS_ENC in pos_enc:\n","                        model_name = f'encoder_{EMBED_DIM}em_{NUM_ENCODER_LAYERS}l_{NUM_HEADS}h{\"_posenc\" if POS_ENC else \"\"}_{str(DROPOUT).replace(\".\",\"\")}dr_{epochs}ep'\n","                        saved, accuracy = train_parameter_model(EMBED_DIM, NUM_ENCODER_LAYERS, NUM_HEADS, DROPOUT, POS_ENC, epochs, print_epochs)\n","                        accuracies[model_name] = accuracy\n","                        if not saved:\n","                            not_saved.append(model_name)\n","    print(\"------------\")\n","    print(\"Not saved as loss too high:\")\n","    print(not_saved)\n","    return accuracies"]},{"cell_type":"markdown","metadata":{},"source":["### E.Coli"]},{"cell_type":"code","execution_count":31,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Länge train_dataset: 3555\n","Länge valid_dataset: 420\n"]}],"source":["organism = \"E.Coli\"\n","min_length = None\n","max_length = 500\n","\n","train_dataset = ml_helper.CodonDataset(organism, \"train\", min_length, max_length, cut_data=True, one_hot_aa=False, data_path=data_path, device=device)\n","print(f\"Länge train_dataset: {len(train_dataset)}\")\n","valid_dataset = ml_helper.CodonDataset(organism, \"valid\", min_length, max_length, cut_data=True, one_hot_aa=False, data_path=data_path, device=device)\n","print(f\"Länge valid_dataset: {len(valid_dataset)}\")\n","\n","BATCH_SIZE = 32\n","train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n","valid_loader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Train single model\n","EMBED_DIM = [256]\n","NUM_ENCODER_LAYERS = [4]\n","NUM_HEADS = [4]\n","dropouts = [0.3]\n","POS_ENC = [False]\n","hyper_parameter_training(EMBED_DIM, NUM_ENCODER_LAYERS, NUM_HEADS, dropouts, POS_ENC, epochs=100)"]},{"cell_type":"markdown","metadata":{},"source":["#### Dropout"]},{"cell_type":"code","execution_count":34,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["----- Start Training: 256 emb, 4 layers, 4 heads, 0.1 dropout, positional encoding: False, 50 epochs -----\n","Epoch [1/50], Loss: 1.1639, Eval Accuracy: 0.4962, Took 3.68 s\n","Epoch [2/50], Loss: 1.0538, Eval Accuracy: 0.5166, Took 3.68 s\n","Epoch [3/50], Loss: 1.0461, Eval Accuracy: 0.5178, Took 3.69 s\n","Epoch [4/50], Loss: 1.0421, Eval Accuracy: 0.52, Took 3.68 s\n","Epoch [5/50], Loss: 1.0397, Eval Accuracy: 0.5076, Took 3.71 s\n","Epoch [6/50], Loss: 1.0378, Eval Accuracy: 0.5178, Took 3.71 s\n","Epoch [7/50], Loss: 1.0361, Eval Accuracy: 0.5162, Took 3.71 s\n","Epoch [8/50], Loss: 1.0355, Eval Accuracy: 0.5191, Took 3.71 s\n","Epoch [9/50], Loss: 1.0326, Eval Accuracy: 0.5233, Took 3.71 s\n","Epoch [10/50], Loss: 1.0331, Eval Accuracy: 0.5229, Took 3.71 s\n","Epoch [11/50], Loss: 1.0323, Eval Accuracy: 0.5174, Took 3.71 s\n","Epoch [12/50], Loss: 1.0308, Eval Accuracy: 0.5192, Took 3.72 s\n","Epoch [13/50], Loss: 1.031, Eval Accuracy: 0.5226, Took 3.72 s\n","Epoch [14/50], Loss: 1.0299, Eval Accuracy: 0.5203, Took 3.71 s\n","Epoch [15/50], Loss: 1.0305, Eval Accuracy: 0.5211, Took 3.72 s\n","Epoch [16/50], Loss: 1.0291, Eval Accuracy: 0.5183, Took 3.72 s\n","Stopped early after epoch 16 as validation accuracy was lower than average of the last 7 accuracies.\n","Last Loss: 1.0291, Last Eval Accuracy: 0.5183, Took 59.32 s\n","Model saved as 20240603142405_encoder_256em_4l_4h_01dr_16ep.pt\n","----- Start Training: 256 emb, 4 layers, 4 heads, 0.2 dropout, positional encoding: False, 50 epochs -----\n","Epoch [1/50], Loss: 1.173, Eval Accuracy: 0.497, Took 3.71 s\n","Epoch [2/50], Loss: 1.0587, Eval Accuracy: 0.5184, Took 3.72 s\n","Epoch [3/50], Loss: 1.0489, Eval Accuracy: 0.515, Took 3.72 s\n","Epoch [4/50], Loss: 1.0437, Eval Accuracy: 0.5206, Took 3.71 s\n","Epoch [5/50], Loss: 1.0405, Eval Accuracy: 0.5092, Took 3.72 s\n","Epoch [6/50], Loss: 1.0381, Eval Accuracy: 0.5177, Took 3.72 s\n","Epoch [7/50], Loss: 1.0362, Eval Accuracy: 0.5159, Took 3.71 s\n","Epoch [8/50], Loss: 1.0355, Eval Accuracy: 0.5185, Took 3.72 s\n","Epoch [9/50], Loss: 1.0329, Eval Accuracy: 0.5242, Took 3.72 s\n","Epoch [10/50], Loss: 1.0328, Eval Accuracy: 0.5236, Took 3.71 s\n","Epoch [11/50], Loss: 1.0319, Eval Accuracy: 0.5177, Took 3.72 s\n","Epoch [12/50], Loss: 1.0308, Eval Accuracy: 0.5194, Took 3.72 s\n","Epoch [13/50], Loss: 1.0311, Eval Accuracy: 0.523, Took 3.71 s\n","Epoch [14/50], Loss: 1.0297, Eval Accuracy: 0.5208, Took 3.73 s\n","Epoch [15/50], Loss: 1.0304, Eval Accuracy: 0.521, Took 3.72 s\n","Epoch [16/50], Loss: 1.0289, Eval Accuracy: 0.5189, Took 3.72 s\n","Stopped early after epoch 16 as validation accuracy was lower than average of the last 7 accuracies.\n","Last Loss: 1.0289, Last Eval Accuracy: 0.5189, Took 59.49 s\n","Model saved as 20240603142505_encoder_256em_4l_4h_02dr_16ep.pt\n","----- Start Training: 256 emb, 4 layers, 4 heads, 0.3 dropout, positional encoding: False, 50 epochs -----\n","Epoch [1/50], Loss: 1.1835, Eval Accuracy: 0.4922, Took 3.72 s\n","Epoch [2/50], Loss: 1.0628, Eval Accuracy: 0.5202, Took 3.72 s\n","Epoch [3/50], Loss: 1.0509, Eval Accuracy: 0.5133, Took 3.71 s\n","Epoch [4/50], Loss: 1.0445, Eval Accuracy: 0.5207, Took 3.72 s\n","Epoch [5/50], Loss: 1.0408, Eval Accuracy: 0.5116, Took 3.72 s\n","Epoch [6/50], Loss: 1.038, Eval Accuracy: 0.5179, Took 3.71 s\n","Epoch [7/50], Loss: 1.036, Eval Accuracy: 0.5158, Took 3.72 s\n","Epoch [8/50], Loss: 1.0355, Eval Accuracy: 0.5182, Took 3.72 s\n","Epoch [9/50], Loss: 1.0333, Eval Accuracy: 0.5239, Took 3.72 s\n","Epoch [10/50], Loss: 1.0329, Eval Accuracy: 0.5229, Took 3.72 s\n","Epoch [11/50], Loss: 1.032, Eval Accuracy: 0.5175, Took 3.72 s\n","Epoch [12/50], Loss: 1.031, Eval Accuracy: 0.519, Took 3.72 s\n","Epoch [13/50], Loss: 1.0313, Eval Accuracy: 0.5229, Took 3.72 s\n","Epoch [14/50], Loss: 1.0298, Eval Accuracy: 0.5211, Took 3.72 s\n","Epoch [15/50], Loss: 1.0304, Eval Accuracy: 0.5205, Took 3.72 s\n","Epoch [16/50], Loss: 1.0294, Eval Accuracy: 0.5182, Took 3.73 s\n","Stopped early after epoch 16 as validation accuracy was lower than average of the last 7 accuracies.\n","Last Loss: 1.0294, Last Eval Accuracy: 0.5182, Took 59.53 s\n","Model saved as 20240603142604_encoder_256em_4l_4h_03dr_16ep.pt\n","----- Start Training: 256 emb, 4 layers, 4 heads, 0.4 dropout, positional encoding: False, 50 epochs -----\n","Epoch [1/50], Loss: 1.1964, Eval Accuracy: 0.4949, Took 3.73 s\n","Epoch [2/50], Loss: 1.0667, Eval Accuracy: 0.5201, Took 3.72 s\n","Epoch [3/50], Loss: 1.0524, Eval Accuracy: 0.5146, Took 3.72 s\n","Epoch [4/50], Loss: 1.0448, Eval Accuracy: 0.5208, Took 3.72 s\n","Epoch [5/50], Loss: 1.0409, Eval Accuracy: 0.5145, Took 3.72 s\n","Epoch [6/50], Loss: 1.038, Eval Accuracy: 0.5182, Took 3.72 s\n","Epoch [7/50], Loss: 1.0362, Eval Accuracy: 0.5155, Took 3.72 s\n","Epoch [8/50], Loss: 1.0357, Eval Accuracy: 0.5181, Took 3.72 s\n","Epoch [9/50], Loss: 1.0337, Eval Accuracy: 0.524, Took 3.72 s\n","Epoch [10/50], Loss: 1.0332, Eval Accuracy: 0.5227, Took 3.72 s\n","Epoch [11/50], Loss: 1.0322, Eval Accuracy: 0.5175, Took 3.72 s\n","Epoch [12/50], Loss: 1.0313, Eval Accuracy: 0.519, Took 3.72 s\n","Epoch [13/50], Loss: 1.0317, Eval Accuracy: 0.5228, Took 3.72 s\n","Epoch [14/50], Loss: 1.0302, Eval Accuracy: 0.5219, Took 3.72 s\n","Epoch [15/50], Loss: 1.0309, Eval Accuracy: 0.5202, Took 3.72 s\n","Epoch [16/50], Loss: 1.0299, Eval Accuracy: 0.5182, Took 3.72 s\n","Stopped early after epoch 16 as validation accuracy was lower than average of the last 7 accuracies.\n","Last Loss: 1.0299, Last Eval Accuracy: 0.5182, Took 59.54 s\n","Model saved as 20240603142704_encoder_256em_4l_4h_04dr_16ep.pt\n","----- Start Training: 256 emb, 4 layers, 4 heads, 0.5 dropout, positional encoding: False, 50 epochs -----\n","Epoch [1/50], Loss: 1.2133, Eval Accuracy: 0.4983, Took 3.71 s\n","Epoch [2/50], Loss: 1.0712, Eval Accuracy: 0.5184, Took 3.71 s\n","Epoch [3/50], Loss: 1.054, Eval Accuracy: 0.5144, Took 3.7 s\n","Epoch [4/50], Loss: 1.0453, Eval Accuracy: 0.5207, Took 3.7 s\n","Epoch [5/50], Loss: 1.0413, Eval Accuracy: 0.5144, Took 3.69 s\n","Epoch [6/50], Loss: 1.0383, Eval Accuracy: 0.5177, Took 3.7 s\n","Epoch [7/50], Loss: 1.0366, Eval Accuracy: 0.5137, Took 3.7 s\n","Epoch [8/50], Loss: 1.0361, Eval Accuracy: 0.5183, Took 3.7 s\n","Epoch [9/50], Loss: 1.0345, Eval Accuracy: 0.524, Took 3.7 s\n","Epoch [10/50], Loss: 1.0337, Eval Accuracy: 0.5226, Took 3.7 s\n","Epoch [11/50], Loss: 1.0328, Eval Accuracy: 0.5177, Took 3.7 s\n","Epoch [12/50], Loss: 1.0318, Eval Accuracy: 0.519, Took 3.7 s\n","Epoch [13/50], Loss: 1.0322, Eval Accuracy: 0.5223, Took 3.7 s\n","Epoch [14/50], Loss: 1.0308, Eval Accuracy: 0.5222, Took 3.7 s\n","Epoch [15/50], Loss: 1.033, Eval Accuracy: 0.5225, Took 3.7 s\n","Epoch [16/50], Loss: 1.0315, Eval Accuracy: 0.5174, Took 3.71 s\n","Stopped early after epoch 16 as validation accuracy was lower than average of the last 7 accuracies.\n","Last Loss: 1.0315, Last Eval Accuracy: 0.5174, Took 59.23 s\n","Model saved as 20240603142803_encoder_256em_4l_4h_05dr_16ep.pt\n","------------\n","Not saved as loss too high:\n","[]\n"]},{"data":{"text/plain":["{'encoder_256em_4l_4h_01dr_50ep': 0.5183,\n"," 'encoder_256em_4l_4h_02dr_50ep': 0.5189,\n"," 'encoder_256em_4l_4h_03dr_50ep': 0.5182,\n"," 'encoder_256em_4l_4h_04dr_50ep': 0.5182,\n"," 'encoder_256em_4l_4h_05dr_50ep': 0.5174}"]},"execution_count":34,"metadata":{},"output_type":"execute_result"}],"source":["EMBED_DIM = [256]\n","NUM_ENCODER_LAYERS = [4]\n","NUM_HEADS = [4]\n","dropouts = [0.1, 0.2, 0.3, 0.4, 0.5]\n","POS_ENC = [False]\n","hyper_parameter_training(EMBED_DIM, NUM_ENCODER_LAYERS, NUM_HEADS, dropouts, POS_ENC)"]},{"cell_type":"markdown","metadata":{},"source":["#### Embedding Dimension"]},{"cell_type":"code","execution_count":35,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["----- Start Training: 16 emb, 4 layers, 4 heads, 0.5 dropout, positional encoding: False, 50 epochs -----\n","Epoch [1/50], Loss: 3.0332, Eval Accuracy: 0.5129, Took 2.03 s\n","Epoch [2/50], Loss: 2.3796, Eval Accuracy: 0.5145, Took 2.02 s\n","Epoch [3/50], Loss: 1.9794, Eval Accuracy: 0.5145, Took 2.02 s\n","Epoch [4/50], Loss: 1.7237, Eval Accuracy: 0.5155, Took 2.03 s\n","Epoch [5/50], Loss: 1.5641, Eval Accuracy: 0.5155, Took 2.02 s\n","Epoch [6/50], Loss: 1.4599, Eval Accuracy: 0.5145, Took 2.02 s\n","Epoch [7/50], Loss: 1.3854, Eval Accuracy: 0.5155, Took 2.02 s\n","Epoch [8/50], Loss: 1.3323, Eval Accuracy: 0.5155, Took 2.02 s\n","Epoch [9/50], Loss: 1.291, Eval Accuracy: 0.5155, Took 2.03 s\n","Epoch [10/50], Loss: 1.2609, Eval Accuracy: 0.5155, Took 2.03 s\n","Epoch [11/50], Loss: 1.2362, Eval Accuracy: 0.5155, Took 2.03 s\n","Epoch [12/50], Loss: 1.2157, Eval Accuracy: 0.5155, Took 2.03 s\n","Epoch [13/50], Loss: 1.2004, Eval Accuracy: 0.5155, Took 2.03 s\n","Epoch [14/50], Loss: 1.1867, Eval Accuracy: 0.5155, Took 2.03 s\n","Epoch [15/50], Loss: 1.1766, Eval Accuracy: 0.5155, Took 2.03 s\n","Epoch [16/50], Loss: 1.1675, Eval Accuracy: 0.5155, Took 2.03 s\n","Epoch [17/50], Loss: 1.1607, Eval Accuracy: 0.5155, Took 2.03 s\n","Epoch [18/50], Loss: 1.1536, Eval Accuracy: 0.5145, Took 2.03 s\n","Stopped early after epoch 18 as validation accuracy was lower than average of the last 7 accuracies.\n","Last Loss: 1.1536, Last Eval Accuracy: 0.5145, Took 36.47 s\n","Model saved as 20240603143100_encoder_16em_4l_4h_05dr_18ep.pt\n","----- Start Training: 32 emb, 4 layers, 4 heads, 0.5 dropout, positional encoding: False, 50 epochs -----\n","Epoch [1/50], Loss: 2.3956, Eval Accuracy: 0.5112, Took 2.07 s\n","Epoch [2/50], Loss: 1.641, Eval Accuracy: 0.5155, Took 2.07 s\n","Epoch [3/50], Loss: 1.3713, Eval Accuracy: 0.5155, Took 2.08 s\n","Epoch [4/50], Loss: 1.2538, Eval Accuracy: 0.5154, Took 2.07 s\n","Epoch [5/50], Loss: 1.1901, Eval Accuracy: 0.5152, Took 2.08 s\n","Epoch [6/50], Loss: 1.1515, Eval Accuracy: 0.516, Took 2.08 s\n","Epoch [7/50], Loss: 1.1238, Eval Accuracy: 0.5164, Took 2.08 s\n","Epoch [8/50], Loss: 1.1059, Eval Accuracy: 0.516, Took 2.08 s\n","Epoch [9/50], Loss: 1.0911, Eval Accuracy: 0.5164, Took 2.08 s\n","Epoch [10/50], Loss: 1.0817, Eval Accuracy: 0.516, Took 2.08 s\n","Epoch [11/50], Loss: 1.0745, Eval Accuracy: 0.5167, Took 2.08 s\n","Epoch [12/50], Loss: 1.0685, Eval Accuracy: 0.5172, Took 2.08 s\n","Epoch [13/50], Loss: 1.0655, Eval Accuracy: 0.5169, Took 2.08 s\n","Epoch [14/50], Loss: 1.0611, Eval Accuracy: 0.5173, Took 2.08 s\n","Epoch [15/50], Loss: 1.0591, Eval Accuracy: 0.5165, Took 2.08 s\n","Epoch [16/50], Loss: 1.0554, Eval Accuracy: 0.5179, Took 2.07 s\n","Epoch [17/50], Loss: 1.054, Eval Accuracy: 0.5175, Took 2.07 s\n","Epoch [18/50], Loss: 1.0515, Eval Accuracy: 0.5175, Took 2.07 s\n","Epoch [19/50], Loss: 1.0504, Eval Accuracy: 0.5187, Took 2.07 s\n","Epoch [20/50], Loss: 1.0492, Eval Accuracy: 0.5176, Took 2.07 s\n","Epoch [21/50], Loss: 1.049, Eval Accuracy: 0.5183, Took 2.07 s\n","Epoch [22/50], Loss: 1.0466, Eval Accuracy: 0.5178, Took 2.08 s\n","Epoch [23/50], Loss: 1.047, Eval Accuracy: 0.5181, Took 2.08 s\n","Epoch [24/50], Loss: 1.0454, Eval Accuracy: 0.5196, Took 2.08 s\n","Epoch [25/50], Loss: 1.0446, Eval Accuracy: 0.5222, Took 2.08 s\n","Epoch [26/50], Loss: 1.0447, Eval Accuracy: 0.5213, Took 2.08 s\n","Epoch [27/50], Loss: 1.0441, Eval Accuracy: 0.5198, Took 2.08 s\n","Epoch [28/50], Loss: 1.0431, Eval Accuracy: 0.5199, Took 2.08 s\n","Epoch [29/50], Loss: 1.0432, Eval Accuracy: 0.521, Took 2.08 s\n","Epoch [30/50], Loss: 1.0419, Eval Accuracy: 0.5203, Took 2.08 s\n","Epoch [31/50], Loss: 1.042, Eval Accuracy: 0.5199, Took 2.08 s\n","Stopped early after epoch 31 as validation accuracy was lower than average of the last 7 accuracies.\n","Last Loss: 1.042, Last Eval Accuracy: 0.5199, Took 64.43 s\n","Model saved as 20240603143205_encoder_32em_4l_4h_05dr_31ep.pt\n","----- Start Training: 64 emb, 4 layers, 4 heads, 0.5 dropout, positional encoding: False, 50 epochs -----\n","Epoch [1/50], Loss: 1.7575, Eval Accuracy: 0.5149, Took 2.2 s\n","Epoch [2/50], Loss: 1.2396, Eval Accuracy: 0.5146, Took 2.2 s\n","Epoch [3/50], Loss: 1.1453, Eval Accuracy: 0.5151, Took 2.2 s\n","Epoch [4/50], Loss: 1.1037, Eval Accuracy: 0.5177, Took 2.2 s\n","Epoch [5/50], Loss: 1.0812, Eval Accuracy: 0.5164, Took 2.21 s\n","Epoch [6/50], Loss: 1.0673, Eval Accuracy: 0.5163, Took 2.2 s\n","Epoch [7/50], Loss: 1.0583, Eval Accuracy: 0.5161, Took 2.2 s\n","Epoch [8/50], Loss: 1.0529, Eval Accuracy: 0.5177, Took 2.2 s\n","Epoch [9/50], Loss: 1.0481, Eval Accuracy: 0.521, Took 2.21 s\n","Epoch [10/50], Loss: 1.045, Eval Accuracy: 0.5228, Took 2.2 s\n","Epoch [11/50], Loss: 1.0425, Eval Accuracy: 0.5182, Took 2.2 s\n","Epoch [12/50], Loss: 1.0404, Eval Accuracy: 0.5198, Took 2.2 s\n","Epoch [13/50], Loss: 1.0405, Eval Accuracy: 0.5229, Took 2.21 s\n","Epoch [14/50], Loss: 1.0376, Eval Accuracy: 0.5228, Took 2.2 s\n","Epoch [15/50], Loss: 1.0374, Eval Accuracy: 0.5195, Took 2.2 s\n","Epoch [16/50], Loss: 1.0363, Eval Accuracy: 0.5231, Took 2.2 s\n","Epoch [17/50], Loss: 1.0359, Eval Accuracy: 0.5227, Took 2.21 s\n","Epoch [18/50], Loss: 1.0348, Eval Accuracy: 0.5212, Took 2.2 s\n","Epoch [19/50], Loss: 1.0344, Eval Accuracy: 0.5223, Took 2.2 s\n","Epoch [20/50], Loss: 1.0343, Eval Accuracy: 0.5219, Took 2.2 s\n","Stopped early after epoch 20 as validation accuracy was lower than average of the last 7 accuracies.\n","Last Loss: 1.0343, Last Eval Accuracy: 0.5219, Took 44.08 s\n","Model saved as 20240603143249_encoder_64em_4l_4h_05dr_20ep.pt\n","----- Start Training: 128 emb, 4 layers, 4 heads, 0.5 dropout, positional encoding: False, 50 epochs -----\n","Epoch [1/50], Loss: 1.3783, Eval Accuracy: 0.5171, Took 2.51 s\n","Epoch [2/50], Loss: 1.109, Eval Accuracy: 0.5169, Took 2.52 s\n","Epoch [3/50], Loss: 1.0744, Eval Accuracy: 0.5121, Took 2.51 s\n","Epoch [4/50], Loss: 1.0582, Eval Accuracy: 0.5202, Took 2.51 s\n","Epoch [5/50], Loss: 1.0496, Eval Accuracy: 0.5191, Took 2.51 s\n","Epoch [6/50], Loss: 1.0446, Eval Accuracy: 0.5169, Took 2.51 s\n","Epoch [7/50], Loss: 1.0412, Eval Accuracy: 0.5123, Took 2.51 s\n","Epoch [8/50], Loss: 1.0394, Eval Accuracy: 0.5195, Took 2.51 s\n","Stopped early after epoch 8 as validation accuracy was lower than average of the last 7 accuracies.\n","Last Loss: 1.0394, Last Eval Accuracy: 0.5195, Took 20.1 s\n","Model saved as 20240603143309_encoder_128em_4l_4h_05dr_8ep.pt\n","----- Start Training: 256 emb, 4 layers, 4 heads, 0.5 dropout, positional encoding: False, 50 epochs -----\n","Epoch [1/50], Loss: 1.2133, Eval Accuracy: 0.4983, Took 3.72 s\n","Epoch [2/50], Loss: 1.0712, Eval Accuracy: 0.5184, Took 3.72 s\n","Epoch [3/50], Loss: 1.054, Eval Accuracy: 0.5144, Took 3.72 s\n","Epoch [4/50], Loss: 1.0453, Eval Accuracy: 0.5207, Took 3.71 s\n","Epoch [5/50], Loss: 1.0413, Eval Accuracy: 0.5144, Took 3.72 s\n","Epoch [6/50], Loss: 1.0383, Eval Accuracy: 0.5177, Took 3.72 s\n","Epoch [7/50], Loss: 1.0366, Eval Accuracy: 0.5137, Took 3.72 s\n","Epoch [8/50], Loss: 1.0361, Eval Accuracy: 0.5183, Took 3.72 s\n","Epoch [9/50], Loss: 1.0345, Eval Accuracy: 0.524, Took 3.72 s\n","Epoch [10/50], Loss: 1.0337, Eval Accuracy: 0.5226, Took 3.72 s\n","Epoch [11/50], Loss: 1.0328, Eval Accuracy: 0.5177, Took 3.71 s\n","Epoch [12/50], Loss: 1.0318, Eval Accuracy: 0.519, Took 3.7 s\n","Epoch [13/50], Loss: 1.0322, Eval Accuracy: 0.5223, Took 3.69 s\n","Epoch [14/50], Loss: 1.0308, Eval Accuracy: 0.5222, Took 3.7 s\n","Epoch [15/50], Loss: 1.033, Eval Accuracy: 0.5225, Took 3.7 s\n","Epoch [16/50], Loss: 1.0315, Eval Accuracy: 0.5174, Took 3.7 s\n","Stopped early after epoch 16 as validation accuracy was lower than average of the last 7 accuracies.\n","Last Loss: 1.0315, Last Eval Accuracy: 0.5174, Took 59.38 s\n","Model saved as 20240603143408_encoder_256em_4l_4h_05dr_16ep.pt\n","----- Start Training: 512 emb, 4 layers, 4 heads, 0.5 dropout, positional encoding: False, 50 epochs -----\n","Epoch [1/50], Loss: 1.1683, Eval Accuracy: 0.4891, Took 6.86 s\n","Epoch [2/50], Loss: 1.0637, Eval Accuracy: 0.52, Took 6.86 s\n","Epoch [3/50], Loss: 1.0497, Eval Accuracy: 0.5158, Took 6.87 s\n","Epoch [4/50], Loss: 1.0434, Eval Accuracy: 0.5201, Took 6.86 s\n","Epoch [5/50], Loss: 1.0399, Eval Accuracy: 0.5002, Took 6.85 s\n","Epoch [6/50], Loss: 1.0382, Eval Accuracy: 0.5178, Took 6.87 s\n","Epoch [7/50], Loss: 1.0366, Eval Accuracy: 0.516, Took 6.88 s\n","Epoch [8/50], Loss: 1.036, Eval Accuracy: 0.5175, Took 6.89 s\n","Epoch [9/50], Loss: 1.0337, Eval Accuracy: 0.5241, Took 6.86 s\n","Epoch [10/50], Loss: 1.0339, Eval Accuracy: 0.5215, Took 6.86 s\n","Epoch [11/50], Loss: 1.0335, Eval Accuracy: 0.518, Took 6.87 s\n","Epoch [12/50], Loss: 1.0325, Eval Accuracy: 0.5218, Took 6.87 s\n","Epoch [13/50], Loss: 1.0328, Eval Accuracy: 0.5218, Took 6.88 s\n","Epoch [14/50], Loss: 1.0328, Eval Accuracy: 0.5203, Took 6.89 s\n","Epoch [15/50], Loss: 1.0351, Eval Accuracy: 0.5211, Took 6.87 s\n","Epoch [16/50], Loss: 1.0335, Eval Accuracy: 0.506, Took 6.9 s\n","Stopped early after epoch 16 as validation accuracy was lower than average of the last 7 accuracies.\n","Last Loss: 1.0335, Last Eval Accuracy: 0.506, Took 109.96 s\n","Model saved as 20240603143558_encoder_512em_4l_4h_05dr_16ep.pt\n","------------\n","Not saved as loss too high:\n","[]\n"]},{"data":{"text/plain":["{'encoder_16em_4l_4h_05dr_50ep': 0.5145,\n"," 'encoder_32em_4l_4h_05dr_50ep': 0.5199,\n"," 'encoder_64em_4l_4h_05dr_50ep': 0.5219,\n"," 'encoder_128em_4l_4h_05dr_50ep': 0.5195,\n"," 'encoder_256em_4l_4h_05dr_50ep': 0.5174,\n"," 'encoder_512em_4l_4h_05dr_50ep': 0.506}"]},"execution_count":35,"metadata":{},"output_type":"execute_result"}],"source":["embed_dims = [16, 32, 64, 128, 256, 512]\n","NUM_ENCODER_LAYERS = [4]\n","NUM_HEADS = [4]\n","DROPOUTS = [0.5]\n","POS_ENC = [False]\n","hyper_parameter_training(embed_dims, NUM_ENCODER_LAYERS, NUM_HEADS, DROPOUTS, POS_ENC)"]},{"cell_type":"markdown","metadata":{},"source":["#### Number Encoder Layers and Heads"]},{"cell_type":"code","execution_count":36,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/mkuehn/.local/lib/python3.10/site-packages/torch/nn/modules/transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n","  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"]},{"name":"stdout","output_type":"stream","text":["----- Start Training: 64 emb, 1 layers, 1 heads, 0.5 dropout, positional encoding: False, 50 epochs -----\n","Epoch [1/50], Loss: 1.8965, Eval Accuracy: 0.5156, Took 0.51 s\n","Epoch [2/50], Loss: 1.2653, Eval Accuracy: 0.5155, Took 0.51 s\n","Epoch [3/50], Loss: 1.1597, Eval Accuracy: 0.5155, Took 0.51 s\n","Epoch [4/50], Loss: 1.1151, Eval Accuracy: 0.5155, Took 0.51 s\n","Epoch [5/50], Loss: 1.0909, Eval Accuracy: 0.5166, Took 0.51 s\n","Epoch [6/50], Loss: 1.0769, Eval Accuracy: 0.5145, Took 0.5 s\n","Epoch [7/50], Loss: 1.0671, Eval Accuracy: 0.5152, Took 0.51 s\n","Epoch [8/50], Loss: 1.0622, Eval Accuracy: 0.5154, Took 0.51 s\n","Stopped early after epoch 8 as validation accuracy was lower than average of the last 7 accuracies.\n","Last Loss: 1.0622, Last Eval Accuracy: 0.5154, Took 4.05 s\n","Model saved as 20240603143811_encoder_64em_1l_1h_05dr_8ep.pt\n","----- Start Training: 64 emb, 1 layers, 2 heads, 0.5 dropout, positional encoding: False, 50 epochs -----\n","Epoch [1/50], Loss: 1.8958, Eval Accuracy: 0.5162, Took 0.55 s\n","Epoch [2/50], Loss: 1.2656, Eval Accuracy: 0.5155, Took 0.55 s\n","Epoch [3/50], Loss: 1.1588, Eval Accuracy: 0.5161, Took 0.55 s\n","Epoch [4/50], Loss: 1.1144, Eval Accuracy: 0.5157, Took 0.55 s\n","Epoch [5/50], Loss: 1.0906, Eval Accuracy: 0.5146, Took 0.55 s\n","Epoch [6/50], Loss: 1.0764, Eval Accuracy: 0.5146, Took 0.56 s\n","Epoch [7/50], Loss: 1.0666, Eval Accuracy: 0.5148, Took 0.55 s\n","Epoch [8/50], Loss: 1.0613, Eval Accuracy: 0.516, Took 0.55 s\n","Stopped early after epoch 8 as validation accuracy was lower than average of the last 7 accuracies.\n","Last Loss: 1.0613, Last Eval Accuracy: 0.516, Took 4.41 s\n","Model saved as 20240603143816_encoder_64em_1l_2h_05dr_8ep.pt\n","----- Start Training: 64 emb, 1 layers, 4 heads, 0.5 dropout, positional encoding: False, 50 epochs -----\n","Epoch [1/50], Loss: 1.896, Eval Accuracy: 0.5154, Took 0.62 s\n","Epoch [2/50], Loss: 1.265, Eval Accuracy: 0.5155, Took 0.62 s\n","Epoch [3/50], Loss: 1.1592, Eval Accuracy: 0.5156, Took 0.63 s\n","Epoch [4/50], Loss: 1.1132, Eval Accuracy: 0.5155, Took 0.63 s\n","Epoch [5/50], Loss: 1.0901, Eval Accuracy: 0.5167, Took 0.62 s\n","Epoch [6/50], Loss: 1.0757, Eval Accuracy: 0.515, Took 0.62 s\n","Epoch [7/50], Loss: 1.0654, Eval Accuracy: 0.5147, Took 0.63 s\n","Epoch [8/50], Loss: 1.06, Eval Accuracy: 0.5165, Took 0.63 s\n","Stopped early after epoch 8 as validation accuracy was lower than average of the last 7 accuracies.\n","Last Loss: 1.06, Last Eval Accuracy: 0.5165, Took 5.01 s\n","Model saved as 20240603143821_encoder_64em_1l_4h_05dr_8ep.pt\n","----- Start Training: 64 emb, 1 layers, 8 heads, 0.5 dropout, positional encoding: False, 50 epochs -----\n","Epoch [1/50], Loss: 1.8966, Eval Accuracy: 0.515, Took 0.78 s\n","Epoch [2/50], Loss: 1.265, Eval Accuracy: 0.5155, Took 0.78 s\n","Epoch [3/50], Loss: 1.1581, Eval Accuracy: 0.5156, Took 0.78 s\n","Epoch [4/50], Loss: 1.1135, Eval Accuracy: 0.5155, Took 0.78 s\n","Epoch [5/50], Loss: 1.0893, Eval Accuracy: 0.5152, Took 0.78 s\n","Epoch [6/50], Loss: 1.0751, Eval Accuracy: 0.5154, Took 0.78 s\n","Epoch [7/50], Loss: 1.0648, Eval Accuracy: 0.5142, Took 0.78 s\n","Epoch [8/50], Loss: 1.0595, Eval Accuracy: 0.5173, Took 0.78 s\n","Epoch [9/50], Loss: 1.0534, Eval Accuracy: 0.5184, Took 0.78 s\n","Epoch [10/50], Loss: 1.0505, Eval Accuracy: 0.5192, Took 0.78 s\n","Epoch [11/50], Loss: 1.0478, Eval Accuracy: 0.518, Took 0.78 s\n","Epoch [12/50], Loss: 1.0449, Eval Accuracy: 0.5183, Took 0.78 s\n","Epoch [13/50], Loss: 1.0445, Eval Accuracy: 0.5192, Took 0.78 s\n","Epoch [14/50], Loss: 1.0425, Eval Accuracy: 0.5175, Took 0.78 s\n","Epoch [15/50], Loss: 1.0414, Eval Accuracy: 0.5187, Took 0.78 s\n","Stopped early after epoch 15 as validation accuracy was lower than average of the last 7 accuracies.\n","Last Loss: 1.0414, Last Eval Accuracy: 0.5187, Took 11.73 s\n","Model saved as 20240603143832_encoder_64em_1l_8h_05dr_15ep.pt\n","----- Start Training: 64 emb, 2 layers, 1 heads, 0.5 dropout, positional encoding: False, 50 epochs -----\n","Epoch [1/50], Loss: 1.796, Eval Accuracy: 0.5147, Took 0.89 s\n","Epoch [2/50], Loss: 1.2471, Eval Accuracy: 0.5146, Took 0.89 s\n","Epoch [3/50], Loss: 1.1491, Eval Accuracy: 0.5161, Took 0.89 s\n","Epoch [4/50], Loss: 1.1068, Eval Accuracy: 0.5168, Took 0.89 s\n","Epoch [5/50], Loss: 1.0838, Eval Accuracy: 0.5191, Took 0.89 s\n","Epoch [6/50], Loss: 1.0693, Eval Accuracy: 0.5168, Took 0.89 s\n","Epoch [7/50], Loss: 1.0596, Eval Accuracy: 0.516, Took 0.89 s\n","Epoch [8/50], Loss: 1.0542, Eval Accuracy: 0.5203, Took 0.89 s\n","Epoch [9/50], Loss: 1.0492, Eval Accuracy: 0.5199, Took 0.9 s\n","Epoch [10/50], Loss: 1.0464, Eval Accuracy: 0.5208, Took 0.9 s\n","Epoch [11/50], Loss: 1.0442, Eval Accuracy: 0.5179, Took 0.9 s\n","Epoch [12/50], Loss: 1.0416, Eval Accuracy: 0.5193, Took 0.9 s\n","Epoch [13/50], Loss: 1.0411, Eval Accuracy: 0.5221, Took 0.9 s\n","Epoch [14/50], Loss: 1.0387, Eval Accuracy: 0.5224, Took 0.9 s\n","Epoch [15/50], Loss: 1.0387, Eval Accuracy: 0.5204, Took 0.9 s\n","Epoch [16/50], Loss: 1.0373, Eval Accuracy: 0.5225, Took 0.9 s\n","Epoch [17/50], Loss: 1.0371, Eval Accuracy: 0.5228, Took 0.9 s\n","Epoch [18/50], Loss: 1.0352, Eval Accuracy: 0.5232, Took 0.9 s\n","Epoch [19/50], Loss: 1.0349, Eval Accuracy: 0.5232, Took 0.9 s\n","Epoch [20/50], Loss: 1.0347, Eval Accuracy: 0.5217, Took 0.9 s\n","Epoch [21/50], Loss: 1.0354, Eval Accuracy: 0.5221, Took 0.9 s\n","Stopped early after epoch 21 as validation accuracy was lower than average of the last 7 accuracies.\n","Last Loss: 1.0354, Last Eval Accuracy: 0.5221, Took 18.8 s\n","Model saved as 20240603143851_encoder_64em_2l_1h_05dr_21ep.pt\n","----- Start Training: 64 emb, 2 layers, 2 heads, 0.5 dropout, positional encoding: False, 50 epochs -----\n","Epoch [1/50], Loss: 1.7955, Eval Accuracy: 0.5148, Took 0.98 s\n","Epoch [2/50], Loss: 1.2463, Eval Accuracy: 0.5146, Took 0.98 s\n","Epoch [3/50], Loss: 1.1496, Eval Accuracy: 0.516, Took 0.98 s\n","Epoch [4/50], Loss: 1.1062, Eval Accuracy: 0.5167, Took 0.98 s\n","Epoch [5/50], Loss: 1.083, Eval Accuracy: 0.52, Took 0.98 s\n","Epoch [6/50], Loss: 1.069, Eval Accuracy: 0.5163, Took 0.98 s\n","Epoch [7/50], Loss: 1.0589, Eval Accuracy: 0.5158, Took 0.98 s\n","Epoch [8/50], Loss: 1.0539, Eval Accuracy: 0.5208, Took 0.98 s\n","Epoch [9/50], Loss: 1.0487, Eval Accuracy: 0.5209, Took 0.98 s\n","Epoch [10/50], Loss: 1.0458, Eval Accuracy: 0.523, Took 0.98 s\n","Epoch [11/50], Loss: 1.0432, Eval Accuracy: 0.5177, Took 0.98 s\n","Epoch [12/50], Loss: 1.0413, Eval Accuracy: 0.5198, Took 0.98 s\n","Stopped early after epoch 12 as validation accuracy was lower than average of the last 7 accuracies.\n","Last Loss: 1.0413, Last Eval Accuracy: 0.5198, Took 11.77 s\n","Model saved as 20240603143903_encoder_64em_2l_2h_05dr_12ep.pt\n","----- Start Training: 64 emb, 2 layers, 4 heads, 0.5 dropout, positional encoding: False, 50 epochs -----\n","Epoch [1/50], Loss: 1.7964, Eval Accuracy: 0.5155, Took 1.14 s\n","Epoch [2/50], Loss: 1.2462, Eval Accuracy: 0.5146, Took 1.14 s\n","Epoch [3/50], Loss: 1.1489, Eval Accuracy: 0.5153, Took 1.14 s\n","Epoch [4/50], Loss: 1.1064, Eval Accuracy: 0.5166, Took 1.14 s\n","Epoch [5/50], Loss: 1.083, Eval Accuracy: 0.5186, Took 1.14 s\n","Epoch [6/50], Loss: 1.0689, Eval Accuracy: 0.5166, Took 1.15 s\n","Epoch [7/50], Loss: 1.0594, Eval Accuracy: 0.5176, Took 1.14 s\n","Epoch [8/50], Loss: 1.0536, Eval Accuracy: 0.5196, Took 1.14 s\n","Epoch [9/50], Loss: 1.0486, Eval Accuracy: 0.5204, Took 1.15 s\n","Epoch [10/50], Loss: 1.0456, Eval Accuracy: 0.522, Took 1.14 s\n","Epoch [11/50], Loss: 1.0435, Eval Accuracy: 0.5184, Took 1.14 s\n","Epoch [12/50], Loss: 1.0409, Eval Accuracy: 0.5198, Took 1.14 s\n","Epoch [13/50], Loss: 1.0407, Eval Accuracy: 0.5218, Took 1.14 s\n","Epoch [14/50], Loss: 1.0382, Eval Accuracy: 0.5218, Took 1.14 s\n","Epoch [15/50], Loss: 1.0381, Eval Accuracy: 0.5199, Took 1.14 s\n","Epoch [16/50], Loss: 1.0368, Eval Accuracy: 0.5222, Took 1.15 s\n","Epoch [17/50], Loss: 1.0367, Eval Accuracy: 0.5226, Took 1.14 s\n","Epoch [18/50], Loss: 1.0349, Eval Accuracy: 0.5226, Took 1.14 s\n","Epoch [19/50], Loss: 1.0345, Eval Accuracy: 0.5231, Took 1.15 s\n","Epoch [20/50], Loss: 1.0347, Eval Accuracy: 0.5209, Took 1.14 s\n","Epoch [21/50], Loss: 1.035, Eval Accuracy: 0.5225, Took 1.14 s\n","Stopped early after epoch 21 as validation accuracy was lower than average of the last 7 accuracies.\n","Last Loss: 1.035, Last Eval Accuracy: 0.5225, Took 24.03 s\n","Model saved as 20240603143927_encoder_64em_2l_4h_05dr_21ep.pt\n","----- Start Training: 64 emb, 2 layers, 8 heads, 0.5 dropout, positional encoding: False, 50 epochs -----\n","Epoch [1/50], Loss: 1.7956, Eval Accuracy: 0.5156, Took 1.48 s\n","Epoch [2/50], Loss: 1.2456, Eval Accuracy: 0.5145, Took 1.48 s\n","Epoch [3/50], Loss: 1.1489, Eval Accuracy: 0.516, Took 1.48 s\n","Epoch [4/50], Loss: 1.1066, Eval Accuracy: 0.5166, Took 1.49 s\n","Epoch [5/50], Loss: 1.0831, Eval Accuracy: 0.5198, Took 1.49 s\n","Epoch [6/50], Loss: 1.0687, Eval Accuracy: 0.5166, Took 1.48 s\n","Epoch [7/50], Loss: 1.0591, Eval Accuracy: 0.5159, Took 1.49 s\n","Epoch [8/50], Loss: 1.0537, Eval Accuracy: 0.5201, Took 1.5 s\n","Epoch [9/50], Loss: 1.0486, Eval Accuracy: 0.5213, Took 1.49 s\n","Epoch [10/50], Loss: 1.0451, Eval Accuracy: 0.5223, Took 1.5 s\n","Epoch [11/50], Loss: 1.0434, Eval Accuracy: 0.5193, Took 1.5 s\n","Epoch [12/50], Loss: 1.0406, Eval Accuracy: 0.5208, Took 1.49 s\n","Epoch [13/50], Loss: 1.0405, Eval Accuracy: 0.5227, Took 1.49 s\n","Epoch [14/50], Loss: 1.0381, Eval Accuracy: 0.5228, Took 1.5 s\n","Epoch [15/50], Loss: 1.0381, Eval Accuracy: 0.5203, Took 1.49 s\n","Epoch [16/50], Loss: 1.0369, Eval Accuracy: 0.5222, Took 1.49 s\n","Stopped early after epoch 16 as validation accuracy was lower than average of the last 7 accuracies.\n","Last Loss: 1.0369, Last Eval Accuracy: 0.5222, Took 23.84 s\n","Model saved as 20240603143951_encoder_64em_2l_8h_05dr_16ep.pt\n","----- Start Training: 64 emb, 4 layers, 1 heads, 0.5 dropout, positional encoding: False, 50 epochs -----\n","Epoch [1/50], Loss: 1.7575, Eval Accuracy: 0.5138, Took 1.72 s\n","Epoch [2/50], Loss: 1.2396, Eval Accuracy: 0.5151, Took 1.7 s\n","Epoch [3/50], Loss: 1.1461, Eval Accuracy: 0.5158, Took 1.7 s\n","Epoch [4/50], Loss: 1.1042, Eval Accuracy: 0.5167, Took 1.7 s\n","Epoch [5/50], Loss: 1.0809, Eval Accuracy: 0.5161, Took 1.7 s\n","Epoch [6/50], Loss: 1.0677, Eval Accuracy: 0.5158, Took 1.7 s\n","Epoch [7/50], Loss: 1.0582, Eval Accuracy: 0.5175, Took 1.69 s\n","Epoch [8/50], Loss: 1.0527, Eval Accuracy: 0.5193, Took 1.69 s\n","Epoch [9/50], Loss: 1.0482, Eval Accuracy: 0.5212, Took 1.7 s\n","Epoch [10/50], Loss: 1.0451, Eval Accuracy: 0.5224, Took 1.7 s\n","Epoch [11/50], Loss: 1.0428, Eval Accuracy: 0.5178, Took 1.71 s\n","Epoch [12/50], Loss: 1.0407, Eval Accuracy: 0.5183, Took 1.76 s\n","Epoch [13/50], Loss: 1.0406, Eval Accuracy: 0.5226, Took 1.76 s\n","Epoch [14/50], Loss: 1.0379, Eval Accuracy: 0.5229, Took 1.75 s\n","Epoch [15/50], Loss: 1.0381, Eval Accuracy: 0.52, Took 1.74 s\n","Epoch [16/50], Loss: 1.0364, Eval Accuracy: 0.5227, Took 1.74 s\n","Epoch [17/50], Loss: 1.0367, Eval Accuracy: 0.523, Took 1.74 s\n","Epoch [18/50], Loss: 1.0347, Eval Accuracy: 0.5219, Took 1.74 s\n","Epoch [19/50], Loss: 1.0344, Eval Accuracy: 0.5219, Took 1.75 s\n","Epoch [20/50], Loss: 1.0344, Eval Accuracy: 0.5214, Took 1.75 s\n","Stopped early after epoch 20 as validation accuracy was lower than average of the last 7 accuracies.\n","Last Loss: 1.0344, Last Eval Accuracy: 0.5214, Took 34.43 s\n","Model saved as 20240603144025_encoder_64em_4l_1h_05dr_20ep.pt\n","----- Start Training: 64 emb, 4 layers, 2 heads, 0.5 dropout, positional encoding: False, 50 epochs -----\n","Epoch [1/50], Loss: 1.7554, Eval Accuracy: 0.515, Took 1.9 s\n","Epoch [2/50], Loss: 1.2395, Eval Accuracy: 0.5145, Took 1.87 s\n","Epoch [3/50], Loss: 1.1458, Eval Accuracy: 0.517, Took 1.87 s\n","Epoch [4/50], Loss: 1.1043, Eval Accuracy: 0.5175, Took 1.87 s\n","Epoch [5/50], Loss: 1.0816, Eval Accuracy: 0.5184, Took 1.87 s\n","Epoch [6/50], Loss: 1.0679, Eval Accuracy: 0.5168, Took 1.87 s\n","Epoch [7/50], Loss: 1.0582, Eval Accuracy: 0.5165, Took 1.87 s\n","Epoch [8/50], Loss: 1.0527, Eval Accuracy: 0.5189, Took 1.87 s\n","Epoch [9/50], Loss: 1.0482, Eval Accuracy: 0.5218, Took 1.87 s\n","Epoch [10/50], Loss: 1.0446, Eval Accuracy: 0.5229, Took 1.87 s\n","Epoch [11/50], Loss: 1.0426, Eval Accuracy: 0.5186, Took 1.87 s\n","Epoch [12/50], Loss: 1.0404, Eval Accuracy: 0.519, Took 1.87 s\n","Epoch [13/50], Loss: 1.0406, Eval Accuracy: 0.5232, Took 1.87 s\n","Epoch [14/50], Loss: 1.0376, Eval Accuracy: 0.5228, Took 1.87 s\n","Epoch [15/50], Loss: 1.0377, Eval Accuracy: 0.5212, Took 1.87 s\n","Epoch [16/50], Loss: 1.0365, Eval Accuracy: 0.5232, Took 1.87 s\n","Epoch [17/50], Loss: 1.0363, Eval Accuracy: 0.523, Took 1.87 s\n","Epoch [18/50], Loss: 1.0348, Eval Accuracy: 0.5208, Took 1.87 s\n","Epoch [19/50], Loss: 1.0342, Eval Accuracy: 0.5228, Took 1.87 s\n","Stopped early after epoch 19 as validation accuracy was lower than average of the last 7 accuracies.\n","Last Loss: 1.0342, Last Eval Accuracy: 0.5228, Took 35.59 s\n","Model saved as 20240603144101_encoder_64em_4l_2h_05dr_19ep.pt\n","----- Start Training: 64 emb, 4 layers, 4 heads, 0.5 dropout, positional encoding: False, 50 epochs -----\n","Epoch [1/50], Loss: 1.7575, Eval Accuracy: 0.5149, Took 2.2 s\n","Epoch [2/50], Loss: 1.2396, Eval Accuracy: 0.5146, Took 2.2 s\n","Epoch [3/50], Loss: 1.1453, Eval Accuracy: 0.5151, Took 2.2 s\n","Epoch [4/50], Loss: 1.1037, Eval Accuracy: 0.5177, Took 2.2 s\n","Epoch [5/50], Loss: 1.0812, Eval Accuracy: 0.5164, Took 2.2 s\n","Epoch [6/50], Loss: 1.0673, Eval Accuracy: 0.5163, Took 2.21 s\n","Epoch [7/50], Loss: 1.0583, Eval Accuracy: 0.5161, Took 2.2 s\n","Epoch [8/50], Loss: 1.0529, Eval Accuracy: 0.5177, Took 2.2 s\n","Epoch [9/50], Loss: 1.0481, Eval Accuracy: 0.521, Took 2.2 s\n","Epoch [10/50], Loss: 1.045, Eval Accuracy: 0.5228, Took 2.2 s\n","Epoch [11/50], Loss: 1.0425, Eval Accuracy: 0.5182, Took 2.2 s\n","Epoch [12/50], Loss: 1.0404, Eval Accuracy: 0.5198, Took 2.21 s\n","Epoch [13/50], Loss: 1.0405, Eval Accuracy: 0.5229, Took 2.2 s\n","Epoch [14/50], Loss: 1.0376, Eval Accuracy: 0.5228, Took 2.2 s\n","Epoch [15/50], Loss: 1.0374, Eval Accuracy: 0.5195, Took 2.2 s\n","Epoch [16/50], Loss: 1.0363, Eval Accuracy: 0.5231, Took 2.21 s\n","Epoch [17/50], Loss: 1.0359, Eval Accuracy: 0.5227, Took 2.2 s\n","Epoch [18/50], Loss: 1.0348, Eval Accuracy: 0.5212, Took 2.21 s\n","Epoch [19/50], Loss: 1.0344, Eval Accuracy: 0.5223, Took 2.21 s\n","Epoch [20/50], Loss: 1.0343, Eval Accuracy: 0.5219, Took 2.21 s\n","Stopped early after epoch 20 as validation accuracy was lower than average of the last 7 accuracies.\n","Last Loss: 1.0343, Last Eval Accuracy: 0.5219, Took 44.1 s\n","Model saved as 20240603144145_encoder_64em_4l_4h_05dr_20ep.pt\n","----- Start Training: 64 emb, 4 layers, 8 heads, 0.5 dropout, positional encoding: False, 50 epochs -----\n","Epoch [1/50], Loss: 1.7566, Eval Accuracy: 0.514, Took 2.87 s\n","Epoch [2/50], Loss: 1.2394, Eval Accuracy: 0.5161, Took 2.87 s\n","Epoch [3/50], Loss: 1.1453, Eval Accuracy: 0.5157, Took 2.87 s\n","Epoch [4/50], Loss: 1.1034, Eval Accuracy: 0.5179, Took 2.87 s\n","Epoch [5/50], Loss: 1.0814, Eval Accuracy: 0.5189, Took 2.87 s\n","Epoch [6/50], Loss: 1.0675, Eval Accuracy: 0.5176, Took 2.87 s\n","Epoch [7/50], Loss: 1.058, Eval Accuracy: 0.5157, Took 2.87 s\n","Epoch [8/50], Loss: 1.0527, Eval Accuracy: 0.5187, Took 2.87 s\n","Epoch [9/50], Loss: 1.0478, Eval Accuracy: 0.5211, Took 2.87 s\n","Epoch [10/50], Loss: 1.0447, Eval Accuracy: 0.5232, Took 2.87 s\n","Epoch [11/50], Loss: 1.0424, Eval Accuracy: 0.5193, Took 2.87 s\n","Epoch [12/50], Loss: 1.0403, Eval Accuracy: 0.5194, Took 2.87 s\n","Epoch [13/50], Loss: 1.0405, Eval Accuracy: 0.5227, Took 2.9 s\n","Epoch [14/50], Loss: 1.0378, Eval Accuracy: 0.5227, Took 2.9 s\n","Epoch [15/50], Loss: 1.0375, Eval Accuracy: 0.5202, Took 2.9 s\n","Epoch [16/50], Loss: 1.0364, Eval Accuracy: 0.5235, Took 2.9 s\n","Epoch [17/50], Loss: 1.0363, Eval Accuracy: 0.5223, Took 2.9 s\n","Epoch [18/50], Loss: 1.0346, Eval Accuracy: 0.5217, Took 2.91 s\n","Epoch [19/50], Loss: 1.034, Eval Accuracy: 0.5224, Took 2.9 s\n","Epoch [20/50], Loss: 1.0344, Eval Accuracy: 0.5222, Took 2.89 s\n","Epoch [21/50], Loss: 1.0349, Eval Accuracy: 0.5231, Took 2.9 s\n","Epoch [22/50], Loss: 1.0328, Eval Accuracy: 0.5216, Took 2.9 s\n","Epoch [23/50], Loss: 1.0344, Eval Accuracy: 0.5219, Took 2.9 s\n","Stopped early after epoch 23 as validation accuracy was lower than average of the last 7 accuracies.\n","Last Loss: 1.0344, Last Eval Accuracy: 0.5219, Took 66.38 s\n","Model saved as 20240603144252_encoder_64em_4l_8h_05dr_23ep.pt\n","----- Start Training: 64 emb, 8 layers, 1 heads, 0.5 dropout, positional encoding: False, 50 epochs -----\n","Epoch [1/50], Loss: 1.8499, Eval Accuracy: 0.5151, Took 3.32 s\n","Epoch [2/50], Loss: 1.2472, Eval Accuracy: 0.5156, Took 3.31 s\n","Epoch [3/50], Loss: 1.1485, Eval Accuracy: 0.5148, Took 3.31 s\n","Epoch [4/50], Loss: 1.107, Eval Accuracy: 0.5171, Took 3.31 s\n","Epoch [5/50], Loss: 1.0826, Eval Accuracy: 0.5143, Took 3.31 s\n","Epoch [6/50], Loss: 1.0695, Eval Accuracy: 0.5185, Took 3.31 s\n","Epoch [7/50], Loss: 1.0589, Eval Accuracy: 0.5183, Took 3.31 s\n","Epoch [8/50], Loss: 1.0544, Eval Accuracy: 0.5185, Took 3.32 s\n","Epoch [9/50], Loss: 1.0487, Eval Accuracy: 0.5222, Took 3.31 s\n","Epoch [10/50], Loss: 1.0462, Eval Accuracy: 0.5221, Took 3.31 s\n","Epoch [11/50], Loss: 1.0438, Eval Accuracy: 0.5197, Took 3.31 s\n","Epoch [12/50], Loss: 1.041, Eval Accuracy: 0.5191, Took 3.31 s\n","Epoch [13/50], Loss: 1.041, Eval Accuracy: 0.5226, Took 3.31 s\n","Epoch [14/50], Loss: 1.0388, Eval Accuracy: 0.5214, Took 3.31 s\n","Epoch [15/50], Loss: 1.0383, Eval Accuracy: 0.5208, Took 3.31 s\n","Epoch [16/50], Loss: 1.0368, Eval Accuracy: 0.5228, Took 3.31 s\n","Epoch [17/50], Loss: 1.0373, Eval Accuracy: 0.522, Took 3.31 s\n","Epoch [18/50], Loss: 1.0357, Eval Accuracy: 0.5232, Took 3.31 s\n","Epoch [19/50], Loss: 1.0356, Eval Accuracy: 0.5211, Took 3.31 s\n","Epoch [20/50], Loss: 1.0351, Eval Accuracy: 0.5209, Took 3.31 s\n","Stopped early after epoch 20 as validation accuracy was lower than average of the last 7 accuracies.\n","Last Loss: 1.0351, Last Eval Accuracy: 0.5209, Took 66.28 s\n","Model saved as 20240603144358_encoder_64em_8l_1h_05dr_20ep.pt\n","----- Start Training: 64 emb, 8 layers, 2 heads, 0.5 dropout, positional encoding: False, 50 epochs -----\n","Epoch [1/50], Loss: 1.8548, Eval Accuracy: 0.5146, Took 3.68 s\n","Epoch [2/50], Loss: 1.2476, Eval Accuracy: 0.5137, Took 3.7 s\n","Epoch [3/50], Loss: 1.1492, Eval Accuracy: 0.5169, Took 3.67 s\n","Epoch [4/50], Loss: 1.1068, Eval Accuracy: 0.5174, Took 3.67 s\n","Epoch [5/50], Loss: 1.0834, Eval Accuracy: 0.5175, Took 3.67 s\n","Epoch [6/50], Loss: 1.0694, Eval Accuracy: 0.5194, Took 3.67 s\n","Epoch [7/50], Loss: 1.0596, Eval Accuracy: 0.518, Took 3.67 s\n","Epoch [8/50], Loss: 1.0541, Eval Accuracy: 0.5182, Took 3.67 s\n","Epoch [9/50], Loss: 1.0484, Eval Accuracy: 0.5227, Took 3.67 s\n","Epoch [10/50], Loss: 1.0467, Eval Accuracy: 0.5224, Took 3.66 s\n","Epoch [11/50], Loss: 1.0438, Eval Accuracy: 0.5188, Took 3.66 s\n","Epoch [12/50], Loss: 1.0414, Eval Accuracy: 0.5183, Took 3.66 s\n","Stopped early after epoch 12 as validation accuracy was lower than average of the last 7 accuracies.\n","Last Loss: 1.0414, Last Eval Accuracy: 0.5183, Took 44.05 s\n","Model saved as 20240603144442_encoder_64em_8l_2h_05dr_12ep.pt\n","----- Start Training: 64 emb, 8 layers, 4 heads, 0.5 dropout, positional encoding: False, 50 epochs -----\n","Epoch [1/50], Loss: 1.8542, Eval Accuracy: 0.5148, Took 4.33 s\n","Epoch [2/50], Loss: 1.2474, Eval Accuracy: 0.5158, Took 4.33 s\n","Epoch [3/50], Loss: 1.149, Eval Accuracy: 0.5158, Took 4.32 s\n","Epoch [4/50], Loss: 1.1065, Eval Accuracy: 0.5168, Took 4.33 s\n","Epoch [5/50], Loss: 1.0829, Eval Accuracy: 0.5156, Took 4.33 s\n","Epoch [6/50], Loss: 1.0693, Eval Accuracy: 0.5184, Took 4.34 s\n","Epoch [7/50], Loss: 1.0591, Eval Accuracy: 0.5184, Took 4.36 s\n","Epoch [8/50], Loss: 1.0538, Eval Accuracy: 0.5176, Took 4.36 s\n","Epoch [9/50], Loss: 1.0487, Eval Accuracy: 0.5223, Took 4.33 s\n","Epoch [10/50], Loss: 1.0467, Eval Accuracy: 0.5217, Took 4.33 s\n","Epoch [11/50], Loss: 1.044, Eval Accuracy: 0.518, Took 4.33 s\n","Epoch [12/50], Loss: 1.0414, Eval Accuracy: 0.5181, Took 4.33 s\n","Stopped early after epoch 12 as validation accuracy was lower than average of the last 7 accuracies.\n","Last Loss: 1.0414, Last Eval Accuracy: 0.5181, Took 52.01 s\n","Model saved as 20240603144534_encoder_64em_8l_4h_05dr_12ep.pt\n","----- Start Training: 64 emb, 8 layers, 8 heads, 0.5 dropout, positional encoding: False, 50 epochs -----\n","Epoch [1/50], Loss: 1.845, Eval Accuracy: 0.5145, Took 5.67 s\n","Epoch [2/50], Loss: 1.2461, Eval Accuracy: 0.5151, Took 5.68 s\n","Epoch [3/50], Loss: 1.1486, Eval Accuracy: 0.5099, Took 5.67 s\n","Epoch [4/50], Loss: 1.106, Eval Accuracy: 0.5171, Took 5.68 s\n","Epoch [5/50], Loss: 1.0826, Eval Accuracy: 0.514, Took 5.68 s\n","Epoch [6/50], Loss: 1.0688, Eval Accuracy: 0.5187, Took 5.68 s\n","Epoch [7/50], Loss: 1.0591, Eval Accuracy: 0.5182, Took 5.67 s\n","Epoch [8/50], Loss: 1.0539, Eval Accuracy: 0.5178, Took 5.68 s\n","Epoch [9/50], Loss: 1.0484, Eval Accuracy: 0.5222, Took 5.67 s\n","Epoch [10/50], Loss: 1.0463, Eval Accuracy: 0.5231, Took 5.68 s\n","Epoch [11/50], Loss: 1.0435, Eval Accuracy: 0.5183, Took 5.68 s\n","Epoch [12/50], Loss: 1.0409, Eval Accuracy: 0.5182, Took 5.68 s\n","Epoch [13/50], Loss: 1.041, Eval Accuracy: 0.5219, Took 5.67 s\n","Epoch [14/50], Loss: 1.0385, Eval Accuracy: 0.5216, Took 5.68 s\n","Epoch [15/50], Loss: 1.0381, Eval Accuracy: 0.5202, Took 5.68 s\n","Epoch [16/50], Loss: 1.0366, Eval Accuracy: 0.5227, Took 5.68 s\n","Epoch [17/50], Loss: 1.0367, Eval Accuracy: 0.5215, Took 5.68 s\n","Epoch [18/50], Loss: 1.0353, Eval Accuracy: 0.5217, Took 5.67 s\n","Epoch [19/50], Loss: 1.0352, Eval Accuracy: 0.5207, Took 5.68 s\n","Epoch [20/50], Loss: 1.0352, Eval Accuracy: 0.5218, Took 5.68 s\n","Stopped early after epoch 20 as validation accuracy was lower than average of the last 7 accuracies.\n","Last Loss: 1.0352, Last Eval Accuracy: 0.5218, Took 113.54 s\n","Model saved as 20240603144728_encoder_64em_8l_8h_05dr_20ep.pt\n","------------\n","Not saved as loss too high:\n","[]\n"]},{"data":{"text/plain":["{'encoder_64em_1l_1h_05dr_50ep': 0.5154,\n"," 'encoder_64em_1l_2h_05dr_50ep': 0.516,\n"," 'encoder_64em_1l_4h_05dr_50ep': 0.5165,\n"," 'encoder_64em_1l_8h_05dr_50ep': 0.5187,\n"," 'encoder_64em_2l_1h_05dr_50ep': 0.5221,\n"," 'encoder_64em_2l_2h_05dr_50ep': 0.5198,\n"," 'encoder_64em_2l_4h_05dr_50ep': 0.5225,\n"," 'encoder_64em_2l_8h_05dr_50ep': 0.5222,\n"," 'encoder_64em_4l_1h_05dr_50ep': 0.5214,\n"," 'encoder_64em_4l_2h_05dr_50ep': 0.5228,\n"," 'encoder_64em_4l_4h_05dr_50ep': 0.5219,\n"," 'encoder_64em_4l_8h_05dr_50ep': 0.5219,\n"," 'encoder_64em_8l_1h_05dr_50ep': 0.5209,\n"," 'encoder_64em_8l_2h_05dr_50ep': 0.5183,\n"," 'encoder_64em_8l_4h_05dr_50ep': 0.5181,\n"," 'encoder_64em_8l_8h_05dr_50ep': 0.5218}"]},"execution_count":36,"metadata":{},"output_type":"execute_result"}],"source":["EMBED_DIM = [64]\n","num_encoder_layers = [1, 2, 4, 8]\n","num_heads = [1, 2, 4, 8]\n","DROPOUTS = [0.5]\n","POS_ENC = [False]\n","hyper_parameter_training(EMBED_DIM, num_encoder_layers, num_heads, DROPOUTS, POS_ENC)"]},{"cell_type":"markdown","metadata":{},"source":["#### Positional Encoding"]},{"cell_type":"code","execution_count":39,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["----- Start Training: 64 emb, 2 layers, 4 heads, 0.5 dropout, positional encoding: True, 50 epochs -----\n","Epoch [1/50], Loss: 2.0597, Eval Accuracy: 0.5154, Took 1.17 s\n","Epoch [2/50], Loss: 1.2627, Eval Accuracy: 0.5155, Took 1.17 s\n","Epoch [3/50], Loss: 1.1491, Eval Accuracy: 0.5137, Took 1.16 s\n","Epoch [4/50], Loss: 1.1068, Eval Accuracy: 0.5155, Took 1.16 s\n","Epoch [5/50], Loss: 1.0852, Eval Accuracy: 0.5145, Took 1.17 s\n","Epoch [6/50], Loss: 1.0717, Eval Accuracy: 0.5153, Took 1.17 s\n","Epoch [7/50], Loss: 1.0629, Eval Accuracy: 0.5159, Took 1.17 s\n","Epoch [8/50], Loss: 1.0585, Eval Accuracy: 0.5163, Took 1.17 s\n","Epoch [9/50], Loss: 1.0538, Eval Accuracy: 0.517, Took 1.14 s\n","Epoch [10/50], Loss: 1.0511, Eval Accuracy: 0.5168, Took 1.14 s\n","Epoch [11/50], Loss: 1.0485, Eval Accuracy: 0.5164, Took 1.14 s\n","Epoch [12/50], Loss: 1.0462, Eval Accuracy: 0.5164, Took 1.15 s\n","Epoch [13/50], Loss: 1.0459, Eval Accuracy: 0.5161, Took 1.15 s\n","Stopped early after epoch 13 as validation accuracy was lower than average of the last 7 accuracies.\n","Last Loss: 1.0459, Last Eval Accuracy: 0.5161, Took 15.07 s\n","Model saved as 20240603145400_encoder_64em_2l_4h_05dr_posenc_13ep.pt\n","----- Start Training: 64 emb, 2 layers, 4 heads, 0.5 dropout, positional encoding: False, 50 epochs -----\n","Epoch [1/50], Loss: 1.7964, Eval Accuracy: 0.5155, Took 1.14 s\n","Epoch [2/50], Loss: 1.2462, Eval Accuracy: 0.5146, Took 1.14 s\n","Epoch [3/50], Loss: 1.1489, Eval Accuracy: 0.5153, Took 1.14 s\n","Epoch [4/50], Loss: 1.1064, Eval Accuracy: 0.5166, Took 1.14 s\n","Epoch [5/50], Loss: 1.083, Eval Accuracy: 0.5186, Took 1.14 s\n","Epoch [6/50], Loss: 1.0689, Eval Accuracy: 0.5166, Took 1.14 s\n","Epoch [7/50], Loss: 1.0594, Eval Accuracy: 0.5176, Took 1.14 s\n","Epoch [8/50], Loss: 1.0536, Eval Accuracy: 0.5196, Took 1.14 s\n","Epoch [9/50], Loss: 1.0486, Eval Accuracy: 0.5204, Took 1.14 s\n","Epoch [10/50], Loss: 1.0456, Eval Accuracy: 0.522, Took 1.14 s\n","Epoch [11/50], Loss: 1.0435, Eval Accuracy: 0.5184, Took 1.14 s\n","Epoch [12/50], Loss: 1.0409, Eval Accuracy: 0.5198, Took 1.14 s\n","Epoch [13/50], Loss: 1.0407, Eval Accuracy: 0.5218, Took 1.14 s\n","Epoch [14/50], Loss: 1.0382, Eval Accuracy: 0.5218, Took 1.14 s\n","Epoch [15/50], Loss: 1.0381, Eval Accuracy: 0.5199, Took 1.14 s\n","Epoch [16/50], Loss: 1.0368, Eval Accuracy: 0.5222, Took 1.14 s\n","Epoch [17/50], Loss: 1.0367, Eval Accuracy: 0.5226, Took 1.14 s\n","Epoch [18/50], Loss: 1.0349, Eval Accuracy: 0.5226, Took 1.14 s\n","Epoch [19/50], Loss: 1.0345, Eval Accuracy: 0.5231, Took 1.14 s\n","Epoch [20/50], Loss: 1.0347, Eval Accuracy: 0.5209, Took 1.14 s\n","Epoch [21/50], Loss: 1.035, Eval Accuracy: 0.5225, Took 1.15 s\n","Stopped early after epoch 21 as validation accuracy was lower than average of the last 7 accuracies.\n","Last Loss: 1.035, Last Eval Accuracy: 0.5225, Took 23.97 s\n","Model saved as 20240603145424_encoder_64em_2l_4h_05dr_21ep.pt\n","------------\n","Not saved as loss too high:\n","[]\n"]},{"data":{"text/plain":["{'encoder_64em_2l_4h_05dr_posenc_50ep': 0.5161,\n"," 'encoder_64em_2l_4h_05dr_50ep': 0.5225}"]},"execution_count":39,"metadata":{},"output_type":"execute_result"}],"source":["EMBED_DIM = [64]\n","NUM_ENCODER_LAYERS = [2]\n","NUM_HEADS = [4]\n","DROPOUTS = [0.5]\n","pos_enc = [True, False]\n","hyper_parameter_training(EMBED_DIM, NUM_ENCODER_LAYERS, NUM_HEADS, DROPOUTS, pos_enc)"]},{"cell_type":"markdown","metadata":{},"source":["## Drosophila.Melanogaster"]},{"cell_type":"code","execution_count":40,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Länge train_dataset: 33040\n","Länge valid_dataset: 4073\n"]}],"source":["organism = \"Drosophila.Melanogaster\"\n","min_length = None\n","max_length = 500\n","\n","train_dataset = ml_helper.CodonDataset(organism, \"train\", min_length, max_length, cut_data=True, one_hot_aa=False, data_path=data_path, device=device)\n","print(f\"Länge train_dataset: {len(train_dataset)}\")\n","valid_dataset = ml_helper.CodonDataset(organism, \"valid\", min_length, max_length, cut_data=True, one_hot_aa=False, data_path=data_path, device=device)\n","print(f\"Länge valid_dataset: {len(valid_dataset)}\")\n","\n","BATCH_SIZE = 32\n","train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n","valid_loader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False)"]},{"cell_type":"code","execution_count":44,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["----- Start Training: 64 emb, 2 layers, 2 heads, 0.2 dropout, positional encoding: False, 10 epochs -----\n","Epoch [1/10], Loss: 1.1824, Eval Accuracy: 0.4967, Took 9.54 s\n","Epoch [2/10], Loss: 1.081, Eval Accuracy: 0.497, Took 9.79 s\n","Epoch [3/10], Loss: 1.076, Eval Accuracy: 0.4977, Took 9.09 s\n","Epoch [4/10], Loss: 1.0746, Eval Accuracy: 0.498, Took 9.1 s\n","Epoch [5/10], Loss: 1.0737, Eval Accuracy: 0.4975, Took 9.1 s\n","Epoch [6/10], Loss: 1.073, Eval Accuracy: 0.4972, Took 9.11 s\n","Epoch [7/10], Loss: 1.0725, Eval Accuracy: 0.4987, Took 9.1 s\n","Epoch [8/10], Loss: 1.0719, Eval Accuracy: 0.4989, Took 9.1 s\n","Epoch [9/10], Loss: 1.0715, Eval Accuracy: 0.4982, Took 10.15 s\n","Epoch [10/10], Loss: 1.071, Eval Accuracy: 0.4991, Took 9.1 s\n","Last Loss: 1.071, Last Eval Accuracy: 0.4991, Took 93.17 s\n","Model saved as 20240603150541_encoder_64em_2l_2h_02dr_10ep.pt\n","----- Start Training: 64 emb, 2 layers, 2 heads, 0.5 dropout, positional encoding: False, 10 epochs -----\n","Epoch [1/10], Loss: 1.2169, Eval Accuracy: 0.4961, Took 9.1 s\n","Epoch [2/10], Loss: 1.0838, Eval Accuracy: 0.4968, Took 9.1 s\n","Epoch [3/10], Loss: 1.0788, Eval Accuracy: 0.4974, Took 9.1 s\n","Epoch [4/10], Loss: 1.0772, Eval Accuracy: 0.4977, Took 9.1 s\n","Epoch [5/10], Loss: 1.0761, Eval Accuracy: 0.4973, Took 9.09 s\n","Epoch [6/10], Loss: 1.0753, Eval Accuracy: 0.4973, Took 9.1 s\n","Epoch [7/10], Loss: 1.0746, Eval Accuracy: 0.4982, Took 9.1 s\n","Epoch [8/10], Loss: 1.074, Eval Accuracy: 0.4986, Took 9.1 s\n","Epoch [9/10], Loss: 1.0736, Eval Accuracy: 0.498, Took 9.1 s\n","Epoch [10/10], Loss: 1.0732, Eval Accuracy: 0.4987, Took 9.09 s\n","Last Loss: 1.0732, Last Eval Accuracy: 0.4987, Took 90.98 s\n","Model saved as 20240603150712_encoder_64em_2l_2h_05dr_10ep.pt\n","----- Start Training: 64 emb, 2 layers, 4 heads, 0.2 dropout, positional encoding: False, 10 epochs -----\n","Epoch [1/10], Loss: 1.1823, Eval Accuracy: 0.4966, Took 10.65 s\n","Epoch [2/10], Loss: 1.0809, Eval Accuracy: 0.4968, Took 10.65 s\n","Epoch [3/10], Loss: 1.076, Eval Accuracy: 0.4976, Took 10.63 s\n","Epoch [4/10], Loss: 1.0745, Eval Accuracy: 0.4978, Took 10.64 s\n","Epoch [5/10], Loss: 1.0735, Eval Accuracy: 0.4974, Took 10.63 s\n","Epoch [6/10], Loss: 1.0729, Eval Accuracy: 0.4977, Took 10.63 s\n","Epoch [7/10], Loss: 1.0723, Eval Accuracy: 0.4985, Took 10.63 s\n","Epoch [8/10], Loss: 1.0717, Eval Accuracy: 0.499, Took 10.63 s\n","Epoch [9/10], Loss: 1.0713, Eval Accuracy: 0.4985, Took 10.64 s\n","Epoch [10/10], Loss: 1.0708, Eval Accuracy: 0.4993, Took 10.63 s\n","Last Loss: 1.0708, Last Eval Accuracy: 0.4993, Took 106.38 s\n","Model saved as 20240603150858_encoder_64em_2l_4h_02dr_10ep.pt\n","----- Start Training: 64 emb, 2 layers, 4 heads, 0.5 dropout, positional encoding: False, 10 epochs -----\n","Epoch [1/10], Loss: 1.2168, Eval Accuracy: 0.4962, Took 10.66 s\n","Epoch [2/10], Loss: 1.0837, Eval Accuracy: 0.4965, Took 10.66 s\n","Epoch [3/10], Loss: 1.0787, Eval Accuracy: 0.4971, Took 10.65 s\n","Epoch [4/10], Loss: 1.0771, Eval Accuracy: 0.4975, Took 10.64 s\n","Epoch [5/10], Loss: 1.076, Eval Accuracy: 0.4971, Took 10.65 s\n","Epoch [6/10], Loss: 1.0753, Eval Accuracy: 0.497, Took 10.63 s\n","Epoch [7/10], Loss: 1.0745, Eval Accuracy: 0.498, Took 10.64 s\n","Epoch [8/10], Loss: 1.0739, Eval Accuracy: 0.4983, Took 10.63 s\n","Epoch [9/10], Loss: 1.0734, Eval Accuracy: 0.4978, Took 10.63 s\n","Epoch [10/10], Loss: 1.073, Eval Accuracy: 0.4989, Took 10.64 s\n","Last Loss: 1.073, Last Eval Accuracy: 0.4989, Took 106.43 s\n","Model saved as 20240603151045_encoder_64em_2l_4h_05dr_10ep.pt\n","----- Start Training: 64 emb, 4 layers, 2 heads, 0.2 dropout, positional encoding: False, 10 epochs -----\n","Epoch [1/10], Loss: 1.1771, Eval Accuracy: 0.496, Took 17.41 s\n","Epoch [2/10], Loss: 1.0809, Eval Accuracy: 0.4962, Took 17.4 s\n","Epoch [3/10], Loss: 1.0765, Eval Accuracy: 0.4977, Took 17.42 s\n","Epoch [4/10], Loss: 1.0746, Eval Accuracy: 0.4978, Took 17.41 s\n","Epoch [5/10], Loss: 1.0736, Eval Accuracy: 0.4972, Took 17.44 s\n","Epoch [6/10], Loss: 1.0729, Eval Accuracy: 0.497, Took 17.43 s\n","Epoch [7/10], Loss: 1.0722, Eval Accuracy: 0.4984, Took 17.41 s\n","Epoch [8/10], Loss: 1.0716, Eval Accuracy: 0.4988, Took 17.39 s\n","Epoch [9/10], Loss: 1.0712, Eval Accuracy: 0.4983, Took 17.52 s\n","Epoch [10/10], Loss: 1.0711, Eval Accuracy: 0.4994, Took 17.56 s\n","Last Loss: 1.0711, Last Eval Accuracy: 0.4994, Took 174.37 s\n","Model saved as 20240603151339_encoder_64em_4l_2h_02dr_10ep.pt\n","----- Start Training: 64 emb, 4 layers, 2 heads, 0.5 dropout, positional encoding: False, 10 epochs -----\n","Epoch [1/10], Loss: 1.2105, Eval Accuracy: 0.4968, Took 17.4 s\n","Epoch [2/10], Loss: 1.0834, Eval Accuracy: 0.4955, Took 17.42 s\n","Epoch [3/10], Loss: 1.0788, Eval Accuracy: 0.4972, Took 17.43 s\n","Epoch [4/10], Loss: 1.0771, Eval Accuracy: 0.4978, Took 17.42 s\n","Epoch [5/10], Loss: 1.0761, Eval Accuracy: 0.4974, Took 17.44 s\n","Epoch [6/10], Loss: 1.0754, Eval Accuracy: 0.4969, Took 17.46 s\n","Epoch [7/10], Loss: 1.0745, Eval Accuracy: 0.4985, Took 17.6 s\n","Epoch [8/10], Loss: 1.074, Eval Accuracy: 0.4985, Took 17.63 s\n","Epoch [9/10], Loss: 1.0734, Eval Accuracy: 0.498, Took 17.64 s\n","Epoch [10/10], Loss: 1.073, Eval Accuracy: 0.4989, Took 17.63 s\n","Last Loss: 1.073, Last Eval Accuracy: 0.4989, Took 175.08 s\n","Model saved as 20240603151634_encoder_64em_4l_2h_05dr_10ep.pt\n","----- Start Training: 64 emb, 4 layers, 4 heads, 0.2 dropout, positional encoding: False, 10 epochs -----\n","Epoch [1/10], Loss: 1.1768, Eval Accuracy: 0.4964, Took 20.46 s\n","Epoch [2/10], Loss: 1.0809, Eval Accuracy: 0.4962, Took 20.5 s\n","Epoch [3/10], Loss: 1.0759, Eval Accuracy: 0.4978, Took 20.48 s\n","Epoch [4/10], Loss: 1.0744, Eval Accuracy: 0.498, Took 20.46 s\n","Epoch [5/10], Loss: 1.0738, Eval Accuracy: 0.4971, Took 20.49 s\n","Epoch [6/10], Loss: 1.0727, Eval Accuracy: 0.4968, Took 20.67 s\n","Epoch [7/10], Loss: 1.0719, Eval Accuracy: 0.4984, Took 20.46 s\n","Epoch [8/10], Loss: 1.0712, Eval Accuracy: 0.4991, Took 20.51 s\n","Epoch [9/10], Loss: 1.0712, Eval Accuracy: 0.4979, Took 20.71 s\n","Epoch [10/10], Loss: 1.0706, Eval Accuracy: 0.4993, Took 20.71 s\n","Last Loss: 1.0706, Last Eval Accuracy: 0.4993, Took 205.45 s\n","Model saved as 20240603152000_encoder_64em_4l_4h_02dr_10ep.pt\n","----- Start Training: 64 emb, 4 layers, 4 heads, 0.5 dropout, positional encoding: False, 10 epochs -----\n","Epoch [1/10], Loss: 1.2103, Eval Accuracy: 0.497, Took 20.77 s\n","Epoch [2/10], Loss: 1.0833, Eval Accuracy: 0.4962, Took 20.5 s\n","Epoch [3/10], Loss: 1.0785, Eval Accuracy: 0.4972, Took 20.5 s\n","Epoch [4/10], Loss: 1.0769, Eval Accuracy: 0.4975, Took 20.5 s\n","Epoch [5/10], Loss: 1.0759, Eval Accuracy: 0.4969, Took 20.52 s\n","Epoch [6/10], Loss: 1.0753, Eval Accuracy: 0.4964, Took 20.46 s\n","Epoch [7/10], Loss: 1.0744, Eval Accuracy: 0.4983, Took 20.52 s\n","Epoch [8/10], Loss: 1.0736, Eval Accuracy: 0.4987, Took 20.52 s\n","Epoch [9/10], Loss: 1.0731, Eval Accuracy: 0.4981, Took 20.49 s\n","Epoch [10/10], Loss: 1.0725, Eval Accuracy: 0.4989, Took 20.51 s\n","Last Loss: 1.0725, Last Eval Accuracy: 0.4989, Took 205.28 s\n","Model saved as 20240603152325_encoder_64em_4l_4h_05dr_10ep.pt\n","----- Start Training: 128 emb, 2 layers, 2 heads, 0.2 dropout, positional encoding: False, 10 epochs -----\n","Epoch [1/10], Loss: 1.124, Eval Accuracy: 0.4957, Took 10.7 s\n","Epoch [2/10], Loss: 1.0772, Eval Accuracy: 0.4965, Took 10.69 s\n","Epoch [3/10], Loss: 1.0744, Eval Accuracy: 0.4982, Took 10.72 s\n","Epoch [4/10], Loss: 1.0734, Eval Accuracy: 0.4975, Took 10.69 s\n","Epoch [5/10], Loss: 1.0727, Eval Accuracy: 0.4968, Took 10.67 s\n","Epoch [6/10], Loss: 1.0724, Eval Accuracy: 0.4964, Took 10.67 s\n","Epoch [7/10], Loss: 1.0721, Eval Accuracy: 0.4981, Took 10.66 s\n","Epoch [8/10], Loss: 1.0713, Eval Accuracy: 0.499, Took 10.67 s\n","Epoch [9/10], Loss: 1.0708, Eval Accuracy: 0.4983, Took 10.67 s\n","Epoch [10/10], Loss: 1.0714, Eval Accuracy: 0.4992, Took 10.66 s\n","Last Loss: 1.0714, Last Eval Accuracy: 0.4992, Took 106.81 s\n","Model saved as 20240603152512_encoder_128em_2l_2h_02dr_10ep.pt\n","----- Start Training: 128 emb, 2 layers, 2 heads, 0.5 dropout, positional encoding: False, 10 epochs -----\n","Epoch [1/10], Loss: 1.1385, Eval Accuracy: 0.4967, Took 10.73 s\n","Epoch [2/10], Loss: 1.0783, Eval Accuracy: 0.4967, Took 10.94 s\n","Epoch [3/10], Loss: 1.0758, Eval Accuracy: 0.498, Took 10.72 s\n","Epoch [4/10], Loss: 1.0751, Eval Accuracy: 0.4974, Took 10.71 s\n","Epoch [5/10], Loss: 1.0742, Eval Accuracy: 0.4968, Took 10.71 s\n","Epoch [6/10], Loss: 1.0737, Eval Accuracy: 0.4956, Took 10.74 s\n","Epoch [7/10], Loss: 1.0734, Eval Accuracy: 0.4981, Took 10.69 s\n","Epoch [8/10], Loss: 1.0727, Eval Accuracy: 0.4989, Took 10.81 s\n","Epoch [9/10], Loss: 1.0722, Eval Accuracy: 0.4979, Took 10.7 s\n","Epoch [10/10], Loss: 1.0718, Eval Accuracy: 0.4993, Took 10.7 s\n","Last Loss: 1.0718, Last Eval Accuracy: 0.4993, Took 107.44 s\n","Model saved as 20240603152659_encoder_128em_2l_2h_05dr_10ep.pt\n","----- Start Training: 128 emb, 2 layers, 4 heads, 0.2 dropout, positional encoding: False, 10 epochs -----\n","Epoch [1/10], Loss: 1.1237, Eval Accuracy: 0.4958, Took 12.06 s\n","Epoch [2/10], Loss: 1.077, Eval Accuracy: 0.4965, Took 12.05 s\n","Epoch [3/10], Loss: 1.0742, Eval Accuracy: 0.498, Took 12.12 s\n","Epoch [4/10], Loss: 1.0734, Eval Accuracy: 0.4973, Took 12.09 s\n","Epoch [5/10], Loss: 1.0725, Eval Accuracy: 0.4965, Took 12.04 s\n","Epoch [6/10], Loss: 1.072, Eval Accuracy: 0.4967, Took 12.03 s\n","Epoch [7/10], Loss: 1.072, Eval Accuracy: 0.4983, Took 12.08 s\n","Epoch [8/10], Loss: 1.0708, Eval Accuracy: 0.499, Took 12.02 s\n","Epoch [9/10], Loss: 1.0703, Eval Accuracy: 0.4982, Took 12.07 s\n","Epoch [10/10], Loss: 1.0698, Eval Accuracy: 0.4992, Took 12.06 s\n","Last Loss: 1.0698, Last Eval Accuracy: 0.4992, Took 120.62 s\n","Model saved as 20240603152900_encoder_128em_2l_4h_02dr_10ep.pt\n","----- Start Training: 128 emb, 2 layers, 4 heads, 0.5 dropout, positional encoding: False, 10 epochs -----\n","Epoch [1/10], Loss: 1.1381, Eval Accuracy: 0.4964, Took 12.1 s\n","Epoch [2/10], Loss: 1.0782, Eval Accuracy: 0.4967, Took 12.05 s\n","Epoch [3/10], Loss: 1.0757, Eval Accuracy: 0.4979, Took 12.04 s\n","Epoch [4/10], Loss: 1.075, Eval Accuracy: 0.4973, Took 12.05 s\n","Epoch [5/10], Loss: 1.074, Eval Accuracy: 0.4966, Took 12.04 s\n","Epoch [6/10], Loss: 1.0735, Eval Accuracy: 0.4963, Took 12.04 s\n","Epoch [7/10], Loss: 1.0732, Eval Accuracy: 0.4985, Took 12.02 s\n","Epoch [8/10], Loss: 1.0722, Eval Accuracy: 0.4991, Took 12.05 s\n","Epoch [9/10], Loss: 1.0718, Eval Accuracy: 0.4982, Took 12.2 s\n","Epoch [10/10], Loss: 1.0715, Eval Accuracy: 0.4989, Took 12.27 s\n","Last Loss: 1.0715, Last Eval Accuracy: 0.4989, Took 120.87 s\n","Model saved as 20240603153101_encoder_128em_2l_4h_05dr_10ep.pt\n","----- Start Training: 128 emb, 4 layers, 2 heads, 0.2 dropout, positional encoding: False, 10 epochs -----\n","Epoch [1/10], Loss: 1.1206, Eval Accuracy: 0.4959, Took 20.59 s\n","Epoch [2/10], Loss: 1.0771, Eval Accuracy: 0.4966, Took 20.59 s\n","Epoch [3/10], Loss: 1.0751, Eval Accuracy: 0.4977, Took 20.59 s\n","Epoch [4/10], Loss: 1.0735, Eval Accuracy: 0.4976, Took 20.58 s\n","Epoch [5/10], Loss: 1.0741, Eval Accuracy: 0.4967, Took 20.58 s\n","Epoch [6/10], Loss: 1.0729, Eval Accuracy: 0.496, Took 20.53 s\n","Epoch [7/10], Loss: 1.0723, Eval Accuracy: 0.4982, Took 20.51 s\n","Epoch [8/10], Loss: 1.0713, Eval Accuracy: 0.4988, Took 20.81 s\n","Epoch [9/10], Loss: 1.0711, Eval Accuracy: 0.4977, Took 20.57 s\n","Epoch [10/10], Loss: 1.0711, Eval Accuracy: 0.4986, Took 20.81 s\n","Last Loss: 1.0711, Last Eval Accuracy: 0.4986, Took 206.16 s\n","Model saved as 20240603153427_encoder_128em_4l_2h_02dr_10ep.pt\n","----- Start Training: 128 emb, 4 layers, 2 heads, 0.5 dropout, positional encoding: False, 10 epochs -----\n","Epoch [1/10], Loss: 1.1341, Eval Accuracy: 0.4962, Took 20.87 s\n","Epoch [2/10], Loss: 1.0781, Eval Accuracy: 0.4965, Took 20.75 s\n","Epoch [3/10], Loss: 1.0767, Eval Accuracy: 0.4975, Took 20.59 s\n","Epoch [4/10], Loss: 1.0751, Eval Accuracy: 0.4977, Took 20.57 s\n","Epoch [5/10], Loss: 1.0745, Eval Accuracy: 0.4967, Took 20.52 s\n","Epoch [6/10], Loss: 1.0742, Eval Accuracy: 0.4967, Took 20.5 s\n","Epoch [7/10], Loss: 1.0737, Eval Accuracy: 0.4954, Took 20.53 s\n","Epoch [8/10], Loss: 1.0734, Eval Accuracy: 0.4984, Took 20.51 s\n","Stopped early after epoch 8 as validation accuracy was lower than average of the last 7 accuracies.\n","Last Loss: 1.0734, Last Eval Accuracy: 0.4984, Took 164.86 s\n","Model saved as 20240603153712_encoder_128em_4l_2h_05dr_8ep.pt\n","----- Start Training: 128 emb, 4 layers, 4 heads, 0.2 dropout, positional encoding: False, 10 epochs -----\n","Epoch [1/10], Loss: 1.1203, Eval Accuracy: 0.4958, Took 23.34 s\n","Epoch [2/10], Loss: 1.077, Eval Accuracy: 0.4964, Took 23.35 s\n","Epoch [3/10], Loss: 1.0744, Eval Accuracy: 0.4977, Took 23.32 s\n","Epoch [4/10], Loss: 1.0733, Eval Accuracy: 0.4976, Took 23.27 s\n","Epoch [5/10], Loss: 1.0728, Eval Accuracy: 0.4969, Took 23.25 s\n","Epoch [6/10], Loss: 1.0726, Eval Accuracy: 0.4963, Took 23.23 s\n","Epoch [7/10], Loss: 1.0718, Eval Accuracy: 0.497, Took 23.32 s\n","Epoch [8/10], Loss: 1.0714, Eval Accuracy: 0.4992, Took 23.26 s\n","Epoch [9/10], Loss: 1.0701, Eval Accuracy: 0.4988, Took 23.27 s\n","Epoch [10/10], Loss: 1.07, Eval Accuracy: 0.4983, Took 23.24 s\n","Last Loss: 1.07, Last Eval Accuracy: 0.4983, Took 232.85 s\n","Model saved as 20240603154105_encoder_128em_4l_4h_02dr_10ep.pt\n","----- Start Training: 128 emb, 4 layers, 4 heads, 0.5 dropout, positional encoding: False, 10 epochs -----\n","Epoch [1/10], Loss: 1.1341, Eval Accuracy: 0.4955, Took 23.32 s\n","Epoch [2/10], Loss: 1.078, Eval Accuracy: 0.4963, Took 23.32 s\n","Epoch [3/10], Loss: 1.0759, Eval Accuracy: 0.4966, Took 23.3 s\n","Epoch [4/10], Loss: 1.0752, Eval Accuracy: 0.4977, Took 23.25 s\n","Epoch [5/10], Loss: 1.0743, Eval Accuracy: 0.4965, Took 23.27 s\n","Epoch [6/10], Loss: 1.0746, Eval Accuracy: 0.4964, Took 23.26 s\n","Epoch [7/10], Loss: 1.073, Eval Accuracy: 0.4982, Took 23.24 s\n","Epoch [8/10], Loss: 1.0726, Eval Accuracy: 0.4989, Took 23.25 s\n","Epoch [9/10], Loss: 1.0719, Eval Accuracy: 0.4986, Took 23.29 s\n","Epoch [10/10], Loss: 1.0717, Eval Accuracy: 0.4987, Took 23.42 s\n","Last Loss: 1.0717, Last Eval Accuracy: 0.4987, Took 232.92 s\n","Model saved as 20240603154458_encoder_128em_4l_4h_05dr_10ep.pt\n","------------\n","Not saved as loss too high:\n","[]\n"]}],"source":["embed_dims = [64, 128]\n","num_encoder_layers = [2, 4]\n","num_heads = [2, 4]\n","DROPOUTS = [0.2, 0.5]\n","POS_ENC = [False]\n","accuracies = hyper_parameter_training(embed_dims, num_encoder_layers, num_heads, DROPOUTS, POS_ENC, epochs=10, print_epochs=True)"]},{"cell_type":"code","execution_count":45,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["----- Start Training: 64 emb, 4 layers, 4 heads, 0.2 dropout, positional encoding: False, 100 epochs -----\n","Epoch [1/100], Loss: 1.1768, Eval Accuracy: 0.4964, Took 20.78 s\n","Epoch [2/100], Loss: 1.0809, Eval Accuracy: 0.4962, Took 20.48 s\n","Epoch [3/100], Loss: 1.0759, Eval Accuracy: 0.4978, Took 20.5 s\n","Epoch [4/100], Loss: 1.0744, Eval Accuracy: 0.498, Took 20.51 s\n","Epoch [5/100], Loss: 1.0738, Eval Accuracy: 0.4971, Took 20.5 s\n","Epoch [6/100], Loss: 1.0727, Eval Accuracy: 0.4968, Took 20.45 s\n","Epoch [7/100], Loss: 1.0719, Eval Accuracy: 0.4984, Took 20.78 s\n","Epoch [8/100], Loss: 1.0712, Eval Accuracy: 0.4991, Took 20.79 s\n","Epoch [9/100], Loss: 1.0712, Eval Accuracy: 0.4979, Took 20.52 s\n","Epoch [10/100], Loss: 1.0706, Eval Accuracy: 0.4993, Took 20.53 s\n","Epoch [11/100], Loss: 1.0698, Eval Accuracy: 0.4988, Took 20.77 s\n","Epoch [12/100], Loss: 1.0691, Eval Accuracy: 0.4987, Took 20.72 s\n","Epoch [13/100], Loss: 1.0687, Eval Accuracy: 0.4993, Took 20.61 s\n","Epoch [14/100], Loss: 1.0678, Eval Accuracy: 0.5002, Took 20.47 s\n","Epoch [15/100], Loss: 1.0677, Eval Accuracy: 0.4998, Took 20.51 s\n","Epoch [16/100], Loss: 1.0667, Eval Accuracy: 0.4986, Took 20.52 s\n","Epoch [17/100], Loss: 1.0659, Eval Accuracy: 0.5004, Took 20.52 s\n","Epoch [18/100], Loss: 1.0655, Eval Accuracy: 0.4995, Took 20.45 s\n","Epoch [19/100], Loss: 1.0646, Eval Accuracy: 0.5004, Took 20.52 s\n","Epoch [20/100], Loss: 1.0639, Eval Accuracy: 0.5004, Took 20.46 s\n","Epoch [21/100], Loss: 1.0631, Eval Accuracy: 0.5015, Took 20.47 s\n","Epoch [22/100], Loss: 1.0625, Eval Accuracy: 0.5016, Took 20.48 s\n","Epoch [23/100], Loss: 1.0615, Eval Accuracy: 0.499, Took 20.49 s\n","Epoch [24/100], Loss: 1.0608, Eval Accuracy: 0.5002, Took 20.44 s\n","Stopped early after epoch 24 as validation accuracy was lower than average of the last 7 accuracies.\n","Last Loss: 1.0608, Last Eval Accuracy: 0.5002, Took 493.3 s\n","Model saved as 20240603162032_encoder_64em_4l_4h_02dr_24ep.pt\n","----- Start Training: 64 emb, 4 layers, 4 heads, 0.2 dropout, positional encoding: True, 100 epochs -----\n","Epoch [1/100], Loss: 1.1862, Eval Accuracy: 0.4965, Took 20.5 s\n","Epoch [2/100], Loss: 1.0814, Eval Accuracy: 0.4959, Took 20.6 s\n","Epoch [3/100], Loss: 1.0763, Eval Accuracy: 0.4972, Took 20.82 s\n","Epoch [4/100], Loss: 1.0751, Eval Accuracy: 0.4978, Took 20.53 s\n","Epoch [5/100], Loss: 1.0738, Eval Accuracy: 0.497, Took 20.51 s\n","Epoch [6/100], Loss: 1.0729, Eval Accuracy: 0.4975, Took 20.54 s\n","Epoch [7/100], Loss: 1.0722, Eval Accuracy: 0.4983, Took 20.53 s\n","Epoch [8/100], Loss: 1.0715, Eval Accuracy: 0.499, Took 20.64 s\n","Epoch [9/100], Loss: 1.071, Eval Accuracy: 0.4982, Took 20.81 s\n","Epoch [10/100], Loss: 1.0703, Eval Accuracy: 0.4989, Took 20.58 s\n","Epoch [11/100], Loss: 1.0694, Eval Accuracy: 0.4988, Took 20.66 s\n","Epoch [12/100], Loss: 1.069, Eval Accuracy: 0.4989, Took 20.52 s\n","Epoch [13/100], Loss: 1.0686, Eval Accuracy: 0.4991, Took 20.76 s\n","Epoch [14/100], Loss: 1.0677, Eval Accuracy: 0.4998, Took 20.76 s\n","Epoch [15/100], Loss: 1.0673, Eval Accuracy: 0.5004, Took 20.78 s\n","Epoch [16/100], Loss: 1.0667, Eval Accuracy: 0.499, Took 20.68 s\n","Epoch [17/100], Loss: 1.0661, Eval Accuracy: 0.5008, Took 20.56 s\n","Epoch [18/100], Loss: 1.0656, Eval Accuracy: 0.4999, Took 20.56 s\n","Epoch [19/100], Loss: 1.0648, Eval Accuracy: 0.5008, Took 20.49 s\n","Epoch [20/100], Loss: 1.0643, Eval Accuracy: 0.5014, Took 20.49 s\n","Epoch [21/100], Loss: 1.0635, Eval Accuracy: 0.5022, Took 20.51 s\n","Epoch [22/100], Loss: 1.0628, Eval Accuracy: 0.5013, Took 20.53 s\n","Epoch [23/100], Loss: 1.062, Eval Accuracy: 0.5015, Took 20.55 s\n","Epoch [24/100], Loss: 1.0614, Eval Accuracy: 0.5021, Took 20.5 s\n","Epoch [25/100], Loss: 1.0607, Eval Accuracy: 0.5026, Took 20.53 s\n","Epoch [26/100], Loss: 1.0599, Eval Accuracy: 0.503, Took 20.51 s\n","Epoch [27/100], Loss: 1.059, Eval Accuracy: 0.503, Took 20.49 s\n","Epoch [28/100], Loss: 1.0582, Eval Accuracy: 0.5037, Took 20.77 s\n","Epoch [29/100], Loss: 1.0574, Eval Accuracy: 0.5027, Took 20.77 s\n","Epoch [30/100], Loss: 1.0566, Eval Accuracy: 0.5042, Took 20.76 s\n","Epoch [31/100], Loss: 1.056, Eval Accuracy: 0.5048, Took 20.55 s\n","Epoch [32/100], Loss: 1.0552, Eval Accuracy: 0.5052, Took 20.52 s\n","Epoch [33/100], Loss: 1.0542, Eval Accuracy: 0.5051, Took 20.54 s\n","Epoch [34/100], Loss: 1.0533, Eval Accuracy: 0.5054, Took 20.52 s\n","Epoch [35/100], Loss: 1.0526, Eval Accuracy: 0.5069, Took 20.52 s\n","Epoch [36/100], Loss: 1.0517, Eval Accuracy: 0.506, Took 20.54 s\n","Epoch [37/100], Loss: 1.0512, Eval Accuracy: 0.5067, Took 20.51 s\n","Epoch [38/100], Loss: 1.0501, Eval Accuracy: 0.5079, Took 20.51 s\n","Epoch [39/100], Loss: 1.0495, Eval Accuracy: 0.5076, Took 20.53 s\n","Epoch [40/100], Loss: 1.0488, Eval Accuracy: 0.507, Took 20.54 s\n","Epoch [41/100], Loss: 1.048, Eval Accuracy: 0.5085, Took 20.56 s\n","Epoch [42/100], Loss: 1.0473, Eval Accuracy: 0.5082, Took 20.51 s\n","Epoch [43/100], Loss: 1.0465, Eval Accuracy: 0.5094, Took 20.54 s\n","Epoch [44/100], Loss: 1.0459, Eval Accuracy: 0.5094, Took 20.54 s\n","Epoch [45/100], Loss: 1.0453, Eval Accuracy: 0.5093, Took 20.53 s\n","Epoch [46/100], Loss: 1.0446, Eval Accuracy: 0.5096, Took 20.72 s\n","Epoch [47/100], Loss: 1.0439, Eval Accuracy: 0.5098, Took 20.81 s\n","Epoch [48/100], Loss: 1.0433, Eval Accuracy: 0.5107, Took 20.66 s\n","Epoch [49/100], Loss: 1.0428, Eval Accuracy: 0.5095, Took 20.54 s\n","Epoch [50/100], Loss: 1.0422, Eval Accuracy: 0.5093, Took 20.57 s\n","Stopped early after epoch 50 as validation accuracy was lower than average of the last 7 accuracies.\n","Last Loss: 1.0422, Last Eval Accuracy: 0.5093, Took 1029.54 s\n","Model saved as 20240603163741_encoder_64em_4l_4h_02dr_posenc_50ep.pt\n","------------\n","Not saved as loss too high:\n","[]\n"]}],"source":["# Train best suited models for longer\n","embed_dims = [64]\n","num_encoder_layers = [4]\n","num_heads = [4]\n","DROPOUTS = [0.2]\n","POS_ENC = [False, True]\n","accuracies = hyper_parameter_training(embed_dims, num_encoder_layers, num_heads, DROPOUTS, POS_ENC, epochs=100, print_epochs=True)"]},{"cell_type":"markdown","metadata":{},"source":["## Homo.Sapiens"]},{"cell_type":"code","execution_count":48,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Länge train_dataset: 140711\n","Länge valid_dataset: 17784\n","CPU times: user 1min 29s, sys: 392 ms, total: 1min 29s\n","Wall time: 1min 29s\n"]}],"source":["%%time\n","\n","organism = \"Homo.Sapiens\"\n","min_length = None\n","max_length = 500\n","\n","train_dataset = ml_helper.CodonDataset(organism, \"train\", min_length, max_length, cut_data=True, one_hot_aa=False, data_path=data_path, device=device)\n","print(f\"Länge train_dataset: {len(train_dataset)}\")\n","valid_dataset = ml_helper.CodonDataset(organism, \"valid\", min_length, max_length, cut_data=True, one_hot_aa=False, data_path=data_path, device=device)\n","print(f\"Länge valid_dataset: {len(valid_dataset)}\")\n","\n","BATCH_SIZE = 32\n","train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n","valid_loader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False)"]},{"cell_type":"code","execution_count":50,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["----- Start Training: 64 emb, 4 layers, 4 heads, 0.2 dropout, positional encoding: False, 100 epochs -----\n","Epoch [1/100], Loss: 1.1119, Eval Accuracy: 0.4747, Took 87.29 s\n","Epoch [2/100], Loss: 1.082, Eval Accuracy: 0.4793, Took 87.42 s\n","Epoch [3/100], Loss: 1.0793, Eval Accuracy: 0.4808, Took 88.48 s\n","Epoch [4/100], Loss: 1.077, Eval Accuracy: 0.483, Took 88.25 s\n","Epoch [5/100], Loss: 1.0746, Eval Accuracy: 0.4845, Took 87.93 s\n","Epoch [6/100], Loss: 1.072, Eval Accuracy: 0.4867, Took 87.49 s\n","Epoch [7/100], Loss: 1.0694, Eval Accuracy: 0.4905, Took 87.57 s\n","Epoch [8/100], Loss: 1.0667, Eval Accuracy: 0.4912, Took 87.8 s\n","Epoch [9/100], Loss: 1.0641, Eval Accuracy: 0.4933, Took 87.63 s\n","Epoch [10/100], Loss: 1.0616, Eval Accuracy: 0.4956, Took 88.19 s\n","Epoch [11/100], Loss: 1.0593, Eval Accuracy: 0.495, Took 88.09 s\n","Epoch [12/100], Loss: 1.0574, Eval Accuracy: 0.4982, Took 87.49 s\n","Epoch [13/100], Loss: 1.0556, Eval Accuracy: 0.4986, Took 87.37 s\n","Epoch [14/100], Loss: 1.0538, Eval Accuracy: 0.4987, Took 87.77 s\n","Epoch [15/100], Loss: 1.0523, Eval Accuracy: 0.5014, Took 87.41 s\n","Epoch [16/100], Loss: 1.0509, Eval Accuracy: 0.4979, Took 87.38 s\n","Epoch [17/100], Loss: 1.0493, Eval Accuracy: 0.502, Took 87.43 s\n","Epoch [18/100], Loss: 1.0483, Eval Accuracy: 0.5024, Took 88.26 s\n","Epoch [19/100], Loss: 1.047, Eval Accuracy: 0.5031, Took 87.65 s\n","Epoch [20/100], Loss: 1.046, Eval Accuracy: 0.5034, Took 87.38 s\n","Epoch [21/100], Loss: 1.0449, Eval Accuracy: 0.5042, Took 87.41 s\n","Epoch [22/100], Loss: 1.044, Eval Accuracy: 0.5046, Took 87.4 s\n","Epoch [23/100], Loss: 1.043, Eval Accuracy: 0.5047, Took 87.91 s\n","Epoch [24/100], Loss: 1.0422, Eval Accuracy: 0.5053, Took 87.88 s\n","Epoch [25/100], Loss: 1.0413, Eval Accuracy: 0.5054, Took 87.37 s\n","Epoch [26/100], Loss: 1.0407, Eval Accuracy: 0.5058, Took 87.38 s\n","Epoch [27/100], Loss: 1.04, Eval Accuracy: 0.5051, Took 88.32 s\n","Epoch [28/100], Loss: 1.0394, Eval Accuracy: 0.5061, Took 87.56 s\n","Epoch [29/100], Loss: 1.0387, Eval Accuracy: 0.5063, Took 87.81 s\n","Epoch [30/100], Loss: 1.0381, Eval Accuracy: 0.5059, Took 87.38 s\n","Epoch [31/100], Loss: 1.0376, Eval Accuracy: 0.5066, Took 88.35 s\n","Epoch [32/100], Loss: 1.037, Eval Accuracy: 0.5061, Took 87.45 s\n","Epoch [33/100], Loss: 1.0366, Eval Accuracy: 0.5066, Took 87.38 s\n","Epoch [34/100], Loss: 1.036, Eval Accuracy: 0.5067, Took 87.37 s\n","Epoch [35/100], Loss: 1.0355, Eval Accuracy: 0.5074, Took 88.39 s\n","Epoch [36/100], Loss: 1.035, Eval Accuracy: 0.5077, Took 88.03 s\n","Epoch [37/100], Loss: 1.0347, Eval Accuracy: 0.5081, Took 87.4 s\n","Epoch [38/100], Loss: 1.0344, Eval Accuracy: 0.5079, Took 87.39 s\n","Epoch [39/100], Loss: 1.0339, Eval Accuracy: 0.5079, Took 87.41 s\n","Epoch [40/100], Loss: 1.0336, Eval Accuracy: 0.5083, Took 87.44 s\n","Epoch [41/100], Loss: 1.0332, Eval Accuracy: 0.5081, Took 87.9 s\n","Epoch [42/100], Loss: 1.0329, Eval Accuracy: 0.508, Took 87.37 s\n","Epoch [43/100], Loss: 1.0325, Eval Accuracy: 0.5083, Took 87.38 s\n","Epoch [44/100], Loss: 1.0321, Eval Accuracy: 0.5084, Took 87.39 s\n","Epoch [45/100], Loss: 1.0319, Eval Accuracy: 0.5079, Took 87.5 s\n","Epoch [46/100], Loss: 1.0316, Eval Accuracy: 0.5084, Took 87.68 s\n","Epoch [47/100], Loss: 1.0314, Eval Accuracy: 0.5084, Took 87.36 s\n","Epoch [48/100], Loss: 1.031, Eval Accuracy: 0.5093, Took 87.49 s\n","Epoch [49/100], Loss: 1.0307, Eval Accuracy: 0.5092, Took 88.3 s\n","Epoch [50/100], Loss: 1.0305, Eval Accuracy: 0.5086, Took 87.71 s\n","Epoch [51/100], Loss: 1.0303, Eval Accuracy: 0.5087, Took 87.4 s\n","Epoch [52/100], Loss: 1.03, Eval Accuracy: 0.5093, Took 87.39 s\n","Epoch [53/100], Loss: 1.0299, Eval Accuracy: 0.5089, Took 87.45 s\n","Epoch [54/100], Loss: 1.0295, Eval Accuracy: 0.5092, Took 87.65 s\n","Epoch [55/100], Loss: 1.0294, Eval Accuracy: 0.5088, Took 87.96 s\n","Stopped early after epoch 55 as validation accuracy was lower than average of the last 7 accuracies.\n","Last Loss: 1.0294, Last Eval Accuracy: 0.5088, Took 4821.28 s\n","Model saved as 20240603182243_encoder_64em_4l_4h_02dr_55ep.pt\n","----- Start Training: 64 emb, 4 layers, 4 heads, 0.2 dropout, positional encoding: True, 100 epochs -----\n","Epoch [1/100], Loss: 1.1145, Eval Accuracy: 0.4759, Took 87.96 s\n","Epoch [2/100], Loss: 1.0813, Eval Accuracy: 0.4778, Took 88.1 s\n","Epoch [3/100], Loss: 1.0784, Eval Accuracy: 0.4809, Took 87.63 s\n","Epoch [4/100], Loss: 1.0759, Eval Accuracy: 0.4834, Took 87.9 s\n","Epoch [5/100], Loss: 1.0738, Eval Accuracy: 0.4837, Took 87.62 s\n","Epoch [6/100], Loss: 1.0719, Eval Accuracy: 0.4875, Took 88.34 s\n","Epoch [7/100], Loss: 1.0701, Eval Accuracy: 0.4889, Took 87.5 s\n","Epoch [8/100], Loss: 1.0681, Eval Accuracy: 0.4886, Took 87.5 s\n","Epoch [9/100], Loss: 1.0661, Eval Accuracy: 0.4922, Took 87.56 s\n","Epoch [10/100], Loss: 1.0642, Eval Accuracy: 0.4936, Took 87.6 s\n","Epoch [11/100], Loss: 1.0622, Eval Accuracy: 0.4928, Took 87.75 s\n","Epoch [12/100], Loss: 1.0605, Eval Accuracy: 0.496, Took 87.77 s\n","Epoch [13/100], Loss: 1.0588, Eval Accuracy: 0.4975, Took 87.58 s\n","Epoch [14/100], Loss: 1.057, Eval Accuracy: 0.4985, Took 87.79 s\n","Epoch [15/100], Loss: 1.0554, Eval Accuracy: 0.5002, Took 88.09 s\n","Epoch [16/100], Loss: 1.0538, Eval Accuracy: 0.4975, Took 87.53 s\n","Epoch [17/100], Loss: 1.0523, Eval Accuracy: 0.5015, Took 88.46 s\n","Epoch [18/100], Loss: 1.0511, Eval Accuracy: 0.5022, Took 87.53 s\n","Epoch [19/100], Loss: 1.0496, Eval Accuracy: 0.503, Took 87.6 s\n","Epoch [20/100], Loss: 1.0484, Eval Accuracy: 0.5039, Took 88.75 s\n","Epoch [21/100], Loss: 1.0471, Eval Accuracy: 0.5046, Took 87.55 s\n","Epoch [22/100], Loss: 1.0461, Eval Accuracy: 0.5066, Took 87.54 s\n","Epoch [23/100], Loss: 1.045, Eval Accuracy: 0.5064, Took 87.56 s\n","Epoch [24/100], Loss: 1.0439, Eval Accuracy: 0.5081, Took 87.58 s\n","Epoch [25/100], Loss: 1.0429, Eval Accuracy: 0.5075, Took 87.59 s\n","Epoch [26/100], Loss: 1.042, Eval Accuracy: 0.5088, Took 87.85 s\n","Epoch [27/100], Loss: 1.041, Eval Accuracy: 0.5097, Took 87.58 s\n","Epoch [28/100], Loss: 1.0402, Eval Accuracy: 0.5096, Took 87.59 s\n","Epoch [29/100], Loss: 1.0393, Eval Accuracy: 0.5114, Took 87.6 s\n","Epoch [30/100], Loss: 1.0385, Eval Accuracy: 0.5095, Took 87.65 s\n","Epoch [31/100], Loss: 1.0378, Eval Accuracy: 0.5104, Took 87.62 s\n","Epoch [32/100], Loss: 1.037, Eval Accuracy: 0.5112, Took 87.6 s\n","Epoch [33/100], Loss: 1.0363, Eval Accuracy: 0.5125, Took 87.59 s\n","Epoch [34/100], Loss: 1.0356, Eval Accuracy: 0.5127, Took 87.6 s\n","Epoch [35/100], Loss: 1.035, Eval Accuracy: 0.5137, Took 87.64 s\n","Epoch [36/100], Loss: 1.0343, Eval Accuracy: 0.5135, Took 87.75 s\n","Epoch [37/100], Loss: 1.0338, Eval Accuracy: 0.5143, Took 88.65 s\n","Epoch [38/100], Loss: 1.0333, Eval Accuracy: 0.5155, Took 87.7 s\n","Epoch [39/100], Loss: 1.0327, Eval Accuracy: 0.5151, Took 87.64 s\n","Epoch [40/100], Loss: 1.0322, Eval Accuracy: 0.5148, Took 88.82 s\n","Epoch [41/100], Loss: 1.0317, Eval Accuracy: 0.516, Took 88.2 s\n","Epoch [42/100], Loss: 1.0311, Eval Accuracy: 0.5146, Took 88.78 s\n","Epoch [43/100], Loss: 1.0308, Eval Accuracy: 0.5164, Took 87.86 s\n","Epoch [44/100], Loss: 1.0303, Eval Accuracy: 0.5158, Took 87.63 s\n","Epoch [45/100], Loss: 1.0297, Eval Accuracy: 0.5166, Took 87.6 s\n","Epoch [46/100], Loss: 1.0293, Eval Accuracy: 0.5168, Took 87.64 s\n","Epoch [47/100], Loss: 1.0288, Eval Accuracy: 0.5176, Took 87.61 s\n","Epoch [48/100], Loss: 1.0285, Eval Accuracy: 0.5181, Took 87.62 s\n","Epoch [49/100], Loss: 1.028, Eval Accuracy: 0.5174, Took 88.53 s\n","Epoch [50/100], Loss: 1.0276, Eval Accuracy: 0.5178, Took 87.62 s\n","Epoch [51/100], Loss: 1.0273, Eval Accuracy: 0.5183, Took 87.64 s\n","Epoch [52/100], Loss: 1.0269, Eval Accuracy: 0.5177, Took 87.64 s\n","Epoch [53/100], Loss: 1.0266, Eval Accuracy: 0.5189, Took 87.63 s\n","Epoch [54/100], Loss: 1.0262, Eval Accuracy: 0.5183, Took 88.04 s\n","Epoch [55/100], Loss: 1.0259, Eval Accuracy: 0.5195, Took 88.03 s\n","Epoch [56/100], Loss: 1.0256, Eval Accuracy: 0.5195, Took 88.13 s\n","Epoch [57/100], Loss: 1.0253, Eval Accuracy: 0.519, Took 88.82 s\n","Epoch [58/100], Loss: 1.0249, Eval Accuracy: 0.5191, Took 88.69 s\n","Epoch [59/100], Loss: 1.0246, Eval Accuracy: 0.519, Took 88.04 s\n","Epoch [60/100], Loss: 1.0244, Eval Accuracy: 0.52, Took 87.65 s\n","Epoch [61/100], Loss: 1.024, Eval Accuracy: 0.5194, Took 87.6 s\n","Epoch [62/100], Loss: 1.0238, Eval Accuracy: 0.5197, Took 87.62 s\n","Epoch [63/100], Loss: 1.0235, Eval Accuracy: 0.5201, Took 87.6 s\n","Epoch [64/100], Loss: 1.0233, Eval Accuracy: 0.5205, Took 87.63 s\n","Epoch [65/100], Loss: 1.023, Eval Accuracy: 0.5205, Took 88.03 s\n","Epoch [66/100], Loss: 1.0227, Eval Accuracy: 0.5212, Took 87.74 s\n","Epoch [67/100], Loss: 1.0225, Eval Accuracy: 0.5202, Took 88.6 s\n","Epoch [68/100], Loss: 1.0224, Eval Accuracy: 0.5211, Took 88.23 s\n","Epoch [69/100], Loss: 1.022, Eval Accuracy: 0.5214, Took 87.62 s\n","Epoch [70/100], Loss: 1.0218, Eval Accuracy: 0.5202, Took 87.61 s\n","Epoch [71/100], Loss: 1.0217, Eval Accuracy: 0.522, Took 88.0 s\n","Epoch [72/100], Loss: 1.0213, Eval Accuracy: 0.5216, Took 87.94 s\n","Epoch [73/100], Loss: 1.0213, Eval Accuracy: 0.5223, Took 87.64 s\n","Epoch [74/100], Loss: 1.021, Eval Accuracy: 0.5221, Took 87.62 s\n","Epoch [75/100], Loss: 1.0206, Eval Accuracy: 0.5224, Took 88.79 s\n","Epoch [76/100], Loss: 1.0206, Eval Accuracy: 0.5224, Took 87.88 s\n","Epoch [77/100], Loss: 1.0203, Eval Accuracy: 0.5223, Took 87.63 s\n","Epoch [78/100], Loss: 1.0202, Eval Accuracy: 0.5226, Took 87.65 s\n","Epoch [79/100], Loss: 1.02, Eval Accuracy: 0.5222, Took 87.69 s\n","Epoch [80/100], Loss: 1.0197, Eval Accuracy: 0.5214, Took 87.62 s\n","Stopped early after epoch 80 as validation accuracy was lower than average of the last 7 accuracies.\n","Last Loss: 1.0197, Last Eval Accuracy: 0.5214, Took 7027.43 s\n","Model saved as 20240603201950_encoder_64em_4l_4h_posenc_02dr_80ep.pt\n","------------\n","Not saved as loss too high:\n","[]\n"]},{"data":{"text/plain":["{'encoder_64em_4l_4h_02dr_100ep': 0.5088,\n"," 'encoder_64em_4l_4h_posenc_02dr_100ep': 0.5214}"]},"execution_count":50,"metadata":{},"output_type":"execute_result"}],"source":["embed_dims = [64]\n","num_encoder_layers = [4]\n","num_heads = [4]\n","DROPOUTS = [0.2]\n","POS_ENC = [False, True]\n","hyper_parameter_training(embed_dims, num_encoder_layers, num_heads, DROPOUTS, POS_ENC, epochs=100)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":0}
