{"cells":[{"cell_type":"markdown","metadata":{"id":"dvibukPbQ7Zg"},"source":["# Encoder-only Transformer Architektur"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20842,"status":"ok","timestamp":1715688662385,"user":{"displayName":"Insa Belter","userId":"09408038895575287386"},"user_tz":-120},"id":"fXeUV5wCRtUz","outputId":"2bb0af2b-b2a5-4f6e-c9d6-addcb643a568"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8804,"status":"ok","timestamp":1715688671184,"user":{"displayName":"Insa Belter","userId":"09408038895575287386"},"user_tz":-120},"id":"3yudZ4edSJEQ","outputId":"d4151a0c-b418-4144-d13b-0f4aef17b8a7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting biopython\n","  Downloading biopython-1.83-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from biopython) (1.25.2)\n","Installing collected packages: biopython\n","Successfully installed biopython-1.83\n"]}],"source":["!pip install biopython"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":5081,"status":"ok","timestamp":1715688676256,"user":{"displayName":"Insa Belter","userId":"09408038895575287386"},"user_tz":-120},"id":"ev_KN7VqQ7Zm"},"outputs":[],"source":["import sys\n","import random\n","import numpy as np\n","import pandas as pd\n","import ast\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader\n","import time\n","\n","#sys.path.append('../scripts')\n","sys.path.append('/content/drive/MyDrive/PMDS/Notebooks')\n","import ml_helper"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1715688676256,"user":{"displayName":"Insa Belter","userId":"09408038895575287386"},"user_tz":-120},"id":"9eRDLHmaS7Im"},"outputs":[],"source":["data_path = '/content/drive/MyDrive/PMDS/Data'\n","#data_path = '../data'"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1715688676256,"user":{"displayName":"Insa Belter","userId":"09408038895575287386"},"user_tz":-120},"id":"0ayA8mz2Q7Zp"},"outputs":[],"source":["SEED = 42\n","random.seed(SEED)\n","np.random.seed(SEED)\n","torch.manual_seed(SEED)\n","torch.cuda.manual_seed(SEED)"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":566,"status":"ok","timestamp":1715688676819,"user":{"displayName":"Insa Belter","userId":"09408038895575287386"},"user_tz":-120},"id":"5hFAHJ8hRE8p","outputId":"6c9d739b-7b72-447c-878a-a0291901b15d"},"outputs":[{"output_type":"stream","name":"stdout","text":["cuda:0\n"]}],"source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(device)"]},{"cell_type":"markdown","metadata":{"id":"1iTm60N3Q7Zr"},"source":["## Prepare Test and Training Data Loader"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1715688680014,"user":{"displayName":"Insa Belter","userId":"09408038895575287386"},"user_tz":-120},"id":"iZLLB2yhQ7Zs"},"outputs":[],"source":["amino_acids = ['A', 'R', 'N', 'D', 'C', 'Q', 'E', 'G', 'H', 'I', 'L', 'K', 'M', 'F', 'P', 'S', 'T', 'W', 'Y', 'V', '*',\n","               '_']\n","\n","aminoacids_to_integer = dict((a, i) for i, a in enumerate(amino_acids))\n","integer_to_aminoacids = dict((i, a) for i, a in enumerate(amino_acids))\n","\n","codons = ['TTT', 'TTC', 'TTA', 'TTG', 'TCT', 'TCC', 'TCA', 'TCG', 'TAT', 'TAC', 'TAA', 'TAG', 'TGT', 'TGC', 'TGA',\n","          'TGG', 'CTT', 'CTC', 'CTA', 'CTG', 'CCT', 'CCC', 'CCA', 'CCG', 'CAT', 'CAC', 'CAA', 'CAG', 'CGT', 'CGC',\n","          'CGA', 'CGG', 'ATT', 'ATC', 'ATA', 'ATG', 'ACT', 'ACC', 'ACA', 'ACG', 'AAT', 'AAC', 'AAA', 'AAG', 'AGT',\n","          'AGC', 'AGA', 'AGG', 'GTT', 'GTC', 'GTA', 'GTG', 'GCT', 'GCC', 'GCA', 'GCG', 'GAT', 'GAC', 'GAA', 'GAG',\n","          'GGT', 'GGC', 'GGA', 'GGG', '___']\n","\n","codons_to_integer = dict((c, i) for i, c in enumerate(codons))\n","integer_to_codons = dict((i, c) for i, c in enumerate(codons))"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14935,"status":"ok","timestamp":1715688695565,"user":{"displayName":"Insa Belter","userId":"09408038895575287386"},"user_tz":-120},"id":"8w1wA5dDQ7Zt","outputId":"f67d1129-17d1-4a11-f6b0-83a4f973ba75"},"outputs":[{"output_type":"stream","name":"stdout","text":["Länge train_dataset: 3561\n","Länge test_dataset: 864\n"]}],"source":["organism = \"E.Coli\"\n","min_length = None\n","max_length = 500\n","\n","train_dataset = ml_helper.CodonDataset(organism, \"train\", min_length, max_length, cut_data=True, one_hot_aa=False, data_path=data_path, device=device)\n","print(f\"Länge train_dataset: {len(train_dataset)}\")\n","test_dataset = ml_helper.CodonDataset(organism, \"test\", min_length, max_length, cut_data=True, one_hot_aa=False, data_path=data_path, device=device)\n","print(f\"Länge test_dataset: {len(test_dataset)}\")"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":369,"status":"ok","timestamp":1715688695930,"user":{"displayName":"Insa Belter","userId":"09408038895575287386"},"user_tz":-120},"id":"TDq7AeaFQ7Zv","outputId":"1b96196c-89a7-4031-b63e-6a9358f7aa09"},"outputs":[{"output_type":"stream","name":"stdout","text":["(tensor([12, 16, 18,  0, 19,  6, 13,  3,  2, 19, 15,  1, 10, 18,  7,  3, 19,  1,\n","         0, 19,  3,  7, 19, 15,  9,  0,  9, 11,  3,  7,  6, 13, 13, 15, 12, 10,\n","         7, 14, 15,  7, 15,  7, 11, 16, 16,  4, 10,  1, 10,  9,  0,  7, 13,  6,\n","         5, 10, 15,  7,  7,  0,  9, 15,  9, 13,  7, 11, 14,  0, 15,  2, 10, 14,\n","        14, 17,  6,  1,  3, 19,  2, 16, 19, 13,  5,  3, 18,  0, 10, 13, 14,  8,\n","        12, 15,  9, 10,  3,  2, 19,  0, 18,  7, 10, 12, 19, 11,  7, 19,  2, 11,\n","        11,  5,  1,  8,  0, 12,  0,  5,  6,  0, 10,  6, 11, 19,  0, 10,  7, 13,\n","        19,  8,  5,  1, 11, 14, 15,  5, 10, 15,  7,  7,  5,  1,  5,  1, 19,  0,\n","         9,  0,  1,  0, 10, 19,  2,  6, 14,  1, 19, 10, 10, 10,  3,  6, 14, 10,\n","         7,  0, 10,  3, 10, 11, 10,  1,  6,  5, 12,  5, 10,  6, 10, 11, 11, 10,\n","         5,  5, 15, 10,  7,  9, 16, 13,  9, 13, 19, 16,  8,  3,  5,  7,  6,  0,\n","        10, 15, 12, 15,  3,  1, 19,  0, 19, 13,  2,  2,  7,  1,  9,  6,  5, 19,\n","         3, 15, 14,  1,  3, 10, 18, 12,  1, 14,  1, 16, 14, 13, 19,  0,  7, 13,\n","        19,  7, 16, 15,  2, 19, 13,  3,  7, 10, 12,  0,  6, 11, 10,  4,  7, 12,\n","        16,  7, 15, 13,  0, 10,  1, 14,  6,  8,  9,  1, 10,  2, 16, 14,  7,  6,\n","        10,  5,  0,  2,  7, 16,  9,  5,  0, 19,  5, 18,  5,  7,  0,  0, 16,  1,\n","        13,  6, 10, 11, 10,  2,  7,  7,  6, 11, 10, 10, 19, 15,  5,  0,  2, 12,\n","        16,  7,  6,  6, 10, 14,  0, 16, 10, 16, 14,  7,  5,  5, 19, 12, 19, 15,\n","        17, 15,  1,  3, 19, 12, 19, 14, 10, 19,  6,  6,  1, 20, 21, 21, 21, 21,\n","        21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21,\n","        21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21,\n","        21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21,\n","        21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21,\n","        21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21,\n","        21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21,\n","        21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21,\n","        21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21,\n","        21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21],\n","       device='cuda:0', dtype=torch.int32), tensor([35., 39.,  9., 54., 51., 59.,  0., 57., 41., 49.,  7., 31.,  3.,  9.,\n","        60., 57., 51., 29., 54., 50., 56., 61., 49., 44., 32., 55., 34., 42.,\n","        56., 60., 59.,  1.,  1.,  4., 35., 19., 63., 23.,  5., 61.,  5., 61.,\n","        42., 37., 37., 13., 19., 29., 19., 32., 52., 61.,  1., 58., 27., 16.,\n","         5., 61., 63., 52., 33.,  4., 33.,  0., 60., 42., 21., 53., 45., 40.,\n","        19., 22., 23., 15., 59., 31., 57., 51., 40., 36., 49.,  0., 27., 57.,\n","         9., 55., 18.,  0., 23., 24., 35.,  7., 32., 16., 57., 40., 49., 53.,\n","         8., 63., 19., 35., 49., 42., 61., 51., 40., 42., 43., 27., 31., 25.,\n","        54., 35., 55., 26., 59., 55., 19., 59., 42., 51., 55.,  3., 63.,  0.,\n","        50., 24., 26., 28., 42., 23.,  6., 26., 16.,  4., 60., 60., 27., 29.,\n","        27., 31., 48., 52., 33., 53., 46., 54.,  3., 51., 40., 58., 23., 29.,\n","        50.,  3., 19.,  3., 56., 58., 23., 17., 61., 54., 19., 56., 17., 42.,\n","         3., 28., 59., 27., 35., 27., 19., 58., 19., 42., 42., 19., 26., 27.,\n","         4., 17., 60., 33., 36.,  0., 33.,  1., 48., 37., 25., 56., 27., 61.,\n","        58., 55.,  2.,  7., 35.,  5., 56., 28., 51., 55., 48.,  1., 40., 40.,\n","        62., 29., 32., 59., 27., 49., 56.,  5., 23., 29., 56., 17.,  8., 35.,\n","        29., 23., 29., 39., 23.,  0., 48., 53., 63.,  1., 48., 60., 38.,  7.,\n","        40., 48.,  0., 56., 62., 19., 35., 54., 59., 42., 16., 12., 61., 35.,\n","        39., 62., 45.,  1., 53., 19., 30., 23., 58., 24., 33., 29., 17., 41.,\n","        37., 20., 60., 58., 19., 27., 53., 40., 61., 39., 33., 27., 55., 51.,\n","        26.,  8., 27., 61., 55., 54., 36., 28.,  0., 58., 19., 42.,  3., 41.,\n","        61., 60., 58., 42., 19., 16., 51., 44., 27., 53., 40., 35., 38., 61.,\n","        58., 58., 19., 20., 53., 39., 17., 39., 21., 62., 26., 27., 51., 35.,\n","        48.,  5., 15.,  7., 28., 56., 51., 35., 51., 23., 19., 48., 59., 59.,\n","        47., 14., 64., 64., 64., 64., 64., 64., 64., 64., 64., 64., 64., 64.,\n","        64., 64., 64., 64., 64., 64., 64., 64., 64., 64., 64., 64., 64., 64.,\n","        64., 64., 64., 64., 64., 64., 64., 64., 64., 64., 64., 64., 64., 64.,\n","        64., 64., 64., 64., 64., 64., 64., 64., 64., 64., 64., 64., 64., 64.,\n","        64., 64., 64., 64., 64., 64., 64., 64., 64., 64., 64., 64., 64., 64.,\n","        64., 64., 64., 64., 64., 64., 64., 64., 64., 64., 64., 64., 64., 64.,\n","        64., 64., 64., 64., 64., 64., 64., 64., 64., 64., 64., 64., 64., 64.,\n","        64., 64., 64., 64., 64., 64., 64., 64., 64., 64., 64., 64., 64., 64.,\n","        64., 64., 64., 64., 64., 64., 64., 64., 64., 64., 64., 64., 64., 64.,\n","        64., 64., 64., 64., 64., 64., 64., 64., 64., 64., 64., 64., 64., 64.,\n","        64., 64., 64., 64., 64., 64., 64., 64., 64., 64., 64., 64., 64., 64.,\n","        64., 64., 64., 64., 64., 64., 64., 64., 64., 64.], device='cuda:0'))\n","torch.Size([500])\n","torch.Size([500])\n"]}],"source":["print(train_dataset[3])\n","print(train_dataset[3][0].shape)\n","print(train_dataset[3][1].shape)"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1715688695930,"user":{"displayName":"Insa Belter","userId":"09408038895575287386"},"user_tz":-120},"id":"MQvx476IQ7Zw"},"outputs":[],"source":["BATCH_SIZE = 32\n","train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n","test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"]},{"cell_type":"markdown","metadata":{"id":"6UP5EBpZQ7Zx"},"source":["## Define the encoder-only model"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":272,"status":"ok","timestamp":1715688700989,"user":{"displayName":"Insa Belter","userId":"09408038895575287386"},"user_tz":-120},"id":"DmAoTz7sQ7Zx"},"outputs":[],"source":["class EncoderClassifier(nn.Module):\n","    def __init__(self, embed_dim, num_layers, num_heads):\n","        super(EncoderClassifier, self).__init__()\n","\n","        self.emb = nn.Embedding(len(amino_acids), embed_dim, padding_idx=len(amino_acids)-1)\n","        self.encoder_layer = nn.TransformerEncoderLayer(\n","            d_model=embed_dim,\n","            nhead=num_heads,\n","            batch_first=True\n","        )\n","        self.encoder = nn.TransformerEncoder(\n","            encoder_layer=self.encoder_layer,\n","            num_layers=num_layers,\n","        )\n","        self.linear = nn.Linear(embed_dim, len(codons))\n","        self.dropout = nn.Dropout(0.2)\n","\n","    def forward(self, x):\n","        x = x.long()\n","        x = self.emb(x)\n","        x = self.encoder(x)\n","        x = self.dropout(x)\n","        out = self.linear(x)\n","        return out"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1715688701504,"user":{"displayName":"Insa Belter","userId":"09408038895575287386"},"user_tz":-120},"id":"2u2Dbb0rQ7Zy"},"outputs":[],"source":["EMBED_DIM = 256\n","NUM_ENCODER_LAYERS = 3\n","NUM_HEADS = 4"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1715688702540,"user":{"displayName":"Insa Belter","userId":"09408038895575287386"},"user_tz":-120},"id":"33ksA3YLQ7Zy","outputId":"559e6f1f-4377-402d-fe71-a0adf4a7a70f"},"outputs":[{"output_type":"stream","name":"stdout","text":["EncoderClassifier(\n","  (emb): Embedding(22, 256, padding_idx=21)\n","  (encoder_layer): TransformerEncoderLayer(\n","    (self_attn): MultiheadAttention(\n","      (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n","    )\n","    (linear1): Linear(in_features=256, out_features=2048, bias=True)\n","    (dropout): Dropout(p=0.1, inplace=False)\n","    (linear2): Linear(in_features=2048, out_features=256, bias=True)\n","    (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","    (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","    (dropout1): Dropout(p=0.1, inplace=False)\n","    (dropout2): Dropout(p=0.1, inplace=False)\n","  )\n","  (encoder): TransformerEncoder(\n","    (layers): ModuleList(\n","      (0-2): 3 x TransformerEncoderLayer(\n","        (self_attn): MultiheadAttention(\n","          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n","        )\n","        (linear1): Linear(in_features=256, out_features=2048, bias=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","        (linear2): Linear(in_features=2048, out_features=256, bias=True)\n","        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","        (dropout1): Dropout(p=0.1, inplace=False)\n","        (dropout2): Dropout(p=0.1, inplace=False)\n","      )\n","    )\n","  )\n","  (linear): Linear(in_features=256, out_features=65, bias=True)\n","  (dropout): Dropout(p=0.2, inplace=False)\n",")\n"]}],"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","model = EncoderClassifier(\n","    embed_dim=EMBED_DIM,\n","    num_layers=NUM_ENCODER_LAYERS,\n","    num_heads=NUM_HEADS\n",").to(device)\n","print(model)"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1715688702799,"user":{"displayName":"Insa Belter","userId":"09408038895575287386"},"user_tz":-120},"id":"DLRNk1mnQ7Zz"},"outputs":[],"source":["# Total parameters and trainable parameters.\n","def print_parameters(model):\n","    total_params = sum(p.numel() for p in model.parameters())\n","    print(f\"{total_params:,} total parameters.\")\n","    total_trainable_params = sum(\n","        p.numel() for p in model.parameters() if p.requires_grad)\n","    print(f\"{total_trainable_params:,} training parameters.\")"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1715688703433,"user":{"displayName":"Insa Belter","userId":"09408038895575287386"},"user_tz":-120},"id":"Ua_2VN3NQ7Zz","outputId":"472c69d7-94cb-40cd-bd7e-8e1e75c00415"},"outputs":[{"output_type":"stream","name":"stdout","text":["5,282,625 total parameters.\n","5,282,625 training parameters.\n"]}],"source":["print_parameters(model)"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1715688704233,"user":{"displayName":"Insa Belter","userId":"09408038895575287386"},"user_tz":-120},"id":"6SEl0FSxQ7Zz"},"outputs":[],"source":["def test_forward_pass(model, data_loader):\n","  batch_data, batch_label = next(iter(data_loader))\n","  print(f\"input dim: {batch_data.shape}\")\n","  output = model(batch_data)\n","  print(f\"output dim: {output.shape}\")"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1152,"status":"ok","timestamp":1715688705880,"user":{"displayName":"Insa Belter","userId":"09408038895575287386"},"user_tz":-120},"id":"X9OgGtB6Q7Z0","outputId":"52e399fa-b185-4c52-c314-91c772f4e98f"},"outputs":[{"output_type":"stream","name":"stdout","text":["input dim: torch.Size([32, 500])\n","output dim: torch.Size([32, 500, 65])\n"]}],"source":["test_forward_pass(model, train_loader)"]},{"cell_type":"markdown","metadata":{"id":"6DIXDxybQ7Z0"},"source":["## Define the training methods"]},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1715688705880,"user":{"displayName":"Insa Belter","userId":"09408038895575287386"},"user_tz":-120},"id":"B8_PCftyQ7Z0"},"outputs":[],"source":["def train_model(model, optimizer, criterion, num_epochs, print_batches=0):\n","    for epoch in range(num_epochs):\n","        model.train()\n","\n","        epoch_start_time = time.time()\n","        batch_start_time = time.time()\n","        epoch_loss = 0\n","        for batch_idx, batch in enumerate(train_loader):\n","            # Clear gradients\n","            optimizer.zero_grad()\n","\n","            # Forward pass\n","            input_data, labels = batch\n","\n","            output = model(input_data)  # (batch_size, seq_len, num_classes)\n","            output = output.view(-1, len(codons)) # (batch_size * seq_len, num_classes)\n","\n","            labels = labels.view(-1).long() # (batch_size, seq_len) -> (batch_size * seq_len)\n","\n","            # Calculate loss\n","            loss = criterion(output, labels)\n","            epoch_loss += loss.item()\n","\n","            # Backward pass\n","            loss.backward()\n","\n","            # Update model parameters\n","            optimizer.step()\n","\n","            if print_batches != 0 and batch_idx % print_batches == (print_batches-1):\n","                batch_time =  round(time.time() - batch_start_time,2)\n","                print(f'Batch [{batch_idx+1}/{len(train_loader)}], Loss: {loss.item():.4f}, Time since last batch print: {batch_time} s')\n","                batch_start_time = time.time()\n","\n","        epoch_time = round(time.time() - epoch_start_time,2)\n","        epoch_loss = round(epoch_loss / len(train_loader),4)\n","        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss}, Took {epoch_time} s')"]},{"cell_type":"markdown","metadata":{"id":"zXx3COjlQ7Z1"},"source":["## Define the evaluation methods to calculate metrics"]},{"cell_type":"code","execution_count":47,"metadata":{"executionInfo":{"elapsed":252,"status":"ok","timestamp":1715689686587,"user":{"displayName":"Insa Belter","userId":"09408038895575287386"},"user_tz":-120},"id":"hnUdxk_OQ7Z1"},"outputs":[],"source":["from sklearn.metrics import accuracy_score\n","\n","def compute_accuracy(predictions, labels):\n","    predictions = np.argmax(predictions, axis=1)\n","\n","    # Find indices where labels are not equal to the padding value\n","    non_padding_indices = labels != codons_to_integer['___']\n","\n","    # Filter out predictions and labels where the label is not padding\n","    filtered_predictions = predictions[non_padding_indices]\n","    filtered_labels = labels[non_padding_indices]\n","\n","    acc = accuracy_score(labels, predictions)\n","    return acc"]},{"cell_type":"code","execution_count":38,"metadata":{"executionInfo":{"elapsed":259,"status":"ok","timestamp":1715689274929,"user":{"displayName":"Insa Belter","userId":"09408038895575287386"},"user_tz":-120},"id":"GyHA89BhQ7Z1"},"outputs":[],"source":["def evaluate_model(model, criterion):\n","    model.eval()  # Set the model to evaluation mode\n","\n","    total_loss = 0.0\n","\n","    with torch.no_grad():\n","        accuracies = []\n","        for batch_idx, batch in enumerate(test_loader):\n","             # Forward pass\n","            input_data, labels = batch\n","\n","            output = model(input_data)  # (batch_size, seq_len, num_classes)\n","            output = output.view(-1, len(codons)) # (batch_size * seq_len, num_classes)\n","\n","            labels = labels.view(-1).long() # (batch_size, seq_len) -> (batch_size * seq_len)\n","\n","            # Calculate loss\n","            loss = criterion(output, labels)\n","\n","            # Compute total loss\n","            total_loss += loss.item()\n","\n","            # Compute custom metrics\n","            accuracy = compute_accuracy(output.cpu(), labels.cpu())\n","            accuracies.append(accuracy)\n","\n","    # Compute average loss\n","    avg_loss = total_loss / len(test_loader)\n","\n","    # Compute average accuracy\n","    avg_accuracy = np.mean(accuracies)\n","\n","    print(f'Average Loss: {avg_loss:.4f}')\n","    print(f'Average Accuracy: {avg_accuracy:.4f}')\n","\n","    return output, labels"]},{"cell_type":"markdown","metadata":{"id":"w60mTX5nQ7Z1"},"source":["## Training the model"]},{"cell_type":"code","execution_count":32,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1715688892531,"user":{"displayName":"Insa Belter","userId":"09408038895575287386"},"user_tz":-120},"id":"Vr8Ge8QYQ7Z2"},"outputs":[],"source":["EMBED_DIM = 256\n","NUM_ENCODER_LAYERS = 4\n","NUM_HEADS = 4"]},{"cell_type":"code","execution_count":33,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":452,"status":"ok","timestamp":1715688894105,"user":{"displayName":"Insa Belter","userId":"09408038895575287386"},"user_tz":-120},"id":"8G-AucPcQ7Z2","outputId":"8483db98-2a68-47ee-eaa2-b7d3c55e90f7"},"outputs":[{"output_type":"stream","name":"stdout","text":["6,597,697 total parameters.\n","6,597,697 training parameters.\n"]}],"source":["model = EncoderClassifier(\n","    embed_dim=EMBED_DIM,\n","    num_layers=NUM_ENCODER_LAYERS,\n","    num_heads=NUM_HEADS\n",").to(device)\n","print_parameters(model)"]},{"cell_type":"code","execution_count":34,"metadata":{"id":"fAaxt51-AqMN","executionInfo":{"status":"ok","timestamp":1715688895757,"user_tz":-120,"elapsed":262,"user":{"displayName":"Insa Belter","userId":"09408038895575287386"}}},"outputs":[],"source":["criterion = torch.nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters())"]},{"cell_type":"code","execution_count":35,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":284046,"status":"ok","timestamp":1715689181251,"user":{"displayName":"Insa Belter","userId":"09408038895575287386"},"user_tz":-120},"id":"9XnDMsIPQ7Z2","outputId":"7a1150c4-80cb-4058-df6e-8021a7e9c16f"},"outputs":[{"output_type":"stream","name":"stdout","text":["----- Start Training -----\n","Epoch [1/10], Loss: 0.7352, Took 28.89 s\n","Epoch [2/10], Loss: 0.5723, Took 28.76 s\n","Epoch [3/10], Loss: 0.5681, Took 27.95 s\n","Epoch [4/10], Loss: 0.5636, Took 28.3 s\n","Epoch [5/10], Loss: 0.5621, Took 28.43 s\n","Epoch [6/10], Loss: 0.5599, Took 28.24 s\n","Epoch [7/10], Loss: 0.5607, Took 28.25 s\n","Epoch [8/10], Loss: 0.5596, Took 28.31 s\n","Epoch [9/10], Loss: 0.5611, Took 28.35 s\n","Epoch [10/10], Loss: 0.5595, Took 28.32 s\n"]}],"source":["EPOCHS = 10\n","print(\"----- Start Training -----\")\n","train_model(model, optimizer, criterion, EPOCHS)"]},{"cell_type":"code","execution_count":36,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":365,"status":"ok","timestamp":1715689185291,"user":{"displayName":"Insa Belter","userId":"09408038895575287386"},"user_tz":-120},"id":"t1RXs8WBQ7Z2","outputId":"8be68388-5953-4aa2-afb1-c8684298c8d8"},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([32, 500, 65])\n"]}],"source":["batch_data, batch_label = next(iter(train_loader))\n","output = model(batch_data)\n","print(output.shape)"]},{"cell_type":"code","execution_count":37,"metadata":{"executionInfo":{"elapsed":2462,"status":"ok","timestamp":1715689192249,"user":{"displayName":"Insa Belter","userId":"09408038895575287386"},"user_tz":-120},"id":"_-HYTiRpY_o1"},"outputs":[],"source":[" torch.save(model.state_dict(), data_path+\"/encoder_256_4_4_10e.pkl\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":337,"status":"ok","timestamp":1715426646972,"user":{"displayName":"Insa Belter","userId":"09408038895575287386"},"user_tz":-120},"id":"BQQaJPfuZOzE","outputId":"19b8b28e-1b1d-4c54-d721-e38f9b92756c"},"outputs":[{"data":{"text/plain":["<All keys matched successfully>"]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":["model = EncoderClassifier(\n","    embed_dim=EMBED_DIM,\n","    num_layers=NUM_ENCODER_LAYERS,\n","    num_heads=NUM_HEADS\n",").to(device)\n","model.load_state_dict(torch.load(data_path+\"/encoder_256_4_4_10e.pkl\", map_location=device))"]},{"cell_type":"code","execution_count":48,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2348,"status":"ok","timestamp":1715689692684,"user":{"displayName":"Insa Belter","userId":"09408038895575287386"},"user_tz":-120},"id":"mnUwIS93Q7Z3","outputId":"153d5f25-9fd0-4a3c-a428-a8c689ab2bfd"},"outputs":[{"output_type":"stream","name":"stdout","text":["Average Loss: 0.5520\n","Average Accuracy: 0.7447\n"]},{"output_type":"execute_result","data":{"text/plain":["(tensor([[ 0.5397,  0.3644,  0.0784,  ..., -0.2049, -0.1571, -0.3564],\n","         [-1.0555, -0.9793, -0.9321,  ..., -0.5827, -0.2546,  0.6944],\n","         [-0.3606, -0.4771, -0.6952,  ..., -0.3903, -0.7320, -0.0236],\n","         ...,\n","         [-1.6050, -1.3830, -1.3978,  ..., -2.0612, -1.8123, 12.6611],\n","         [-1.6050, -1.3830, -1.3978,  ..., -2.0612, -1.8123, 12.6611],\n","         [-1.6050, -1.3830, -1.3978,  ..., -2.0612, -1.8123, 12.6611]],\n","        device='cuda:0'),\n"," tensor([35, 52, 40,  ..., 64, 64, 64], device='cuda:0'))"]},"metadata":{},"execution_count":48}],"source":["evaluate_model(model, criterion)"]},{"cell_type":"code","source":[],"metadata":{"id":"Fif3pd5cDOOU"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":0}