{"cells":[{"cell_type":"markdown","metadata":{"id":"dvibukPbQ7Zg"},"source":["# Encoder-only Transformer Architektur"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20842,"status":"ok","timestamp":1715688662385,"user":{"displayName":"Insa Belter","userId":"09408038895575287386"},"user_tz":-120},"id":"fXeUV5wCRtUz","outputId":"2bb0af2b-b2a5-4f6e-c9d6-addcb643a568"},"outputs":[],"source":["#from google.colab import drive\n","#drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8804,"status":"ok","timestamp":1715688671184,"user":{"displayName":"Insa Belter","userId":"09408038895575287386"},"user_tz":-120},"id":"3yudZ4edSJEQ","outputId":"d4151a0c-b418-4144-d13b-0f4aef17b8a7"},"outputs":[{"name":"stdout","output_type":"stream","text":["Defaulting to user installation because normal site-packages is not writeable\n","Requirement already satisfied: biopython in /home/mkuehn/.local/lib/python3.10/site-packages (1.83)\n","Requirement already satisfied: numpy in /home/mkuehn/.local/lib/python3.10/site-packages (from biopython) (1.26.4)\n"]}],"source":["!pip install biopython"]},{"cell_type":"code","execution_count":19,"metadata":{"executionInfo":{"elapsed":5081,"status":"ok","timestamp":1715688676256,"user":{"displayName":"Insa Belter","userId":"09408038895575287386"},"user_tz":-120},"id":"ev_KN7VqQ7Zm"},"outputs":[{"name":"stdout","output_type":"stream","text":["The autoreload extension is already loaded. To reload it, use:\n","  %reload_ext autoreload\n"]}],"source":["%load_ext autoreload\n","%autoreload\n","\n","import sys\n","import torch\n","from torch.utils.data import DataLoader\n","\n","sys.path.append('../scripts')\n","#sys.path.append('/content/drive/MyDrive/PMDS/Notebooks')\n","import ml_helper as mlh\n","import encoder as e"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1715688676256,"user":{"displayName":"Insa Belter","userId":"09408038895575287386"},"user_tz":-120},"id":"9eRDLHmaS7Im"},"outputs":[],"source":["#data_path = '/content/drive/MyDrive/PMDS/Data'\n","data_path = '../data'"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":566,"status":"ok","timestamp":1715688676819,"user":{"displayName":"Insa Belter","userId":"09408038895575287386"},"user_tz":-120},"id":"5hFAHJ8hRE8p","outputId":"6c9d739b-7b72-447c-878a-a0291901b15d"},"outputs":[{"name":"stdout","output_type":"stream","text":["cuda:1\n"]}],"source":["device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n","print(device)"]},{"cell_type":"markdown","metadata":{"id":"6UP5EBpZQ7Zx"},"source":["## Define the encoder-only model"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Länge train_dataset: 3555\n","Länge valid_dataset: 420\n"]}],"source":["e.load_train_valid_data(\"E.Coli\")"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1715688701504,"user":{"displayName":"Insa Belter","userId":"09408038895575287386"},"user_tz":-120},"id":"2u2Dbb0rQ7Zy"},"outputs":[],"source":["EMBED_DIM = 256\n","NUM_ENCODER_LAYERS = 4\n","NUM_HEADS = 4\n","DROP_OUT = 0.2"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1715688702540,"user":{"displayName":"Insa Belter","userId":"09408038895575287386"},"user_tz":-120},"id":"33ksA3YLQ7Zy","outputId":"559e6f1f-4377-402d-fe71-a0adf4a7a70f"},"outputs":[{"name":"stdout","output_type":"stream","text":["EncoderClassifier(\n","  (emb): Embedding(22, 256, padding_idx=21)\n","  (pos_encoder): PositionalEncoding(\n","    (dropout): Dropout(p=0.2, inplace=False)\n","  )\n","  (encoder_layer): TransformerEncoderLayer(\n","    (self_attn): MultiheadAttention(\n","      (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n","    )\n","    (linear1): Linear(in_features=256, out_features=2048, bias=True)\n","    (dropout): Dropout(p=0.1, inplace=False)\n","    (linear2): Linear(in_features=2048, out_features=256, bias=True)\n","    (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","    (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","    (dropout1): Dropout(p=0.1, inplace=False)\n","    (dropout2): Dropout(p=0.1, inplace=False)\n","  )\n","  (encoder): TransformerEncoder(\n","    (layers): ModuleList(\n","      (0-3): 4 x TransformerEncoderLayer(\n","        (self_attn): MultiheadAttention(\n","          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n","        )\n","        (linear1): Linear(in_features=256, out_features=2048, bias=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","        (linear2): Linear(in_features=2048, out_features=256, bias=True)\n","        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","        (dropout1): Dropout(p=0.1, inplace=False)\n","        (dropout2): Dropout(p=0.1, inplace=False)\n","      )\n","    )\n","  )\n","  (linear): Linear(in_features=256, out_features=65, bias=True)\n","  (dropout): Dropout(p=0.2, inplace=False)\n",")\n"]}],"source":["model = e.EncoderClassifier(\n","    embed_dim=EMBED_DIM,\n","    num_layers=NUM_ENCODER_LAYERS,\n","    num_heads=NUM_HEADS,\n","    dropout=DROP_OUT,\n","    pos_enc=True\n",").to(device)\n","print(model)"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1715688702799,"user":{"displayName":"Insa Belter","userId":"09408038895575287386"},"user_tz":-120},"id":"DLRNk1mnQ7Zz"},"outputs":[],"source":["# Total parameters and trainable parameters.\n","def print_parameters(model):\n","    total_params = sum(p.numel() for p in model.parameters())\n","    print(f\"{total_params:,} total parameters.\")\n","    total_trainable_params = sum(\n","        p.numel() for p in model.parameters() if p.requires_grad)\n","    print(f\"{total_trainable_params:,} training parameters.\")"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1715688703433,"user":{"displayName":"Insa Belter","userId":"09408038895575287386"},"user_tz":-120},"id":"Ua_2VN3NQ7Zz","outputId":"472c69d7-94cb-40cd-bd7e-8e1e75c00415"},"outputs":[{"name":"stdout","output_type":"stream","text":["6,597,697 total parameters.\n","6,597,697 training parameters.\n"]}],"source":["print_parameters(model)"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1715688704233,"user":{"displayName":"Insa Belter","userId":"09408038895575287386"},"user_tz":-120},"id":"6SEl0FSxQ7Zz"},"outputs":[],"source":["def test_forward_pass(model, data_loader):\n","  batch_data, batch_label = next(iter(data_loader))\n","  print(f\"input dim: {batch_data.shape}\")\n","  output, attn_weights = model(batch_data, attn_weights_needed=True)\n","  output = model(batch_data)\n","  print(f\"output dim: {output.shape}\")\n","  print(f\"attn_weights dim: {attn_weights}\")"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1152,"status":"ok","timestamp":1715688705880,"user":{"displayName":"Insa Belter","userId":"09408038895575287386"},"user_tz":-120},"id":"X9OgGtB6Q7Z0","outputId":"52e399fa-b185-4c52-c314-91c772f4e98f"},"outputs":[{"name":"stdout","output_type":"stream","text":["input dim: torch.Size([32, 500])\n","output dim: torch.Size([32, 500, 65])\n","attn_weights dim: [tensor([[[[0.0000, 0.0010, 0.0004,  ..., 0.0000, 0.0014, 0.0017],\n","          [0.0015, 0.0000, 0.0020,  ..., 0.0013, 0.0015, 0.0021],\n","          [0.0013, 0.0014, 0.0009,  ..., 0.0011, 0.0008, 0.0019],\n","          ...,\n","          [0.0022, 0.0020, 0.0012,  ..., 0.0023, 0.0023, 0.0024],\n","          [0.0023, 0.0000, 0.0019,  ..., 0.0022, 0.0025, 0.0026],\n","          [0.0024, 0.0016, 0.0000,  ..., 0.0027, 0.0029, 0.0034]],\n","\n","         [[0.0023, 0.0030, 0.0039,  ..., 0.0025, 0.0016, 0.0018],\n","          [0.0018, 0.0227, 0.0129,  ..., 0.0026, 0.0030, 0.0024],\n","          [0.0019, 0.0000, 0.0000,  ..., 0.0000, 0.0032, 0.0018],\n","          ...,\n","          [0.0011, 0.0037, 0.0030,  ..., 0.0028, 0.0026, 0.0000],\n","          [0.0010, 0.0050, 0.0030,  ..., 0.0023, 0.0020, 0.0024],\n","          [0.0015, 0.0028, 0.0014,  ..., 0.0028, 0.0018, 0.0023]],\n","\n","         [[0.0026, 0.0013, 0.0000,  ..., 0.0010, 0.0016, 0.0000],\n","          [0.0011, 0.0028, 0.0032,  ..., 0.0011, 0.0010, 0.0010],\n","          [0.0011, 0.0014, 0.0013,  ..., 0.0018, 0.0018, 0.0018],\n","          ...,\n","          [0.0029, 0.0012, 0.0020,  ..., 0.0011, 0.0013, 0.0014],\n","          [0.0027, 0.0015, 0.0021,  ..., 0.0015, 0.0016, 0.0021],\n","          [0.0022, 0.0012, 0.0000,  ..., 0.0011, 0.0013, 0.0017]],\n","\n","         [[0.0023, 0.0009, 0.0008,  ..., 0.0014, 0.0026, 0.0016],\n","          [0.0007, 0.0004, 0.0005,  ..., 0.0011, 0.0016, 0.0019],\n","          [0.0006, 0.0000, 0.0007,  ..., 0.0018, 0.0025, 0.0029],\n","          ...,\n","          [0.0044, 0.0028, 0.0014,  ..., 0.0000, 0.0031, 0.0028],\n","          [0.0025, 0.0046, 0.0026,  ..., 0.0016, 0.0023, 0.0020],\n","          [0.0019, 0.0026, 0.0013,  ..., 0.0000, 0.0029, 0.0023]]],\n","\n","\n","        [[[0.0026, 0.0013, 0.0022,  ..., 0.0016, 0.0021, 0.0023],\n","          [0.0006, 0.0079, 0.0012,  ..., 0.0005, 0.0016, 0.0024],\n","          [0.0035, 0.0044, 0.0010,  ..., 0.0019, 0.0018, 0.0032],\n","          ...,\n","          [0.0017, 0.0021, 0.0000,  ..., 0.0000, 0.0017, 0.0020],\n","          [0.0023, 0.0024, 0.0051,  ..., 0.0022, 0.0028, 0.0027],\n","          [0.0026, 0.0044, 0.0031,  ..., 0.0019, 0.0029, 0.0031]],\n","\n","         [[0.0010, 0.0069, 0.0015,  ..., 0.0032, 0.0026, 0.0022],\n","          [0.0029, 0.0044, 0.0013,  ..., 0.0019, 0.0025, 0.0000],\n","          [0.0010, 0.0024, 0.0027,  ..., 0.0019, 0.0040, 0.0034],\n","          ...,\n","          [0.0014, 0.0035, 0.0000,  ..., 0.0000, 0.0024, 0.0021],\n","          [0.0019, 0.0040, 0.0038,  ..., 0.0021, 0.0000, 0.0021],\n","          [0.0009, 0.0028, 0.0038,  ..., 0.0014, 0.0019, 0.0017]],\n","\n","         [[0.0044, 0.0121, 0.0011,  ..., 0.0012, 0.0032, 0.0024],\n","          [0.0000, 0.0000, 0.0004,  ..., 0.0018, 0.0027, 0.0025],\n","          [0.0000, 0.0054, 0.0017,  ..., 0.0012, 0.0015, 0.0020],\n","          ...,\n","          [0.0045, 0.0046, 0.0023,  ..., 0.0014, 0.0016, 0.0000],\n","          [0.0024, 0.0041, 0.0011,  ..., 0.0014, 0.0000, 0.0000],\n","          [0.0031, 0.0031, 0.0025,  ..., 0.0000, 0.0000, 0.0021]],\n","\n","         [[0.0015, 0.0052, 0.0011,  ..., 0.0028, 0.0025, 0.0018],\n","          [0.0010, 0.0003, 0.0000,  ..., 0.0017, 0.0012, 0.0009],\n","          [0.0025, 0.0010, 0.0017,  ..., 0.0033, 0.0039, 0.0036],\n","          ...,\n","          [0.0024, 0.0018, 0.0010,  ..., 0.0017, 0.0024, 0.0022],\n","          [0.0000, 0.0009, 0.0009,  ..., 0.0022, 0.0000, 0.0019],\n","          [0.0024, 0.0012, 0.0011,  ..., 0.0018, 0.0019, 0.0017]]],\n","\n","\n","        [[[0.0022, 0.0000, 0.0011,  ..., 0.0013, 0.0015, 0.0020],\n","          [0.0005, 0.0208, 0.0011,  ..., 0.0010, 0.0010, 0.0015],\n","          [0.0016, 0.0062, 0.0064,  ..., 0.0029, 0.0000, 0.0019],\n","          ...,\n","          [0.0039, 0.0028, 0.0037,  ..., 0.0023, 0.0023, 0.0031],\n","          [0.0028, 0.0032, 0.0042,  ..., 0.0025, 0.0023, 0.0000],\n","          [0.0026, 0.0025, 0.0040,  ..., 0.0024, 0.0021, 0.0030]],\n","\n","         [[0.0042, 0.0008, 0.0023,  ..., 0.0028, 0.0021, 0.0029],\n","          [0.0031, 0.0017, 0.0010,  ..., 0.0025, 0.0023, 0.0030],\n","          [0.0077, 0.0045, 0.0064,  ..., 0.0015, 0.0015, 0.0011],\n","          ...,\n","          [0.0011, 0.0035, 0.0005,  ..., 0.0021, 0.0021, 0.0022],\n","          [0.0013, 0.0034, 0.0007,  ..., 0.0022, 0.0023, 0.0025],\n","          [0.0017, 0.0034, 0.0008,  ..., 0.0022, 0.0023, 0.0026]],\n","\n","         [[0.0038, 0.0115, 0.0020,  ..., 0.0023, 0.0000, 0.0033],\n","          [0.0023, 0.0031, 0.0003,  ..., 0.0018, 0.0015, 0.0000],\n","          [0.0008, 0.0059, 0.0000,  ..., 0.0010, 0.0008, 0.0008],\n","          ...,\n","          [0.0012, 0.0030, 0.0015,  ..., 0.0015, 0.0012, 0.0019],\n","          [0.0015, 0.0000, 0.0010,  ..., 0.0018, 0.0015, 0.0019],\n","          [0.0016, 0.0011, 0.0008,  ..., 0.0015, 0.0011, 0.0017]],\n","\n","         [[0.0022, 0.0033, 0.0021,  ..., 0.0014, 0.0000, 0.0025],\n","          [0.0179, 0.0005, 0.0027,  ..., 0.0000, 0.0019, 0.0013],\n","          [0.0000, 0.0032, 0.0048,  ..., 0.0023, 0.0017, 0.0016],\n","          ...,\n","          [0.0044, 0.0021, 0.0022,  ..., 0.0021, 0.0019, 0.0022],\n","          [0.0026, 0.0000, 0.0011,  ..., 0.0014, 0.0015, 0.0013],\n","          [0.0022, 0.0009, 0.0013,  ..., 0.0013, 0.0016, 0.0015]]],\n","\n","\n","        ...,\n","\n","\n","        [[[0.0057, 0.0015, 0.0007,  ..., 0.0004, 0.0012, 0.0005],\n","          [0.0026, 0.0013, 0.0034,  ..., 0.0010, 0.0020, 0.0011],\n","          [0.0000, 0.0041, 0.0026,  ..., 0.0020, 0.0003, 0.0015],\n","          ...,\n","          [0.0030, 0.0026, 0.0058,  ..., 0.0052, 0.0011, 0.0012],\n","          [0.0026, 0.0015, 0.0042,  ..., 0.0017, 0.0018, 0.0046],\n","          [0.0042, 0.0006, 0.0027,  ..., 0.0027, 0.0027, 0.0000]],\n","\n","         [[0.0000, 0.0016, 0.0020,  ..., 0.0052, 0.0017, 0.0000],\n","          [0.0012, 0.0070, 0.0009,  ..., 0.0046, 0.0035, 0.0000],\n","          [0.0029, 0.0024, 0.0066,  ..., 0.0048, 0.0008, 0.0072],\n","          ...,\n","          [0.0010, 0.0033, 0.0000,  ..., 0.0026, 0.0034, 0.0045],\n","          [0.0005, 0.0005, 0.0015,  ..., 0.0027, 0.0071, 0.0035],\n","          [0.0012, 0.0061, 0.0031,  ..., 0.0016, 0.0014, 0.0000]],\n","\n","         [[0.0021, 0.0002, 0.0011,  ..., 0.0007, 0.0014, 0.0015],\n","          [0.0006, 0.0012, 0.0030,  ..., 0.0016, 0.0011, 0.0012],\n","          [0.0019, 0.0041, 0.0000,  ..., 0.0006, 0.0003, 0.0014],\n","          ...,\n","          [0.0023, 0.0012, 0.0012,  ..., 0.0019, 0.0007, 0.0004],\n","          [0.0017, 0.0009, 0.0018,  ..., 0.0014, 0.0005, 0.0013],\n","          [0.0038, 0.0004, 0.0004,  ..., 0.0007, 0.0008, 0.0002]],\n","\n","         [[0.0137, 0.0006, 0.0003,  ..., 0.0004, 0.0016, 0.0009],\n","          [0.0029, 0.0022, 0.0025,  ..., 0.0067, 0.0007, 0.0000],\n","          [0.0006, 0.0006, 0.0008,  ..., 0.0015, 0.0009, 0.0029],\n","          ...,\n","          [0.0006, 0.0003, 0.0010,  ..., 0.0006, 0.0005, 0.0023],\n","          [0.0010, 0.0003, 0.0033,  ..., 0.0016, 0.0005, 0.0005],\n","          [0.0015, 0.0007, 0.0019,  ..., 0.0027, 0.0010, 0.0016]]],\n","\n","\n","        [[[0.0170, 0.0015, 0.0027,  ..., 0.0022, 0.0036, 0.0024],\n","          [0.0038, 0.0009, 0.0025,  ..., 0.0019, 0.0034, 0.0028],\n","          [0.0036, 0.0008, 0.0020,  ..., 0.0030, 0.0000, 0.0024],\n","          ...,\n","          [0.0000, 0.0006, 0.0019,  ..., 0.0023, 0.0000, 0.0000],\n","          [0.0027, 0.0011, 0.0017,  ..., 0.0027, 0.0032, 0.0030],\n","          [0.0025, 0.0015, 0.0047,  ..., 0.0023, 0.0026, 0.0028]],\n","\n","         [[0.0020, 0.0018, 0.0017,  ..., 0.0026, 0.0020, 0.0018],\n","          [0.0018, 0.0012, 0.0013,  ..., 0.0015, 0.0021, 0.0000],\n","          [0.0062, 0.0011, 0.0107,  ..., 0.0000, 0.0030, 0.0023],\n","          ...,\n","          [0.0000, 0.0025, 0.0010,  ..., 0.0032, 0.0022, 0.0024],\n","          [0.0017, 0.0026, 0.0007,  ..., 0.0027, 0.0000, 0.0023],\n","          [0.0025, 0.0034, 0.0015,  ..., 0.0023, 0.0023, 0.0020]],\n","\n","         [[0.0091, 0.0024, 0.0020,  ..., 0.0000, 0.0024, 0.0028],\n","          [0.0008, 0.0011, 0.0007,  ..., 0.0018, 0.0023, 0.0017],\n","          [0.0000, 0.0007, 0.0005,  ..., 0.0000, 0.0009, 0.0013],\n","          ...,\n","          [0.0019, 0.0017, 0.0000,  ..., 0.0014, 0.0022, 0.0000],\n","          [0.0020, 0.0000, 0.0011,  ..., 0.0017, 0.0025, 0.0022],\n","          [0.0023, 0.0031, 0.0019,  ..., 0.0015, 0.0021, 0.0018]],\n","\n","         [[0.0035, 0.0020, 0.0017,  ..., 0.0015, 0.0025, 0.0000],\n","          [0.0017, 0.0025, 0.0007,  ..., 0.0014, 0.0011, 0.0008],\n","          [0.0134, 0.0016, 0.0030,  ..., 0.0017, 0.0029, 0.0030],\n","          ...,\n","          [0.0036, 0.0014, 0.0000,  ..., 0.0021, 0.0017, 0.0019],\n","          [0.0032, 0.0014, 0.0000,  ..., 0.0021, 0.0000, 0.0014],\n","          [0.0037, 0.0012, 0.0019,  ..., 0.0016, 0.0000, 0.0012]]],\n","\n","\n","        [[[0.0050, 0.0010, 0.0036,  ..., 0.0013, 0.0014, 0.0015],\n","          [0.0000, 0.0005, 0.0007,  ..., 0.0016, 0.0018, 0.0014],\n","          [0.0020, 0.0003, 0.0018,  ..., 0.0022, 0.0017, 0.0012],\n","          ...,\n","          [0.0031, 0.0010, 0.0019,  ..., 0.0030, 0.0031, 0.0030],\n","          [0.0030, 0.0009, 0.0015,  ..., 0.0026, 0.0026, 0.0000],\n","          [0.0040, 0.0011, 0.0019,  ..., 0.0037, 0.0037, 0.0041]],\n","\n","         [[0.0017, 0.0018, 0.0006,  ..., 0.0024, 0.0019, 0.0020],\n","          [0.0020, 0.0010, 0.0011,  ..., 0.0026, 0.0041, 0.0038],\n","          [0.0031, 0.0017, 0.0017,  ..., 0.0023, 0.0022, 0.0000],\n","          ...,\n","          [0.0018, 0.0020, 0.0021,  ..., 0.0000, 0.0000, 0.0031],\n","          [0.0012, 0.0020, 0.0031,  ..., 0.0017, 0.0018, 0.0028],\n","          [0.0000, 0.0015, 0.0039,  ..., 0.0018, 0.0016, 0.0029]],\n","\n","         [[0.0027, 0.0015, 0.0078,  ..., 0.0025, 0.0032, 0.0024],\n","          [0.0017, 0.0025, 0.0027,  ..., 0.0020, 0.0030, 0.0026],\n","          [0.0016, 0.0009, 0.0022,  ..., 0.0014, 0.0013, 0.0010],\n","          ...,\n","          [0.0036, 0.0013, 0.0121,  ..., 0.0013, 0.0014, 0.0000],\n","          [0.0018, 0.0016, 0.0081,  ..., 0.0000, 0.0014, 0.0017],\n","          [0.0000, 0.0012, 0.0065,  ..., 0.0014, 0.0015, 0.0022]],\n","\n","         [[0.0000, 0.0021, 0.0024,  ..., 0.0019, 0.0023, 0.0012],\n","          [0.0007, 0.0021, 0.0000,  ..., 0.0037, 0.0000, 0.0020],\n","          [0.0028, 0.0032, 0.0006,  ..., 0.0041, 0.0000, 0.0018],\n","          ...,\n","          [0.0023, 0.0015, 0.0013,  ..., 0.0029, 0.0025, 0.0028],\n","          [0.0022, 0.0026, 0.0015,  ..., 0.0023, 0.0018, 0.0019],\n","          [0.0012, 0.0013, 0.0007,  ..., 0.0000, 0.0016, 0.0021]]]],\n","       device='cuda:1', grad_fn=<ViewBackward0>), tensor([[[[0.0027, 0.0014, 0.0009,  ..., 0.0012, 0.0000, 0.0010],\n","          [0.0000, 0.0037, 0.0020,  ..., 0.0009, 0.0013, 0.0015],\n","          [0.0020, 0.0018, 0.0014,  ..., 0.0010, 0.0012, 0.0018],\n","          ...,\n","          [0.0020, 0.0017, 0.0011,  ..., 0.0020, 0.0016, 0.0016],\n","          [0.0021, 0.0024, 0.0022,  ..., 0.0016, 0.0018, 0.0000],\n","          [0.0018, 0.0015, 0.0017,  ..., 0.0022, 0.0019, 0.0025]],\n","\n","         [[0.0020, 0.0000, 0.0026,  ..., 0.0025, 0.0022, 0.0018],\n","          [0.0012, 0.0090, 0.0050,  ..., 0.0029, 0.0038, 0.0025],\n","          [0.0015, 0.0052, 0.0000,  ..., 0.0030, 0.0041, 0.0025],\n","          ...,\n","          [0.0007, 0.0031, 0.0028,  ..., 0.0034, 0.0034, 0.0031],\n","          [0.0006, 0.0053, 0.0033,  ..., 0.0030, 0.0029, 0.0000],\n","          [0.0009, 0.0025, 0.0014,  ..., 0.0033, 0.0017, 0.0023]],\n","\n","         [[0.0028, 0.0021, 0.0017,  ..., 0.0014, 0.0015, 0.0011],\n","          [0.0022, 0.0000, 0.0000,  ..., 0.0000, 0.0020, 0.0028],\n","          [0.0024, 0.0024, 0.0020,  ..., 0.0028, 0.0028, 0.0040],\n","          ...,\n","          [0.0038, 0.0013, 0.0017,  ..., 0.0011, 0.0010, 0.0017],\n","          [0.0026, 0.0000, 0.0021,  ..., 0.0018, 0.0016, 0.0042],\n","          [0.0027, 0.0014, 0.0017,  ..., 0.0011, 0.0013, 0.0031]],\n","\n","         [[0.0018, 0.0012, 0.0013,  ..., 0.0015, 0.0032, 0.0018],\n","          [0.0009, 0.0009, 0.0011,  ..., 0.0015, 0.0022, 0.0020],\n","          [0.0006, 0.0000, 0.0012,  ..., 0.0025, 0.0033, 0.0027],\n","          ...,\n","          [0.0032, 0.0029, 0.0017,  ..., 0.0039, 0.0049, 0.0034],\n","          [0.0021, 0.0038, 0.0026,  ..., 0.0023, 0.0036, 0.0021],\n","          [0.0019, 0.0019, 0.0010,  ..., 0.0000, 0.0042, 0.0024]]],\n","\n","\n","        [[[0.0019, 0.0000, 0.0021,  ..., 0.0008, 0.0012, 0.0014],\n","          [0.0014, 0.0070, 0.0018,  ..., 0.0003, 0.0010, 0.0014],\n","          [0.0029, 0.0027, 0.0000,  ..., 0.0012, 0.0015, 0.0029],\n","          ...,\n","          [0.0014, 0.0016, 0.0017,  ..., 0.0009, 0.0000, 0.0013],\n","          [0.0019, 0.0018, 0.0037,  ..., 0.0000, 0.0022, 0.0000],\n","          [0.0017, 0.0035, 0.0022,  ..., 0.0007, 0.0000, 0.0000]],\n","\n","         [[0.0000, 0.0028, 0.0011,  ..., 0.0036, 0.0026, 0.0021],\n","          [0.0016, 0.0000, 0.0012,  ..., 0.0023, 0.0031, 0.0025],\n","          [0.0010, 0.0023, 0.0017,  ..., 0.0015, 0.0034, 0.0022],\n","          ...,\n","          [0.0006, 0.0000, 0.0011,  ..., 0.0023, 0.0028, 0.0027],\n","          [0.0010, 0.0026, 0.0022,  ..., 0.0026, 0.0030, 0.0023],\n","          [0.0004, 0.0022, 0.0020,  ..., 0.0016, 0.0023, 0.0000]],\n","\n","         [[0.0024, 0.0052, 0.0025,  ..., 0.0014, 0.0041, 0.0027],\n","          [0.0039, 0.0016, 0.0013,  ..., 0.0021, 0.0022, 0.0034],\n","          [0.0018, 0.0038, 0.0023,  ..., 0.0012, 0.0012, 0.0019],\n","          ...,\n","          [0.0048, 0.0030, 0.0000,  ..., 0.0012, 0.0018, 0.0033],\n","          [0.0026, 0.0025, 0.0010,  ..., 0.0012, 0.0018, 0.0033],\n","          [0.0033, 0.0017, 0.0000,  ..., 0.0014, 0.0014, 0.0029]],\n","\n","         [[0.0000, 0.0033, 0.0012,  ..., 0.0025, 0.0016, 0.0015],\n","          [0.0016, 0.0008, 0.0015,  ..., 0.0012, 0.0008, 0.0011],\n","          [0.0029, 0.0014, 0.0018,  ..., 0.0027, 0.0024, 0.0027],\n","          ...,\n","          [0.0018, 0.0000, 0.0006,  ..., 0.0014, 0.0023, 0.0026],\n","          [0.0016, 0.0010, 0.0007,  ..., 0.0019, 0.0000, 0.0022],\n","          [0.0020, 0.0011, 0.0010,  ..., 0.0016, 0.0017, 0.0019]]],\n","\n","\n","        [[[0.0021, 0.0034, 0.0012,  ..., 0.0009, 0.0010, 0.0023],\n","          [0.0010, 0.0111, 0.0015,  ..., 0.0009, 0.0007, 0.0014],\n","          [0.0019, 0.0045, 0.0033,  ..., 0.0019, 0.0011, 0.0018],\n","          ...,\n","          [0.0042, 0.0021, 0.0037,  ..., 0.0017, 0.0013, 0.0031],\n","          [0.0021, 0.0026, 0.0041,  ..., 0.0018, 0.0012, 0.0022],\n","          [0.0028, 0.0029, 0.0036,  ..., 0.0000, 0.0009, 0.0024]],\n","\n","         [[0.0000, 0.0010, 0.0023,  ..., 0.0034, 0.0022, 0.0034],\n","          [0.0015, 0.0015, 0.0016,  ..., 0.0000, 0.0029, 0.0034],\n","          [0.0000, 0.0038, 0.0038,  ..., 0.0017, 0.0015, 0.0011],\n","          ...,\n","          [0.0006, 0.0025, 0.0008,  ..., 0.0024, 0.0020, 0.0027],\n","          [0.0007, 0.0026, 0.0011,  ..., 0.0022, 0.0022, 0.0026],\n","          [0.0006, 0.0025, 0.0010,  ..., 0.0026, 0.0027, 0.0036]],\n","\n","         [[0.0032, 0.0055, 0.0000,  ..., 0.0021, 0.0019, 0.0000],\n","          [0.0037, 0.0032, 0.0013,  ..., 0.0016, 0.0000, 0.0028],\n","          [0.0016, 0.0000, 0.0012,  ..., 0.0010, 0.0010, 0.0000],\n","          ...,\n","          [0.0000, 0.0000, 0.0018,  ..., 0.0012, 0.0009, 0.0021],\n","          [0.0016, 0.0015, 0.0011,  ..., 0.0015, 0.0011, 0.0017],\n","          [0.0020, 0.0007, 0.0008,  ..., 0.0013, 0.0007, 0.0016]],\n","\n","         [[0.0020, 0.0018, 0.0016,  ..., 0.0009, 0.0014, 0.0021],\n","          [0.0050, 0.0011, 0.0027,  ..., 0.0014, 0.0016, 0.0011],\n","          [0.0069, 0.0038, 0.0064,  ..., 0.0028, 0.0017, 0.0014],\n","          ...,\n","          [0.0035, 0.0016, 0.0016,  ..., 0.0016, 0.0013, 0.0020],\n","          [0.0022, 0.0009, 0.0011,  ..., 0.0011, 0.0012, 0.0012],\n","          [0.0018, 0.0005, 0.0009,  ..., 0.0011, 0.0014, 0.0017]]],\n","\n","\n","        ...,\n","\n","\n","        [[[0.0033, 0.0021, 0.0011,  ..., 0.0009, 0.0016, 0.0009],\n","          [0.0021, 0.0012, 0.0030,  ..., 0.0011, 0.0022, 0.0014],\n","          [0.0015, 0.0037, 0.0028,  ..., 0.0016, 0.0010, 0.0018],\n","          ...,\n","          [0.0023, 0.0024, 0.0052,  ..., 0.0000, 0.0019, 0.0017],\n","          [0.0023, 0.0020, 0.0034,  ..., 0.0019, 0.0017, 0.0029],\n","          [0.0000, 0.0012, 0.0026,  ..., 0.0016, 0.0025, 0.0059]],\n","\n","         [[0.0013, 0.0015, 0.0014,  ..., 0.0031, 0.0029, 0.0017],\n","          [0.0013, 0.0036, 0.0012,  ..., 0.0027, 0.0029, 0.0020],\n","          [0.0019, 0.0019, 0.0033,  ..., 0.0030, 0.0018, 0.0044],\n","          ...,\n","          [0.0013, 0.0000, 0.0013,  ..., 0.0023, 0.0028, 0.0000],\n","          [0.0000, 0.0010, 0.0022,  ..., 0.0034, 0.0039, 0.0035],\n","          [0.0013, 0.0036, 0.0026,  ..., 0.0019, 0.0014, 0.0025]],\n","\n","         [[0.0021, 0.0008, 0.0014,  ..., 0.0016, 0.0023, 0.0021],\n","          [0.0012, 0.0019, 0.0026,  ..., 0.0029, 0.0000, 0.0000],\n","          [0.0034, 0.0054, 0.0041,  ..., 0.0015, 0.0011, 0.0023],\n","          ...,\n","          [0.0028, 0.0015, 0.0016,  ..., 0.0000, 0.0016, 0.0009],\n","          [0.0017, 0.0018, 0.0017,  ..., 0.0021, 0.0016, 0.0014],\n","          [0.0047, 0.0012, 0.0000,  ..., 0.0022, 0.0027, 0.0008]],\n","\n","         [[0.0000, 0.0009, 0.0000,  ..., 0.0007, 0.0018, 0.0008],\n","          [0.0026, 0.0019, 0.0000,  ..., 0.0038, 0.0019, 0.0029],\n","          [0.0008, 0.0008, 0.0014,  ..., 0.0000, 0.0014, 0.0021],\n","          ...,\n","          [0.0009, 0.0007, 0.0018,  ..., 0.0011, 0.0013, 0.0020],\n","          [0.0015, 0.0008, 0.0031,  ..., 0.0025, 0.0016, 0.0012],\n","          [0.0000, 0.0011, 0.0022,  ..., 0.0025, 0.0017, 0.0017]]],\n","\n","\n","        [[[0.0054, 0.0021, 0.0018,  ..., 0.0012, 0.0022, 0.0020],\n","          [0.0023, 0.0020, 0.0000,  ..., 0.0011, 0.0021, 0.0024],\n","          [0.0025, 0.0017, 0.0017,  ..., 0.0000, 0.0000, 0.0015],\n","          ...,\n","          [0.0023, 0.0008, 0.0017,  ..., 0.0013, 0.0015, 0.0018],\n","          [0.0027, 0.0014, 0.0015,  ..., 0.0015, 0.0021, 0.0025],\n","          [0.0025, 0.0016, 0.0039,  ..., 0.0012, 0.0018, 0.0026]],\n","\n","         [[0.0017, 0.0021, 0.0032,  ..., 0.0030, 0.0019, 0.0019],\n","          [0.0017, 0.0015, 0.0018,  ..., 0.0016, 0.0019, 0.0031],\n","          [0.0035, 0.0017, 0.0044,  ..., 0.0028, 0.0027, 0.0023],\n","          ...,\n","          [0.0006, 0.0020, 0.0012,  ..., 0.0037, 0.0019, 0.0023],\n","          [0.0009, 0.0016, 0.0000,  ..., 0.0036, 0.0016, 0.0000],\n","          [0.0015, 0.0026, 0.0022,  ..., 0.0026, 0.0019, 0.0018]],\n","\n","         [[0.0041, 0.0037, 0.0023,  ..., 0.0019, 0.0018, 0.0029],\n","          [0.0014, 0.0021, 0.0011,  ..., 0.0020, 0.0020, 0.0020],\n","          [0.0014, 0.0000, 0.0011,  ..., 0.0016, 0.0010, 0.0014],\n","          ...,\n","          [0.0016, 0.0016, 0.0016,  ..., 0.0013, 0.0020, 0.0013],\n","          [0.0016, 0.0022, 0.0011,  ..., 0.0014, 0.0021, 0.0022],\n","          [0.0023, 0.0029, 0.0021,  ..., 0.0013, 0.0000, 0.0018]],\n","\n","         [[0.0022, 0.0015, 0.0015,  ..., 0.0012, 0.0000, 0.0030],\n","          [0.0016, 0.0023, 0.0011,  ..., 0.0012, 0.0010, 0.0008],\n","          [0.0101, 0.0021, 0.0051,  ..., 0.0012, 0.0025, 0.0025],\n","          ...,\n","          [0.0024, 0.0011, 0.0018,  ..., 0.0018, 0.0013, 0.0018],\n","          [0.0022, 0.0013, 0.0016,  ..., 0.0017, 0.0000, 0.0010],\n","          [0.0024, 0.0011, 0.0020,  ..., 0.0014, 0.0008, 0.0010]]],\n","\n","\n","        [[[0.0036, 0.0030, 0.0043,  ..., 0.0009, 0.0012, 0.0010],\n","          [0.0000, 0.0019, 0.0012,  ..., 0.0013, 0.0017, 0.0009],\n","          [0.0018, 0.0022, 0.0024,  ..., 0.0012, 0.0012, 0.0007],\n","          ...,\n","          [0.0029, 0.0015, 0.0023,  ..., 0.0022, 0.0000, 0.0031],\n","          [0.0025, 0.0017, 0.0018,  ..., 0.0018, 0.0020, 0.0018],\n","          [0.0028, 0.0019, 0.0020,  ..., 0.0028, 0.0037, 0.0039]],\n","\n","         [[0.0014, 0.0020, 0.0006,  ..., 0.0030, 0.0024, 0.0024],\n","          [0.0018, 0.0014, 0.0009,  ..., 0.0025, 0.0033, 0.0037],\n","          [0.0027, 0.0022, 0.0017,  ..., 0.0000, 0.0016, 0.0013],\n","          ...,\n","          [0.0000, 0.0021, 0.0016,  ..., 0.0019, 0.0015, 0.0000],\n","          [0.0006, 0.0021, 0.0016,  ..., 0.0017, 0.0018, 0.0044],\n","          [0.0007, 0.0012, 0.0020,  ..., 0.0019, 0.0016, 0.0053]],\n","\n","         [[0.0024, 0.0021, 0.0032,  ..., 0.0025, 0.0036, 0.0027],\n","          [0.0020, 0.0029, 0.0014,  ..., 0.0018, 0.0026, 0.0025],\n","          [0.0000, 0.0000, 0.0017,  ..., 0.0021, 0.0017, 0.0015],\n","          ...,\n","          [0.0050, 0.0014, 0.0071,  ..., 0.0012, 0.0000, 0.0023],\n","          [0.0028, 0.0017, 0.0062,  ..., 0.0013, 0.0012, 0.0020],\n","          [0.0041, 0.0013, 0.0044,  ..., 0.0014, 0.0013, 0.0027]],\n","\n","         [[0.0000, 0.0018, 0.0020,  ..., 0.0016, 0.0020, 0.0012],\n","          [0.0013, 0.0025, 0.0022,  ..., 0.0025, 0.0026, 0.0021],\n","          [0.0025, 0.0028, 0.0013,  ..., 0.0025, 0.0025, 0.0016],\n","          ...,\n","          [0.0025, 0.0011, 0.0013,  ..., 0.0034, 0.0031, 0.0000],\n","          [0.0025, 0.0017, 0.0014,  ..., 0.0023, 0.0017, 0.0023],\n","          [0.0013, 0.0009, 0.0009,  ..., 0.0028, 0.0017, 0.0031]]]],\n","       device='cuda:1', grad_fn=<ViewBackward0>), tensor([[[[0.0027, 0.0014, 0.0014,  ..., 0.0010, 0.0011, 0.0008],\n","          [0.0017, 0.0000, 0.0019,  ..., 0.0000, 0.0016, 0.0014],\n","          [0.0023, 0.0017, 0.0014,  ..., 0.0011, 0.0016, 0.0017],\n","          ...,\n","          [0.0016, 0.0017, 0.0014,  ..., 0.0016, 0.0015, 0.0013],\n","          [0.0018, 0.0025, 0.0028,  ..., 0.0000, 0.0013, 0.0014],\n","          [0.0013, 0.0016, 0.0024,  ..., 0.0016, 0.0013, 0.0015]],\n","\n","         [[0.0017, 0.0017, 0.0000,  ..., 0.0000, 0.0024, 0.0026],\n","          [0.0013, 0.0063, 0.0044,  ..., 0.0031, 0.0036, 0.0033],\n","          [0.0013, 0.0051, 0.0026,  ..., 0.0035, 0.0037, 0.0030],\n","          ...,\n","          [0.0007, 0.0027, 0.0029,  ..., 0.0043, 0.0000, 0.0042],\n","          [0.0000, 0.0039, 0.0037,  ..., 0.0036, 0.0033, 0.0046],\n","          [0.0007, 0.0025, 0.0018,  ..., 0.0035, 0.0018, 0.0027]],\n","\n","         [[0.0023, 0.0023, 0.0018,  ..., 0.0016, 0.0011, 0.0000],\n","          [0.0029, 0.0038, 0.0030,  ..., 0.0000, 0.0018, 0.0031],\n","          [0.0031, 0.0028, 0.0022,  ..., 0.0025, 0.0000, 0.0037],\n","          ...,\n","          [0.0040, 0.0016, 0.0014,  ..., 0.0015, 0.0013, 0.0018],\n","          [0.0025, 0.0000, 0.0018,  ..., 0.0023, 0.0020, 0.0039],\n","          [0.0029, 0.0017, 0.0015,  ..., 0.0016, 0.0017, 0.0032]],\n","\n","         [[0.0018, 0.0015, 0.0013,  ..., 0.0019, 0.0029, 0.0022],\n","          [0.0010, 0.0014, 0.0013,  ..., 0.0023, 0.0027, 0.0023],\n","          [0.0006, 0.0011, 0.0013,  ..., 0.0034, 0.0039, 0.0030],\n","          ...,\n","          [0.0025, 0.0024, 0.0017,  ..., 0.0051, 0.0047, 0.0041],\n","          [0.0018, 0.0000, 0.0021,  ..., 0.0037, 0.0040, 0.0029],\n","          [0.0018, 0.0016, 0.0009,  ..., 0.0042, 0.0050, 0.0033]]],\n","\n","\n","        [[[0.0014, 0.0015, 0.0018,  ..., 0.0009, 0.0010, 0.0011],\n","          [0.0012, 0.0056, 0.0000,  ..., 0.0004, 0.0008, 0.0007],\n","          [0.0024, 0.0024, 0.0010,  ..., 0.0011, 0.0010, 0.0021],\n","          ...,\n","          [0.0012, 0.0014, 0.0014,  ..., 0.0000, 0.0009, 0.0008],\n","          [0.0016, 0.0015, 0.0000,  ..., 0.0008, 0.0015, 0.0010],\n","          [0.0014, 0.0027, 0.0016,  ..., 0.0006, 0.0013, 0.0012]],\n","\n","         [[0.0008, 0.0021, 0.0000,  ..., 0.0042, 0.0033, 0.0026],\n","          [0.0012, 0.0015, 0.0012,  ..., 0.0032, 0.0040, 0.0030],\n","          [0.0000, 0.0024, 0.0016,  ..., 0.0018, 0.0034, 0.0019],\n","          ...,\n","          [0.0006, 0.0000, 0.0011,  ..., 0.0033, 0.0034, 0.0034],\n","          [0.0008, 0.0021, 0.0015,  ..., 0.0044, 0.0035, 0.0032],\n","          [0.0004, 0.0019, 0.0014,  ..., 0.0029, 0.0026, 0.0032]],\n","\n","         [[0.0022, 0.0052, 0.0029,  ..., 0.0015, 0.0037, 0.0019],\n","          [0.0035, 0.0000, 0.0011,  ..., 0.0022, 0.0018, 0.0000],\n","          [0.0023, 0.0032, 0.0024,  ..., 0.0014, 0.0000, 0.0019],\n","          ...,\n","          [0.0051, 0.0029, 0.0023,  ..., 0.0016, 0.0018, 0.0037],\n","          [0.0028, 0.0025, 0.0012,  ..., 0.0018, 0.0018, 0.0038],\n","          [0.0040, 0.0019, 0.0019,  ..., 0.0019, 0.0017, 0.0027]],\n","\n","         [[0.0023, 0.0029, 0.0011,  ..., 0.0029, 0.0000, 0.0000],\n","          [0.0000, 0.0012, 0.0014,  ..., 0.0013, 0.0011, 0.0016],\n","          [0.0023, 0.0015, 0.0017,  ..., 0.0026, 0.0022, 0.0026],\n","          ...,\n","          [0.0017, 0.0014, 0.0006,  ..., 0.0020, 0.0028, 0.0036],\n","          [0.0013, 0.0011, 0.0005,  ..., 0.0022, 0.0023, 0.0033],\n","          [0.0018, 0.0013, 0.0010,  ..., 0.0023, 0.0026, 0.0030]]],\n","\n","\n","        [[[0.0020, 0.0036, 0.0012,  ..., 0.0000, 0.0010, 0.0029],\n","          [0.0010, 0.0098, 0.0012,  ..., 0.0009, 0.0007, 0.0014],\n","          [0.0000, 0.0044, 0.0000,  ..., 0.0000, 0.0009, 0.0020],\n","          ...,\n","          [0.0036, 0.0016, 0.0030,  ..., 0.0016, 0.0000, 0.0028],\n","          [0.0000, 0.0027, 0.0032,  ..., 0.0014, 0.0000, 0.0018],\n","          [0.0027, 0.0028, 0.0029,  ..., 0.0011, 0.0006, 0.0021]],\n","\n","         [[0.0019, 0.0011, 0.0023,  ..., 0.0000, 0.0039, 0.0000],\n","          [0.0011, 0.0015, 0.0019,  ..., 0.0051, 0.0042, 0.0045],\n","          [0.0023, 0.0038, 0.0037,  ..., 0.0025, 0.0022, 0.0015],\n","          ...,\n","          [0.0005, 0.0023, 0.0010,  ..., 0.0042, 0.0033, 0.0034],\n","          [0.0006, 0.0000, 0.0000,  ..., 0.0030, 0.0000, 0.0025],\n","          [0.0006, 0.0023, 0.0015,  ..., 0.0040, 0.0040, 0.0037]],\n","\n","         [[0.0023, 0.0046, 0.0024,  ..., 0.0017, 0.0016, 0.0032],\n","          [0.0029, 0.0027, 0.0017,  ..., 0.0014, 0.0011, 0.0000],\n","          [0.0017, 0.0038, 0.0016,  ..., 0.0010, 0.0000, 0.0015],\n","          ...,\n","          [0.0017, 0.0015, 0.0030,  ..., 0.0015, 0.0000, 0.0025],\n","          [0.0018, 0.0016, 0.0020,  ..., 0.0015, 0.0013, 0.0019],\n","          [0.0000, 0.0008, 0.0013,  ..., 0.0000, 0.0009, 0.0019]],\n","\n","         [[0.0000, 0.0014, 0.0015,  ..., 0.0009, 0.0014, 0.0029],\n","          [0.0038, 0.0014, 0.0021,  ..., 0.0014, 0.0019, 0.0015],\n","          [0.0062, 0.0035, 0.0056,  ..., 0.0000, 0.0017, 0.0018],\n","          ...,\n","          [0.0041, 0.0017, 0.0017,  ..., 0.0018, 0.0016, 0.0000],\n","          [0.0000, 0.0010, 0.0015,  ..., 0.0016, 0.0015, 0.0024],\n","          [0.0023, 0.0007, 0.0009,  ..., 0.0019, 0.0021, 0.0033]]],\n","\n","\n","        ...,\n","\n","\n","        [[[0.0000, 0.0020, 0.0009,  ..., 0.0010, 0.0015, 0.0010],\n","          [0.0024, 0.0011, 0.0041,  ..., 0.0012, 0.0020, 0.0013],\n","          [0.0000, 0.0033, 0.0031,  ..., 0.0017, 0.0013, 0.0000],\n","          ...,\n","          [0.0019, 0.0022, 0.0055,  ..., 0.0032, 0.0020, 0.0017],\n","          [0.0019, 0.0024, 0.0030,  ..., 0.0019, 0.0000, 0.0024],\n","          [0.0000, 0.0011, 0.0024,  ..., 0.0000, 0.0022, 0.0042]],\n","\n","         [[0.0011, 0.0014, 0.0010,  ..., 0.0028, 0.0033, 0.0021],\n","          [0.0014, 0.0030, 0.0012,  ..., 0.0025, 0.0022, 0.0027],\n","          [0.0016, 0.0018, 0.0030,  ..., 0.0037, 0.0025, 0.0047],\n","          ...,\n","          [0.0014, 0.0019, 0.0013,  ..., 0.0023, 0.0032, 0.0055],\n","          [0.0007, 0.0016, 0.0021,  ..., 0.0034, 0.0037, 0.0051],\n","          [0.0012, 0.0000, 0.0025,  ..., 0.0022, 0.0013, 0.0029]],\n","\n","         [[0.0017, 0.0011, 0.0013,  ..., 0.0017, 0.0025, 0.0000],\n","          [0.0014, 0.0020, 0.0027,  ..., 0.0000, 0.0027, 0.0015],\n","          [0.0035, 0.0047, 0.0042,  ..., 0.0022, 0.0017, 0.0023],\n","          ...,\n","          [0.0032, 0.0017, 0.0016,  ..., 0.0031, 0.0000, 0.0009],\n","          [0.0023, 0.0020, 0.0019,  ..., 0.0021, 0.0020, 0.0013],\n","          [0.0050, 0.0013, 0.0019,  ..., 0.0028, 0.0000, 0.0009]],\n","\n","         [[0.0060, 0.0010, 0.0010,  ..., 0.0008, 0.0020, 0.0010],\n","          [0.0000, 0.0018, 0.0028,  ..., 0.0038, 0.0024, 0.0022],\n","          [0.0010, 0.0008, 0.0000,  ..., 0.0015, 0.0000, 0.0026],\n","          ...,\n","          [0.0008, 0.0008, 0.0018,  ..., 0.0013, 0.0016, 0.0021],\n","          [0.0000, 0.0000, 0.0021,  ..., 0.0032, 0.0025, 0.0020],\n","          [0.0017, 0.0010, 0.0000,  ..., 0.0028, 0.0025, 0.0018]]],\n","\n","\n","        [[[0.0045, 0.0025, 0.0019,  ..., 0.0011, 0.0017, 0.0023],\n","          [0.0023, 0.0028, 0.0022,  ..., 0.0008, 0.0018, 0.0023],\n","          [0.0022, 0.0029, 0.0017,  ..., 0.0012, 0.0016, 0.0015],\n","          ...,\n","          [0.0021, 0.0015, 0.0019,  ..., 0.0010, 0.0013, 0.0017],\n","          [0.0025, 0.0024, 0.0017,  ..., 0.0011, 0.0015, 0.0022],\n","          [0.0025, 0.0027, 0.0029,  ..., 0.0009, 0.0016, 0.0000]],\n","\n","         [[0.0015, 0.0000, 0.0040,  ..., 0.0045, 0.0032, 0.0000],\n","          [0.0014, 0.0015, 0.0019,  ..., 0.0025, 0.0022, 0.0038],\n","          [0.0031, 0.0016, 0.0036,  ..., 0.0033, 0.0032, 0.0028],\n","          ...,\n","          [0.0007, 0.0015, 0.0000,  ..., 0.0042, 0.0026, 0.0000],\n","          [0.0008, 0.0012, 0.0015,  ..., 0.0043, 0.0022, 0.0043],\n","          [0.0013, 0.0017, 0.0000,  ..., 0.0033, 0.0024, 0.0025]],\n","\n","         [[0.0000, 0.0040, 0.0000,  ..., 0.0014, 0.0013, 0.0019],\n","          [0.0016, 0.0000, 0.0010,  ..., 0.0000, 0.0020, 0.0018],\n","          [0.0013, 0.0033, 0.0012,  ..., 0.0016, 0.0011, 0.0013],\n","          ...,\n","          [0.0016, 0.0021, 0.0020,  ..., 0.0016, 0.0017, 0.0014],\n","          [0.0016, 0.0028, 0.0000,  ..., 0.0016, 0.0019, 0.0022],\n","          [0.0021, 0.0029, 0.0024,  ..., 0.0017, 0.0019, 0.0021]],\n","\n","         [[0.0018, 0.0000, 0.0000,  ..., 0.0016, 0.0000, 0.0000],\n","          [0.0020, 0.0026, 0.0011,  ..., 0.0020, 0.0018, 0.0011],\n","          [0.0000, 0.0023, 0.0052,  ..., 0.0014, 0.0027, 0.0023],\n","          ...,\n","          [0.0018, 0.0012, 0.0016,  ..., 0.0026, 0.0018, 0.0028],\n","          [0.0017, 0.0000, 0.0014,  ..., 0.0021, 0.0000, 0.0015],\n","          [0.0019, 0.0010, 0.0016,  ..., 0.0024, 0.0000, 0.0017]]],\n","\n","\n","        [[[0.0031, 0.0000, 0.0000,  ..., 0.0009, 0.0010, 0.0000],\n","          [0.0017, 0.0020, 0.0011,  ..., 0.0013, 0.0016, 0.0009],\n","          [0.0018, 0.0027, 0.0021,  ..., 0.0010, 0.0011, 0.0007],\n","          ...,\n","          [0.0000, 0.0016, 0.0024,  ..., 0.0018, 0.0022, 0.0027],\n","          [0.0021, 0.0019, 0.0018,  ..., 0.0016, 0.0018, 0.0019],\n","          [0.0022, 0.0022, 0.0022,  ..., 0.0019, 0.0026, 0.0028]],\n","\n","         [[0.0014, 0.0016, 0.0004,  ..., 0.0042, 0.0030, 0.0031],\n","          [0.0018, 0.0015, 0.0006,  ..., 0.0029, 0.0036, 0.0041],\n","          [0.0029, 0.0022, 0.0010,  ..., 0.0026, 0.0018, 0.0015],\n","          ...,\n","          [0.0012, 0.0022, 0.0011,  ..., 0.0022, 0.0000, 0.0042],\n","          [0.0007, 0.0020, 0.0010,  ..., 0.0024, 0.0024, 0.0049],\n","          [0.0008, 0.0014, 0.0013,  ..., 0.0025, 0.0022, 0.0056]],\n","\n","         [[0.0023, 0.0029, 0.0029,  ..., 0.0018, 0.0029, 0.0018],\n","          [0.0020, 0.0033, 0.0013,  ..., 0.0018, 0.0020, 0.0020],\n","          [0.0023, 0.0028, 0.0016,  ..., 0.0021, 0.0019, 0.0014],\n","          ...,\n","          [0.0042, 0.0019, 0.0057,  ..., 0.0014, 0.0015, 0.0021],\n","          [0.0029, 0.0027, 0.0000,  ..., 0.0016, 0.0016, 0.0018],\n","          [0.0039, 0.0020, 0.0035,  ..., 0.0017, 0.0018, 0.0026]],\n","\n","         [[0.0027, 0.0015, 0.0019,  ..., 0.0021, 0.0025, 0.0016],\n","          [0.0014, 0.0020, 0.0015,  ..., 0.0026, 0.0028, 0.0025],\n","          [0.0021, 0.0020, 0.0013,  ..., 0.0030, 0.0032, 0.0023],\n","          ...,\n","          [0.0020, 0.0009, 0.0010,  ..., 0.0000, 0.0000, 0.0053],\n","          [0.0023, 0.0012, 0.0012,  ..., 0.0033, 0.0027, 0.0037],\n","          [0.0014, 0.0008, 0.0010,  ..., 0.0033, 0.0023, 0.0042]]]],\n","       device='cuda:1', grad_fn=<ViewBackward0>), tensor([[[[0.0023, 0.0016, 0.0015,  ..., 0.0008, 0.0000, 0.0008],\n","          [0.0013, 0.0029, 0.0018,  ..., 0.0000, 0.0017, 0.0013],\n","          [0.0021, 0.0019, 0.0015,  ..., 0.0010, 0.0019, 0.0016],\n","          ...,\n","          [0.0014, 0.0017, 0.0014,  ..., 0.0014, 0.0014, 0.0013],\n","          [0.0015, 0.0025, 0.0028,  ..., 0.0000, 0.0012, 0.0014],\n","          [0.0010, 0.0000, 0.0025,  ..., 0.0012, 0.0010, 0.0013]],\n","\n","         [[0.0018, 0.0018, 0.0028,  ..., 0.0031, 0.0027, 0.0025],\n","          [0.0014, 0.0039, 0.0000,  ..., 0.0000, 0.0041, 0.0034],\n","          [0.0013, 0.0034, 0.0022,  ..., 0.0038, 0.0043, 0.0040],\n","          ...,\n","          [0.0008, 0.0021, 0.0025,  ..., 0.0045, 0.0033, 0.0000],\n","          [0.0007, 0.0027, 0.0029,  ..., 0.0041, 0.0000, 0.0043],\n","          [0.0008, 0.0023, 0.0020,  ..., 0.0034, 0.0000, 0.0029]],\n","\n","         [[0.0022, 0.0019, 0.0018,  ..., 0.0015, 0.0011, 0.0013],\n","          [0.0036, 0.0035, 0.0033,  ..., 0.0021, 0.0018, 0.0032],\n","          [0.0036, 0.0029, 0.0024,  ..., 0.0023, 0.0028, 0.0000],\n","          ...,\n","          [0.0039, 0.0000, 0.0014,  ..., 0.0018, 0.0017, 0.0021],\n","          [0.0026, 0.0019, 0.0016,  ..., 0.0024, 0.0023, 0.0034],\n","          [0.0035, 0.0000, 0.0015,  ..., 0.0022, 0.0025, 0.0037]],\n","\n","         [[0.0000, 0.0015, 0.0013,  ..., 0.0025, 0.0032, 0.0023],\n","          [0.0013, 0.0000, 0.0000,  ..., 0.0029, 0.0000, 0.0024],\n","          [0.0006, 0.0000, 0.0015,  ..., 0.0033, 0.0037, 0.0025],\n","          ...,\n","          [0.0023, 0.0019, 0.0020,  ..., 0.0048, 0.0000, 0.0042],\n","          [0.0020, 0.0023, 0.0021,  ..., 0.0043, 0.0044, 0.0031],\n","          [0.0020, 0.0013, 0.0011,  ..., 0.0047, 0.0052, 0.0040]]],\n","\n","\n","        [[[0.0011, 0.0012, 0.0000,  ..., 0.0009, 0.0011, 0.0010],\n","          [0.0009, 0.0038, 0.0013,  ..., 0.0005, 0.0009, 0.0005],\n","          [0.0021, 0.0019, 0.0000,  ..., 0.0009, 0.0000, 0.0017],\n","          ...,\n","          [0.0010, 0.0012, 0.0014,  ..., 0.0007, 0.0010, 0.0008],\n","          [0.0000, 0.0011, 0.0000,  ..., 0.0007, 0.0015, 0.0008],\n","          [0.0011, 0.0020, 0.0012,  ..., 0.0006, 0.0013, 0.0009]],\n","\n","         [[0.0000, 0.0020, 0.0011,  ..., 0.0039, 0.0036, 0.0029],\n","          [0.0000, 0.0017, 0.0012,  ..., 0.0035, 0.0043, 0.0000],\n","          [0.0010, 0.0000, 0.0017,  ..., 0.0024, 0.0030, 0.0019],\n","          ...,\n","          [0.0007, 0.0016, 0.0012,  ..., 0.0040, 0.0042, 0.0043],\n","          [0.0009, 0.0022, 0.0000,  ..., 0.0048, 0.0040, 0.0037],\n","          [0.0006, 0.0021, 0.0013,  ..., 0.0034, 0.0000, 0.0037]],\n","\n","         [[0.0023, 0.0050, 0.0029,  ..., 0.0015, 0.0034, 0.0014],\n","          [0.0026, 0.0018, 0.0011,  ..., 0.0020, 0.0017, 0.0019],\n","          [0.0028, 0.0037, 0.0022,  ..., 0.0019, 0.0016, 0.0016],\n","          ...,\n","          [0.0042, 0.0032, 0.0023,  ..., 0.0020, 0.0000, 0.0024],\n","          [0.0030, 0.0024, 0.0000,  ..., 0.0023, 0.0019, 0.0000],\n","          [0.0039, 0.0018, 0.0021,  ..., 0.0023, 0.0019, 0.0022]],\n","\n","         [[0.0021, 0.0031, 0.0012,  ..., 0.0034, 0.0020, 0.0025],\n","          [0.0000, 0.0016, 0.0000,  ..., 0.0019, 0.0012, 0.0019],\n","          [0.0026, 0.0021, 0.0015,  ..., 0.0029, 0.0000, 0.0000],\n","          ...,\n","          [0.0021, 0.0015, 0.0007,  ..., 0.0023, 0.0028, 0.0040],\n","          [0.0000, 0.0000, 0.0006,  ..., 0.0024, 0.0028, 0.0000],\n","          [0.0023, 0.0017, 0.0010,  ..., 0.0028, 0.0031, 0.0036]]],\n","\n","\n","        [[[0.0000, 0.0033, 0.0000,  ..., 0.0011, 0.0010, 0.0031],\n","          [0.0013, 0.0083, 0.0012,  ..., 0.0000, 0.0000, 0.0017],\n","          [0.0017, 0.0039, 0.0021,  ..., 0.0013, 0.0010, 0.0022],\n","          ...,\n","          [0.0032, 0.0017, 0.0026,  ..., 0.0015, 0.0009, 0.0000],\n","          [0.0000, 0.0026, 0.0025,  ..., 0.0012, 0.0008, 0.0019],\n","          [0.0025, 0.0025, 0.0027,  ..., 0.0012, 0.0007, 0.0020]],\n","\n","         [[0.0016, 0.0014, 0.0024,  ..., 0.0068, 0.0045, 0.0049],\n","          [0.0000, 0.0019, 0.0024,  ..., 0.0060, 0.0046, 0.0044],\n","          [0.0017, 0.0040, 0.0035,  ..., 0.0033, 0.0000, 0.0017],\n","          ...,\n","          [0.0007, 0.0025, 0.0000,  ..., 0.0062, 0.0048, 0.0039],\n","          [0.0008, 0.0027, 0.0020,  ..., 0.0043, 0.0000, 0.0026],\n","          [0.0007, 0.0025, 0.0015,  ..., 0.0057, 0.0048, 0.0039]],\n","\n","         [[0.0024, 0.0034, 0.0025,  ..., 0.0016, 0.0016, 0.0027],\n","          [0.0026, 0.0025, 0.0019,  ..., 0.0016, 0.0011, 0.0000],\n","          [0.0021, 0.0032, 0.0019,  ..., 0.0013, 0.0014, 0.0022],\n","          ...,\n","          [0.0018, 0.0015, 0.0034,  ..., 0.0000, 0.0015, 0.0031],\n","          [0.0022, 0.0015, 0.0025,  ..., 0.0018, 0.0017, 0.0023],\n","          [0.0000, 0.0010, 0.0016,  ..., 0.0019, 0.0015, 0.0026]],\n","\n","         [[0.0026, 0.0012, 0.0014,  ..., 0.0014, 0.0016, 0.0000],\n","          [0.0032, 0.0020, 0.0018,  ..., 0.0016, 0.0000, 0.0022],\n","          [0.0058, 0.0035, 0.0040,  ..., 0.0033, 0.0000, 0.0021],\n","          ...,\n","          [0.0044, 0.0000, 0.0013,  ..., 0.0022, 0.0018, 0.0039],\n","          [0.0032, 0.0012, 0.0013,  ..., 0.0023, 0.0019, 0.0029],\n","          [0.0028, 0.0010, 0.0009,  ..., 0.0030, 0.0022, 0.0038]]],\n","\n","\n","        ...,\n","\n","\n","        [[[0.0026, 0.0021, 0.0011,  ..., 0.0013, 0.0014, 0.0012],\n","          [0.0025, 0.0012, 0.0040,  ..., 0.0014, 0.0021, 0.0016],\n","          [0.0000, 0.0031, 0.0000,  ..., 0.0017, 0.0017, 0.0018],\n","          ...,\n","          [0.0018, 0.0019, 0.0049,  ..., 0.0028, 0.0026, 0.0023],\n","          [0.0019, 0.0022, 0.0027,  ..., 0.0019, 0.0019, 0.0000],\n","          [0.0000, 0.0013, 0.0023,  ..., 0.0011, 0.0000, 0.0038]],\n","\n","         [[0.0013, 0.0016, 0.0011,  ..., 0.0026, 0.0034, 0.0027],\n","          [0.0017, 0.0030, 0.0012,  ..., 0.0023, 0.0020, 0.0027],\n","          [0.0017, 0.0018, 0.0026,  ..., 0.0036, 0.0029, 0.0052],\n","          ...,\n","          [0.0016, 0.0023, 0.0015,  ..., 0.0000, 0.0031, 0.0056],\n","          [0.0009, 0.0000, 0.0019,  ..., 0.0031, 0.0035, 0.0050],\n","          [0.0000, 0.0030, 0.0000,  ..., 0.0022, 0.0012, 0.0028]],\n","\n","         [[0.0022, 0.0015, 0.0012,  ..., 0.0021, 0.0024, 0.0022],\n","          [0.0019, 0.0022, 0.0024,  ..., 0.0039, 0.0030, 0.0014],\n","          [0.0042, 0.0036, 0.0031,  ..., 0.0026, 0.0000, 0.0000],\n","          ...,\n","          [0.0000, 0.0018, 0.0014,  ..., 0.0035, 0.0020, 0.0010],\n","          [0.0027, 0.0023, 0.0016,  ..., 0.0021, 0.0024, 0.0014],\n","          [0.0053, 0.0013, 0.0019,  ..., 0.0038, 0.0040, 0.0011]],\n","\n","         [[0.0044, 0.0011, 0.0013,  ..., 0.0010, 0.0022, 0.0011],\n","          [0.0030, 0.0018, 0.0022,  ..., 0.0032, 0.0025, 0.0019],\n","          [0.0014, 0.0008, 0.0016,  ..., 0.0019, 0.0022, 0.0000],\n","          ...,\n","          [0.0010, 0.0009, 0.0019,  ..., 0.0017, 0.0019, 0.0019],\n","          [0.0023, 0.0000, 0.0018,  ..., 0.0034, 0.0028, 0.0021],\n","          [0.0022, 0.0010, 0.0018,  ..., 0.0029, 0.0032, 0.0000]]],\n","\n","\n","        [[[0.0040, 0.0034, 0.0019,  ..., 0.0010, 0.0019, 0.0023],\n","          [0.0022, 0.0032, 0.0023,  ..., 0.0008, 0.0019, 0.0023],\n","          [0.0021, 0.0040, 0.0018,  ..., 0.0011, 0.0016, 0.0017],\n","          ...,\n","          [0.0022, 0.0000, 0.0021,  ..., 0.0009, 0.0014, 0.0017],\n","          [0.0024, 0.0029, 0.0000,  ..., 0.0010, 0.0015, 0.0020],\n","          [0.0024, 0.0030, 0.0026,  ..., 0.0000, 0.0015, 0.0023]],\n","\n","         [[0.0018, 0.0014, 0.0039,  ..., 0.0057, 0.0000, 0.0028],\n","          [0.0016, 0.0000, 0.0023,  ..., 0.0038, 0.0030, 0.0037],\n","          [0.0033, 0.0017, 0.0029,  ..., 0.0000, 0.0035, 0.0025],\n","          ...,\n","          [0.0010, 0.0014, 0.0020,  ..., 0.0047, 0.0000, 0.0032],\n","          [0.0011, 0.0013, 0.0019,  ..., 0.0048, 0.0027, 0.0037],\n","          [0.0016, 0.0014, 0.0031,  ..., 0.0039, 0.0029, 0.0026]],\n","\n","         [[0.0024, 0.0039, 0.0017,  ..., 0.0014, 0.0015, 0.0020],\n","          [0.0016, 0.0025, 0.0010,  ..., 0.0017, 0.0020, 0.0021],\n","          [0.0015, 0.0041, 0.0010,  ..., 0.0017, 0.0015, 0.0016],\n","          ...,\n","          [0.0017, 0.0026, 0.0022,  ..., 0.0017, 0.0000, 0.0019],\n","          [0.0015, 0.0028, 0.0012,  ..., 0.0000, 0.0016, 0.0021],\n","          [0.0018, 0.0030, 0.0000,  ..., 0.0018, 0.0018, 0.0024]],\n","\n","         [[0.0000, 0.0014, 0.0013,  ..., 0.0019, 0.0027, 0.0024],\n","          [0.0020, 0.0031, 0.0012,  ..., 0.0027, 0.0022, 0.0015],\n","          [0.0061, 0.0023, 0.0042,  ..., 0.0016, 0.0029, 0.0000],\n","          ...,\n","          [0.0015, 0.0015, 0.0016,  ..., 0.0029, 0.0022, 0.0028],\n","          [0.0017, 0.0014, 0.0011,  ..., 0.0026, 0.0018, 0.0019],\n","          [0.0000, 0.0011, 0.0012,  ..., 0.0033, 0.0018, 0.0021]]],\n","\n","\n","        [[[0.0025, 0.0032, 0.0032,  ..., 0.0009, 0.0011, 0.0011],\n","          [0.0015, 0.0020, 0.0013,  ..., 0.0012, 0.0015, 0.0010],\n","          [0.0022, 0.0034, 0.0020,  ..., 0.0011, 0.0012, 0.0009],\n","          ...,\n","          [0.0020, 0.0019, 0.0025,  ..., 0.0018, 0.0018, 0.0021],\n","          [0.0017, 0.0022, 0.0019,  ..., 0.0015, 0.0016, 0.0018],\n","          [0.0017, 0.0025, 0.0022,  ..., 0.0015, 0.0000, 0.0020]],\n","\n","         [[0.0016, 0.0012, 0.0003,  ..., 0.0046, 0.0036, 0.0042],\n","          [0.0018, 0.0015, 0.0004,  ..., 0.0031, 0.0038, 0.0038],\n","          [0.0028, 0.0016, 0.0007,  ..., 0.0029, 0.0021, 0.0018],\n","          ...,\n","          [0.0012, 0.0018, 0.0008,  ..., 0.0021, 0.0017, 0.0044],\n","          [0.0008, 0.0017, 0.0008,  ..., 0.0023, 0.0024, 0.0051],\n","          [0.0009, 0.0013, 0.0009,  ..., 0.0023, 0.0023, 0.0054]],\n","\n","         [[0.0000, 0.0032, 0.0028,  ..., 0.0015, 0.0017, 0.0013],\n","          [0.0023, 0.0027, 0.0016,  ..., 0.0018, 0.0018, 0.0017],\n","          [0.0027, 0.0032, 0.0018,  ..., 0.0000, 0.0000, 0.0016],\n","          ...,\n","          [0.0038, 0.0025, 0.0044,  ..., 0.0017, 0.0014, 0.0016],\n","          [0.0030, 0.0031, 0.0047,  ..., 0.0016, 0.0016, 0.0015],\n","          [0.0039, 0.0025, 0.0032,  ..., 0.0018, 0.0018, 0.0021]],\n","\n","         [[0.0027, 0.0016, 0.0018,  ..., 0.0024, 0.0026, 0.0016],\n","          [0.0018, 0.0021, 0.0015,  ..., 0.0024, 0.0024, 0.0023],\n","          [0.0023, 0.0020, 0.0013,  ..., 0.0000, 0.0029, 0.0024],\n","          ...,\n","          [0.0018, 0.0009, 0.0011,  ..., 0.0052, 0.0049, 0.0051],\n","          [0.0025, 0.0014, 0.0014,  ..., 0.0031, 0.0029, 0.0037],\n","          [0.0017, 0.0010, 0.0011,  ..., 0.0033, 0.0025, 0.0041]]]],\n","       device='cuda:1', grad_fn=<ViewBackward0>)]\n"]}],"source":["test_forward_pass(model, e.train_loader)"]},{"cell_type":"markdown","metadata":{"id":"w60mTX5nQ7Z1"},"source":["## Training the model"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1715688892531,"user":{"displayName":"Insa Belter","userId":"09408038895575287386"},"user_tz":-120},"id":"Vr8Ge8QYQ7Z2"},"outputs":[{"name":"stdout","output_type":"stream","text":["849,089 total parameters.\n","849,089 training parameters.\n"]}],"source":["e.set_seed()\n","EMBED_DIM = 64\n","NUM_ENCODER_LAYERS = 2\n","NUM_HEADS = 4\n","DROPOUT = 0.5\n","\n","model = e.EncoderClassifier(\n","    embed_dim=EMBED_DIM,\n","    num_layers=NUM_ENCODER_LAYERS,\n","    num_heads=NUM_HEADS,\n","    dropout=DROPOUT,\n","    pos_enc=False\n",").to(device)\n","print_parameters(model)"]},{"cell_type":"code","execution_count":48,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":452,"status":"ok","timestamp":1715688894105,"user":{"displayName":"Insa Belter","userId":"09408038895575287386"},"user_tz":-120},"id":"8G-AucPcQ7Z2","outputId":"8483db98-2a68-47ee-eaa2-b7d3c55e90f7"},"outputs":[{"name":"stdout","output_type":"stream","text":["----- Start Training -----\n","Epoch [1/50], Loss: 1.7964, Eval Accuracy: 0.5155, Took 1.16 s\n","Epoch [2/50], Loss: 1.2462, Eval Accuracy: 0.5146, Took 1.15 s\n","Epoch [3/50], Loss: 1.1489, Eval Accuracy: 0.5153, Took 1.15 s\n","Epoch [4/50], Loss: 1.1064, Eval Accuracy: 0.5166, Took 1.15 s\n","Epoch [5/50], Loss: 1.083, Eval Accuracy: 0.5186, Took 1.15 s\n","Epoch [6/50], Loss: 1.0689, Eval Accuracy: 0.5166, Took 1.16 s\n","Epoch [7/50], Loss: 1.0594, Eval Accuracy: 0.5176, Took 1.16 s\n","Epoch [8/50], Loss: 1.0536, Eval Accuracy: 0.5196, Took 1.15 s\n","Epoch [9/50], Loss: 1.0486, Eval Accuracy: 0.5204, Took 1.15 s\n","Epoch [10/50], Loss: 1.0456, Eval Accuracy: 0.522, Took 1.17 s\n","Epoch [11/50], Loss: 1.0435, Eval Accuracy: 0.5184, Took 1.18 s\n","Epoch [12/50], Loss: 1.0409, Eval Accuracy: 0.5198, Took 1.18 s\n","Epoch [13/50], Loss: 1.0407, Eval Accuracy: 0.5218, Took 1.18 s\n","Epoch [14/50], Loss: 1.0382, Eval Accuracy: 0.5218, Took 1.19 s\n","Epoch [15/50], Loss: 1.0381, Eval Accuracy: 0.5199, Took 1.19 s\n","Epoch [16/50], Loss: 1.0368, Eval Accuracy: 0.5222, Took 1.17 s\n","Epoch [17/50], Loss: 1.0367, Eval Accuracy: 0.5226, Took 1.16 s\n","Epoch [18/50], Loss: 1.0349, Eval Accuracy: 0.5226, Took 1.16 s\n","Epoch [19/50], Loss: 1.0345, Eval Accuracy: 0.5231, Took 1.17 s\n","Epoch [20/50], Loss: 1.0347, Eval Accuracy: 0.5209, Took 1.16 s\n","Epoch [21/50], Loss: 1.035, Eval Accuracy: 0.5225, Took 1.16 s\n","Stopped early after epoch 21 as validation accuracy was lower than average of the last 7 accuracies.\n","Last Loss: 1.035, Last Eval Accuracy: 0.5225, Took 24.47 s\n"]},{"data":{"text/plain":["(1.035, 0.5225, 21)"]},"execution_count":48,"metadata":{},"output_type":"execute_result"}],"source":["EPOCHS = 100\n","print(\"----- Start Training -----\")\n","e.train_model(model, EPOCHS)"]},{"cell_type":"code","execution_count":50,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Model saved as 20240616081217_encoder_64em_2l_4h_05dr_21ep.pt\n"]}],"source":["mlh.save_model(model, f'encoder_64em_2l_4h_05dr_21ep', e.organism)"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[],"source":["#model = mlh.load_model(f'encoder_256em_4l_4h_03dr_10ep', organism)"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[],"source":["criterion = torch.nn.CrossEntropyLoss(ignore_index=mlh.codons_to_integer['___'])\n","#evaluate_model(model, criterion)"]},{"cell_type":"markdown","metadata":{},"source":["## Hyperparameter tuning"]},{"cell_type":"markdown","metadata":{},"source":["### E.Coli"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Länge train_dataset: 3555\n","Länge valid_dataset: 420\n"]}],"source":["organism = \"E.Coli\"\n","e.load_train_valid_data(organism)"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["----- Start Training: 64 emb, 2 layers, 4 heads, 0.5 dropout, positional encoding: False, 100 epochs -----\n","Epoch [1/100], Loss: 1.7964, Eval Accuracy: 0.5155, Took 1.19 s\n","Epoch [2/100], Loss: 1.2462, Eval Accuracy: 0.5146, Took 1.18 s\n","Epoch [3/100], Loss: 1.1489, Eval Accuracy: 0.5153, Took 1.17 s\n","Epoch [4/100], Loss: 1.1064, Eval Accuracy: 0.5166, Took 1.16 s\n","Epoch [5/100], Loss: 1.083, Eval Accuracy: 0.5186, Took 1.16 s\n","Epoch [6/100], Loss: 1.0689, Eval Accuracy: 0.5166, Took 1.16 s\n","Epoch [7/100], Loss: 1.0594, Eval Accuracy: 0.5176, Took 1.16 s\n","Epoch [8/100], Loss: 1.0536, Eval Accuracy: 0.5196, Took 1.16 s\n","Epoch [9/100], Loss: 1.0486, Eval Accuracy: 0.5204, Took 1.16 s\n","Epoch [10/100], Loss: 1.0456, Eval Accuracy: 0.522, Took 1.17 s\n","Epoch [11/100], Loss: 1.0435, Eval Accuracy: 0.5184, Took 1.16 s\n","Epoch [12/100], Loss: 1.0409, Eval Accuracy: 0.5198, Took 1.16 s\n","Epoch [13/100], Loss: 1.0407, Eval Accuracy: 0.5218, Took 1.16 s\n","Epoch [14/100], Loss: 1.0382, Eval Accuracy: 0.5218, Took 1.16 s\n","Epoch [15/100], Loss: 1.0381, Eval Accuracy: 0.5199, Took 1.16 s\n","Epoch [16/100], Loss: 1.0368, Eval Accuracy: 0.5222, Took 1.16 s\n","Epoch [17/100], Loss: 1.0367, Eval Accuracy: 0.5226, Took 1.16 s\n","Epoch [18/100], Loss: 1.0349, Eval Accuracy: 0.5226, Took 1.16 s\n","Epoch [19/100], Loss: 1.0345, Eval Accuracy: 0.5231, Took 1.16 s\n","Epoch [20/100], Loss: 1.0347, Eval Accuracy: 0.5209, Took 1.16 s\n","Epoch [21/100], Loss: 1.035, Eval Accuracy: 0.5225, Took 1.16 s\n","Stopped early after epoch 21 as validation accuracy was lower than average of the last 7 accuracies.\n","Last Loss: 1.035, Last Eval Accuracy: 0.5225, Took 24.44 s\n","Model saved as 20240624162003_encoder_64em_2l_4h_05dr_21ep.pt\n","------------\n","Not saved as loss too high:\n","[]\n"]}],"source":["# Train single model\n","EMBED_DIM = [64]\n","NUM_ENCODER_LAYERS = [2]\n","NUM_HEADS = [4]\n","dropouts = [0.5]\n","POS_ENC = [False]\n","accuracies, all_accuracies = e.hyper_parameter_training(EMBED_DIM, NUM_ENCODER_LAYERS, NUM_HEADS, dropouts, POS_ENC, epochs=100)"]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[],"source":["mlh.to_pickle(all_accuracies, data_path+f'/{e.organism}/training_accuracies_encoder.pkl')"]},{"cell_type":"markdown","metadata":{},"source":["#### Dropout"]},{"cell_type":"code","execution_count":34,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["----- Start Training: 256 emb, 4 layers, 4 heads, 0.1 dropout, positional encoding: False, 50 epochs -----\n","Epoch [1/50], Loss: 1.1639, Eval Accuracy: 0.4962, Took 3.68 s\n","Epoch [2/50], Loss: 1.0538, Eval Accuracy: 0.5166, Took 3.68 s\n","Epoch [3/50], Loss: 1.0461, Eval Accuracy: 0.5178, Took 3.69 s\n","Epoch [4/50], Loss: 1.0421, Eval Accuracy: 0.52, Took 3.68 s\n","Epoch [5/50], Loss: 1.0397, Eval Accuracy: 0.5076, Took 3.71 s\n","Epoch [6/50], Loss: 1.0378, Eval Accuracy: 0.5178, Took 3.71 s\n","Epoch [7/50], Loss: 1.0361, Eval Accuracy: 0.5162, Took 3.71 s\n","Epoch [8/50], Loss: 1.0355, Eval Accuracy: 0.5191, Took 3.71 s\n","Epoch [9/50], Loss: 1.0326, Eval Accuracy: 0.5233, Took 3.71 s\n","Epoch [10/50], Loss: 1.0331, Eval Accuracy: 0.5229, Took 3.71 s\n","Epoch [11/50], Loss: 1.0323, Eval Accuracy: 0.5174, Took 3.71 s\n","Epoch [12/50], Loss: 1.0308, Eval Accuracy: 0.5192, Took 3.72 s\n","Epoch [13/50], Loss: 1.031, Eval Accuracy: 0.5226, Took 3.72 s\n","Epoch [14/50], Loss: 1.0299, Eval Accuracy: 0.5203, Took 3.71 s\n","Epoch [15/50], Loss: 1.0305, Eval Accuracy: 0.5211, Took 3.72 s\n","Epoch [16/50], Loss: 1.0291, Eval Accuracy: 0.5183, Took 3.72 s\n","Stopped early after epoch 16 as validation accuracy was lower than average of the last 7 accuracies.\n","Last Loss: 1.0291, Last Eval Accuracy: 0.5183, Took 59.32 s\n","Model saved as 20240603142405_encoder_256em_4l_4h_01dr_16ep.pt\n","----- Start Training: 256 emb, 4 layers, 4 heads, 0.2 dropout, positional encoding: False, 50 epochs -----\n","Epoch [1/50], Loss: 1.173, Eval Accuracy: 0.497, Took 3.71 s\n","Epoch [2/50], Loss: 1.0587, Eval Accuracy: 0.5184, Took 3.72 s\n","Epoch [3/50], Loss: 1.0489, Eval Accuracy: 0.515, Took 3.72 s\n","Epoch [4/50], Loss: 1.0437, Eval Accuracy: 0.5206, Took 3.71 s\n","Epoch [5/50], Loss: 1.0405, Eval Accuracy: 0.5092, Took 3.72 s\n","Epoch [6/50], Loss: 1.0381, Eval Accuracy: 0.5177, Took 3.72 s\n","Epoch [7/50], Loss: 1.0362, Eval Accuracy: 0.5159, Took 3.71 s\n","Epoch [8/50], Loss: 1.0355, Eval Accuracy: 0.5185, Took 3.72 s\n","Epoch [9/50], Loss: 1.0329, Eval Accuracy: 0.5242, Took 3.72 s\n","Epoch [10/50], Loss: 1.0328, Eval Accuracy: 0.5236, Took 3.71 s\n","Epoch [11/50], Loss: 1.0319, Eval Accuracy: 0.5177, Took 3.72 s\n","Epoch [12/50], Loss: 1.0308, Eval Accuracy: 0.5194, Took 3.72 s\n","Epoch [13/50], Loss: 1.0311, Eval Accuracy: 0.523, Took 3.71 s\n","Epoch [14/50], Loss: 1.0297, Eval Accuracy: 0.5208, Took 3.73 s\n","Epoch [15/50], Loss: 1.0304, Eval Accuracy: 0.521, Took 3.72 s\n","Epoch [16/50], Loss: 1.0289, Eval Accuracy: 0.5189, Took 3.72 s\n","Stopped early after epoch 16 as validation accuracy was lower than average of the last 7 accuracies.\n","Last Loss: 1.0289, Last Eval Accuracy: 0.5189, Took 59.49 s\n","Model saved as 20240603142505_encoder_256em_4l_4h_02dr_16ep.pt\n","----- Start Training: 256 emb, 4 layers, 4 heads, 0.3 dropout, positional encoding: False, 50 epochs -----\n","Epoch [1/50], Loss: 1.1835, Eval Accuracy: 0.4922, Took 3.72 s\n","Epoch [2/50], Loss: 1.0628, Eval Accuracy: 0.5202, Took 3.72 s\n","Epoch [3/50], Loss: 1.0509, Eval Accuracy: 0.5133, Took 3.71 s\n","Epoch [4/50], Loss: 1.0445, Eval Accuracy: 0.5207, Took 3.72 s\n","Epoch [5/50], Loss: 1.0408, Eval Accuracy: 0.5116, Took 3.72 s\n","Epoch [6/50], Loss: 1.038, Eval Accuracy: 0.5179, Took 3.71 s\n","Epoch [7/50], Loss: 1.036, Eval Accuracy: 0.5158, Took 3.72 s\n","Epoch [8/50], Loss: 1.0355, Eval Accuracy: 0.5182, Took 3.72 s\n","Epoch [9/50], Loss: 1.0333, Eval Accuracy: 0.5239, Took 3.72 s\n","Epoch [10/50], Loss: 1.0329, Eval Accuracy: 0.5229, Took 3.72 s\n","Epoch [11/50], Loss: 1.032, Eval Accuracy: 0.5175, Took 3.72 s\n","Epoch [12/50], Loss: 1.031, Eval Accuracy: 0.519, Took 3.72 s\n","Epoch [13/50], Loss: 1.0313, Eval Accuracy: 0.5229, Took 3.72 s\n","Epoch [14/50], Loss: 1.0298, Eval Accuracy: 0.5211, Took 3.72 s\n","Epoch [15/50], Loss: 1.0304, Eval Accuracy: 0.5205, Took 3.72 s\n","Epoch [16/50], Loss: 1.0294, Eval Accuracy: 0.5182, Took 3.73 s\n","Stopped early after epoch 16 as validation accuracy was lower than average of the last 7 accuracies.\n","Last Loss: 1.0294, Last Eval Accuracy: 0.5182, Took 59.53 s\n","Model saved as 20240603142604_encoder_256em_4l_4h_03dr_16ep.pt\n","----- Start Training: 256 emb, 4 layers, 4 heads, 0.4 dropout, positional encoding: False, 50 epochs -----\n","Epoch [1/50], Loss: 1.1964, Eval Accuracy: 0.4949, Took 3.73 s\n","Epoch [2/50], Loss: 1.0667, Eval Accuracy: 0.5201, Took 3.72 s\n","Epoch [3/50], Loss: 1.0524, Eval Accuracy: 0.5146, Took 3.72 s\n","Epoch [4/50], Loss: 1.0448, Eval Accuracy: 0.5208, Took 3.72 s\n","Epoch [5/50], Loss: 1.0409, Eval Accuracy: 0.5145, Took 3.72 s\n","Epoch [6/50], Loss: 1.038, Eval Accuracy: 0.5182, Took 3.72 s\n","Epoch [7/50], Loss: 1.0362, Eval Accuracy: 0.5155, Took 3.72 s\n","Epoch [8/50], Loss: 1.0357, Eval Accuracy: 0.5181, Took 3.72 s\n","Epoch [9/50], Loss: 1.0337, Eval Accuracy: 0.524, Took 3.72 s\n","Epoch [10/50], Loss: 1.0332, Eval Accuracy: 0.5227, Took 3.72 s\n","Epoch [11/50], Loss: 1.0322, Eval Accuracy: 0.5175, Took 3.72 s\n","Epoch [12/50], Loss: 1.0313, Eval Accuracy: 0.519, Took 3.72 s\n","Epoch [13/50], Loss: 1.0317, Eval Accuracy: 0.5228, Took 3.72 s\n","Epoch [14/50], Loss: 1.0302, Eval Accuracy: 0.5219, Took 3.72 s\n","Epoch [15/50], Loss: 1.0309, Eval Accuracy: 0.5202, Took 3.72 s\n","Epoch [16/50], Loss: 1.0299, Eval Accuracy: 0.5182, Took 3.72 s\n","Stopped early after epoch 16 as validation accuracy was lower than average of the last 7 accuracies.\n","Last Loss: 1.0299, Last Eval Accuracy: 0.5182, Took 59.54 s\n","Model saved as 20240603142704_encoder_256em_4l_4h_04dr_16ep.pt\n","----- Start Training: 256 emb, 4 layers, 4 heads, 0.5 dropout, positional encoding: False, 50 epochs -----\n","Epoch [1/50], Loss: 1.2133, Eval Accuracy: 0.4983, Took 3.71 s\n","Epoch [2/50], Loss: 1.0712, Eval Accuracy: 0.5184, Took 3.71 s\n","Epoch [3/50], Loss: 1.054, Eval Accuracy: 0.5144, Took 3.7 s\n","Epoch [4/50], Loss: 1.0453, Eval Accuracy: 0.5207, Took 3.7 s\n","Epoch [5/50], Loss: 1.0413, Eval Accuracy: 0.5144, Took 3.69 s\n","Epoch [6/50], Loss: 1.0383, Eval Accuracy: 0.5177, Took 3.7 s\n","Epoch [7/50], Loss: 1.0366, Eval Accuracy: 0.5137, Took 3.7 s\n","Epoch [8/50], Loss: 1.0361, Eval Accuracy: 0.5183, Took 3.7 s\n","Epoch [9/50], Loss: 1.0345, Eval Accuracy: 0.524, Took 3.7 s\n","Epoch [10/50], Loss: 1.0337, Eval Accuracy: 0.5226, Took 3.7 s\n","Epoch [11/50], Loss: 1.0328, Eval Accuracy: 0.5177, Took 3.7 s\n","Epoch [12/50], Loss: 1.0318, Eval Accuracy: 0.519, Took 3.7 s\n","Epoch [13/50], Loss: 1.0322, Eval Accuracy: 0.5223, Took 3.7 s\n","Epoch [14/50], Loss: 1.0308, Eval Accuracy: 0.5222, Took 3.7 s\n","Epoch [15/50], Loss: 1.033, Eval Accuracy: 0.5225, Took 3.7 s\n","Epoch [16/50], Loss: 1.0315, Eval Accuracy: 0.5174, Took 3.71 s\n","Stopped early after epoch 16 as validation accuracy was lower than average of the last 7 accuracies.\n","Last Loss: 1.0315, Last Eval Accuracy: 0.5174, Took 59.23 s\n","Model saved as 20240603142803_encoder_256em_4l_4h_05dr_16ep.pt\n","------------\n","Not saved as loss too high:\n","[]\n"]},{"data":{"text/plain":["{'encoder_256em_4l_4h_01dr_50ep': 0.5183,\n"," 'encoder_256em_4l_4h_02dr_50ep': 0.5189,\n"," 'encoder_256em_4l_4h_03dr_50ep': 0.5182,\n"," 'encoder_256em_4l_4h_04dr_50ep': 0.5182,\n"," 'encoder_256em_4l_4h_05dr_50ep': 0.5174}"]},"execution_count":34,"metadata":{},"output_type":"execute_result"}],"source":["EMBED_DIM = [256]\n","NUM_ENCODER_LAYERS = [4]\n","NUM_HEADS = [4]\n","dropouts = [0.1, 0.2, 0.3, 0.4, 0.5]\n","POS_ENC = [False]\n","e.hyper_parameter_training(EMBED_DIM, NUM_ENCODER_LAYERS, NUM_HEADS, dropouts, POS_ENC)"]},{"cell_type":"markdown","metadata":{},"source":["#### Embedding Dimension"]},{"cell_type":"code","execution_count":35,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["----- Start Training: 16 emb, 4 layers, 4 heads, 0.5 dropout, positional encoding: False, 50 epochs -----\n","Epoch [1/50], Loss: 3.0332, Eval Accuracy: 0.5129, Took 2.03 s\n","Epoch [2/50], Loss: 2.3796, Eval Accuracy: 0.5145, Took 2.02 s\n","Epoch [3/50], Loss: 1.9794, Eval Accuracy: 0.5145, Took 2.02 s\n","Epoch [4/50], Loss: 1.7237, Eval Accuracy: 0.5155, Took 2.03 s\n","Epoch [5/50], Loss: 1.5641, Eval Accuracy: 0.5155, Took 2.02 s\n","Epoch [6/50], Loss: 1.4599, Eval Accuracy: 0.5145, Took 2.02 s\n","Epoch [7/50], Loss: 1.3854, Eval Accuracy: 0.5155, Took 2.02 s\n","Epoch [8/50], Loss: 1.3323, Eval Accuracy: 0.5155, Took 2.02 s\n","Epoch [9/50], Loss: 1.291, Eval Accuracy: 0.5155, Took 2.03 s\n","Epoch [10/50], Loss: 1.2609, Eval Accuracy: 0.5155, Took 2.03 s\n","Epoch [11/50], Loss: 1.2362, Eval Accuracy: 0.5155, Took 2.03 s\n","Epoch [12/50], Loss: 1.2157, Eval Accuracy: 0.5155, Took 2.03 s\n","Epoch [13/50], Loss: 1.2004, Eval Accuracy: 0.5155, Took 2.03 s\n","Epoch [14/50], Loss: 1.1867, Eval Accuracy: 0.5155, Took 2.03 s\n","Epoch [15/50], Loss: 1.1766, Eval Accuracy: 0.5155, Took 2.03 s\n","Epoch [16/50], Loss: 1.1675, Eval Accuracy: 0.5155, Took 2.03 s\n","Epoch [17/50], Loss: 1.1607, Eval Accuracy: 0.5155, Took 2.03 s\n","Epoch [18/50], Loss: 1.1536, Eval Accuracy: 0.5145, Took 2.03 s\n","Stopped early after epoch 18 as validation accuracy was lower than average of the last 7 accuracies.\n","Last Loss: 1.1536, Last Eval Accuracy: 0.5145, Took 36.47 s\n","Model saved as 20240603143100_encoder_16em_4l_4h_05dr_18ep.pt\n","----- Start Training: 32 emb, 4 layers, 4 heads, 0.5 dropout, positional encoding: False, 50 epochs -----\n","Epoch [1/50], Loss: 2.3956, Eval Accuracy: 0.5112, Took 2.07 s\n","Epoch [2/50], Loss: 1.641, Eval Accuracy: 0.5155, Took 2.07 s\n","Epoch [3/50], Loss: 1.3713, Eval Accuracy: 0.5155, Took 2.08 s\n","Epoch [4/50], Loss: 1.2538, Eval Accuracy: 0.5154, Took 2.07 s\n","Epoch [5/50], Loss: 1.1901, Eval Accuracy: 0.5152, Took 2.08 s\n","Epoch [6/50], Loss: 1.1515, Eval Accuracy: 0.516, Took 2.08 s\n","Epoch [7/50], Loss: 1.1238, Eval Accuracy: 0.5164, Took 2.08 s\n","Epoch [8/50], Loss: 1.1059, Eval Accuracy: 0.516, Took 2.08 s\n","Epoch [9/50], Loss: 1.0911, Eval Accuracy: 0.5164, Took 2.08 s\n","Epoch [10/50], Loss: 1.0817, Eval Accuracy: 0.516, Took 2.08 s\n","Epoch [11/50], Loss: 1.0745, Eval Accuracy: 0.5167, Took 2.08 s\n","Epoch [12/50], Loss: 1.0685, Eval Accuracy: 0.5172, Took 2.08 s\n","Epoch [13/50], Loss: 1.0655, Eval Accuracy: 0.5169, Took 2.08 s\n","Epoch [14/50], Loss: 1.0611, Eval Accuracy: 0.5173, Took 2.08 s\n","Epoch [15/50], Loss: 1.0591, Eval Accuracy: 0.5165, Took 2.08 s\n","Epoch [16/50], Loss: 1.0554, Eval Accuracy: 0.5179, Took 2.07 s\n","Epoch [17/50], Loss: 1.054, Eval Accuracy: 0.5175, Took 2.07 s\n","Epoch [18/50], Loss: 1.0515, Eval Accuracy: 0.5175, Took 2.07 s\n","Epoch [19/50], Loss: 1.0504, Eval Accuracy: 0.5187, Took 2.07 s\n","Epoch [20/50], Loss: 1.0492, Eval Accuracy: 0.5176, Took 2.07 s\n","Epoch [21/50], Loss: 1.049, Eval Accuracy: 0.5183, Took 2.07 s\n","Epoch [22/50], Loss: 1.0466, Eval Accuracy: 0.5178, Took 2.08 s\n","Epoch [23/50], Loss: 1.047, Eval Accuracy: 0.5181, Took 2.08 s\n","Epoch [24/50], Loss: 1.0454, Eval Accuracy: 0.5196, Took 2.08 s\n","Epoch [25/50], Loss: 1.0446, Eval Accuracy: 0.5222, Took 2.08 s\n","Epoch [26/50], Loss: 1.0447, Eval Accuracy: 0.5213, Took 2.08 s\n","Epoch [27/50], Loss: 1.0441, Eval Accuracy: 0.5198, Took 2.08 s\n","Epoch [28/50], Loss: 1.0431, Eval Accuracy: 0.5199, Took 2.08 s\n","Epoch [29/50], Loss: 1.0432, Eval Accuracy: 0.521, Took 2.08 s\n","Epoch [30/50], Loss: 1.0419, Eval Accuracy: 0.5203, Took 2.08 s\n","Epoch [31/50], Loss: 1.042, Eval Accuracy: 0.5199, Took 2.08 s\n","Stopped early after epoch 31 as validation accuracy was lower than average of the last 7 accuracies.\n","Last Loss: 1.042, Last Eval Accuracy: 0.5199, Took 64.43 s\n","Model saved as 20240603143205_encoder_32em_4l_4h_05dr_31ep.pt\n","----- Start Training: 64 emb, 4 layers, 4 heads, 0.5 dropout, positional encoding: False, 50 epochs -----\n","Epoch [1/50], Loss: 1.7575, Eval Accuracy: 0.5149, Took 2.2 s\n","Epoch [2/50], Loss: 1.2396, Eval Accuracy: 0.5146, Took 2.2 s\n","Epoch [3/50], Loss: 1.1453, Eval Accuracy: 0.5151, Took 2.2 s\n","Epoch [4/50], Loss: 1.1037, Eval Accuracy: 0.5177, Took 2.2 s\n","Epoch [5/50], Loss: 1.0812, Eval Accuracy: 0.5164, Took 2.21 s\n","Epoch [6/50], Loss: 1.0673, Eval Accuracy: 0.5163, Took 2.2 s\n","Epoch [7/50], Loss: 1.0583, Eval Accuracy: 0.5161, Took 2.2 s\n","Epoch [8/50], Loss: 1.0529, Eval Accuracy: 0.5177, Took 2.2 s\n","Epoch [9/50], Loss: 1.0481, Eval Accuracy: 0.521, Took 2.21 s\n","Epoch [10/50], Loss: 1.045, Eval Accuracy: 0.5228, Took 2.2 s\n","Epoch [11/50], Loss: 1.0425, Eval Accuracy: 0.5182, Took 2.2 s\n","Epoch [12/50], Loss: 1.0404, Eval Accuracy: 0.5198, Took 2.2 s\n","Epoch [13/50], Loss: 1.0405, Eval Accuracy: 0.5229, Took 2.21 s\n","Epoch [14/50], Loss: 1.0376, Eval Accuracy: 0.5228, Took 2.2 s\n","Epoch [15/50], Loss: 1.0374, Eval Accuracy: 0.5195, Took 2.2 s\n","Epoch [16/50], Loss: 1.0363, Eval Accuracy: 0.5231, Took 2.2 s\n","Epoch [17/50], Loss: 1.0359, Eval Accuracy: 0.5227, Took 2.21 s\n","Epoch [18/50], Loss: 1.0348, Eval Accuracy: 0.5212, Took 2.2 s\n","Epoch [19/50], Loss: 1.0344, Eval Accuracy: 0.5223, Took 2.2 s\n","Epoch [20/50], Loss: 1.0343, Eval Accuracy: 0.5219, Took 2.2 s\n","Stopped early after epoch 20 as validation accuracy was lower than average of the last 7 accuracies.\n","Last Loss: 1.0343, Last Eval Accuracy: 0.5219, Took 44.08 s\n","Model saved as 20240603143249_encoder_64em_4l_4h_05dr_20ep.pt\n","----- Start Training: 128 emb, 4 layers, 4 heads, 0.5 dropout, positional encoding: False, 50 epochs -----\n","Epoch [1/50], Loss: 1.3783, Eval Accuracy: 0.5171, Took 2.51 s\n","Epoch [2/50], Loss: 1.109, Eval Accuracy: 0.5169, Took 2.52 s\n","Epoch [3/50], Loss: 1.0744, Eval Accuracy: 0.5121, Took 2.51 s\n","Epoch [4/50], Loss: 1.0582, Eval Accuracy: 0.5202, Took 2.51 s\n","Epoch [5/50], Loss: 1.0496, Eval Accuracy: 0.5191, Took 2.51 s\n","Epoch [6/50], Loss: 1.0446, Eval Accuracy: 0.5169, Took 2.51 s\n","Epoch [7/50], Loss: 1.0412, Eval Accuracy: 0.5123, Took 2.51 s\n","Epoch [8/50], Loss: 1.0394, Eval Accuracy: 0.5195, Took 2.51 s\n","Stopped early after epoch 8 as validation accuracy was lower than average of the last 7 accuracies.\n","Last Loss: 1.0394, Last Eval Accuracy: 0.5195, Took 20.1 s\n","Model saved as 20240603143309_encoder_128em_4l_4h_05dr_8ep.pt\n","----- Start Training: 256 emb, 4 layers, 4 heads, 0.5 dropout, positional encoding: False, 50 epochs -----\n","Epoch [1/50], Loss: 1.2133, Eval Accuracy: 0.4983, Took 3.72 s\n","Epoch [2/50], Loss: 1.0712, Eval Accuracy: 0.5184, Took 3.72 s\n","Epoch [3/50], Loss: 1.054, Eval Accuracy: 0.5144, Took 3.72 s\n","Epoch [4/50], Loss: 1.0453, Eval Accuracy: 0.5207, Took 3.71 s\n","Epoch [5/50], Loss: 1.0413, Eval Accuracy: 0.5144, Took 3.72 s\n","Epoch [6/50], Loss: 1.0383, Eval Accuracy: 0.5177, Took 3.72 s\n","Epoch [7/50], Loss: 1.0366, Eval Accuracy: 0.5137, Took 3.72 s\n","Epoch [8/50], Loss: 1.0361, Eval Accuracy: 0.5183, Took 3.72 s\n","Epoch [9/50], Loss: 1.0345, Eval Accuracy: 0.524, Took 3.72 s\n","Epoch [10/50], Loss: 1.0337, Eval Accuracy: 0.5226, Took 3.72 s\n","Epoch [11/50], Loss: 1.0328, Eval Accuracy: 0.5177, Took 3.71 s\n","Epoch [12/50], Loss: 1.0318, Eval Accuracy: 0.519, Took 3.7 s\n","Epoch [13/50], Loss: 1.0322, Eval Accuracy: 0.5223, Took 3.69 s\n","Epoch [14/50], Loss: 1.0308, Eval Accuracy: 0.5222, Took 3.7 s\n","Epoch [15/50], Loss: 1.033, Eval Accuracy: 0.5225, Took 3.7 s\n","Epoch [16/50], Loss: 1.0315, Eval Accuracy: 0.5174, Took 3.7 s\n","Stopped early after epoch 16 as validation accuracy was lower than average of the last 7 accuracies.\n","Last Loss: 1.0315, Last Eval Accuracy: 0.5174, Took 59.38 s\n","Model saved as 20240603143408_encoder_256em_4l_4h_05dr_16ep.pt\n","----- Start Training: 512 emb, 4 layers, 4 heads, 0.5 dropout, positional encoding: False, 50 epochs -----\n","Epoch [1/50], Loss: 1.1683, Eval Accuracy: 0.4891, Took 6.86 s\n","Epoch [2/50], Loss: 1.0637, Eval Accuracy: 0.52, Took 6.86 s\n","Epoch [3/50], Loss: 1.0497, Eval Accuracy: 0.5158, Took 6.87 s\n","Epoch [4/50], Loss: 1.0434, Eval Accuracy: 0.5201, Took 6.86 s\n","Epoch [5/50], Loss: 1.0399, Eval Accuracy: 0.5002, Took 6.85 s\n","Epoch [6/50], Loss: 1.0382, Eval Accuracy: 0.5178, Took 6.87 s\n","Epoch [7/50], Loss: 1.0366, Eval Accuracy: 0.516, Took 6.88 s\n","Epoch [8/50], Loss: 1.036, Eval Accuracy: 0.5175, Took 6.89 s\n","Epoch [9/50], Loss: 1.0337, Eval Accuracy: 0.5241, Took 6.86 s\n","Epoch [10/50], Loss: 1.0339, Eval Accuracy: 0.5215, Took 6.86 s\n","Epoch [11/50], Loss: 1.0335, Eval Accuracy: 0.518, Took 6.87 s\n","Epoch [12/50], Loss: 1.0325, Eval Accuracy: 0.5218, Took 6.87 s\n","Epoch [13/50], Loss: 1.0328, Eval Accuracy: 0.5218, Took 6.88 s\n","Epoch [14/50], Loss: 1.0328, Eval Accuracy: 0.5203, Took 6.89 s\n","Epoch [15/50], Loss: 1.0351, Eval Accuracy: 0.5211, Took 6.87 s\n","Epoch [16/50], Loss: 1.0335, Eval Accuracy: 0.506, Took 6.9 s\n","Stopped early after epoch 16 as validation accuracy was lower than average of the last 7 accuracies.\n","Last Loss: 1.0335, Last Eval Accuracy: 0.506, Took 109.96 s\n","Model saved as 20240603143558_encoder_512em_4l_4h_05dr_16ep.pt\n","------------\n","Not saved as loss too high:\n","[]\n"]},{"data":{"text/plain":["{'encoder_16em_4l_4h_05dr_50ep': 0.5145,\n"," 'encoder_32em_4l_4h_05dr_50ep': 0.5199,\n"," 'encoder_64em_4l_4h_05dr_50ep': 0.5219,\n"," 'encoder_128em_4l_4h_05dr_50ep': 0.5195,\n"," 'encoder_256em_4l_4h_05dr_50ep': 0.5174,\n"," 'encoder_512em_4l_4h_05dr_50ep': 0.506}"]},"execution_count":35,"metadata":{},"output_type":"execute_result"}],"source":["embed_dims = [16, 32, 64, 128, 256, 512]\n","NUM_ENCODER_LAYERS = [4]\n","NUM_HEADS = [4]\n","DROPOUTS = [0.5]\n","POS_ENC = [False]\n","e.hyper_parameter_training(embed_dims, NUM_ENCODER_LAYERS, NUM_HEADS, DROPOUTS, POS_ENC)"]},{"cell_type":"markdown","metadata":{},"source":["#### Number Encoder Layers and Heads"]},{"cell_type":"code","execution_count":36,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/mkuehn/.local/lib/python3.10/site-packages/torch/nn/modules/transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n","  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"]},{"name":"stdout","output_type":"stream","text":["----- Start Training: 64 emb, 1 layers, 1 heads, 0.5 dropout, positional encoding: False, 50 epochs -----\n","Epoch [1/50], Loss: 1.8965, Eval Accuracy: 0.5156, Took 0.51 s\n","Epoch [2/50], Loss: 1.2653, Eval Accuracy: 0.5155, Took 0.51 s\n","Epoch [3/50], Loss: 1.1597, Eval Accuracy: 0.5155, Took 0.51 s\n","Epoch [4/50], Loss: 1.1151, Eval Accuracy: 0.5155, Took 0.51 s\n","Epoch [5/50], Loss: 1.0909, Eval Accuracy: 0.5166, Took 0.51 s\n","Epoch [6/50], Loss: 1.0769, Eval Accuracy: 0.5145, Took 0.5 s\n","Epoch [7/50], Loss: 1.0671, Eval Accuracy: 0.5152, Took 0.51 s\n","Epoch [8/50], Loss: 1.0622, Eval Accuracy: 0.5154, Took 0.51 s\n","Stopped early after epoch 8 as validation accuracy was lower than average of the last 7 accuracies.\n","Last Loss: 1.0622, Last Eval Accuracy: 0.5154, Took 4.05 s\n","Model saved as 20240603143811_encoder_64em_1l_1h_05dr_8ep.pt\n","----- Start Training: 64 emb, 1 layers, 2 heads, 0.5 dropout, positional encoding: False, 50 epochs -----\n","Epoch [1/50], Loss: 1.8958, Eval Accuracy: 0.5162, Took 0.55 s\n","Epoch [2/50], Loss: 1.2656, Eval Accuracy: 0.5155, Took 0.55 s\n","Epoch [3/50], Loss: 1.1588, Eval Accuracy: 0.5161, Took 0.55 s\n","Epoch [4/50], Loss: 1.1144, Eval Accuracy: 0.5157, Took 0.55 s\n","Epoch [5/50], Loss: 1.0906, Eval Accuracy: 0.5146, Took 0.55 s\n","Epoch [6/50], Loss: 1.0764, Eval Accuracy: 0.5146, Took 0.56 s\n","Epoch [7/50], Loss: 1.0666, Eval Accuracy: 0.5148, Took 0.55 s\n","Epoch [8/50], Loss: 1.0613, Eval Accuracy: 0.516, Took 0.55 s\n","Stopped early after epoch 8 as validation accuracy was lower than average of the last 7 accuracies.\n","Last Loss: 1.0613, Last Eval Accuracy: 0.516, Took 4.41 s\n","Model saved as 20240603143816_encoder_64em_1l_2h_05dr_8ep.pt\n","----- Start Training: 64 emb, 1 layers, 4 heads, 0.5 dropout, positional encoding: False, 50 epochs -----\n","Epoch [1/50], Loss: 1.896, Eval Accuracy: 0.5154, Took 0.62 s\n","Epoch [2/50], Loss: 1.265, Eval Accuracy: 0.5155, Took 0.62 s\n","Epoch [3/50], Loss: 1.1592, Eval Accuracy: 0.5156, Took 0.63 s\n","Epoch [4/50], Loss: 1.1132, Eval Accuracy: 0.5155, Took 0.63 s\n","Epoch [5/50], Loss: 1.0901, Eval Accuracy: 0.5167, Took 0.62 s\n","Epoch [6/50], Loss: 1.0757, Eval Accuracy: 0.515, Took 0.62 s\n","Epoch [7/50], Loss: 1.0654, Eval Accuracy: 0.5147, Took 0.63 s\n","Epoch [8/50], Loss: 1.06, Eval Accuracy: 0.5165, Took 0.63 s\n","Stopped early after epoch 8 as validation accuracy was lower than average of the last 7 accuracies.\n","Last Loss: 1.06, Last Eval Accuracy: 0.5165, Took 5.01 s\n","Model saved as 20240603143821_encoder_64em_1l_4h_05dr_8ep.pt\n","----- Start Training: 64 emb, 1 layers, 8 heads, 0.5 dropout, positional encoding: False, 50 epochs -----\n","Epoch [1/50], Loss: 1.8966, Eval Accuracy: 0.515, Took 0.78 s\n","Epoch [2/50], Loss: 1.265, Eval Accuracy: 0.5155, Took 0.78 s\n","Epoch [3/50], Loss: 1.1581, Eval Accuracy: 0.5156, Took 0.78 s\n","Epoch [4/50], Loss: 1.1135, Eval Accuracy: 0.5155, Took 0.78 s\n","Epoch [5/50], Loss: 1.0893, Eval Accuracy: 0.5152, Took 0.78 s\n","Epoch [6/50], Loss: 1.0751, Eval Accuracy: 0.5154, Took 0.78 s\n","Epoch [7/50], Loss: 1.0648, Eval Accuracy: 0.5142, Took 0.78 s\n","Epoch [8/50], Loss: 1.0595, Eval Accuracy: 0.5173, Took 0.78 s\n","Epoch [9/50], Loss: 1.0534, Eval Accuracy: 0.5184, Took 0.78 s\n","Epoch [10/50], Loss: 1.0505, Eval Accuracy: 0.5192, Took 0.78 s\n","Epoch [11/50], Loss: 1.0478, Eval Accuracy: 0.518, Took 0.78 s\n","Epoch [12/50], Loss: 1.0449, Eval Accuracy: 0.5183, Took 0.78 s\n","Epoch [13/50], Loss: 1.0445, Eval Accuracy: 0.5192, Took 0.78 s\n","Epoch [14/50], Loss: 1.0425, Eval Accuracy: 0.5175, Took 0.78 s\n","Epoch [15/50], Loss: 1.0414, Eval Accuracy: 0.5187, Took 0.78 s\n","Stopped early after epoch 15 as validation accuracy was lower than average of the last 7 accuracies.\n","Last Loss: 1.0414, Last Eval Accuracy: 0.5187, Took 11.73 s\n","Model saved as 20240603143832_encoder_64em_1l_8h_05dr_15ep.pt\n","----- Start Training: 64 emb, 2 layers, 1 heads, 0.5 dropout, positional encoding: False, 50 epochs -----\n","Epoch [1/50], Loss: 1.796, Eval Accuracy: 0.5147, Took 0.89 s\n","Epoch [2/50], Loss: 1.2471, Eval Accuracy: 0.5146, Took 0.89 s\n","Epoch [3/50], Loss: 1.1491, Eval Accuracy: 0.5161, Took 0.89 s\n","Epoch [4/50], Loss: 1.1068, Eval Accuracy: 0.5168, Took 0.89 s\n","Epoch [5/50], Loss: 1.0838, Eval Accuracy: 0.5191, Took 0.89 s\n","Epoch [6/50], Loss: 1.0693, Eval Accuracy: 0.5168, Took 0.89 s\n","Epoch [7/50], Loss: 1.0596, Eval Accuracy: 0.516, Took 0.89 s\n","Epoch [8/50], Loss: 1.0542, Eval Accuracy: 0.5203, Took 0.89 s\n","Epoch [9/50], Loss: 1.0492, Eval Accuracy: 0.5199, Took 0.9 s\n","Epoch [10/50], Loss: 1.0464, Eval Accuracy: 0.5208, Took 0.9 s\n","Epoch [11/50], Loss: 1.0442, Eval Accuracy: 0.5179, Took 0.9 s\n","Epoch [12/50], Loss: 1.0416, Eval Accuracy: 0.5193, Took 0.9 s\n","Epoch [13/50], Loss: 1.0411, Eval Accuracy: 0.5221, Took 0.9 s\n","Epoch [14/50], Loss: 1.0387, Eval Accuracy: 0.5224, Took 0.9 s\n","Epoch [15/50], Loss: 1.0387, Eval Accuracy: 0.5204, Took 0.9 s\n","Epoch [16/50], Loss: 1.0373, Eval Accuracy: 0.5225, Took 0.9 s\n","Epoch [17/50], Loss: 1.0371, Eval Accuracy: 0.5228, Took 0.9 s\n","Epoch [18/50], Loss: 1.0352, Eval Accuracy: 0.5232, Took 0.9 s\n","Epoch [19/50], Loss: 1.0349, Eval Accuracy: 0.5232, Took 0.9 s\n","Epoch [20/50], Loss: 1.0347, Eval Accuracy: 0.5217, Took 0.9 s\n","Epoch [21/50], Loss: 1.0354, Eval Accuracy: 0.5221, Took 0.9 s\n","Stopped early after epoch 21 as validation accuracy was lower than average of the last 7 accuracies.\n","Last Loss: 1.0354, Last Eval Accuracy: 0.5221, Took 18.8 s\n","Model saved as 20240603143851_encoder_64em_2l_1h_05dr_21ep.pt\n","----- Start Training: 64 emb, 2 layers, 2 heads, 0.5 dropout, positional encoding: False, 50 epochs -----\n","Epoch [1/50], Loss: 1.7955, Eval Accuracy: 0.5148, Took 0.98 s\n","Epoch [2/50], Loss: 1.2463, Eval Accuracy: 0.5146, Took 0.98 s\n","Epoch [3/50], Loss: 1.1496, Eval Accuracy: 0.516, Took 0.98 s\n","Epoch [4/50], Loss: 1.1062, Eval Accuracy: 0.5167, Took 0.98 s\n","Epoch [5/50], Loss: 1.083, Eval Accuracy: 0.52, Took 0.98 s\n","Epoch [6/50], Loss: 1.069, Eval Accuracy: 0.5163, Took 0.98 s\n","Epoch [7/50], Loss: 1.0589, Eval Accuracy: 0.5158, Took 0.98 s\n","Epoch [8/50], Loss: 1.0539, Eval Accuracy: 0.5208, Took 0.98 s\n","Epoch [9/50], Loss: 1.0487, Eval Accuracy: 0.5209, Took 0.98 s\n","Epoch [10/50], Loss: 1.0458, Eval Accuracy: 0.523, Took 0.98 s\n","Epoch [11/50], Loss: 1.0432, Eval Accuracy: 0.5177, Took 0.98 s\n","Epoch [12/50], Loss: 1.0413, Eval Accuracy: 0.5198, Took 0.98 s\n","Stopped early after epoch 12 as validation accuracy was lower than average of the last 7 accuracies.\n","Last Loss: 1.0413, Last Eval Accuracy: 0.5198, Took 11.77 s\n","Model saved as 20240603143903_encoder_64em_2l_2h_05dr_12ep.pt\n","----- Start Training: 64 emb, 2 layers, 4 heads, 0.5 dropout, positional encoding: False, 50 epochs -----\n","Epoch [1/50], Loss: 1.7964, Eval Accuracy: 0.5155, Took 1.14 s\n","Epoch [2/50], Loss: 1.2462, Eval Accuracy: 0.5146, Took 1.14 s\n","Epoch [3/50], Loss: 1.1489, Eval Accuracy: 0.5153, Took 1.14 s\n","Epoch [4/50], Loss: 1.1064, Eval Accuracy: 0.5166, Took 1.14 s\n","Epoch [5/50], Loss: 1.083, Eval Accuracy: 0.5186, Took 1.14 s\n","Epoch [6/50], Loss: 1.0689, Eval Accuracy: 0.5166, Took 1.15 s\n","Epoch [7/50], Loss: 1.0594, Eval Accuracy: 0.5176, Took 1.14 s\n","Epoch [8/50], Loss: 1.0536, Eval Accuracy: 0.5196, Took 1.14 s\n","Epoch [9/50], Loss: 1.0486, Eval Accuracy: 0.5204, Took 1.15 s\n","Epoch [10/50], Loss: 1.0456, Eval Accuracy: 0.522, Took 1.14 s\n","Epoch [11/50], Loss: 1.0435, Eval Accuracy: 0.5184, Took 1.14 s\n","Epoch [12/50], Loss: 1.0409, Eval Accuracy: 0.5198, Took 1.14 s\n","Epoch [13/50], Loss: 1.0407, Eval Accuracy: 0.5218, Took 1.14 s\n","Epoch [14/50], Loss: 1.0382, Eval Accuracy: 0.5218, Took 1.14 s\n","Epoch [15/50], Loss: 1.0381, Eval Accuracy: 0.5199, Took 1.14 s\n","Epoch [16/50], Loss: 1.0368, Eval Accuracy: 0.5222, Took 1.15 s\n","Epoch [17/50], Loss: 1.0367, Eval Accuracy: 0.5226, Took 1.14 s\n","Epoch [18/50], Loss: 1.0349, Eval Accuracy: 0.5226, Took 1.14 s\n","Epoch [19/50], Loss: 1.0345, Eval Accuracy: 0.5231, Took 1.15 s\n","Epoch [20/50], Loss: 1.0347, Eval Accuracy: 0.5209, Took 1.14 s\n","Epoch [21/50], Loss: 1.035, Eval Accuracy: 0.5225, Took 1.14 s\n","Stopped early after epoch 21 as validation accuracy was lower than average of the last 7 accuracies.\n","Last Loss: 1.035, Last Eval Accuracy: 0.5225, Took 24.03 s\n","Model saved as 20240603143927_encoder_64em_2l_4h_05dr_21ep.pt\n","----- Start Training: 64 emb, 2 layers, 8 heads, 0.5 dropout, positional encoding: False, 50 epochs -----\n","Epoch [1/50], Loss: 1.7956, Eval Accuracy: 0.5156, Took 1.48 s\n","Epoch [2/50], Loss: 1.2456, Eval Accuracy: 0.5145, Took 1.48 s\n","Epoch [3/50], Loss: 1.1489, Eval Accuracy: 0.516, Took 1.48 s\n","Epoch [4/50], Loss: 1.1066, Eval Accuracy: 0.5166, Took 1.49 s\n","Epoch [5/50], Loss: 1.0831, Eval Accuracy: 0.5198, Took 1.49 s\n","Epoch [6/50], Loss: 1.0687, Eval Accuracy: 0.5166, Took 1.48 s\n","Epoch [7/50], Loss: 1.0591, Eval Accuracy: 0.5159, Took 1.49 s\n","Epoch [8/50], Loss: 1.0537, Eval Accuracy: 0.5201, Took 1.5 s\n","Epoch [9/50], Loss: 1.0486, Eval Accuracy: 0.5213, Took 1.49 s\n","Epoch [10/50], Loss: 1.0451, Eval Accuracy: 0.5223, Took 1.5 s\n","Epoch [11/50], Loss: 1.0434, Eval Accuracy: 0.5193, Took 1.5 s\n","Epoch [12/50], Loss: 1.0406, Eval Accuracy: 0.5208, Took 1.49 s\n","Epoch [13/50], Loss: 1.0405, Eval Accuracy: 0.5227, Took 1.49 s\n","Epoch [14/50], Loss: 1.0381, Eval Accuracy: 0.5228, Took 1.5 s\n","Epoch [15/50], Loss: 1.0381, Eval Accuracy: 0.5203, Took 1.49 s\n","Epoch [16/50], Loss: 1.0369, Eval Accuracy: 0.5222, Took 1.49 s\n","Stopped early after epoch 16 as validation accuracy was lower than average of the last 7 accuracies.\n","Last Loss: 1.0369, Last Eval Accuracy: 0.5222, Took 23.84 s\n","Model saved as 20240603143951_encoder_64em_2l_8h_05dr_16ep.pt\n","----- Start Training: 64 emb, 4 layers, 1 heads, 0.5 dropout, positional encoding: False, 50 epochs -----\n","Epoch [1/50], Loss: 1.7575, Eval Accuracy: 0.5138, Took 1.72 s\n","Epoch [2/50], Loss: 1.2396, Eval Accuracy: 0.5151, Took 1.7 s\n","Epoch [3/50], Loss: 1.1461, Eval Accuracy: 0.5158, Took 1.7 s\n","Epoch [4/50], Loss: 1.1042, Eval Accuracy: 0.5167, Took 1.7 s\n","Epoch [5/50], Loss: 1.0809, Eval Accuracy: 0.5161, Took 1.7 s\n","Epoch [6/50], Loss: 1.0677, Eval Accuracy: 0.5158, Took 1.7 s\n","Epoch [7/50], Loss: 1.0582, Eval Accuracy: 0.5175, Took 1.69 s\n","Epoch [8/50], Loss: 1.0527, Eval Accuracy: 0.5193, Took 1.69 s\n","Epoch [9/50], Loss: 1.0482, Eval Accuracy: 0.5212, Took 1.7 s\n","Epoch [10/50], Loss: 1.0451, Eval Accuracy: 0.5224, Took 1.7 s\n","Epoch [11/50], Loss: 1.0428, Eval Accuracy: 0.5178, Took 1.71 s\n","Epoch [12/50], Loss: 1.0407, Eval Accuracy: 0.5183, Took 1.76 s\n","Epoch [13/50], Loss: 1.0406, Eval Accuracy: 0.5226, Took 1.76 s\n","Epoch [14/50], Loss: 1.0379, Eval Accuracy: 0.5229, Took 1.75 s\n","Epoch [15/50], Loss: 1.0381, Eval Accuracy: 0.52, Took 1.74 s\n","Epoch [16/50], Loss: 1.0364, Eval Accuracy: 0.5227, Took 1.74 s\n","Epoch [17/50], Loss: 1.0367, Eval Accuracy: 0.523, Took 1.74 s\n","Epoch [18/50], Loss: 1.0347, Eval Accuracy: 0.5219, Took 1.74 s\n","Epoch [19/50], Loss: 1.0344, Eval Accuracy: 0.5219, Took 1.75 s\n","Epoch [20/50], Loss: 1.0344, Eval Accuracy: 0.5214, Took 1.75 s\n","Stopped early after epoch 20 as validation accuracy was lower than average of the last 7 accuracies.\n","Last Loss: 1.0344, Last Eval Accuracy: 0.5214, Took 34.43 s\n","Model saved as 20240603144025_encoder_64em_4l_1h_05dr_20ep.pt\n","----- Start Training: 64 emb, 4 layers, 2 heads, 0.5 dropout, positional encoding: False, 50 epochs -----\n","Epoch [1/50], Loss: 1.7554, Eval Accuracy: 0.515, Took 1.9 s\n","Epoch [2/50], Loss: 1.2395, Eval Accuracy: 0.5145, Took 1.87 s\n","Epoch [3/50], Loss: 1.1458, Eval Accuracy: 0.517, Took 1.87 s\n","Epoch [4/50], Loss: 1.1043, Eval Accuracy: 0.5175, Took 1.87 s\n","Epoch [5/50], Loss: 1.0816, Eval Accuracy: 0.5184, Took 1.87 s\n","Epoch [6/50], Loss: 1.0679, Eval Accuracy: 0.5168, Took 1.87 s\n","Epoch [7/50], Loss: 1.0582, Eval Accuracy: 0.5165, Took 1.87 s\n","Epoch [8/50], Loss: 1.0527, Eval Accuracy: 0.5189, Took 1.87 s\n","Epoch [9/50], Loss: 1.0482, Eval Accuracy: 0.5218, Took 1.87 s\n","Epoch [10/50], Loss: 1.0446, Eval Accuracy: 0.5229, Took 1.87 s\n","Epoch [11/50], Loss: 1.0426, Eval Accuracy: 0.5186, Took 1.87 s\n","Epoch [12/50], Loss: 1.0404, Eval Accuracy: 0.519, Took 1.87 s\n","Epoch [13/50], Loss: 1.0406, Eval Accuracy: 0.5232, Took 1.87 s\n","Epoch [14/50], Loss: 1.0376, Eval Accuracy: 0.5228, Took 1.87 s\n","Epoch [15/50], Loss: 1.0377, Eval Accuracy: 0.5212, Took 1.87 s\n","Epoch [16/50], Loss: 1.0365, Eval Accuracy: 0.5232, Took 1.87 s\n","Epoch [17/50], Loss: 1.0363, Eval Accuracy: 0.523, Took 1.87 s\n","Epoch [18/50], Loss: 1.0348, Eval Accuracy: 0.5208, Took 1.87 s\n","Epoch [19/50], Loss: 1.0342, Eval Accuracy: 0.5228, Took 1.87 s\n","Stopped early after epoch 19 as validation accuracy was lower than average of the last 7 accuracies.\n","Last Loss: 1.0342, Last Eval Accuracy: 0.5228, Took 35.59 s\n","Model saved as 20240603144101_encoder_64em_4l_2h_05dr_19ep.pt\n","----- Start Training: 64 emb, 4 layers, 4 heads, 0.5 dropout, positional encoding: False, 50 epochs -----\n","Epoch [1/50], Loss: 1.7575, Eval Accuracy: 0.5149, Took 2.2 s\n","Epoch [2/50], Loss: 1.2396, Eval Accuracy: 0.5146, Took 2.2 s\n","Epoch [3/50], Loss: 1.1453, Eval Accuracy: 0.5151, Took 2.2 s\n","Epoch [4/50], Loss: 1.1037, Eval Accuracy: 0.5177, Took 2.2 s\n","Epoch [5/50], Loss: 1.0812, Eval Accuracy: 0.5164, Took 2.2 s\n","Epoch [6/50], Loss: 1.0673, Eval Accuracy: 0.5163, Took 2.21 s\n","Epoch [7/50], Loss: 1.0583, Eval Accuracy: 0.5161, Took 2.2 s\n","Epoch [8/50], Loss: 1.0529, Eval Accuracy: 0.5177, Took 2.2 s\n","Epoch [9/50], Loss: 1.0481, Eval Accuracy: 0.521, Took 2.2 s\n","Epoch [10/50], Loss: 1.045, Eval Accuracy: 0.5228, Took 2.2 s\n","Epoch [11/50], Loss: 1.0425, Eval Accuracy: 0.5182, Took 2.2 s\n","Epoch [12/50], Loss: 1.0404, Eval Accuracy: 0.5198, Took 2.21 s\n","Epoch [13/50], Loss: 1.0405, Eval Accuracy: 0.5229, Took 2.2 s\n","Epoch [14/50], Loss: 1.0376, Eval Accuracy: 0.5228, Took 2.2 s\n","Epoch [15/50], Loss: 1.0374, Eval Accuracy: 0.5195, Took 2.2 s\n","Epoch [16/50], Loss: 1.0363, Eval Accuracy: 0.5231, Took 2.21 s\n","Epoch [17/50], Loss: 1.0359, Eval Accuracy: 0.5227, Took 2.2 s\n","Epoch [18/50], Loss: 1.0348, Eval Accuracy: 0.5212, Took 2.21 s\n","Epoch [19/50], Loss: 1.0344, Eval Accuracy: 0.5223, Took 2.21 s\n","Epoch [20/50], Loss: 1.0343, Eval Accuracy: 0.5219, Took 2.21 s\n","Stopped early after epoch 20 as validation accuracy was lower than average of the last 7 accuracies.\n","Last Loss: 1.0343, Last Eval Accuracy: 0.5219, Took 44.1 s\n","Model saved as 20240603144145_encoder_64em_4l_4h_05dr_20ep.pt\n","----- Start Training: 64 emb, 4 layers, 8 heads, 0.5 dropout, positional encoding: False, 50 epochs -----\n","Epoch [1/50], Loss: 1.7566, Eval Accuracy: 0.514, Took 2.87 s\n","Epoch [2/50], Loss: 1.2394, Eval Accuracy: 0.5161, Took 2.87 s\n","Epoch [3/50], Loss: 1.1453, Eval Accuracy: 0.5157, Took 2.87 s\n","Epoch [4/50], Loss: 1.1034, Eval Accuracy: 0.5179, Took 2.87 s\n","Epoch [5/50], Loss: 1.0814, Eval Accuracy: 0.5189, Took 2.87 s\n","Epoch [6/50], Loss: 1.0675, Eval Accuracy: 0.5176, Took 2.87 s\n","Epoch [7/50], Loss: 1.058, Eval Accuracy: 0.5157, Took 2.87 s\n","Epoch [8/50], Loss: 1.0527, Eval Accuracy: 0.5187, Took 2.87 s\n","Epoch [9/50], Loss: 1.0478, Eval Accuracy: 0.5211, Took 2.87 s\n","Epoch [10/50], Loss: 1.0447, Eval Accuracy: 0.5232, Took 2.87 s\n","Epoch [11/50], Loss: 1.0424, Eval Accuracy: 0.5193, Took 2.87 s\n","Epoch [12/50], Loss: 1.0403, Eval Accuracy: 0.5194, Took 2.87 s\n","Epoch [13/50], Loss: 1.0405, Eval Accuracy: 0.5227, Took 2.9 s\n","Epoch [14/50], Loss: 1.0378, Eval Accuracy: 0.5227, Took 2.9 s\n","Epoch [15/50], Loss: 1.0375, Eval Accuracy: 0.5202, Took 2.9 s\n","Epoch [16/50], Loss: 1.0364, Eval Accuracy: 0.5235, Took 2.9 s\n","Epoch [17/50], Loss: 1.0363, Eval Accuracy: 0.5223, Took 2.9 s\n","Epoch [18/50], Loss: 1.0346, Eval Accuracy: 0.5217, Took 2.91 s\n","Epoch [19/50], Loss: 1.034, Eval Accuracy: 0.5224, Took 2.9 s\n","Epoch [20/50], Loss: 1.0344, Eval Accuracy: 0.5222, Took 2.89 s\n","Epoch [21/50], Loss: 1.0349, Eval Accuracy: 0.5231, Took 2.9 s\n","Epoch [22/50], Loss: 1.0328, Eval Accuracy: 0.5216, Took 2.9 s\n","Epoch [23/50], Loss: 1.0344, Eval Accuracy: 0.5219, Took 2.9 s\n","Stopped early after epoch 23 as validation accuracy was lower than average of the last 7 accuracies.\n","Last Loss: 1.0344, Last Eval Accuracy: 0.5219, Took 66.38 s\n","Model saved as 20240603144252_encoder_64em_4l_8h_05dr_23ep.pt\n","----- Start Training: 64 emb, 8 layers, 1 heads, 0.5 dropout, positional encoding: False, 50 epochs -----\n","Epoch [1/50], Loss: 1.8499, Eval Accuracy: 0.5151, Took 3.32 s\n","Epoch [2/50], Loss: 1.2472, Eval Accuracy: 0.5156, Took 3.31 s\n","Epoch [3/50], Loss: 1.1485, Eval Accuracy: 0.5148, Took 3.31 s\n","Epoch [4/50], Loss: 1.107, Eval Accuracy: 0.5171, Took 3.31 s\n","Epoch [5/50], Loss: 1.0826, Eval Accuracy: 0.5143, Took 3.31 s\n","Epoch [6/50], Loss: 1.0695, Eval Accuracy: 0.5185, Took 3.31 s\n","Epoch [7/50], Loss: 1.0589, Eval Accuracy: 0.5183, Took 3.31 s\n","Epoch [8/50], Loss: 1.0544, Eval Accuracy: 0.5185, Took 3.32 s\n","Epoch [9/50], Loss: 1.0487, Eval Accuracy: 0.5222, Took 3.31 s\n","Epoch [10/50], Loss: 1.0462, Eval Accuracy: 0.5221, Took 3.31 s\n","Epoch [11/50], Loss: 1.0438, Eval Accuracy: 0.5197, Took 3.31 s\n","Epoch [12/50], Loss: 1.041, Eval Accuracy: 0.5191, Took 3.31 s\n","Epoch [13/50], Loss: 1.041, Eval Accuracy: 0.5226, Took 3.31 s\n","Epoch [14/50], Loss: 1.0388, Eval Accuracy: 0.5214, Took 3.31 s\n","Epoch [15/50], Loss: 1.0383, Eval Accuracy: 0.5208, Took 3.31 s\n","Epoch [16/50], Loss: 1.0368, Eval Accuracy: 0.5228, Took 3.31 s\n","Epoch [17/50], Loss: 1.0373, Eval Accuracy: 0.522, Took 3.31 s\n","Epoch [18/50], Loss: 1.0357, Eval Accuracy: 0.5232, Took 3.31 s\n","Epoch [19/50], Loss: 1.0356, Eval Accuracy: 0.5211, Took 3.31 s\n","Epoch [20/50], Loss: 1.0351, Eval Accuracy: 0.5209, Took 3.31 s\n","Stopped early after epoch 20 as validation accuracy was lower than average of the last 7 accuracies.\n","Last Loss: 1.0351, Last Eval Accuracy: 0.5209, Took 66.28 s\n","Model saved as 20240603144358_encoder_64em_8l_1h_05dr_20ep.pt\n","----- Start Training: 64 emb, 8 layers, 2 heads, 0.5 dropout, positional encoding: False, 50 epochs -----\n","Epoch [1/50], Loss: 1.8548, Eval Accuracy: 0.5146, Took 3.68 s\n","Epoch [2/50], Loss: 1.2476, Eval Accuracy: 0.5137, Took 3.7 s\n","Epoch [3/50], Loss: 1.1492, Eval Accuracy: 0.5169, Took 3.67 s\n","Epoch [4/50], Loss: 1.1068, Eval Accuracy: 0.5174, Took 3.67 s\n","Epoch [5/50], Loss: 1.0834, Eval Accuracy: 0.5175, Took 3.67 s\n","Epoch [6/50], Loss: 1.0694, Eval Accuracy: 0.5194, Took 3.67 s\n","Epoch [7/50], Loss: 1.0596, Eval Accuracy: 0.518, Took 3.67 s\n","Epoch [8/50], Loss: 1.0541, Eval Accuracy: 0.5182, Took 3.67 s\n","Epoch [9/50], Loss: 1.0484, Eval Accuracy: 0.5227, Took 3.67 s\n","Epoch [10/50], Loss: 1.0467, Eval Accuracy: 0.5224, Took 3.66 s\n","Epoch [11/50], Loss: 1.0438, Eval Accuracy: 0.5188, Took 3.66 s\n","Epoch [12/50], Loss: 1.0414, Eval Accuracy: 0.5183, Took 3.66 s\n","Stopped early after epoch 12 as validation accuracy was lower than average of the last 7 accuracies.\n","Last Loss: 1.0414, Last Eval Accuracy: 0.5183, Took 44.05 s\n","Model saved as 20240603144442_encoder_64em_8l_2h_05dr_12ep.pt\n","----- Start Training: 64 emb, 8 layers, 4 heads, 0.5 dropout, positional encoding: False, 50 epochs -----\n","Epoch [1/50], Loss: 1.8542, Eval Accuracy: 0.5148, Took 4.33 s\n","Epoch [2/50], Loss: 1.2474, Eval Accuracy: 0.5158, Took 4.33 s\n","Epoch [3/50], Loss: 1.149, Eval Accuracy: 0.5158, Took 4.32 s\n","Epoch [4/50], Loss: 1.1065, Eval Accuracy: 0.5168, Took 4.33 s\n","Epoch [5/50], Loss: 1.0829, Eval Accuracy: 0.5156, Took 4.33 s\n","Epoch [6/50], Loss: 1.0693, Eval Accuracy: 0.5184, Took 4.34 s\n","Epoch [7/50], Loss: 1.0591, Eval Accuracy: 0.5184, Took 4.36 s\n","Epoch [8/50], Loss: 1.0538, Eval Accuracy: 0.5176, Took 4.36 s\n","Epoch [9/50], Loss: 1.0487, Eval Accuracy: 0.5223, Took 4.33 s\n","Epoch [10/50], Loss: 1.0467, Eval Accuracy: 0.5217, Took 4.33 s\n","Epoch [11/50], Loss: 1.044, Eval Accuracy: 0.518, Took 4.33 s\n","Epoch [12/50], Loss: 1.0414, Eval Accuracy: 0.5181, Took 4.33 s\n","Stopped early after epoch 12 as validation accuracy was lower than average of the last 7 accuracies.\n","Last Loss: 1.0414, Last Eval Accuracy: 0.5181, Took 52.01 s\n","Model saved as 20240603144534_encoder_64em_8l_4h_05dr_12ep.pt\n","----- Start Training: 64 emb, 8 layers, 8 heads, 0.5 dropout, positional encoding: False, 50 epochs -----\n","Epoch [1/50], Loss: 1.845, Eval Accuracy: 0.5145, Took 5.67 s\n","Epoch [2/50], Loss: 1.2461, Eval Accuracy: 0.5151, Took 5.68 s\n","Epoch [3/50], Loss: 1.1486, Eval Accuracy: 0.5099, Took 5.67 s\n","Epoch [4/50], Loss: 1.106, Eval Accuracy: 0.5171, Took 5.68 s\n","Epoch [5/50], Loss: 1.0826, Eval Accuracy: 0.514, Took 5.68 s\n","Epoch [6/50], Loss: 1.0688, Eval Accuracy: 0.5187, Took 5.68 s\n","Epoch [7/50], Loss: 1.0591, Eval Accuracy: 0.5182, Took 5.67 s\n","Epoch [8/50], Loss: 1.0539, Eval Accuracy: 0.5178, Took 5.68 s\n","Epoch [9/50], Loss: 1.0484, Eval Accuracy: 0.5222, Took 5.67 s\n","Epoch [10/50], Loss: 1.0463, Eval Accuracy: 0.5231, Took 5.68 s\n","Epoch [11/50], Loss: 1.0435, Eval Accuracy: 0.5183, Took 5.68 s\n","Epoch [12/50], Loss: 1.0409, Eval Accuracy: 0.5182, Took 5.68 s\n","Epoch [13/50], Loss: 1.041, Eval Accuracy: 0.5219, Took 5.67 s\n","Epoch [14/50], Loss: 1.0385, Eval Accuracy: 0.5216, Took 5.68 s\n","Epoch [15/50], Loss: 1.0381, Eval Accuracy: 0.5202, Took 5.68 s\n","Epoch [16/50], Loss: 1.0366, Eval Accuracy: 0.5227, Took 5.68 s\n","Epoch [17/50], Loss: 1.0367, Eval Accuracy: 0.5215, Took 5.68 s\n","Epoch [18/50], Loss: 1.0353, Eval Accuracy: 0.5217, Took 5.67 s\n","Epoch [19/50], Loss: 1.0352, Eval Accuracy: 0.5207, Took 5.68 s\n","Epoch [20/50], Loss: 1.0352, Eval Accuracy: 0.5218, Took 5.68 s\n","Stopped early after epoch 20 as validation accuracy was lower than average of the last 7 accuracies.\n","Last Loss: 1.0352, Last Eval Accuracy: 0.5218, Took 113.54 s\n","Model saved as 20240603144728_encoder_64em_8l_8h_05dr_20ep.pt\n","------------\n","Not saved as loss too high:\n","[]\n"]},{"data":{"text/plain":["{'encoder_64em_1l_1h_05dr_50ep': 0.5154,\n"," 'encoder_64em_1l_2h_05dr_50ep': 0.516,\n"," 'encoder_64em_1l_4h_05dr_50ep': 0.5165,\n"," 'encoder_64em_1l_8h_05dr_50ep': 0.5187,\n"," 'encoder_64em_2l_1h_05dr_50ep': 0.5221,\n"," 'encoder_64em_2l_2h_05dr_50ep': 0.5198,\n"," 'encoder_64em_2l_4h_05dr_50ep': 0.5225,\n"," 'encoder_64em_2l_8h_05dr_50ep': 0.5222,\n"," 'encoder_64em_4l_1h_05dr_50ep': 0.5214,\n"," 'encoder_64em_4l_2h_05dr_50ep': 0.5228,\n"," 'encoder_64em_4l_4h_05dr_50ep': 0.5219,\n"," 'encoder_64em_4l_8h_05dr_50ep': 0.5219,\n"," 'encoder_64em_8l_1h_05dr_50ep': 0.5209,\n"," 'encoder_64em_8l_2h_05dr_50ep': 0.5183,\n"," 'encoder_64em_8l_4h_05dr_50ep': 0.5181,\n"," 'encoder_64em_8l_8h_05dr_50ep': 0.5218}"]},"execution_count":36,"metadata":{},"output_type":"execute_result"}],"source":["EMBED_DIM = [64]\n","num_encoder_layers = [1, 2, 4, 8]\n","num_heads = [1, 2, 4, 8]\n","DROPOUTS = [0.5]\n","POS_ENC = [False]\n","e.hyper_parameter_training(EMBED_DIM, num_encoder_layers, num_heads, DROPOUTS, POS_ENC)"]},{"cell_type":"markdown","metadata":{},"source":["#### Positional Encoding"]},{"cell_type":"code","execution_count":39,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["----- Start Training: 64 emb, 2 layers, 4 heads, 0.5 dropout, positional encoding: True, 50 epochs -----\n","Epoch [1/50], Loss: 2.0597, Eval Accuracy: 0.5154, Took 1.17 s\n","Epoch [2/50], Loss: 1.2627, Eval Accuracy: 0.5155, Took 1.17 s\n","Epoch [3/50], Loss: 1.1491, Eval Accuracy: 0.5137, Took 1.16 s\n","Epoch [4/50], Loss: 1.1068, Eval Accuracy: 0.5155, Took 1.16 s\n","Epoch [5/50], Loss: 1.0852, Eval Accuracy: 0.5145, Took 1.17 s\n","Epoch [6/50], Loss: 1.0717, Eval Accuracy: 0.5153, Took 1.17 s\n","Epoch [7/50], Loss: 1.0629, Eval Accuracy: 0.5159, Took 1.17 s\n","Epoch [8/50], Loss: 1.0585, Eval Accuracy: 0.5163, Took 1.17 s\n","Epoch [9/50], Loss: 1.0538, Eval Accuracy: 0.517, Took 1.14 s\n","Epoch [10/50], Loss: 1.0511, Eval Accuracy: 0.5168, Took 1.14 s\n","Epoch [11/50], Loss: 1.0485, Eval Accuracy: 0.5164, Took 1.14 s\n","Epoch [12/50], Loss: 1.0462, Eval Accuracy: 0.5164, Took 1.15 s\n","Epoch [13/50], Loss: 1.0459, Eval Accuracy: 0.5161, Took 1.15 s\n","Stopped early after epoch 13 as validation accuracy was lower than average of the last 7 accuracies.\n","Last Loss: 1.0459, Last Eval Accuracy: 0.5161, Took 15.07 s\n","Model saved as 20240603145400_encoder_64em_2l_4h_05dr_posenc_13ep.pt\n","----- Start Training: 64 emb, 2 layers, 4 heads, 0.5 dropout, positional encoding: False, 50 epochs -----\n","Epoch [1/50], Loss: 1.7964, Eval Accuracy: 0.5155, Took 1.14 s\n","Epoch [2/50], Loss: 1.2462, Eval Accuracy: 0.5146, Took 1.14 s\n","Epoch [3/50], Loss: 1.1489, Eval Accuracy: 0.5153, Took 1.14 s\n","Epoch [4/50], Loss: 1.1064, Eval Accuracy: 0.5166, Took 1.14 s\n","Epoch [5/50], Loss: 1.083, Eval Accuracy: 0.5186, Took 1.14 s\n","Epoch [6/50], Loss: 1.0689, Eval Accuracy: 0.5166, Took 1.14 s\n","Epoch [7/50], Loss: 1.0594, Eval Accuracy: 0.5176, Took 1.14 s\n","Epoch [8/50], Loss: 1.0536, Eval Accuracy: 0.5196, Took 1.14 s\n","Epoch [9/50], Loss: 1.0486, Eval Accuracy: 0.5204, Took 1.14 s\n","Epoch [10/50], Loss: 1.0456, Eval Accuracy: 0.522, Took 1.14 s\n","Epoch [11/50], Loss: 1.0435, Eval Accuracy: 0.5184, Took 1.14 s\n","Epoch [12/50], Loss: 1.0409, Eval Accuracy: 0.5198, Took 1.14 s\n","Epoch [13/50], Loss: 1.0407, Eval Accuracy: 0.5218, Took 1.14 s\n","Epoch [14/50], Loss: 1.0382, Eval Accuracy: 0.5218, Took 1.14 s\n","Epoch [15/50], Loss: 1.0381, Eval Accuracy: 0.5199, Took 1.14 s\n","Epoch [16/50], Loss: 1.0368, Eval Accuracy: 0.5222, Took 1.14 s\n","Epoch [17/50], Loss: 1.0367, Eval Accuracy: 0.5226, Took 1.14 s\n","Epoch [18/50], Loss: 1.0349, Eval Accuracy: 0.5226, Took 1.14 s\n","Epoch [19/50], Loss: 1.0345, Eval Accuracy: 0.5231, Took 1.14 s\n","Epoch [20/50], Loss: 1.0347, Eval Accuracy: 0.5209, Took 1.14 s\n","Epoch [21/50], Loss: 1.035, Eval Accuracy: 0.5225, Took 1.15 s\n","Stopped early after epoch 21 as validation accuracy was lower than average of the last 7 accuracies.\n","Last Loss: 1.035, Last Eval Accuracy: 0.5225, Took 23.97 s\n","Model saved as 20240603145424_encoder_64em_2l_4h_05dr_21ep.pt\n","------------\n","Not saved as loss too high:\n","[]\n"]},{"data":{"text/plain":["{'encoder_64em_2l_4h_05dr_posenc_50ep': 0.5161,\n"," 'encoder_64em_2l_4h_05dr_50ep': 0.5225}"]},"execution_count":39,"metadata":{},"output_type":"execute_result"}],"source":["EMBED_DIM = [64]\n","NUM_ENCODER_LAYERS = [2]\n","NUM_HEADS = [4]\n","DROPOUTS = [0.5]\n","pos_enc = [True, False]\n","e.hyper_parameter_training(EMBED_DIM, NUM_ENCODER_LAYERS, NUM_HEADS, DROPOUTS, pos_enc)"]},{"cell_type":"markdown","metadata":{},"source":["### Drosophila.Melanogaster"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Länge train_dataset: 33040\n","Länge valid_dataset: 4073\n"]}],"source":["organism = \"Drosophila.Melanogaster\"\n","e.load_train_valid_data(organism)"]},{"cell_type":"code","execution_count":44,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["----- Start Training: 64 emb, 2 layers, 2 heads, 0.2 dropout, positional encoding: False, 10 epochs -----\n","Epoch [1/10], Loss: 1.1824, Eval Accuracy: 0.4967, Took 9.54 s\n","Epoch [2/10], Loss: 1.081, Eval Accuracy: 0.497, Took 9.79 s\n","Epoch [3/10], Loss: 1.076, Eval Accuracy: 0.4977, Took 9.09 s\n","Epoch [4/10], Loss: 1.0746, Eval Accuracy: 0.498, Took 9.1 s\n","Epoch [5/10], Loss: 1.0737, Eval Accuracy: 0.4975, Took 9.1 s\n","Epoch [6/10], Loss: 1.073, Eval Accuracy: 0.4972, Took 9.11 s\n","Epoch [7/10], Loss: 1.0725, Eval Accuracy: 0.4987, Took 9.1 s\n","Epoch [8/10], Loss: 1.0719, Eval Accuracy: 0.4989, Took 9.1 s\n","Epoch [9/10], Loss: 1.0715, Eval Accuracy: 0.4982, Took 10.15 s\n","Epoch [10/10], Loss: 1.071, Eval Accuracy: 0.4991, Took 9.1 s\n","Last Loss: 1.071, Last Eval Accuracy: 0.4991, Took 93.17 s\n","Model saved as 20240603150541_encoder_64em_2l_2h_02dr_10ep.pt\n","----- Start Training: 64 emb, 2 layers, 2 heads, 0.5 dropout, positional encoding: False, 10 epochs -----\n","Epoch [1/10], Loss: 1.2169, Eval Accuracy: 0.4961, Took 9.1 s\n","Epoch [2/10], Loss: 1.0838, Eval Accuracy: 0.4968, Took 9.1 s\n","Epoch [3/10], Loss: 1.0788, Eval Accuracy: 0.4974, Took 9.1 s\n","Epoch [4/10], Loss: 1.0772, Eval Accuracy: 0.4977, Took 9.1 s\n","Epoch [5/10], Loss: 1.0761, Eval Accuracy: 0.4973, Took 9.09 s\n","Epoch [6/10], Loss: 1.0753, Eval Accuracy: 0.4973, Took 9.1 s\n","Epoch [7/10], Loss: 1.0746, Eval Accuracy: 0.4982, Took 9.1 s\n","Epoch [8/10], Loss: 1.074, Eval Accuracy: 0.4986, Took 9.1 s\n","Epoch [9/10], Loss: 1.0736, Eval Accuracy: 0.498, Took 9.1 s\n","Epoch [10/10], Loss: 1.0732, Eval Accuracy: 0.4987, Took 9.09 s\n","Last Loss: 1.0732, Last Eval Accuracy: 0.4987, Took 90.98 s\n","Model saved as 20240603150712_encoder_64em_2l_2h_05dr_10ep.pt\n","----- Start Training: 64 emb, 2 layers, 4 heads, 0.2 dropout, positional encoding: False, 10 epochs -----\n","Epoch [1/10], Loss: 1.1823, Eval Accuracy: 0.4966, Took 10.65 s\n","Epoch [2/10], Loss: 1.0809, Eval Accuracy: 0.4968, Took 10.65 s\n","Epoch [3/10], Loss: 1.076, Eval Accuracy: 0.4976, Took 10.63 s\n","Epoch [4/10], Loss: 1.0745, Eval Accuracy: 0.4978, Took 10.64 s\n","Epoch [5/10], Loss: 1.0735, Eval Accuracy: 0.4974, Took 10.63 s\n","Epoch [6/10], Loss: 1.0729, Eval Accuracy: 0.4977, Took 10.63 s\n","Epoch [7/10], Loss: 1.0723, Eval Accuracy: 0.4985, Took 10.63 s\n","Epoch [8/10], Loss: 1.0717, Eval Accuracy: 0.499, Took 10.63 s\n","Epoch [9/10], Loss: 1.0713, Eval Accuracy: 0.4985, Took 10.64 s\n","Epoch [10/10], Loss: 1.0708, Eval Accuracy: 0.4993, Took 10.63 s\n","Last Loss: 1.0708, Last Eval Accuracy: 0.4993, Took 106.38 s\n","Model saved as 20240603150858_encoder_64em_2l_4h_02dr_10ep.pt\n","----- Start Training: 64 emb, 2 layers, 4 heads, 0.5 dropout, positional encoding: False, 10 epochs -----\n","Epoch [1/10], Loss: 1.2168, Eval Accuracy: 0.4962, Took 10.66 s\n","Epoch [2/10], Loss: 1.0837, Eval Accuracy: 0.4965, Took 10.66 s\n","Epoch [3/10], Loss: 1.0787, Eval Accuracy: 0.4971, Took 10.65 s\n","Epoch [4/10], Loss: 1.0771, Eval Accuracy: 0.4975, Took 10.64 s\n","Epoch [5/10], Loss: 1.076, Eval Accuracy: 0.4971, Took 10.65 s\n","Epoch [6/10], Loss: 1.0753, Eval Accuracy: 0.497, Took 10.63 s\n","Epoch [7/10], Loss: 1.0745, Eval Accuracy: 0.498, Took 10.64 s\n","Epoch [8/10], Loss: 1.0739, Eval Accuracy: 0.4983, Took 10.63 s\n","Epoch [9/10], Loss: 1.0734, Eval Accuracy: 0.4978, Took 10.63 s\n","Epoch [10/10], Loss: 1.073, Eval Accuracy: 0.4989, Took 10.64 s\n","Last Loss: 1.073, Last Eval Accuracy: 0.4989, Took 106.43 s\n","Model saved as 20240603151045_encoder_64em_2l_4h_05dr_10ep.pt\n","----- Start Training: 64 emb, 4 layers, 2 heads, 0.2 dropout, positional encoding: False, 10 epochs -----\n","Epoch [1/10], Loss: 1.1771, Eval Accuracy: 0.496, Took 17.41 s\n","Epoch [2/10], Loss: 1.0809, Eval Accuracy: 0.4962, Took 17.4 s\n","Epoch [3/10], Loss: 1.0765, Eval Accuracy: 0.4977, Took 17.42 s\n","Epoch [4/10], Loss: 1.0746, Eval Accuracy: 0.4978, Took 17.41 s\n","Epoch [5/10], Loss: 1.0736, Eval Accuracy: 0.4972, Took 17.44 s\n","Epoch [6/10], Loss: 1.0729, Eval Accuracy: 0.497, Took 17.43 s\n","Epoch [7/10], Loss: 1.0722, Eval Accuracy: 0.4984, Took 17.41 s\n","Epoch [8/10], Loss: 1.0716, Eval Accuracy: 0.4988, Took 17.39 s\n","Epoch [9/10], Loss: 1.0712, Eval Accuracy: 0.4983, Took 17.52 s\n","Epoch [10/10], Loss: 1.0711, Eval Accuracy: 0.4994, Took 17.56 s\n","Last Loss: 1.0711, Last Eval Accuracy: 0.4994, Took 174.37 s\n","Model saved as 20240603151339_encoder_64em_4l_2h_02dr_10ep.pt\n","----- Start Training: 64 emb, 4 layers, 2 heads, 0.5 dropout, positional encoding: False, 10 epochs -----\n","Epoch [1/10], Loss: 1.2105, Eval Accuracy: 0.4968, Took 17.4 s\n","Epoch [2/10], Loss: 1.0834, Eval Accuracy: 0.4955, Took 17.42 s\n","Epoch [3/10], Loss: 1.0788, Eval Accuracy: 0.4972, Took 17.43 s\n","Epoch [4/10], Loss: 1.0771, Eval Accuracy: 0.4978, Took 17.42 s\n","Epoch [5/10], Loss: 1.0761, Eval Accuracy: 0.4974, Took 17.44 s\n","Epoch [6/10], Loss: 1.0754, Eval Accuracy: 0.4969, Took 17.46 s\n","Epoch [7/10], Loss: 1.0745, Eval Accuracy: 0.4985, Took 17.6 s\n","Epoch [8/10], Loss: 1.074, Eval Accuracy: 0.4985, Took 17.63 s\n","Epoch [9/10], Loss: 1.0734, Eval Accuracy: 0.498, Took 17.64 s\n","Epoch [10/10], Loss: 1.073, Eval Accuracy: 0.4989, Took 17.63 s\n","Last Loss: 1.073, Last Eval Accuracy: 0.4989, Took 175.08 s\n","Model saved as 20240603151634_encoder_64em_4l_2h_05dr_10ep.pt\n","----- Start Training: 64 emb, 4 layers, 4 heads, 0.2 dropout, positional encoding: False, 10 epochs -----\n","Epoch [1/10], Loss: 1.1768, Eval Accuracy: 0.4964, Took 20.46 s\n","Epoch [2/10], Loss: 1.0809, Eval Accuracy: 0.4962, Took 20.5 s\n","Epoch [3/10], Loss: 1.0759, Eval Accuracy: 0.4978, Took 20.48 s\n","Epoch [4/10], Loss: 1.0744, Eval Accuracy: 0.498, Took 20.46 s\n","Epoch [5/10], Loss: 1.0738, Eval Accuracy: 0.4971, Took 20.49 s\n","Epoch [6/10], Loss: 1.0727, Eval Accuracy: 0.4968, Took 20.67 s\n","Epoch [7/10], Loss: 1.0719, Eval Accuracy: 0.4984, Took 20.46 s\n","Epoch [8/10], Loss: 1.0712, Eval Accuracy: 0.4991, Took 20.51 s\n","Epoch [9/10], Loss: 1.0712, Eval Accuracy: 0.4979, Took 20.71 s\n","Epoch [10/10], Loss: 1.0706, Eval Accuracy: 0.4993, Took 20.71 s\n","Last Loss: 1.0706, Last Eval Accuracy: 0.4993, Took 205.45 s\n","Model saved as 20240603152000_encoder_64em_4l_4h_02dr_10ep.pt\n","----- Start Training: 64 emb, 4 layers, 4 heads, 0.5 dropout, positional encoding: False, 10 epochs -----\n","Epoch [1/10], Loss: 1.2103, Eval Accuracy: 0.497, Took 20.77 s\n","Epoch [2/10], Loss: 1.0833, Eval Accuracy: 0.4962, Took 20.5 s\n","Epoch [3/10], Loss: 1.0785, Eval Accuracy: 0.4972, Took 20.5 s\n","Epoch [4/10], Loss: 1.0769, Eval Accuracy: 0.4975, Took 20.5 s\n","Epoch [5/10], Loss: 1.0759, Eval Accuracy: 0.4969, Took 20.52 s\n","Epoch [6/10], Loss: 1.0753, Eval Accuracy: 0.4964, Took 20.46 s\n","Epoch [7/10], Loss: 1.0744, Eval Accuracy: 0.4983, Took 20.52 s\n","Epoch [8/10], Loss: 1.0736, Eval Accuracy: 0.4987, Took 20.52 s\n","Epoch [9/10], Loss: 1.0731, Eval Accuracy: 0.4981, Took 20.49 s\n","Epoch [10/10], Loss: 1.0725, Eval Accuracy: 0.4989, Took 20.51 s\n","Last Loss: 1.0725, Last Eval Accuracy: 0.4989, Took 205.28 s\n","Model saved as 20240603152325_encoder_64em_4l_4h_05dr_10ep.pt\n","----- Start Training: 128 emb, 2 layers, 2 heads, 0.2 dropout, positional encoding: False, 10 epochs -----\n","Epoch [1/10], Loss: 1.124, Eval Accuracy: 0.4957, Took 10.7 s\n","Epoch [2/10], Loss: 1.0772, Eval Accuracy: 0.4965, Took 10.69 s\n","Epoch [3/10], Loss: 1.0744, Eval Accuracy: 0.4982, Took 10.72 s\n","Epoch [4/10], Loss: 1.0734, Eval Accuracy: 0.4975, Took 10.69 s\n","Epoch [5/10], Loss: 1.0727, Eval Accuracy: 0.4968, Took 10.67 s\n","Epoch [6/10], Loss: 1.0724, Eval Accuracy: 0.4964, Took 10.67 s\n","Epoch [7/10], Loss: 1.0721, Eval Accuracy: 0.4981, Took 10.66 s\n","Epoch [8/10], Loss: 1.0713, Eval Accuracy: 0.499, Took 10.67 s\n","Epoch [9/10], Loss: 1.0708, Eval Accuracy: 0.4983, Took 10.67 s\n","Epoch [10/10], Loss: 1.0714, Eval Accuracy: 0.4992, Took 10.66 s\n","Last Loss: 1.0714, Last Eval Accuracy: 0.4992, Took 106.81 s\n","Model saved as 20240603152512_encoder_128em_2l_2h_02dr_10ep.pt\n","----- Start Training: 128 emb, 2 layers, 2 heads, 0.5 dropout, positional encoding: False, 10 epochs -----\n","Epoch [1/10], Loss: 1.1385, Eval Accuracy: 0.4967, Took 10.73 s\n","Epoch [2/10], Loss: 1.0783, Eval Accuracy: 0.4967, Took 10.94 s\n","Epoch [3/10], Loss: 1.0758, Eval Accuracy: 0.498, Took 10.72 s\n","Epoch [4/10], Loss: 1.0751, Eval Accuracy: 0.4974, Took 10.71 s\n","Epoch [5/10], Loss: 1.0742, Eval Accuracy: 0.4968, Took 10.71 s\n","Epoch [6/10], Loss: 1.0737, Eval Accuracy: 0.4956, Took 10.74 s\n","Epoch [7/10], Loss: 1.0734, Eval Accuracy: 0.4981, Took 10.69 s\n","Epoch [8/10], Loss: 1.0727, Eval Accuracy: 0.4989, Took 10.81 s\n","Epoch [9/10], Loss: 1.0722, Eval Accuracy: 0.4979, Took 10.7 s\n","Epoch [10/10], Loss: 1.0718, Eval Accuracy: 0.4993, Took 10.7 s\n","Last Loss: 1.0718, Last Eval Accuracy: 0.4993, Took 107.44 s\n","Model saved as 20240603152659_encoder_128em_2l_2h_05dr_10ep.pt\n","----- Start Training: 128 emb, 2 layers, 4 heads, 0.2 dropout, positional encoding: False, 10 epochs -----\n","Epoch [1/10], Loss: 1.1237, Eval Accuracy: 0.4958, Took 12.06 s\n","Epoch [2/10], Loss: 1.077, Eval Accuracy: 0.4965, Took 12.05 s\n","Epoch [3/10], Loss: 1.0742, Eval Accuracy: 0.498, Took 12.12 s\n","Epoch [4/10], Loss: 1.0734, Eval Accuracy: 0.4973, Took 12.09 s\n","Epoch [5/10], Loss: 1.0725, Eval Accuracy: 0.4965, Took 12.04 s\n","Epoch [6/10], Loss: 1.072, Eval Accuracy: 0.4967, Took 12.03 s\n","Epoch [7/10], Loss: 1.072, Eval Accuracy: 0.4983, Took 12.08 s\n","Epoch [8/10], Loss: 1.0708, Eval Accuracy: 0.499, Took 12.02 s\n","Epoch [9/10], Loss: 1.0703, Eval Accuracy: 0.4982, Took 12.07 s\n","Epoch [10/10], Loss: 1.0698, Eval Accuracy: 0.4992, Took 12.06 s\n","Last Loss: 1.0698, Last Eval Accuracy: 0.4992, Took 120.62 s\n","Model saved as 20240603152900_encoder_128em_2l_4h_02dr_10ep.pt\n","----- Start Training: 128 emb, 2 layers, 4 heads, 0.5 dropout, positional encoding: False, 10 epochs -----\n","Epoch [1/10], Loss: 1.1381, Eval Accuracy: 0.4964, Took 12.1 s\n","Epoch [2/10], Loss: 1.0782, Eval Accuracy: 0.4967, Took 12.05 s\n","Epoch [3/10], Loss: 1.0757, Eval Accuracy: 0.4979, Took 12.04 s\n","Epoch [4/10], Loss: 1.075, Eval Accuracy: 0.4973, Took 12.05 s\n","Epoch [5/10], Loss: 1.074, Eval Accuracy: 0.4966, Took 12.04 s\n","Epoch [6/10], Loss: 1.0735, Eval Accuracy: 0.4963, Took 12.04 s\n","Epoch [7/10], Loss: 1.0732, Eval Accuracy: 0.4985, Took 12.02 s\n","Epoch [8/10], Loss: 1.0722, Eval Accuracy: 0.4991, Took 12.05 s\n","Epoch [9/10], Loss: 1.0718, Eval Accuracy: 0.4982, Took 12.2 s\n","Epoch [10/10], Loss: 1.0715, Eval Accuracy: 0.4989, Took 12.27 s\n","Last Loss: 1.0715, Last Eval Accuracy: 0.4989, Took 120.87 s\n","Model saved as 20240603153101_encoder_128em_2l_4h_05dr_10ep.pt\n","----- Start Training: 128 emb, 4 layers, 2 heads, 0.2 dropout, positional encoding: False, 10 epochs -----\n","Epoch [1/10], Loss: 1.1206, Eval Accuracy: 0.4959, Took 20.59 s\n","Epoch [2/10], Loss: 1.0771, Eval Accuracy: 0.4966, Took 20.59 s\n","Epoch [3/10], Loss: 1.0751, Eval Accuracy: 0.4977, Took 20.59 s\n","Epoch [4/10], Loss: 1.0735, Eval Accuracy: 0.4976, Took 20.58 s\n","Epoch [5/10], Loss: 1.0741, Eval Accuracy: 0.4967, Took 20.58 s\n","Epoch [6/10], Loss: 1.0729, Eval Accuracy: 0.496, Took 20.53 s\n","Epoch [7/10], Loss: 1.0723, Eval Accuracy: 0.4982, Took 20.51 s\n","Epoch [8/10], Loss: 1.0713, Eval Accuracy: 0.4988, Took 20.81 s\n","Epoch [9/10], Loss: 1.0711, Eval Accuracy: 0.4977, Took 20.57 s\n","Epoch [10/10], Loss: 1.0711, Eval Accuracy: 0.4986, Took 20.81 s\n","Last Loss: 1.0711, Last Eval Accuracy: 0.4986, Took 206.16 s\n","Model saved as 20240603153427_encoder_128em_4l_2h_02dr_10ep.pt\n","----- Start Training: 128 emb, 4 layers, 2 heads, 0.5 dropout, positional encoding: False, 10 epochs -----\n","Epoch [1/10], Loss: 1.1341, Eval Accuracy: 0.4962, Took 20.87 s\n","Epoch [2/10], Loss: 1.0781, Eval Accuracy: 0.4965, Took 20.75 s\n","Epoch [3/10], Loss: 1.0767, Eval Accuracy: 0.4975, Took 20.59 s\n","Epoch [4/10], Loss: 1.0751, Eval Accuracy: 0.4977, Took 20.57 s\n","Epoch [5/10], Loss: 1.0745, Eval Accuracy: 0.4967, Took 20.52 s\n","Epoch [6/10], Loss: 1.0742, Eval Accuracy: 0.4967, Took 20.5 s\n","Epoch [7/10], Loss: 1.0737, Eval Accuracy: 0.4954, Took 20.53 s\n","Epoch [8/10], Loss: 1.0734, Eval Accuracy: 0.4984, Took 20.51 s\n","Stopped early after epoch 8 as validation accuracy was lower than average of the last 7 accuracies.\n","Last Loss: 1.0734, Last Eval Accuracy: 0.4984, Took 164.86 s\n","Model saved as 20240603153712_encoder_128em_4l_2h_05dr_8ep.pt\n","----- Start Training: 128 emb, 4 layers, 4 heads, 0.2 dropout, positional encoding: False, 10 epochs -----\n","Epoch [1/10], Loss: 1.1203, Eval Accuracy: 0.4958, Took 23.34 s\n","Epoch [2/10], Loss: 1.077, Eval Accuracy: 0.4964, Took 23.35 s\n","Epoch [3/10], Loss: 1.0744, Eval Accuracy: 0.4977, Took 23.32 s\n","Epoch [4/10], Loss: 1.0733, Eval Accuracy: 0.4976, Took 23.27 s\n","Epoch [5/10], Loss: 1.0728, Eval Accuracy: 0.4969, Took 23.25 s\n","Epoch [6/10], Loss: 1.0726, Eval Accuracy: 0.4963, Took 23.23 s\n","Epoch [7/10], Loss: 1.0718, Eval Accuracy: 0.497, Took 23.32 s\n","Epoch [8/10], Loss: 1.0714, Eval Accuracy: 0.4992, Took 23.26 s\n","Epoch [9/10], Loss: 1.0701, Eval Accuracy: 0.4988, Took 23.27 s\n","Epoch [10/10], Loss: 1.07, Eval Accuracy: 0.4983, Took 23.24 s\n","Last Loss: 1.07, Last Eval Accuracy: 0.4983, Took 232.85 s\n","Model saved as 20240603154105_encoder_128em_4l_4h_02dr_10ep.pt\n","----- Start Training: 128 emb, 4 layers, 4 heads, 0.5 dropout, positional encoding: False, 10 epochs -----\n","Epoch [1/10], Loss: 1.1341, Eval Accuracy: 0.4955, Took 23.32 s\n","Epoch [2/10], Loss: 1.078, Eval Accuracy: 0.4963, Took 23.32 s\n","Epoch [3/10], Loss: 1.0759, Eval Accuracy: 0.4966, Took 23.3 s\n","Epoch [4/10], Loss: 1.0752, Eval Accuracy: 0.4977, Took 23.25 s\n","Epoch [5/10], Loss: 1.0743, Eval Accuracy: 0.4965, Took 23.27 s\n","Epoch [6/10], Loss: 1.0746, Eval Accuracy: 0.4964, Took 23.26 s\n","Epoch [7/10], Loss: 1.073, Eval Accuracy: 0.4982, Took 23.24 s\n","Epoch [8/10], Loss: 1.0726, Eval Accuracy: 0.4989, Took 23.25 s\n","Epoch [9/10], Loss: 1.0719, Eval Accuracy: 0.4986, Took 23.29 s\n","Epoch [10/10], Loss: 1.0717, Eval Accuracy: 0.4987, Took 23.42 s\n","Last Loss: 1.0717, Last Eval Accuracy: 0.4987, Took 232.92 s\n","Model saved as 20240603154458_encoder_128em_4l_4h_05dr_10ep.pt\n","------------\n","Not saved as loss too high:\n","[]\n"]}],"source":["embed_dims = [64, 128]\n","num_encoder_layers = [2, 4]\n","num_heads = [2, 4]\n","DROPOUTS = [0.2, 0.5]\n","POS_ENC = [False]\n","accuracies = e.hyper_parameter_training(embed_dims, num_encoder_layers, num_heads, DROPOUTS, POS_ENC, epochs=10, print_epochs=True)"]},{"cell_type":"code","execution_count":45,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["----- Start Training: 64 emb, 4 layers, 4 heads, 0.2 dropout, positional encoding: False, 100 epochs -----\n","Epoch [1/100], Loss: 1.1768, Eval Accuracy: 0.4964, Took 20.78 s\n","Epoch [2/100], Loss: 1.0809, Eval Accuracy: 0.4962, Took 20.48 s\n","Epoch [3/100], Loss: 1.0759, Eval Accuracy: 0.4978, Took 20.5 s\n","Epoch [4/100], Loss: 1.0744, Eval Accuracy: 0.498, Took 20.51 s\n","Epoch [5/100], Loss: 1.0738, Eval Accuracy: 0.4971, Took 20.5 s\n","Epoch [6/100], Loss: 1.0727, Eval Accuracy: 0.4968, Took 20.45 s\n","Epoch [7/100], Loss: 1.0719, Eval Accuracy: 0.4984, Took 20.78 s\n","Epoch [8/100], Loss: 1.0712, Eval Accuracy: 0.4991, Took 20.79 s\n","Epoch [9/100], Loss: 1.0712, Eval Accuracy: 0.4979, Took 20.52 s\n","Epoch [10/100], Loss: 1.0706, Eval Accuracy: 0.4993, Took 20.53 s\n","Epoch [11/100], Loss: 1.0698, Eval Accuracy: 0.4988, Took 20.77 s\n","Epoch [12/100], Loss: 1.0691, Eval Accuracy: 0.4987, Took 20.72 s\n","Epoch [13/100], Loss: 1.0687, Eval Accuracy: 0.4993, Took 20.61 s\n","Epoch [14/100], Loss: 1.0678, Eval Accuracy: 0.5002, Took 20.47 s\n","Epoch [15/100], Loss: 1.0677, Eval Accuracy: 0.4998, Took 20.51 s\n","Epoch [16/100], Loss: 1.0667, Eval Accuracy: 0.4986, Took 20.52 s\n","Epoch [17/100], Loss: 1.0659, Eval Accuracy: 0.5004, Took 20.52 s\n","Epoch [18/100], Loss: 1.0655, Eval Accuracy: 0.4995, Took 20.45 s\n","Epoch [19/100], Loss: 1.0646, Eval Accuracy: 0.5004, Took 20.52 s\n","Epoch [20/100], Loss: 1.0639, Eval Accuracy: 0.5004, Took 20.46 s\n","Epoch [21/100], Loss: 1.0631, Eval Accuracy: 0.5015, Took 20.47 s\n","Epoch [22/100], Loss: 1.0625, Eval Accuracy: 0.5016, Took 20.48 s\n","Epoch [23/100], Loss: 1.0615, Eval Accuracy: 0.499, Took 20.49 s\n","Epoch [24/100], Loss: 1.0608, Eval Accuracy: 0.5002, Took 20.44 s\n","Stopped early after epoch 24 as validation accuracy was lower than average of the last 7 accuracies.\n","Last Loss: 1.0608, Last Eval Accuracy: 0.5002, Took 493.3 s\n","Model saved as 20240603162032_encoder_64em_4l_4h_02dr_24ep.pt\n","----- Start Training: 64 emb, 4 layers, 4 heads, 0.2 dropout, positional encoding: True, 100 epochs -----\n","Epoch [1/100], Loss: 1.1862, Eval Accuracy: 0.4965, Took 20.5 s\n","Epoch [2/100], Loss: 1.0814, Eval Accuracy: 0.4959, Took 20.6 s\n","Epoch [3/100], Loss: 1.0763, Eval Accuracy: 0.4972, Took 20.82 s\n","Epoch [4/100], Loss: 1.0751, Eval Accuracy: 0.4978, Took 20.53 s\n","Epoch [5/100], Loss: 1.0738, Eval Accuracy: 0.497, Took 20.51 s\n","Epoch [6/100], Loss: 1.0729, Eval Accuracy: 0.4975, Took 20.54 s\n","Epoch [7/100], Loss: 1.0722, Eval Accuracy: 0.4983, Took 20.53 s\n","Epoch [8/100], Loss: 1.0715, Eval Accuracy: 0.499, Took 20.64 s\n","Epoch [9/100], Loss: 1.071, Eval Accuracy: 0.4982, Took 20.81 s\n","Epoch [10/100], Loss: 1.0703, Eval Accuracy: 0.4989, Took 20.58 s\n","Epoch [11/100], Loss: 1.0694, Eval Accuracy: 0.4988, Took 20.66 s\n","Epoch [12/100], Loss: 1.069, Eval Accuracy: 0.4989, Took 20.52 s\n","Epoch [13/100], Loss: 1.0686, Eval Accuracy: 0.4991, Took 20.76 s\n","Epoch [14/100], Loss: 1.0677, Eval Accuracy: 0.4998, Took 20.76 s\n","Epoch [15/100], Loss: 1.0673, Eval Accuracy: 0.5004, Took 20.78 s\n","Epoch [16/100], Loss: 1.0667, Eval Accuracy: 0.499, Took 20.68 s\n","Epoch [17/100], Loss: 1.0661, Eval Accuracy: 0.5008, Took 20.56 s\n","Epoch [18/100], Loss: 1.0656, Eval Accuracy: 0.4999, Took 20.56 s\n","Epoch [19/100], Loss: 1.0648, Eval Accuracy: 0.5008, Took 20.49 s\n","Epoch [20/100], Loss: 1.0643, Eval Accuracy: 0.5014, Took 20.49 s\n","Epoch [21/100], Loss: 1.0635, Eval Accuracy: 0.5022, Took 20.51 s\n","Epoch [22/100], Loss: 1.0628, Eval Accuracy: 0.5013, Took 20.53 s\n","Epoch [23/100], Loss: 1.062, Eval Accuracy: 0.5015, Took 20.55 s\n","Epoch [24/100], Loss: 1.0614, Eval Accuracy: 0.5021, Took 20.5 s\n","Epoch [25/100], Loss: 1.0607, Eval Accuracy: 0.5026, Took 20.53 s\n","Epoch [26/100], Loss: 1.0599, Eval Accuracy: 0.503, Took 20.51 s\n","Epoch [27/100], Loss: 1.059, Eval Accuracy: 0.503, Took 20.49 s\n","Epoch [28/100], Loss: 1.0582, Eval Accuracy: 0.5037, Took 20.77 s\n","Epoch [29/100], Loss: 1.0574, Eval Accuracy: 0.5027, Took 20.77 s\n","Epoch [30/100], Loss: 1.0566, Eval Accuracy: 0.5042, Took 20.76 s\n","Epoch [31/100], Loss: 1.056, Eval Accuracy: 0.5048, Took 20.55 s\n","Epoch [32/100], Loss: 1.0552, Eval Accuracy: 0.5052, Took 20.52 s\n","Epoch [33/100], Loss: 1.0542, Eval Accuracy: 0.5051, Took 20.54 s\n","Epoch [34/100], Loss: 1.0533, Eval Accuracy: 0.5054, Took 20.52 s\n","Epoch [35/100], Loss: 1.0526, Eval Accuracy: 0.5069, Took 20.52 s\n","Epoch [36/100], Loss: 1.0517, Eval Accuracy: 0.506, Took 20.54 s\n","Epoch [37/100], Loss: 1.0512, Eval Accuracy: 0.5067, Took 20.51 s\n","Epoch [38/100], Loss: 1.0501, Eval Accuracy: 0.5079, Took 20.51 s\n","Epoch [39/100], Loss: 1.0495, Eval Accuracy: 0.5076, Took 20.53 s\n","Epoch [40/100], Loss: 1.0488, Eval Accuracy: 0.507, Took 20.54 s\n","Epoch [41/100], Loss: 1.048, Eval Accuracy: 0.5085, Took 20.56 s\n","Epoch [42/100], Loss: 1.0473, Eval Accuracy: 0.5082, Took 20.51 s\n","Epoch [43/100], Loss: 1.0465, Eval Accuracy: 0.5094, Took 20.54 s\n","Epoch [44/100], Loss: 1.0459, Eval Accuracy: 0.5094, Took 20.54 s\n","Epoch [45/100], Loss: 1.0453, Eval Accuracy: 0.5093, Took 20.53 s\n","Epoch [46/100], Loss: 1.0446, Eval Accuracy: 0.5096, Took 20.72 s\n","Epoch [47/100], Loss: 1.0439, Eval Accuracy: 0.5098, Took 20.81 s\n","Epoch [48/100], Loss: 1.0433, Eval Accuracy: 0.5107, Took 20.66 s\n","Epoch [49/100], Loss: 1.0428, Eval Accuracy: 0.5095, Took 20.54 s\n","Epoch [50/100], Loss: 1.0422, Eval Accuracy: 0.5093, Took 20.57 s\n","Stopped early after epoch 50 as validation accuracy was lower than average of the last 7 accuracies.\n","Last Loss: 1.0422, Last Eval Accuracy: 0.5093, Took 1029.54 s\n","Model saved as 20240603163741_encoder_64em_4l_4h_02dr_posenc_50ep.pt\n","------------\n","Not saved as loss too high:\n","[]\n"]}],"source":["# Train best suited models for longer\n","embed_dims = [64]\n","num_encoder_layers = [4]\n","num_heads = [4]\n","DROPOUTS = [0.2]\n","POS_ENC = [False, True]\n","accuracies = e.hyper_parameter_training(embed_dims, num_encoder_layers, num_heads, DROPOUTS, POS_ENC, epochs=100, print_epochs=True)"]},{"cell_type":"code","execution_count":32,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["----- Start Training: 64 emb, 4 layers, 4 heads, 0.2 dropout, positional encoding: True, 100 epochs -----\n","Epoch [1/100], Loss: 1.1862, Eval Accuracy: 0.4965, Took 20.69 s\n","Epoch [2/100], Loss: 1.0814, Eval Accuracy: 0.4959, Took 20.7 s\n","Epoch [3/100], Loss: 1.0763, Eval Accuracy: 0.4972, Took 20.69 s\n","Epoch [4/100], Loss: 1.0751, Eval Accuracy: 0.4978, Took 20.68 s\n","Epoch [5/100], Loss: 1.0738, Eval Accuracy: 0.497, Took 20.71 s\n","Epoch [6/100], Loss: 1.0729, Eval Accuracy: 0.4975, Took 20.68 s\n","Epoch [7/100], Loss: 1.0722, Eval Accuracy: 0.4983, Took 20.72 s\n","Epoch [8/100], Loss: 1.0715, Eval Accuracy: 0.499, Took 20.72 s\n","Epoch [9/100], Loss: 1.071, Eval Accuracy: 0.4982, Took 20.71 s\n","Epoch [10/100], Loss: 1.0703, Eval Accuracy: 0.4989, Took 20.7 s\n","Epoch [11/100], Loss: 1.0694, Eval Accuracy: 0.4988, Took 20.7 s\n","Epoch [12/100], Loss: 1.069, Eval Accuracy: 0.4989, Took 20.71 s\n","Epoch [13/100], Loss: 1.0686, Eval Accuracy: 0.4991, Took 20.71 s\n","Epoch [14/100], Loss: 1.0677, Eval Accuracy: 0.4998, Took 20.73 s\n","Epoch [15/100], Loss: 1.0673, Eval Accuracy: 0.5004, Took 20.7 s\n","Epoch [16/100], Loss: 1.0667, Eval Accuracy: 0.499, Took 20.7 s\n","Epoch [17/100], Loss: 1.0661, Eval Accuracy: 0.5008, Took 20.71 s\n","Epoch [18/100], Loss: 1.0656, Eval Accuracy: 0.4999, Took 20.73 s\n","Epoch [19/100], Loss: 1.0648, Eval Accuracy: 0.5008, Took 20.71 s\n","Epoch [20/100], Loss: 1.0643, Eval Accuracy: 0.5014, Took 20.7 s\n","Epoch [21/100], Loss: 1.0635, Eval Accuracy: 0.5022, Took 20.71 s\n","Epoch [22/100], Loss: 1.0628, Eval Accuracy: 0.5013, Took 20.7 s\n","Epoch [23/100], Loss: 1.062, Eval Accuracy: 0.5015, Took 20.7 s\n","Epoch [24/100], Loss: 1.0614, Eval Accuracy: 0.5021, Took 20.96 s\n","Epoch [25/100], Loss: 1.0607, Eval Accuracy: 0.5026, Took 20.97 s\n","Epoch [26/100], Loss: 1.0599, Eval Accuracy: 0.503, Took 20.8 s\n","Epoch [27/100], Loss: 1.059, Eval Accuracy: 0.503, Took 20.84 s\n","Epoch [28/100], Loss: 1.0582, Eval Accuracy: 0.5037, Took 20.71 s\n","Epoch [29/100], Loss: 1.0574, Eval Accuracy: 0.5027, Took 20.71 s\n","Epoch [30/100], Loss: 1.0566, Eval Accuracy: 0.5042, Took 20.71 s\n","Epoch [31/100], Loss: 1.056, Eval Accuracy: 0.5048, Took 20.73 s\n","Epoch [32/100], Loss: 1.0552, Eval Accuracy: 0.5052, Took 20.71 s\n","Epoch [33/100], Loss: 1.0542, Eval Accuracy: 0.5051, Took 20.72 s\n","Epoch [34/100], Loss: 1.0533, Eval Accuracy: 0.5054, Took 20.71 s\n","Epoch [35/100], Loss: 1.0526, Eval Accuracy: 0.5069, Took 20.71 s\n","Epoch [36/100], Loss: 1.0517, Eval Accuracy: 0.506, Took 20.71 s\n","Epoch [37/100], Loss: 1.0512, Eval Accuracy: 0.5067, Took 20.72 s\n","Epoch [38/100], Loss: 1.0501, Eval Accuracy: 0.5079, Took 20.92 s\n","Epoch [39/100], Loss: 1.0495, Eval Accuracy: 0.5076, Took 20.71 s\n","Epoch [40/100], Loss: 1.0488, Eval Accuracy: 0.507, Took 20.72 s\n","Epoch [41/100], Loss: 1.048, Eval Accuracy: 0.5085, Took 20.72 s\n","Epoch [42/100], Loss: 1.0473, Eval Accuracy: 0.5082, Took 20.72 s\n","Epoch [43/100], Loss: 1.0465, Eval Accuracy: 0.5094, Took 20.72 s\n","Epoch [44/100], Loss: 1.0459, Eval Accuracy: 0.5094, Took 20.72 s\n","Epoch [45/100], Loss: 1.0453, Eval Accuracy: 0.5093, Took 20.73 s\n","Epoch [46/100], Loss: 1.0446, Eval Accuracy: 0.5096, Took 20.86 s\n","Epoch [47/100], Loss: 1.0439, Eval Accuracy: 0.5098, Took 20.97 s\n","Epoch [48/100], Loss: 1.0433, Eval Accuracy: 0.5107, Took 20.98 s\n","Epoch [49/100], Loss: 1.0428, Eval Accuracy: 0.5095, Took 20.98 s\n","Epoch [50/100], Loss: 1.0422, Eval Accuracy: 0.5093, Took 20.98 s\n","Stopped early after epoch 50 as validation accuracy was lower than average of the last 7 accuracies.\n","Last Loss: 1.0422, Last Eval Accuracy: 0.5093, Took 1037.69 s\n","Model saved as 20240624164002_encoder_64em_4l_4h_posenc_02dr_50ep.pt\n","------------\n","Not saved as loss too high:\n","[]\n","CPU times: user 31min 8s, sys: 1.69 s, total: 31min 10s\n","Wall time: 17min 17s\n"]}],"source":["%%time\n","\n","# Train best model for longer\n","embed_dims = [64]\n","num_encoder_layers = [4]\n","num_heads = [4]\n","DROPOUTS = [0.2]\n","POS_ENC = [True]\n","accuracies, all_accuracies = e.hyper_parameter_training(embed_dims, num_encoder_layers, num_heads, DROPOUTS, POS_ENC, epochs=100, print_epochs=True)"]},{"cell_type":"code","execution_count":33,"metadata":{},"outputs":[],"source":["mlh.to_pickle(all_accuracies, data_path+f'/{e.organism}/training_accuracies_encoder.pkl')"]},{"cell_type":"markdown","metadata":{},"source":["### Homo.Sapiens"]},{"cell_type":"code","execution_count":35,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Länge train_dataset: 140711\n","Länge valid_dataset: 17784\n","CPU times: user 1min 29s, sys: 552 ms, total: 1min 29s\n","Wall time: 1min 29s\n"]}],"source":["%%time\n","\n","organism = \"Homo.Sapiens\"\n","e.load_train_valid_data(organism)"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["----- Start Training: 64 emb, 4 layers, 4 heads, 0.2 dropout, positional encoding: True, 100 epochs -----\n"]},{"name":"stderr","output_type":"stream","text":["/home/mkuehn/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [1/100], Loss: 1.1145, Eval Accuracy: 0.4759, Took 88.67 s\n","Epoch [2/100], Loss: 1.0813, Eval Accuracy: 0.4778, Took 87.75 s\n","Epoch [3/100], Loss: 1.0784, Eval Accuracy: 0.4809, Took 88.37 s\n","Epoch [4/100], Loss: 1.0759, Eval Accuracy: 0.4834, Took 87.4 s\n","Epoch [5/100], Loss: 1.0738, Eval Accuracy: 0.4837, Took 87.3 s\n","Epoch [6/100], Loss: 1.0719, Eval Accuracy: 0.4875, Took 87.73 s\n","Epoch [7/100], Loss: 1.0701, Eval Accuracy: 0.4889, Took 87.27 s\n","Epoch [8/100], Loss: 1.0681, Eval Accuracy: 0.4886, Took 87.55 s\n","Epoch [9/100], Loss: 1.0661, Eval Accuracy: 0.4922, Took 87.25 s\n","Epoch [10/100], Loss: 1.0642, Eval Accuracy: 0.4936, Took 87.25 s\n","Epoch [11/100], Loss: 1.0622, Eval Accuracy: 0.4928, Took 87.27 s\n","Epoch [12/100], Loss: 1.0605, Eval Accuracy: 0.496, Took 87.29 s\n","Epoch [13/100], Loss: 1.0588, Eval Accuracy: 0.4975, Took 87.23 s\n","Epoch [14/100], Loss: 1.057, Eval Accuracy: 0.4985, Took 87.34 s\n","Epoch [15/100], Loss: 1.0554, Eval Accuracy: 0.5002, Took 87.46 s\n","Epoch [16/100], Loss: 1.0538, Eval Accuracy: 0.4975, Took 87.29 s\n","Epoch [17/100], Loss: 1.0523, Eval Accuracy: 0.5015, Took 87.32 s\n","Epoch [18/100], Loss: 1.0511, Eval Accuracy: 0.5022, Took 87.31 s\n","Epoch [19/100], Loss: 1.0496, Eval Accuracy: 0.503, Took 87.31 s\n","Epoch [20/100], Loss: 1.0484, Eval Accuracy: 0.5039, Took 87.31 s\n","Epoch [21/100], Loss: 1.0471, Eval Accuracy: 0.5046, Took 87.35 s\n","Epoch [22/100], Loss: 1.0461, Eval Accuracy: 0.5066, Took 87.34 s\n","Epoch [23/100], Loss: 1.045, Eval Accuracy: 0.5064, Took 87.35 s\n","Epoch [24/100], Loss: 1.0439, Eval Accuracy: 0.5081, Took 87.38 s\n","Epoch [25/100], Loss: 1.0429, Eval Accuracy: 0.5075, Took 87.91 s\n","Epoch [26/100], Loss: 1.042, Eval Accuracy: 0.5088, Took 88.52 s\n","Epoch [27/100], Loss: 1.041, Eval Accuracy: 0.5097, Took 87.31 s\n","Epoch [28/100], Loss: 1.0402, Eval Accuracy: 0.5096, Took 87.58 s\n","Epoch [29/100], Loss: 1.0393, Eval Accuracy: 0.5114, Took 87.36 s\n","Epoch [30/100], Loss: 1.0385, Eval Accuracy: 0.5095, Took 87.37 s\n","Epoch [31/100], Loss: 1.0378, Eval Accuracy: 0.5104, Took 88.03 s\n","Epoch [32/100], Loss: 1.037, Eval Accuracy: 0.5112, Took 87.41 s\n","Epoch [33/100], Loss: 1.0363, Eval Accuracy: 0.5125, Took 88.22 s\n","Epoch [34/100], Loss: 1.0356, Eval Accuracy: 0.5127, Took 87.51 s\n","Epoch [35/100], Loss: 1.0349, Eval Accuracy: 0.5134, Took 87.37 s\n","Epoch [36/100], Loss: 1.0343, Eval Accuracy: 0.5138, Took 87.37 s\n","Epoch [37/100], Loss: 1.0338, Eval Accuracy: 0.5142, Took 88.24 s\n","Epoch [38/100], Loss: 1.0332, Eval Accuracy: 0.515, Took 87.41 s\n","Epoch [39/100], Loss: 1.0327, Eval Accuracy: 0.5152, Took 87.35 s\n","Epoch [40/100], Loss: 1.0322, Eval Accuracy: 0.5146, Took 87.53 s\n","Epoch [41/100], Loss: 1.0317, Eval Accuracy: 0.5157, Took 88.37 s\n","Epoch [42/100], Loss: 1.0311, Eval Accuracy: 0.5147, Took 87.34 s\n","Epoch [43/100], Loss: 1.0307, Eval Accuracy: 0.5162, Took 87.34 s\n","Epoch [44/100], Loss: 1.0303, Eval Accuracy: 0.5153, Took 87.33 s\n","Epoch [45/100], Loss: 1.0297, Eval Accuracy: 0.5163, Took 87.47 s\n","Epoch [46/100], Loss: 1.0293, Eval Accuracy: 0.5167, Took 87.33 s\n","Epoch [47/100], Loss: 1.0289, Eval Accuracy: 0.5177, Took 87.46 s\n","Epoch [48/100], Loss: 1.0285, Eval Accuracy: 0.5178, Took 87.34 s\n","Epoch [49/100], Loss: 1.028, Eval Accuracy: 0.518, Took 87.35 s\n","Epoch [50/100], Loss: 1.0276, Eval Accuracy: 0.5176, Took 87.45 s\n","Epoch [51/100], Loss: 1.0273, Eval Accuracy: 0.5178, Took 87.75 s\n","Epoch [52/100], Loss: 1.0269, Eval Accuracy: 0.5182, Took 87.86 s\n","Epoch [53/100], Loss: 1.0266, Eval Accuracy: 0.519, Took 87.87 s\n","Epoch [54/100], Loss: 1.0262, Eval Accuracy: 0.5187, Took 87.68 s\n","Epoch [55/100], Loss: 1.0259, Eval Accuracy: 0.5194, Took 88.06 s\n","Epoch [56/100], Loss: 1.0256, Eval Accuracy: 0.5194, Took 87.35 s\n","Epoch [57/100], Loss: 1.0253, Eval Accuracy: 0.5197, Took 87.95 s\n","Epoch [58/100], Loss: 1.0249, Eval Accuracy: 0.5194, Took 87.7 s\n","Epoch [59/100], Loss: 1.0246, Eval Accuracy: 0.5193, Took 88.43 s\n","Epoch [60/100], Loss: 1.0243, Eval Accuracy: 0.5194, Took 87.62 s\n","Epoch [61/100], Loss: 1.0241, Eval Accuracy: 0.5197, Took 87.44 s\n","Epoch [62/100], Loss: 1.0237, Eval Accuracy: 0.5197, Took 87.35 s\n","Epoch [63/100], Loss: 1.0235, Eval Accuracy: 0.52, Took 87.52 s\n","Epoch [64/100], Loss: 1.0233, Eval Accuracy: 0.5207, Took 87.39 s\n","Epoch [65/100], Loss: 1.023, Eval Accuracy: 0.5203, Took 87.35 s\n","Epoch [66/100], Loss: 1.0227, Eval Accuracy: 0.5214, Took 87.39 s\n","Epoch [67/100], Loss: 1.0225, Eval Accuracy: 0.5204, Took 87.45 s\n","Epoch [68/100], Loss: 1.0223, Eval Accuracy: 0.5212, Took 88.43 s\n","Epoch [69/100], Loss: 1.022, Eval Accuracy: 0.5218, Took 87.43 s\n","Epoch [70/100], Loss: 1.0218, Eval Accuracy: 0.5201, Took 87.53 s\n","Epoch [71/100], Loss: 1.0216, Eval Accuracy: 0.5213, Took 87.62 s\n","Stopped early after epoch 71 as validation accuracy was lower than average of the last 7 accuracies.\n","Last Loss: 1.0216, Last Eval Accuracy: 0.5213, Took 6217.62 s\n","Model saved as 20240616111205_encoder_64em_4l_4h_posenc_02dr_71ep.pt\n","------------\n","Not saved as loss too high:\n","[]\n"]},{"data":{"text/plain":["{'encoder_64em_4l_4h_posenc_02dr_100ep': 0.5213}"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["embed_dims = [64]\n","num_encoder_layers = [4]\n","num_heads = [4]\n","DROPOUTS = [0.2]\n","POS_ENC = [True, False]\n","e.hyper_parameter_training(embed_dims, num_encoder_layers, num_heads, DROPOUTS, POS_ENC, epochs=100)"]},{"cell_type":"code","execution_count":36,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["----- Start Training: 64 emb, 4 layers, 4 heads, 0.2 dropout, positional encoding: True, 100 epochs -----\n","Epoch [1/100], Loss: 1.1145, Eval Accuracy: 0.4759, Took 88.65 s\n","Epoch [2/100], Loss: 1.0813, Eval Accuracy: 0.4778, Took 89.17 s\n","Epoch [3/100], Loss: 1.0784, Eval Accuracy: 0.4809, Took 88.28 s\n","Epoch [4/100], Loss: 1.0759, Eval Accuracy: 0.4834, Took 88.31 s\n","Epoch [5/100], Loss: 1.0738, Eval Accuracy: 0.4837, Took 88.29 s\n","Epoch [6/100], Loss: 1.0719, Eval Accuracy: 0.4875, Took 88.32 s\n","Epoch [7/100], Loss: 1.0701, Eval Accuracy: 0.4889, Took 88.26 s\n","Epoch [8/100], Loss: 1.0681, Eval Accuracy: 0.4886, Took 88.26 s\n","Epoch [9/100], Loss: 1.0661, Eval Accuracy: 0.4922, Took 88.38 s\n","Epoch [10/100], Loss: 1.0642, Eval Accuracy: 0.4936, Took 88.33 s\n","Epoch [11/100], Loss: 1.0622, Eval Accuracy: 0.4928, Took 88.32 s\n","Epoch [12/100], Loss: 1.0605, Eval Accuracy: 0.496, Took 88.49 s\n","Epoch [13/100], Loss: 1.0588, Eval Accuracy: 0.4975, Took 88.4 s\n","Epoch [14/100], Loss: 1.057, Eval Accuracy: 0.4985, Took 89.01 s\n","Epoch [15/100], Loss: 1.0554, Eval Accuracy: 0.5002, Took 88.4 s\n","Epoch [16/100], Loss: 1.0538, Eval Accuracy: 0.4975, Took 88.34 s\n","Epoch [17/100], Loss: 1.0523, Eval Accuracy: 0.5015, Took 88.97 s\n","Epoch [18/100], Loss: 1.0511, Eval Accuracy: 0.5022, Took 88.42 s\n","Epoch [19/100], Loss: 1.0496, Eval Accuracy: 0.503, Took 88.37 s\n","Epoch [20/100], Loss: 1.0484, Eval Accuracy: 0.5039, Took 88.34 s\n","Epoch [21/100], Loss: 1.0471, Eval Accuracy: 0.5046, Took 88.31 s\n","Epoch [22/100], Loss: 1.0461, Eval Accuracy: 0.5066, Took 88.63 s\n","Epoch [23/100], Loss: 1.045, Eval Accuracy: 0.5064, Took 88.42 s\n","Epoch [24/100], Loss: 1.0439, Eval Accuracy: 0.5081, Took 88.32 s\n","Epoch [25/100], Loss: 1.0429, Eval Accuracy: 0.5075, Took 88.38 s\n","Epoch [26/100], Loss: 1.042, Eval Accuracy: 0.5088, Took 89.54 s\n","Epoch [27/100], Loss: 1.041, Eval Accuracy: 0.5097, Took 89.22 s\n","Epoch [28/100], Loss: 1.0402, Eval Accuracy: 0.5096, Took 88.37 s\n","Epoch [29/100], Loss: 1.0393, Eval Accuracy: 0.5114, Took 88.41 s\n","Epoch [30/100], Loss: 1.0385, Eval Accuracy: 0.5095, Took 88.4 s\n","Epoch [31/100], Loss: 1.0378, Eval Accuracy: 0.5104, Took 88.99 s\n","Epoch [32/100], Loss: 1.037, Eval Accuracy: 0.5112, Took 88.53 s\n","Epoch [33/100], Loss: 1.0363, Eval Accuracy: 0.5125, Took 88.68 s\n","Epoch [34/100], Loss: 1.0356, Eval Accuracy: 0.5127, Took 89.62 s\n","Epoch [35/100], Loss: 1.035, Eval Accuracy: 0.5137, Took 88.52 s\n","Epoch [36/100], Loss: 1.0343, Eval Accuracy: 0.5135, Took 88.59 s\n","Epoch [37/100], Loss: 1.0338, Eval Accuracy: 0.5143, Took 89.52 s\n","Epoch [38/100], Loss: 1.0333, Eval Accuracy: 0.5155, Took 89.47 s\n","Epoch [39/100], Loss: 1.0327, Eval Accuracy: 0.5151, Took 89.08 s\n","Epoch [40/100], Loss: 1.0322, Eval Accuracy: 0.5148, Took 88.49 s\n","Epoch [41/100], Loss: 1.0317, Eval Accuracy: 0.516, Took 89.26 s\n","Epoch [42/100], Loss: 1.0311, Eval Accuracy: 0.5146, Took 89.04 s\n","Epoch [43/100], Loss: 1.0308, Eval Accuracy: 0.5164, Took 88.4 s\n","Epoch [44/100], Loss: 1.0303, Eval Accuracy: 0.5158, Took 88.76 s\n","Epoch [45/100], Loss: 1.0297, Eval Accuracy: 0.5166, Took 88.69 s\n","Epoch [46/100], Loss: 1.0293, Eval Accuracy: 0.5168, Took 88.63 s\n","Epoch [47/100], Loss: 1.0288, Eval Accuracy: 0.5176, Took 88.55 s\n","Epoch [48/100], Loss: 1.0285, Eval Accuracy: 0.5181, Took 89.19 s\n","Epoch [49/100], Loss: 1.028, Eval Accuracy: 0.5174, Took 89.1 s\n","Epoch [50/100], Loss: 1.0276, Eval Accuracy: 0.5178, Took 88.44 s\n","Epoch [51/100], Loss: 1.0273, Eval Accuracy: 0.5182, Took 88.7 s\n","Epoch [52/100], Loss: 1.0269, Eval Accuracy: 0.5176, Took 88.4 s\n","Epoch [53/100], Loss: 1.0267, Eval Accuracy: 0.5186, Took 88.99 s\n","Epoch [54/100], Loss: 1.0262, Eval Accuracy: 0.5189, Took 88.96 s\n","Epoch [55/100], Loss: 1.0259, Eval Accuracy: 0.5193, Took 88.84 s\n","Epoch [56/100], Loss: 1.0256, Eval Accuracy: 0.5197, Took 88.78 s\n","Epoch [57/100], Loss: 1.0253, Eval Accuracy: 0.5193, Took 88.49 s\n","Epoch [58/100], Loss: 1.0249, Eval Accuracy: 0.5192, Took 88.45 s\n","Epoch [59/100], Loss: 1.0246, Eval Accuracy: 0.5191, Took 88.43 s\n","Epoch [60/100], Loss: 1.0243, Eval Accuracy: 0.5196, Took 88.41 s\n","Epoch [61/100], Loss: 1.024, Eval Accuracy: 0.5196, Took 88.43 s\n","Epoch [62/100], Loss: 1.0238, Eval Accuracy: 0.5196, Took 88.5 s\n","Epoch [63/100], Loss: 1.0234, Eval Accuracy: 0.5204, Took 88.42 s\n","Epoch [64/100], Loss: 1.0233, Eval Accuracy: 0.52, Took 88.44 s\n","Epoch [65/100], Loss: 1.023, Eval Accuracy: 0.5207, Took 88.42 s\n","Epoch [66/100], Loss: 1.0227, Eval Accuracy: 0.521, Took 89.56 s\n","Epoch [67/100], Loss: 1.0225, Eval Accuracy: 0.5205, Took 88.66 s\n","Epoch [68/100], Loss: 1.0223, Eval Accuracy: 0.5211, Took 89.03 s\n","Epoch [69/100], Loss: 1.022, Eval Accuracy: 0.5214, Took 88.54 s\n","Epoch [70/100], Loss: 1.0218, Eval Accuracy: 0.5206, Took 89.08 s\n","Epoch [71/100], Loss: 1.0216, Eval Accuracy: 0.522, Took 88.46 s\n","Epoch [72/100], Loss: 1.0214, Eval Accuracy: 0.5214, Took 88.39 s\n","Epoch [73/100], Loss: 1.0212, Eval Accuracy: 0.5217, Took 88.94 s\n","Epoch [74/100], Loss: 1.0209, Eval Accuracy: 0.522, Took 89.04 s\n","Epoch [75/100], Loss: 1.0207, Eval Accuracy: 0.5226, Took 88.74 s\n","Epoch [76/100], Loss: 1.0205, Eval Accuracy: 0.5223, Took 88.4 s\n","Epoch [77/100], Loss: 1.0204, Eval Accuracy: 0.5222, Took 88.4 s\n","Epoch [78/100], Loss: 1.0202, Eval Accuracy: 0.5224, Took 88.38 s\n","Epoch [79/100], Loss: 1.02, Eval Accuracy: 0.5224, Took 88.87 s\n","Epoch [80/100], Loss: 1.0197, Eval Accuracy: 0.5215, Took 88.81 s\n","Stopped early after epoch 80 as validation accuracy was lower than average of the last 7 accuracies.\n","Last Loss: 1.0197, Last Eval Accuracy: 0.5215, Took 7092.84 s\n","Model saved as 20240624185936_encoder_64em_4l_4h_posenc_02dr_80ep.pt\n","------------\n","Not saved as loss too high:\n","[]\n","CPU times: user 3h 34min 5s, sys: 11.9 s, total: 3h 34min 17s\n","Wall time: 1h 58min 12s\n"]}],"source":["%%time\n","\n","# Train best model \n","embed_dims = [64]\n","num_encoder_layers = [4]\n","num_heads = [4]\n","DROPOUTS = [0.2]\n","POS_ENC = [True]\n","accuracies, all_accuracies = e.hyper_parameter_training(embed_dims, num_encoder_layers, num_heads, DROPOUTS, POS_ENC, epochs=100)"]},{"cell_type":"code","execution_count":37,"metadata":{},"outputs":[],"source":["mlh.to_pickle(all_accuracies, data_path+f'/{e.organism}/training_accuracies_encoder.pkl')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":0}
