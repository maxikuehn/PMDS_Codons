{"cells":[{"cell_type":"markdown","metadata":{"id":"dvibukPbQ7Zg"},"source":["# Encoder-only Transformer Architektur"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20842,"status":"ok","timestamp":1715688662385,"user":{"displayName":"Insa Belter","userId":"09408038895575287386"},"user_tz":-120},"id":"fXeUV5wCRtUz","outputId":"2bb0af2b-b2a5-4f6e-c9d6-addcb643a568"},"outputs":[],"source":["#from google.colab import drive\n","#drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8804,"status":"ok","timestamp":1715688671184,"user":{"displayName":"Insa Belter","userId":"09408038895575287386"},"user_tz":-120},"id":"3yudZ4edSJEQ","outputId":"d4151a0c-b418-4144-d13b-0f4aef17b8a7"},"outputs":[{"name":"stdout","output_type":"stream","text":["Defaulting to user installation because normal site-packages is not writeable\n","Requirement already satisfied: biopython in /home/mkuehn/.local/lib/python3.10/site-packages (1.83)\n","Requirement already satisfied: numpy in /home/mkuehn/.local/lib/python3.10/site-packages (from biopython) (1.26.4)\n"]}],"source":["!pip install biopython"]},{"cell_type":"code","execution_count":41,"metadata":{"executionInfo":{"elapsed":5081,"status":"ok","timestamp":1715688676256,"user":{"displayName":"Insa Belter","userId":"09408038895575287386"},"user_tz":-120},"id":"ev_KN7VqQ7Zm"},"outputs":[],"source":["import sys\n","import random\n","import numpy as np\n","import pandas as pd\n","import ast\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader\n","from torch import Tensor\n","import time\n","import math\n","\n","sys.path.append('../scripts')\n","#sys.path.append('/content/drive/MyDrive/PMDS/Notebooks')\n","import ml_helper"]},{"cell_type":"code","execution_count":42,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1715688676256,"user":{"displayName":"Insa Belter","userId":"09408038895575287386"},"user_tz":-120},"id":"9eRDLHmaS7Im"},"outputs":[],"source":["#data_path = '/content/drive/MyDrive/PMDS/Data'\n","data_path = '../data'"]},{"cell_type":"code","execution_count":43,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1715688676256,"user":{"displayName":"Insa Belter","userId":"09408038895575287386"},"user_tz":-120},"id":"0ayA8mz2Q7Zp"},"outputs":[],"source":["SEED = 42\n","def set_seed(SEED=SEED):\n","    random.seed(SEED)\n","    np.random.seed(SEED)\n","    torch.manual_seed(SEED)\n","    torch.cuda.manual_seed(SEED)\n","set_seed()"]},{"cell_type":"code","execution_count":44,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":566,"status":"ok","timestamp":1715688676819,"user":{"displayName":"Insa Belter","userId":"09408038895575287386"},"user_tz":-120},"id":"5hFAHJ8hRE8p","outputId":"6c9d739b-7b72-447c-878a-a0291901b15d"},"outputs":[{"name":"stdout","output_type":"stream","text":["cuda:0\n"]}],"source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(device)"]},{"cell_type":"markdown","metadata":{"id":"1iTm60N3Q7Zr"},"source":["## Prepare Test and Training Data Loader"]},{"cell_type":"code","execution_count":45,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1715688680014,"user":{"displayName":"Insa Belter","userId":"09408038895575287386"},"user_tz":-120},"id":"iZLLB2yhQ7Zs"},"outputs":[],"source":["amino_acids = ['A', 'R', 'N', 'D', 'C', 'Q', 'E', 'G', 'H', 'I', 'L', 'K', 'M', 'F', 'P', 'S', 'T', 'W', 'Y', 'V', '*',\n","               '_']\n","\n","aminoacids_to_integer = dict((a, i) for i, a in enumerate(amino_acids))\n","integer_to_aminoacids = dict((i, a) for i, a in enumerate(amino_acids))\n","\n","codons = ['TTT', 'TTC', 'TTA', 'TTG', 'TCT', 'TCC', 'TCA', 'TCG', 'TAT', 'TAC', 'TAA', 'TAG', 'TGT', 'TGC', 'TGA',\n","          'TGG', 'CTT', 'CTC', 'CTA', 'CTG', 'CCT', 'CCC', 'CCA', 'CCG', 'CAT', 'CAC', 'CAA', 'CAG', 'CGT', 'CGC',\n","          'CGA', 'CGG', 'ATT', 'ATC', 'ATA', 'ATG', 'ACT', 'ACC', 'ACA', 'ACG', 'AAT', 'AAC', 'AAA', 'AAG', 'AGT',\n","          'AGC', 'AGA', 'AGG', 'GTT', 'GTC', 'GTA', 'GTG', 'GCT', 'GCC', 'GCA', 'GCG', 'GAT', 'GAC', 'GAA', 'GAG',\n","          'GGT', 'GGC', 'GGA', 'GGG', '___']\n","\n","codons_to_integer = dict((c, i) for i, c in enumerate(codons))\n","integer_to_codons = dict((i, c) for i, c in enumerate(codons))"]},{"cell_type":"code","execution_count":46,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14935,"status":"ok","timestamp":1715688695565,"user":{"displayName":"Insa Belter","userId":"09408038895575287386"},"user_tz":-120},"id":"8w1wA5dDQ7Zt","outputId":"f67d1129-17d1-4a11-f6b0-83a4f973ba75"},"outputs":[{"name":"stdout","output_type":"stream","text":["L채nge train_dataset: 3561\n","L채nge test_dataset: 864\n"]}],"source":["organism = \"E.Coli\"\n","min_length = None\n","max_length = 500\n","\n","SPEEDS_ADDED = True\n","\n","train_dataset = ml_helper.CodonDataset(organism, \"train\", min_length, max_length, add_speeds=SPEEDS_ADDED, cut_data=True, one_hot_aa=False, data_path=data_path, device=device)\n","print(f\"L채nge train_dataset: {len(train_dataset)}\")\n","test_dataset = ml_helper.CodonDataset(organism, \"test\", min_length, max_length, add_speeds=SPEEDS_ADDED, cut_data=True, one_hot_aa=False, data_path=data_path, device=device)\n","print(f\"L채nge test_dataset: {len(test_dataset)}\")"]},{"cell_type":"code","execution_count":47,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":369,"status":"ok","timestamp":1715688695930,"user":{"displayName":"Insa Belter","userId":"09408038895575287386"},"user_tz":-120},"id":"TDq7AeaFQ7Zv","outputId":"1b96196c-89a7-4031-b63e-6a9358f7aa09"},"outputs":[{"name":"stdout","output_type":"stream","text":["(tensor([[ 12.0000,   1.0000],\n","        [ 16.0000,   1.0000],\n","        [ 18.0000,   2.5500],\n","        [  0.0000,   0.8800],\n","        [ 19.0000,   1.5000],\n","        [  6.0000,   1.8500],\n","        [ 13.0000,   2.1000],\n","        [  3.0000,   1.9000],\n","        [  2.0000,   1.6500],\n","        [ 19.0000,   1.5000],\n","        [ 15.0000,   2.5200],\n","        [  1.0000,   5.8700],\n","        [ 10.0000,   1.6800],\n","        [ 18.0000,   2.5500],\n","        [  7.0000,   2.7500],\n","        [  3.0000,   1.9000],\n","        [ 19.0000,   1.5000],\n","        [  1.0000,   5.8700],\n","        [  0.0000,   0.8800],\n","        [ 19.0000,   1.5000],\n","        [  3.0000,   1.9000],\n","        [  7.0000,   2.7500],\n","        [ 19.0000,   1.5000],\n","        [ 15.0000,   2.5200],\n","        [  9.0000,   2.1000],\n","        [  0.0000,   0.8800],\n","        [  9.0000,   2.1000],\n","        [ 11.0000,   1.2500],\n","        [  3.0000,   1.9000],\n","        [  7.0000,   2.7500],\n","        [  6.0000,   1.8500],\n","        [ 13.0000,   2.1000],\n","        [ 13.0000,   2.1000],\n","        [ 15.0000,   2.5200],\n","        [ 12.0000,   1.0000],\n","        [ 10.0000,   1.6800],\n","        [  7.0000,   2.7500],\n","        [ 14.0000,   2.2500],\n","        [ 15.0000,   2.5200],\n","        [  7.0000,   2.7500],\n","        [ 15.0000,   2.5200],\n","        [  7.0000,   2.7500],\n","        [ 11.0000,   1.2500],\n","        [ 16.0000,   1.0000],\n","        [ 16.0000,   1.0000],\n","        [  4.0000,   3.2000],\n","        [ 10.0000,   1.6800],\n","        [  1.0000,   5.8700],\n","        [ 10.0000,   1.6800],\n","        [  9.0000,   2.1000],\n","        [  0.0000,   0.8800],\n","        [  7.0000,   2.7500],\n","        [ 13.0000,   2.1000],\n","        [  6.0000,   1.8500],\n","        [  5.0000,   1.2500],\n","        [ 10.0000,   1.6800],\n","        [ 15.0000,   2.5200],\n","        [  7.0000,   2.7500],\n","        [  7.0000,   2.7500],\n","        [  0.0000,   0.8800],\n","        [  9.0000,   2.1000],\n","        [ 15.0000,   2.5200],\n","        [  9.0000,   2.1000],\n","        [ 13.0000,   2.1000],\n","        [  7.0000,   2.7500],\n","        [ 11.0000,   1.2500],\n","        [ 14.0000,   2.2500],\n","        [  0.0000,   0.8800],\n","        [ 15.0000,   2.5200],\n","        [  2.0000,   1.6500],\n","        [ 10.0000,   1.6800],\n","        [ 14.0000,   2.2500],\n","        [ 14.0000,   2.2500],\n","        [ 17.0000,   2.4000],\n","        [  6.0000,   1.8500],\n","        [  1.0000,   5.8700],\n","        [  3.0000,   1.9000],\n","        [ 19.0000,   1.5000],\n","        [  2.0000,   1.6500],\n","        [ 16.0000,   1.0000],\n","        [ 19.0000,   1.5000],\n","        [ 13.0000,   2.1000],\n","        [  5.0000,   1.2500],\n","        [  3.0000,   1.9000],\n","        [ 18.0000,   2.5500],\n","        [  0.0000,   0.8800],\n","        [ 10.0000,   1.6800],\n","        [ 13.0000,   2.1000],\n","        [ 14.0000,   2.2500],\n","        [  8.0000,   1.3500],\n","        [ 12.0000,   1.0000],\n","        [ 15.0000,   2.5200],\n","        [  9.0000,   2.1000],\n","        [ 10.0000,   1.6800],\n","        [  3.0000,   1.9000],\n","        [  2.0000,   1.6500],\n","        [ 19.0000,   1.5000],\n","        [  0.0000,   0.8800],\n","        [ 18.0000,   2.5500],\n","        [  7.0000,   2.7500],\n","        [ 10.0000,   1.6800],\n","        [ 12.0000,   1.0000],\n","        [ 19.0000,   1.5000],\n","        [ 11.0000,   1.2500],\n","        [  7.0000,   2.7500],\n","        [ 19.0000,   1.5000],\n","        [  2.0000,   1.6500],\n","        [ 11.0000,   1.2500],\n","        [ 11.0000,   1.2500],\n","        [  5.0000,   1.2500],\n","        [  1.0000,   5.8700],\n","        [  8.0000,   1.3500],\n","        [  0.0000,   0.8800],\n","        [ 12.0000,   1.0000],\n","        [  0.0000,   0.8800],\n","        [  5.0000,   1.2500],\n","        [  6.0000,   1.8500],\n","        [  0.0000,   0.8800],\n","        [ 10.0000,   1.6800],\n","        [  6.0000,   1.8500],\n","        [ 11.0000,   1.2500],\n","        [ 19.0000,   1.5000],\n","        [  0.0000,   0.8800],\n","        [ 10.0000,   1.6800],\n","        [  7.0000,   2.7500],\n","        [ 13.0000,   2.1000],\n","        [ 19.0000,   1.5000],\n","        [  8.0000,   1.3500],\n","        [  5.0000,   1.2500],\n","        [  1.0000,   5.8700],\n","        [ 11.0000,   1.2500],\n","        [ 14.0000,   2.2500],\n","        [ 15.0000,   2.5200],\n","        [  5.0000,   1.2500],\n","        [ 10.0000,   1.6800],\n","        [ 15.0000,   2.5200],\n","        [  7.0000,   2.7500],\n","        [  7.0000,   2.7500],\n","        [  5.0000,   1.2500],\n","        [  1.0000,   5.8700],\n","        [  5.0000,   1.2500],\n","        [  1.0000,   5.8700],\n","        [ 19.0000,   1.5000],\n","        [  0.0000,   0.8800],\n","        [  9.0000,   2.1000],\n","        [  0.0000,   0.8800],\n","        [  1.0000,   5.8700],\n","        [  0.0000,   0.8800],\n","        [ 10.0000,   1.6800],\n","        [ 19.0000,   1.5000],\n","        [  2.0000,   1.6500],\n","        [  6.0000,   1.8500],\n","        [ 14.0000,   2.2500],\n","        [  1.0000,   5.8700],\n","        [ 19.0000,   1.5000],\n","        [ 10.0000,   1.6800],\n","        [ 10.0000,   1.6800],\n","        [ 10.0000,   1.6800],\n","        [  3.0000,   1.9000],\n","        [  6.0000,   1.8500],\n","        [ 14.0000,   2.2500],\n","        [ 10.0000,   1.6800],\n","        [  7.0000,   2.7500],\n","        [  0.0000,   0.8800],\n","        [ 10.0000,   1.6800],\n","        [  3.0000,   1.9000],\n","        [ 10.0000,   1.6800],\n","        [ 11.0000,   1.2500],\n","        [ 10.0000,   1.6800],\n","        [  1.0000,   5.8700],\n","        [  6.0000,   1.8500],\n","        [  5.0000,   1.2500],\n","        [ 12.0000,   1.0000],\n","        [  5.0000,   1.2500],\n","        [ 10.0000,   1.6800],\n","        [  6.0000,   1.8500],\n","        [ 10.0000,   1.6800],\n","        [ 11.0000,   1.2500],\n","        [ 11.0000,   1.2500],\n","        [ 10.0000,   1.6800],\n","        [  5.0000,   1.2500],\n","        [  5.0000,   1.2500],\n","        [ 15.0000,   2.5200],\n","        [ 10.0000,   1.6800],\n","        [  7.0000,   2.7500],\n","        [  9.0000,   2.1000],\n","        [ 16.0000,   1.0000],\n","        [ 13.0000,   2.1000],\n","        [  9.0000,   2.1000],\n","        [ 13.0000,   2.1000],\n","        [ 19.0000,   1.5000],\n","        [ 16.0000,   1.0000],\n","        [  8.0000,   1.3500],\n","        [  3.0000,   1.9000],\n","        [  5.0000,   1.2500],\n","        [  7.0000,   2.7500],\n","        [  6.0000,   1.8500],\n","        [  0.0000,   0.8800],\n","        [ 10.0000,   1.6800],\n","        [ 15.0000,   2.5200],\n","        [ 12.0000,   1.0000],\n","        [ 15.0000,   2.5200],\n","        [  3.0000,   1.9000],\n","        [  1.0000,   5.8700],\n","        [ 19.0000,   1.5000],\n","        [  0.0000,   0.8800],\n","        [ 19.0000,   1.5000],\n","        [ 13.0000,   2.1000],\n","        [  2.0000,   1.6500],\n","        [  2.0000,   1.6500],\n","        [  7.0000,   2.7500],\n","        [  1.0000,   5.8700],\n","        [  9.0000,   2.1000],\n","        [  6.0000,   1.8500],\n","        [  5.0000,   1.2500],\n","        [ 19.0000,   1.5000],\n","        [  3.0000,   1.9000],\n","        [ 15.0000,   2.5200],\n","        [ 14.0000,   2.2500],\n","        [  1.0000,   5.8700],\n","        [  3.0000,   1.9000],\n","        [ 10.0000,   1.6800],\n","        [ 18.0000,   2.5500],\n","        [ 12.0000,   1.0000],\n","        [  1.0000,   5.8700],\n","        [ 14.0000,   2.2500],\n","        [  1.0000,   5.8700],\n","        [ 16.0000,   1.0000],\n","        [ 14.0000,   2.2500],\n","        [ 13.0000,   2.1000],\n","        [ 19.0000,   1.5000],\n","        [  0.0000,   0.8800],\n","        [  7.0000,   2.7500],\n","        [ 13.0000,   2.1000],\n","        [ 19.0000,   1.5000],\n","        [  7.0000,   2.7500],\n","        [ 16.0000,   1.0000],\n","        [ 15.0000,   2.5200],\n","        [  2.0000,   1.6500],\n","        [ 19.0000,   1.5000],\n","        [ 13.0000,   2.1000],\n","        [  3.0000,   1.9000],\n","        [  7.0000,   2.7500],\n","        [ 10.0000,   1.6800],\n","        [ 12.0000,   1.0000],\n","        [  0.0000,   0.8800],\n","        [  6.0000,   1.8500],\n","        [ 11.0000,   1.2500],\n","        [ 10.0000,   1.6800],\n","        [  4.0000,   3.2000],\n","        [  7.0000,   2.7500],\n","        [ 12.0000,   1.0000],\n","        [ 16.0000,   1.0000],\n","        [  7.0000,   2.7500],\n","        [ 15.0000,   2.5200],\n","        [ 13.0000,   2.1000],\n","        [  0.0000,   0.8800],\n","        [ 10.0000,   1.6800],\n","        [  1.0000,   5.8700],\n","        [ 14.0000,   2.2500],\n","        [  6.0000,   1.8500],\n","        [  8.0000,   1.3500],\n","        [  9.0000,   2.1000],\n","        [  1.0000,   5.8700],\n","        [ 10.0000,   1.6800],\n","        [  2.0000,   1.6500],\n","        [ 16.0000,   1.0000],\n","        [ 14.0000,   2.2500],\n","        [  7.0000,   2.7500],\n","        [  6.0000,   1.8500],\n","        [ 10.0000,   1.6800],\n","        [  5.0000,   1.2500],\n","        [  0.0000,   0.8800],\n","        [  2.0000,   1.6500],\n","        [  7.0000,   2.7500],\n","        [ 16.0000,   1.0000],\n","        [  9.0000,   2.1000],\n","        [  5.0000,   1.2500],\n","        [  0.0000,   0.8800],\n","        [ 19.0000,   1.5000],\n","        [  5.0000,   1.2500],\n","        [ 18.0000,   2.5500],\n","        [  5.0000,   1.2500],\n","        [  7.0000,   2.7500],\n","        [  0.0000,   0.8800],\n","        [  0.0000,   0.8800],\n","        [ 16.0000,   1.0000],\n","        [  1.0000,   5.8700],\n","        [ 13.0000,   2.1000],\n","        [  6.0000,   1.8500],\n","        [ 10.0000,   1.6800],\n","        [ 11.0000,   1.2500],\n","        [ 10.0000,   1.6800],\n","        [  2.0000,   1.6500],\n","        [  7.0000,   2.7500],\n","        [  7.0000,   2.7500],\n","        [  6.0000,   1.8500],\n","        [ 11.0000,   1.2500],\n","        [ 10.0000,   1.6800],\n","        [ 10.0000,   1.6800],\n","        [ 19.0000,   1.5000],\n","        [ 15.0000,   2.5200],\n","        [  5.0000,   1.2500],\n","        [  0.0000,   0.8800],\n","        [  2.0000,   1.6500],\n","        [ 12.0000,   1.0000],\n","        [ 16.0000,   1.0000],\n","        [  7.0000,   2.7500],\n","        [  6.0000,   1.8500],\n","        [  6.0000,   1.8500],\n","        [ 10.0000,   1.6800],\n","        [ 14.0000,   2.2500],\n","        [  0.0000,   0.8800],\n","        [ 16.0000,   1.0000],\n","        [ 10.0000,   1.6800],\n","        [ 16.0000,   1.0000],\n","        [ 14.0000,   2.2500],\n","        [  7.0000,   2.7500],\n","        [  5.0000,   1.2500],\n","        [  5.0000,   1.2500],\n","        [ 19.0000,   1.5000],\n","        [ 12.0000,   1.0000],\n","        [ 19.0000,   1.5000],\n","        [ 15.0000,   2.5200],\n","        [ 17.0000,   2.4000],\n","        [ 15.0000,   2.5200],\n","        [  1.0000,   5.8700],\n","        [  3.0000,   1.9000],\n","        [ 19.0000,   1.5000],\n","        [ 12.0000,   1.0000],\n","        [ 19.0000,   1.5000],\n","        [ 14.0000,   2.2500],\n","        [ 10.0000,   1.6800],\n","        [ 19.0000,   1.5000],\n","        [  6.0000,   1.8500],\n","        [  6.0000,   1.8500],\n","        [  1.0000,   5.8700],\n","        [ 20.0000,  25.3300],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000],\n","        [ 21.0000, -10.0000]], device='cuda:0', dtype=torch.float64), tensor([35., 39.,  9., 54., 51., 59.,  0., 57., 41., 49.,  7., 31.,  3.,  9.,\n","        60., 57., 51., 29., 54., 50., 56., 61., 49., 44., 32., 55., 34., 42.,\n","        56., 60., 59.,  1.,  1.,  4., 35., 19., 63., 23.,  5., 61.,  5., 61.,\n","        42., 37., 37., 13., 19., 29., 19., 32., 52., 61.,  1., 58., 27., 16.,\n","         5., 61., 63., 52., 33.,  4., 33.,  0., 60., 42., 21., 53., 45., 40.,\n","        19., 22., 23., 15., 59., 31., 57., 51., 40., 36., 49.,  0., 27., 57.,\n","         9., 55., 18.,  0., 23., 24., 35.,  7., 32., 16., 57., 40., 49., 53.,\n","         8., 63., 19., 35., 49., 42., 61., 51., 40., 42., 43., 27., 31., 25.,\n","        54., 35., 55., 26., 59., 55., 19., 59., 42., 51., 55.,  3., 63.,  0.,\n","        50., 24., 26., 28., 42., 23.,  6., 26., 16.,  4., 60., 60., 27., 29.,\n","        27., 31., 48., 52., 33., 53., 46., 54.,  3., 51., 40., 58., 23., 29.,\n","        50.,  3., 19.,  3., 56., 58., 23., 17., 61., 54., 19., 56., 17., 42.,\n","         3., 28., 59., 27., 35., 27., 19., 58., 19., 42., 42., 19., 26., 27.,\n","         4., 17., 60., 33., 36.,  0., 33.,  1., 48., 37., 25., 56., 27., 61.,\n","        58., 55.,  2.,  7., 35.,  5., 56., 28., 51., 55., 48.,  1., 40., 40.,\n","        62., 29., 32., 59., 27., 49., 56.,  5., 23., 29., 56., 17.,  8., 35.,\n","        29., 23., 29., 39., 23.,  0., 48., 53., 63.,  1., 48., 60., 38.,  7.,\n","        40., 48.,  0., 56., 62., 19., 35., 54., 59., 42., 16., 12., 61., 35.,\n","        39., 62., 45.,  1., 53., 19., 30., 23., 58., 24., 33., 29., 17., 41.,\n","        37., 20., 60., 58., 19., 27., 53., 40., 61., 39., 33., 27., 55., 51.,\n","        26.,  8., 27., 61., 55., 54., 36., 28.,  0., 58., 19., 42.,  3., 41.,\n","        61., 60., 58., 42., 19., 16., 51., 44., 27., 53., 40., 35., 38., 61.,\n","        58., 58., 19., 20., 53., 39., 17., 39., 21., 62., 26., 27., 51., 35.,\n","        48.,  5., 15.,  7., 28., 56., 51., 35., 51., 23., 19., 48., 59., 59.,\n","        47., 14., 64., 64., 64., 64., 64., 64., 64., 64., 64., 64., 64., 64.,\n","        64., 64., 64., 64., 64., 64., 64., 64., 64., 64., 64., 64., 64., 64.,\n","        64., 64., 64., 64., 64., 64., 64., 64., 64., 64., 64., 64., 64., 64.,\n","        64., 64., 64., 64., 64., 64., 64., 64., 64., 64., 64., 64., 64., 64.,\n","        64., 64., 64., 64., 64., 64., 64., 64., 64., 64., 64., 64., 64., 64.,\n","        64., 64., 64., 64., 64., 64., 64., 64., 64., 64., 64., 64., 64., 64.,\n","        64., 64., 64., 64., 64., 64., 64., 64., 64., 64., 64., 64., 64., 64.,\n","        64., 64., 64., 64., 64., 64., 64., 64., 64., 64., 64., 64., 64., 64.,\n","        64., 64., 64., 64., 64., 64., 64., 64., 64., 64., 64., 64., 64., 64.,\n","        64., 64., 64., 64., 64., 64., 64., 64., 64., 64., 64., 64., 64., 64.,\n","        64., 64., 64., 64., 64., 64., 64., 64., 64., 64., 64., 64., 64., 64.,\n","        64., 64., 64., 64., 64., 64., 64., 64., 64., 64.], device='cuda:0'))\n","torch.Size([500, 2])\n","torch.Size([500])\n"]}],"source":["print(train_dataset[3])\n","print(train_dataset[3][0].shape)\n","print(train_dataset[3][1].shape)"]},{"cell_type":"code","execution_count":48,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1715688695930,"user":{"displayName":"Insa Belter","userId":"09408038895575287386"},"user_tz":-120},"id":"MQvx476IQ7Zw"},"outputs":[],"source":["BATCH_SIZE = 32\n","train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n","test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"]},{"cell_type":"markdown","metadata":{"id":"6UP5EBpZQ7Zx"},"source":["## Define the encoder-only model"]},{"cell_type":"code","execution_count":49,"metadata":{},"outputs":[],"source":["class PositionalEncoding(nn.Module):\n","\n","    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 500):\n","        super().__init__()\n","        self.dropout = nn.Dropout(p=dropout)\n","\n","        position = torch.arange(max_len).unsqueeze(1)\n","        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n","        pe = torch.zeros(max_len, 1, d_model)\n","        pe[:, 0, 0::2] = torch.sin(position * div_term)\n","        pe[:, 0, 1::2] = torch.cos(position * div_term)\n","        self.register_buffer('pe', pe)\n","\n","    def forward(self, x: Tensor) -> Tensor:\n","        \"\"\"\n","        Arguments:\n","            x: Tensor, shape ``[seq_len, batch_size, embedding_dim]``\n","        \"\"\"\n","        x = x + self.pe[:x.size(0)]\n","        return self.dropout(x)"]},{"cell_type":"code","execution_count":50,"metadata":{"executionInfo":{"elapsed":272,"status":"ok","timestamp":1715688700989,"user":{"displayName":"Insa Belter","userId":"09408038895575287386"},"user_tz":-120},"id":"DmAoTz7sQ7Zx"},"outputs":[],"source":["class EncoderClassifier(nn.Module):\n","    def __init__(self, embed_dim, num_layers, num_heads, dropout=0.2, pos_enc=False):\n","        super(EncoderClassifier, self).__init__()\n","\n","        emb_size = embed_dim\n","        if SPEEDS_ADDED:\n","            emb_size -= 1\n","        self.emb = nn.Embedding(len(amino_acids), emb_size, padding_idx=len(amino_acids)-1)\n","        self.pos_enc = pos_enc\n","        self.pos_encoder = PositionalEncoding(embed_dim, dropout)\n","\n","        self.encoder_layer = nn.TransformerEncoderLayer(\n","            d_model=embed_dim,\n","            nhead=num_heads,\n","            batch_first=True\n","        )\n","        self.encoder = nn.TransformerEncoder(\n","            encoder_layer=self.encoder_layer,\n","            num_layers=num_layers,\n","        )\n","        self.linear = nn.Linear(embed_dim, len(codons))\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, x):\n","        x = x.long()\n","        if SPEEDS_ADDED:\n","            x1 = self.emb(x[:, :, 0])\n","            x2 = x[:, :, 1].unsqueeze(-1)\n","            x = torch.cat((x1, x2), dim=-1)  # Concatenate along the feature dimension\n","        else:\n","            x = self.emb(x)\n","\n","        if self.pos_enc:\n","            x = self.pos_encoder(x)  # Add positional encoding\n","        x = self.encoder(x)\n","        x = self.dropout(x)\n","        out = self.linear(x)\n","        return out"]},{"cell_type":"code","execution_count":51,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1715688701504,"user":{"displayName":"Insa Belter","userId":"09408038895575287386"},"user_tz":-120},"id":"2u2Dbb0rQ7Zy"},"outputs":[],"source":["EMBED_DIM = 256\n","NUM_ENCODER_LAYERS = 4\n","NUM_HEADS = 4\n","DROP_OUT = 0.2"]},{"cell_type":"code","execution_count":52,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1715688702540,"user":{"displayName":"Insa Belter","userId":"09408038895575287386"},"user_tz":-120},"id":"33ksA3YLQ7Zy","outputId":"559e6f1f-4377-402d-fe71-a0adf4a7a70f"},"outputs":[{"name":"stdout","output_type":"stream","text":["EncoderClassifier(\n","  (emb): Embedding(22, 255, padding_idx=21)\n","  (pos_encoder): PositionalEncoding(\n","    (dropout): Dropout(p=0.2, inplace=False)\n","  )\n","  (encoder_layer): TransformerEncoderLayer(\n","    (self_attn): MultiheadAttention(\n","      (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n","    )\n","    (linear1): Linear(in_features=256, out_features=2048, bias=True)\n","    (dropout): Dropout(p=0.1, inplace=False)\n","    (linear2): Linear(in_features=2048, out_features=256, bias=True)\n","    (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","    (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","    (dropout1): Dropout(p=0.1, inplace=False)\n","    (dropout2): Dropout(p=0.1, inplace=False)\n","  )\n","  (encoder): TransformerEncoder(\n","    (layers): ModuleList(\n","      (0-3): 4 x TransformerEncoderLayer(\n","        (self_attn): MultiheadAttention(\n","          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n","        )\n","        (linear1): Linear(in_features=256, out_features=2048, bias=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","        (linear2): Linear(in_features=2048, out_features=256, bias=True)\n","        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","        (dropout1): Dropout(p=0.1, inplace=False)\n","        (dropout2): Dropout(p=0.1, inplace=False)\n","      )\n","    )\n","  )\n","  (linear): Linear(in_features=256, out_features=65, bias=True)\n","  (dropout): Dropout(p=0.2, inplace=False)\n",")\n"]}],"source":["model = EncoderClassifier(\n","    embed_dim=EMBED_DIM,\n","    num_layers=NUM_ENCODER_LAYERS,\n","    num_heads=NUM_HEADS,\n","    dropout=DROP_OUT,\n","    pos_enc=False\n",").to(device)\n","print(model)"]},{"cell_type":"code","execution_count":53,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1715688702799,"user":{"displayName":"Insa Belter","userId":"09408038895575287386"},"user_tz":-120},"id":"DLRNk1mnQ7Zz"},"outputs":[],"source":["# Total parameters and trainable parameters.\n","def print_parameters(model):\n","    total_params = sum(p.numel() for p in model.parameters())\n","    print(f\"{total_params:,} total parameters.\")\n","    total_trainable_params = sum(\n","        p.numel() for p in model.parameters() if p.requires_grad)\n","    print(f\"{total_trainable_params:,} training parameters.\")"]},{"cell_type":"code","execution_count":54,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1715688703433,"user":{"displayName":"Insa Belter","userId":"09408038895575287386"},"user_tz":-120},"id":"Ua_2VN3NQ7Zz","outputId":"472c69d7-94cb-40cd-bd7e-8e1e75c00415"},"outputs":[{"name":"stdout","output_type":"stream","text":["6,597,675 total parameters.\n","6,597,675 training parameters.\n"]}],"source":["print_parameters(model)"]},{"cell_type":"code","execution_count":55,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1715688704233,"user":{"displayName":"Insa Belter","userId":"09408038895575287386"},"user_tz":-120},"id":"6SEl0FSxQ7Zz"},"outputs":[],"source":["def test_forward_pass(model, data_loader):\n","  batch_data, batch_label = next(iter(data_loader))\n","  print(f\"input dim: {batch_data.shape}\")\n","  output = model(batch_data)\n","  print(f\"output dim: {output.shape}\")"]},{"cell_type":"code","execution_count":56,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1152,"status":"ok","timestamp":1715688705880,"user":{"displayName":"Insa Belter","userId":"09408038895575287386"},"user_tz":-120},"id":"X9OgGtB6Q7Z0","outputId":"52e399fa-b185-4c52-c314-91c772f4e98f"},"outputs":[{"name":"stdout","output_type":"stream","text":["input dim: torch.Size([32, 500, 2])\n","output dim: torch.Size([32, 500, 65])\n"]}],"source":["test_forward_pass(model, train_loader)"]},{"cell_type":"markdown","metadata":{"id":"6DIXDxybQ7Z0"},"source":["## Define the training methods"]},{"cell_type":"code","execution_count":57,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1715688705880,"user":{"displayName":"Insa Belter","userId":"09408038895575287386"},"user_tz":-120},"id":"B8_PCftyQ7Z0"},"outputs":[],"source":["def train_model(model, optimizer, criterion, num_epochs, print_batches=0):\n","    for epoch in range(num_epochs):\n","        model.train()\n","\n","        epoch_start_time = time.time()\n","        batch_start_time = time.time()\n","        epoch_loss = 0\n","        for batch_idx, batch in enumerate(train_loader):\n","            # Clear gradients\n","            optimizer.zero_grad()\n","\n","            # Forward pass\n","            input_data, labels = batch\n","\n","            output = model(input_data)  # (batch_size, seq_len, num_classes)\n","            output = output.view(-1, len(codons)) # (batch_size * seq_len, num_classes)\n","\n","            labels = labels.view(-1).long() # (batch_size, seq_len) -> (batch_size * seq_len)\n","\n","            # Calculate loss\n","            loss = criterion(output, labels)\n","            epoch_loss += loss.item()\n","\n","            # Backward pass\n","            loss.backward()\n","\n","            # Update model parameters\n","            optimizer.step()\n","\n","            if print_batches != 0 and batch_idx % print_batches == (print_batches-1):\n","                batch_time =  round(time.time() - batch_start_time,2)\n","                print(f'Batch [{batch_idx+1}/{len(train_loader)}], Loss: {loss.item():.4f}, Time since last batch print: {batch_time} s')\n","                batch_start_time = time.time()\n","\n","        epoch_time = round(time.time() - epoch_start_time,2)\n","        epoch_loss = round(epoch_loss / len(train_loader),4)\n","        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss}, Took {epoch_time} s')"]},{"cell_type":"markdown","metadata":{"id":"zXx3COjlQ7Z1"},"source":["## Define the evaluation methods to calculate metrics"]},{"cell_type":"code","execution_count":58,"metadata":{"executionInfo":{"elapsed":252,"status":"ok","timestamp":1715689686587,"user":{"displayName":"Insa Belter","userId":"09408038895575287386"},"user_tz":-120},"id":"hnUdxk_OQ7Z1"},"outputs":[],"source":["from sklearn.metrics import accuracy_score\n","\n","def compute_accuracy(predictions, labels):\n","    predictions = np.argmax(predictions, axis=1)\n","\n","    # Find indices where labels are not equal to the padding value\n","    non_padding_indices = labels != codons_to_integer['___']\n","\n","    # Filter out predictions and labels where the label is not padding\n","    filtered_predictions = predictions[non_padding_indices]\n","    filtered_labels = labels[non_padding_indices]\n","\n","    acc = accuracy_score(labels, predictions)\n","    return acc"]},{"cell_type":"code","execution_count":59,"metadata":{"executionInfo":{"elapsed":259,"status":"ok","timestamp":1715689274929,"user":{"displayName":"Insa Belter","userId":"09408038895575287386"},"user_tz":-120},"id":"GyHA89BhQ7Z1"},"outputs":[],"source":["def evaluate_model(model, criterion):\n","    model.eval()  # Set the model to evaluation mode\n","\n","    total_loss = 0.0\n","\n","    with torch.no_grad():\n","        accuracies = []\n","        for batch_idx, batch in enumerate(test_loader):\n","             # Forward pass\n","            input_data, labels = batch\n","\n","            output = model(input_data)  # (batch_size, seq_len, num_classes)\n","            output = output.view(-1, len(codons)) # (batch_size * seq_len, num_classes)\n","\n","            labels = labels.view(-1).long() # (batch_size, seq_len) -> (batch_size * seq_len)\n","\n","            # Calculate loss\n","            loss = criterion(output, labels)\n","\n","            # Compute total loss\n","            total_loss += loss.item()\n","\n","            # Compute custom metrics\n","            accuracy = compute_accuracy(output.cpu(), labels.cpu())\n","            accuracies.append(accuracy)\n","\n","    # Compute average loss\n","    avg_loss = total_loss / len(test_loader)\n","\n","    # Compute average accuracy\n","    avg_accuracy = np.mean(accuracies)\n","\n","    print(f'Average Loss: {avg_loss:.4f}')\n","    print(f'Average Accuracy: {avg_accuracy:.4f}')\n","\n","    return output, labels"]},{"cell_type":"markdown","metadata":{"id":"w60mTX5nQ7Z1"},"source":["## Training the model"]},{"cell_type":"code","execution_count":60,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1715688892531,"user":{"displayName":"Insa Belter","userId":"09408038895575287386"},"user_tz":-120},"id":"Vr8Ge8QYQ7Z2"},"outputs":[],"source":["set_seed()\n","EMBED_DIM = 256\n","NUM_ENCODER_LAYERS = 4\n","NUM_HEADS = 4\n","DROPOUT = 0.2"]},{"cell_type":"code","execution_count":61,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":452,"status":"ok","timestamp":1715688894105,"user":{"displayName":"Insa Belter","userId":"09408038895575287386"},"user_tz":-120},"id":"8G-AucPcQ7Z2","outputId":"8483db98-2a68-47ee-eaa2-b7d3c55e90f7"},"outputs":[{"name":"stdout","output_type":"stream","text":["6,597,675 total parameters.\n","6,597,675 training parameters.\n"]}],"source":["model = EncoderClassifier(\n","    embed_dim=EMBED_DIM,\n","    num_layers=NUM_ENCODER_LAYERS,\n","    num_heads=NUM_HEADS,\n","    dropout=DROPOUT,\n","    pos_enc=False\n",").to(device)\n","print_parameters(model)"]},{"cell_type":"code","execution_count":62,"metadata":{"executionInfo":{"elapsed":262,"status":"ok","timestamp":1715688895757,"user":{"displayName":"Insa Belter","userId":"09408038895575287386"},"user_tz":-120},"id":"fAaxt51-AqMN"},"outputs":[],"source":["criterion = torch.nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters())"]},{"cell_type":"code","execution_count":63,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":284046,"status":"ok","timestamp":1715689181251,"user":{"displayName":"Insa Belter","userId":"09408038895575287386"},"user_tz":-120},"id":"9XnDMsIPQ7Z2","outputId":"7a1150c4-80cb-4058-df6e-8021a7e9c16f"},"outputs":[{"name":"stdout","output_type":"stream","text":["----- Start Training -----\n","Epoch [1/10], Loss: 0.7026, Took 3.67 s\n","Epoch [2/10], Loss: 0.5737, Took 3.56 s\n","Epoch [3/10], Loss: 0.5695, Took 3.57 s\n","Epoch [4/10], Loss: 0.565, Took 3.56 s\n","Epoch [5/10], Loss: 0.5621, Took 3.57 s\n","Epoch [6/10], Loss: 0.5607, Took 3.57 s\n","Epoch [7/10], Loss: 0.5603, Took 3.57 s\n","Epoch [8/10], Loss: 0.5607, Took 3.57 s\n","Epoch [9/10], Loss: 0.5595, Took 3.57 s\n","Epoch [10/10], Loss: 0.5595, Took 3.56 s\n"]}],"source":["EPOCHS = 10\n","print(\"----- Start Training -----\")\n","train_model(model, optimizer, criterion, EPOCHS)"]},{"cell_type":"code","execution_count":64,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":365,"status":"ok","timestamp":1715689185291,"user":{"displayName":"Insa Belter","userId":"09408038895575287386"},"user_tz":-120},"id":"t1RXs8WBQ7Z2","outputId":"8be68388-5953-4aa2-afb1-c8684298c8d8"},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([32, 500, 65])\n"]}],"source":["batch_data, batch_label = next(iter(train_loader))\n","output = model(batch_data)\n","print(output.shape)"]},{"cell_type":"code","execution_count":65,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Model saved as 20240522184144_encoder_256em_4l_4h_02dr_10ep_speeds.pt\n"]}],"source":["ml_helper.save_model(model, 'encoder_256em_4l_4h_02dr_10ep_speeds', organism)"]},{"cell_type":"code","execution_count":284,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":337,"status":"ok","timestamp":1715426646972,"user":{"displayName":"Insa Belter","userId":"09408038895575287386"},"user_tz":-120},"id":"BQQaJPfuZOzE","outputId":"19b8b28e-1b1d-4c54-d721-e38f9b92756c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model loaded: 20240518113523_encoder_256em_4l_4h_02dr_10ep.pt\n"]}],"source":["model = EncoderClassifier(\n","    embed_dim=EMBED_DIM,\n","    num_layers=NUM_ENCODER_LAYERS,\n","    num_heads=NUM_HEADS,\n","    dropout=DROPOUT,\n","    pos_enc=False\n",").to(device)\n","model = ml_helper.load_model('encoder_256em_4l_4h_02dr_10ep', organism)"]},{"cell_type":"code","execution_count":285,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2348,"status":"ok","timestamp":1715689692684,"user":{"displayName":"Insa Belter","userId":"09408038895575287386"},"user_tz":-120},"id":"mnUwIS93Q7Z3","outputId":"153d5f25-9fd0-4a3c-a428-a8c689ab2bfd"},"outputs":[{"name":"stdout","output_type":"stream","text":["Average Loss: 0.5520\n","Average Accuracy: 0.7443\n"]},{"data":{"text/plain":["(tensor([[ 0.9152,  0.5791,  0.0878,  ..., -0.0355, -0.4697, -0.5985],\n","         [-1.2141, -1.1749, -0.8081,  ..., -0.5642, -0.7749, -0.1969],\n","         [-0.3878, -0.4670, -1.3479,  ..., -0.3965,  0.2353,  0.5023],\n","         ...,\n","         [-2.1591, -1.8035, -1.4565,  ..., -1.9126, -1.7272, 12.4792],\n","         [-2.1591, -1.8035, -1.4565,  ..., -1.9126, -1.7272, 12.4792],\n","         [-2.1591, -1.8035, -1.4565,  ..., -1.9126, -1.7272, 12.4792]],\n","        device='cuda:0'),\n"," tensor([35, 52, 40,  ..., 64, 64, 64], device='cuda:0'))"]},"execution_count":285,"metadata":{},"output_type":"execute_result"}],"source":["evaluate_model(model, criterion)"]},{"cell_type":"markdown","metadata":{},"source":["## Hyperparameter tuning"]},{"cell_type":"code","execution_count":296,"metadata":{},"outputs":[],"source":["def train_parameter_model(embed_dim, num_encoder_layers, num_heads, dropout, pos_enc, num_epochs):\n","    set_seed()\n","    \n","    model = EncoderClassifier(\n","        embed_dim=embed_dim,\n","        num_layers=num_encoder_layers,\n","        num_heads=num_heads,\n","        dropout=dropout,\n","        pos_enc=pos_enc\n","    ).to(device)\n","    print_parameters(model)\n","\n","    criterion = torch.nn.CrossEntropyLoss()\n","    optimizer = optim.Adam(model.parameters())\n","\n","    print(f\"----- Start Training: {embed_dim} emb, {num_encoder_layers} layers, {num_heads} heads, {dropout} dropout, positional encoding: {pos_enc}, {num_epochs} epochs -----\")\n","    train_model(model, optimizer, criterion, num_epochs)\n","\n","    ml_helper.save_model(model, f'encoder_{embed_dim}em_{num_encoder_layers}l_{num_heads}h_{str(dropout).replace(\".\",\"\")}dr_{num_epochs}ep{\"_posenc\" if pos_enc else \"\"}', organism)"]},{"cell_type":"markdown","metadata":{},"source":["### Dropout"]},{"cell_type":"code","execution_count":297,"metadata":{},"outputs":[],"source":["EMBED_DIM = 256\n","NUM_ENCODER_LAYERS = 4\n","NUM_HEADS = 4\n","dropouts = [0.1, 0.2, 0.3, 0.4, 0.5]\n","POS_ENC = False\n","EPOCHS = 10"]},{"cell_type":"code","execution_count":298,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["6,597,697 total parameters.\n","6,597,697 training parameters.\n","----- Start Training: 256 emb, 4 layers, 4 heads, 0.1 dropout, positional encoding: False, 10 epochs -----\n","Epoch [1/10], Loss: 0.7416, Took 3.49 s\n","Epoch [2/10], Loss: 0.5721, Took 3.49 s\n","Epoch [3/10], Loss: 0.5657, Took 3.49 s\n","Epoch [4/10], Loss: 0.5641, Took 3.5 s\n","Epoch [5/10], Loss: 0.5632, Took 3.5 s\n","Epoch [6/10], Loss: 0.5608, Took 3.5 s\n","Epoch [7/10], Loss: 0.5612, Took 3.5 s\n","Epoch [8/10], Loss: 0.5596, Took 3.5 s\n","Epoch [9/10], Loss: 0.5605, Took 3.5 s\n","Epoch [10/10], Loss: 0.5602, Took 3.51 s\n","Model saved as 20240518114512_encoder_256em_4l_4h_01dr_10ep.pt\n","6,597,697 total parameters.\n","6,597,697 training parameters.\n","----- Start Training: 256 emb, 4 layers, 4 heads, 0.2 dropout, positional encoding: False, 10 epochs -----\n","Epoch [1/10], Loss: 0.7472, Took 3.51 s\n","Epoch [2/10], Loss: 0.5737, Took 3.5 s\n","Epoch [3/10], Loss: 0.5664, Took 3.5 s\n","Epoch [4/10], Loss: 0.5642, Took 3.51 s\n","Epoch [5/10], Loss: 0.5631, Took 3.51 s\n","Epoch [6/10], Loss: 0.561, Took 3.51 s\n","Epoch [7/10], Loss: 0.5613, Took 3.51 s\n","Epoch [8/10], Loss: 0.5593, Took 3.51 s\n","Epoch [9/10], Loss: 0.5602, Took 3.51 s\n","Epoch [10/10], Loss: 0.5603, Took 3.51 s\n","Model saved as 20240518114547_encoder_256em_4l_4h_02dr_10ep.pt\n","6,597,697 total parameters.\n","6,597,697 training parameters.\n","----- Start Training: 256 emb, 4 layers, 4 heads, 0.3 dropout, positional encoding: False, 10 epochs -----\n","Epoch [1/10], Loss: 0.753, Took 3.51 s\n","Epoch [2/10], Loss: 0.5751, Took 3.51 s\n","Epoch [3/10], Loss: 0.5666, Took 3.51 s\n","Epoch [4/10], Loss: 0.5644, Took 3.51 s\n","Epoch [5/10], Loss: 0.5629, Took 3.51 s\n","Epoch [6/10], Loss: 0.5609, Took 3.52 s\n","Epoch [7/10], Loss: 0.5612, Took 3.52 s\n","Epoch [8/10], Loss: 0.5597, Took 3.52 s\n","Epoch [9/10], Loss: 0.5603, Took 3.52 s\n","Epoch [10/10], Loss: 0.5604, Took 3.52 s\n","Model saved as 20240518114622_encoder_256em_4l_4h_03dr_10ep.pt\n","6,597,697 total parameters.\n","6,597,697 training parameters.\n","----- Start Training: 256 emb, 4 layers, 4 heads, 0.4 dropout, positional encoding: False, 10 epochs -----\n","Epoch [1/10], Loss: 0.7594, Took 3.52 s\n","Epoch [2/10], Loss: 0.5761, Took 3.52 s\n","Epoch [3/10], Loss: 0.5671, Took 3.52 s\n","Epoch [4/10], Loss: 0.5644, Took 3.52 s\n","Epoch [5/10], Loss: 0.5633, Took 3.52 s\n","Epoch [6/10], Loss: 0.561, Took 3.52 s\n","Epoch [7/10], Loss: 0.5611, Took 3.52 s\n","Epoch [8/10], Loss: 0.5598, Took 3.52 s\n","Epoch [9/10], Loss: 0.5606, Took 3.52 s\n","Epoch [10/10], Loss: 0.5605, Took 3.52 s\n","Model saved as 20240518114658_encoder_256em_4l_4h_04dr_10ep.pt\n","6,597,697 total parameters.\n","6,597,697 training parameters.\n","----- Start Training: 256 emb, 4 layers, 4 heads, 0.5 dropout, positional encoding: False, 10 epochs -----\n","Epoch [1/10], Loss: 0.769, Took 3.52 s\n","Epoch [2/10], Loss: 0.5772, Took 3.52 s\n","Epoch [3/10], Loss: 0.568, Took 3.52 s\n","Epoch [4/10], Loss: 0.5653, Took 3.52 s\n","Epoch [5/10], Loss: 0.5637, Took 3.52 s\n","Epoch [6/10], Loss: 0.5614, Took 3.52 s\n","Epoch [7/10], Loss: 0.5617, Took 3.52 s\n","Epoch [8/10], Loss: 0.5615, Took 3.52 s\n","Epoch [9/10], Loss: 0.562, Took 3.52 s\n","Epoch [10/10], Loss: 0.5614, Took 3.52 s\n","Model saved as 20240518114733_encoder_256em_4l_4h_05dr_10ep.pt\n"]}],"source":["for DROPOUT in dropouts:\n","    train_parameter_model(EMBED_DIM, NUM_ENCODER_LAYERS, NUM_HEADS, DROPOUT, POS_ENC, EPOCHS)"]},{"cell_type":"markdown","metadata":{},"source":["### Positional Encoding"]},{"cell_type":"code","execution_count":299,"metadata":{},"outputs":[],"source":["EMBED_DIM = 256\n","NUM_ENCODER_LAYERS = 4\n","NUM_HEADS = 4\n","DROPOUT = 0.3\n","pos_enc = [True, False]\n","EPOCHS = 10"]},{"cell_type":"code","execution_count":300,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["6,597,697 total parameters.\n","6,597,697 training parameters.\n","----- Start Training: 256 emb, 4 layers, 4 heads, 0.3 dropout, positional encoding: True, 10 epochs -----\n","Epoch [1/10], Loss: 1.4638, Took 3.51 s\n","Epoch [2/10], Loss: 0.5765, Took 3.51 s\n","Epoch [3/10], Loss: 0.5681, Took 3.51 s\n","Epoch [4/10], Loss: 0.5652, Took 3.51 s\n","Epoch [5/10], Loss: 0.5642, Took 3.51 s\n","Epoch [6/10], Loss: 0.5619, Took 3.51 s\n","Epoch [7/10], Loss: 0.5618, Took 3.51 s\n","Epoch [8/10], Loss: 0.5612, Took 3.51 s\n","Epoch [9/10], Loss: 0.5614, Took 3.51 s\n","Epoch [10/10], Loss: 0.5615, Took 3.52 s\n","Model saved as 20240518115201_encoder_256em_4l_4h_03dr_10ep_posenc.pt\n","6,597,697 total parameters.\n","6,597,697 training parameters.\n","----- Start Training: 256 emb, 4 layers, 4 heads, 0.3 dropout, positional encoding: False, 10 epochs -----\n","Epoch [1/10], Loss: 0.753, Took 3.51 s\n","Epoch [2/10], Loss: 0.5751, Took 3.51 s\n","Epoch [3/10], Loss: 0.5666, Took 3.51 s\n","Epoch [4/10], Loss: 0.5644, Took 3.51 s\n","Epoch [5/10], Loss: 0.5629, Took 3.51 s\n","Epoch [6/10], Loss: 0.5609, Took 3.51 s\n","Epoch [7/10], Loss: 0.5612, Took 3.51 s\n","Epoch [8/10], Loss: 0.5597, Took 3.51 s\n","Epoch [9/10], Loss: 0.5603, Took 3.52 s\n","Epoch [10/10], Loss: 0.5604, Took 3.51 s\n","Model saved as 20240518115236_encoder_256em_4l_4h_03dr_10ep.pt\n"]}],"source":["for POS_ENC in pos_enc:\n","    train_parameter_model(EMBED_DIM, NUM_ENCODER_LAYERS, NUM_HEADS, DROPOUT, POS_ENC, EPOCHS)"]},{"cell_type":"markdown","metadata":{},"source":["### Embedding Dimension"]},{"cell_type":"code","execution_count":301,"metadata":{},"outputs":[],"source":["embed_dims = [32, 64, 128, 256, 512, 1028]\n","NUM_ENCODER_LAYERS = 4\n","NUM_HEADS = 4\n","DROPOUT = 0.3\n","POS_ENC = False\n","EPOCHS = 10"]},{"cell_type":"code","execution_count":302,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["690,369 total parameters.\n","690,369 training parameters.\n","----- Start Training: 32 emb, 4 layers, 4 heads, 0.3 dropout, positional encoding: False, 10 epochs -----\n","Epoch [1/10], Loss: 1.4734, Took 1.98 s\n","Epoch [2/10], Loss: 0.7379, Took 1.97 s\n","Epoch [3/10], Loss: 0.6394, Took 1.97 s\n","Epoch [4/10], Loss: 0.6079, Took 1.97 s\n","Epoch [5/10], Loss: 0.593, Took 1.97 s\n","Epoch [6/10], Loss: 0.584, Took 1.97 s\n","Epoch [7/10], Loss: 0.5777, Took 1.97 s\n","Epoch [8/10], Loss: 0.5742, Took 1.97 s\n","Epoch [9/10], Loss: 0.5738, Took 1.97 s\n","Epoch [10/10], Loss: 0.5719, Took 1.97 s\n","Model saved as 20240518115409_encoder_32em_4l_4h_03dr_10ep.pt\n","1,411,393 total parameters.\n","1,411,393 training parameters.\n","----- Start Training: 64 emb, 4 layers, 4 heads, 0.3 dropout, positional encoding: False, 10 epochs -----\n","Epoch [1/10], Loss: 0.9535, Took 2.09 s\n","Epoch [2/10], Loss: 0.6092, Took 2.09 s\n","Epoch [3/10], Loss: 0.5858, Took 2.09 s\n","Epoch [4/10], Loss: 0.576, Took 2.09 s\n","Epoch [5/10], Loss: 0.5714, Took 2.09 s\n","Epoch [6/10], Loss: 0.5668, Took 2.09 s\n","Epoch [7/10], Loss: 0.5643, Took 2.09 s\n","Epoch [8/10], Loss: 0.5638, Took 2.09 s\n","Epoch [9/10], Loss: 0.5622, Took 2.09 s\n","Epoch [10/10], Loss: 0.5614, Took 2.09 s\n","Model saved as 20240518115430_encoder_64em_4l_4h_03dr_10ep.pt\n","2,976,321 total parameters.\n","2,976,321 training parameters.\n","----- Start Training: 128 emb, 4 layers, 4 heads, 0.3 dropout, positional encoding: False, 10 epochs -----\n","Epoch [1/10], Loss: 0.7771, Took 2.38 s\n","Epoch [2/10], Loss: 0.5804, Took 2.38 s\n","Epoch [3/10], Loss: 0.5712, Took 2.38 s\n","Epoch [4/10], Loss: 0.567, Took 2.38 s\n","Epoch [5/10], Loss: 0.5638, Took 2.38 s\n","Epoch [6/10], Loss: 0.5632, Took 2.38 s\n","Epoch [7/10], Loss: 0.5618, Took 2.38 s\n","Epoch [8/10], Loss: 0.5587, Took 2.38 s\n","Epoch [9/10], Loss: 0.5587, Took 2.38 s\n","Epoch [10/10], Loss: 0.559, Took 2.38 s\n","Model saved as 20240518115453_encoder_128em_4l_4h_03dr_10ep.pt\n","6,597,697 total parameters.\n","6,597,697 training parameters.\n","----- Start Training: 256 emb, 4 layers, 4 heads, 0.3 dropout, positional encoding: False, 10 epochs -----\n","Epoch [1/10], Loss: 0.753, Took 3.51 s\n","Epoch [2/10], Loss: 0.5751, Took 3.51 s\n","Epoch [3/10], Loss: 0.5666, Took 3.51 s\n","Epoch [4/10], Loss: 0.5644, Took 3.52 s\n","Epoch [5/10], Loss: 0.5629, Took 3.51 s\n","Epoch [6/10], Loss: 0.5609, Took 3.51 s\n","Epoch [7/10], Loss: 0.5612, Took 3.51 s\n","Epoch [8/10], Loss: 0.5597, Took 3.51 s\n","Epoch [9/10], Loss: 0.5603, Took 3.52 s\n","Epoch [10/10], Loss: 0.5604, Took 3.52 s\n","Model saved as 20240518115529_encoder_256em_4l_4h_03dr_10ep.pt\n","15,806,529 total parameters.\n","15,806,529 training parameters.\n","----- Start Training: 512 emb, 4 layers, 4 heads, 0.3 dropout, positional encoding: False, 10 epochs -----\n","Epoch [1/10], Loss: 0.8789, Took 6.55 s\n","Epoch [2/10], Loss: 0.5728, Took 6.55 s\n","Epoch [3/10], Loss: 0.5685, Took 6.56 s\n","Epoch [4/10], Loss: 0.5666, Took 6.55 s\n","Epoch [5/10], Loss: 0.5648, Took 6.56 s\n","Epoch [6/10], Loss: 0.5629, Took 6.56 s\n","Epoch [7/10], Loss: 0.5626, Took 6.56 s\n","Epoch [8/10], Loss: 0.5625, Took 6.56 s\n","Epoch [9/10], Loss: 0.5606, Took 6.56 s\n","Epoch [10/10], Loss: 0.5612, Took 6.56 s\n","Model saved as 20240518115634_encoder_512em_4l_4h_03dr_10ep.pt\n","42,335,121 total parameters.\n","42,335,121 training parameters.\n","----- Start Training: 1028 emb, 4 layers, 4 heads, 0.3 dropout, positional encoding: False, 10 epochs -----\n","Epoch [1/10], Loss: 2.9813, Took 14.75 s\n","Epoch [2/10], Loss: 2.8524, Took 14.77 s\n","Epoch [3/10], Loss: 2.8388, Took 14.76 s\n","Epoch [4/10], Loss: 2.8408, Took 14.74 s\n","Epoch [5/10], Loss: 2.8379, Took 14.72 s\n","Epoch [6/10], Loss: 2.8339, Took 14.68 s\n","Epoch [7/10], Loss: 2.8394, Took 14.67 s\n","Epoch [8/10], Loss: 2.8381, Took 14.69 s\n","Epoch [9/10], Loss: 2.8374, Took 14.66 s\n","Epoch [10/10], Loss: 2.833, Took 14.65 s\n","Model saved as 20240518115901_encoder_1028em_4l_4h_03dr_10ep.pt\n"]}],"source":["for EMBED_DIM in embed_dims:\n","    train_parameter_model(EMBED_DIM, NUM_ENCODER_LAYERS, NUM_HEADS, DROPOUT, POS_ENC, EPOCHS)"]},{"cell_type":"markdown","metadata":{},"source":["### Number Encoder Layers and Heads"]},{"cell_type":"code","execution_count":303,"metadata":{},"outputs":[],"source":["EMBED_DIM = 256\n","num_encoder_layers = [2, 4, 8, 16]\n","num_heads = [2, 4, 8, 16]\n","DROPOUT = 0.3\n","POS_ENC = False\n","EPOCHS = 10"]},{"cell_type":"code","execution_count":304,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["3,967,553 total parameters.\n","3,967,553 training parameters.\n","----- Start Training: 256 emb, 2 layers, 2 heads, 0.3 dropout, positional encoding: False, 10 epochs -----\n","Epoch [1/10], Loss: 0.677, Took 1.77 s\n","Epoch [2/10], Loss: 0.5755, Took 1.77 s\n","Epoch [3/10], Loss: 0.568, Took 1.76 s\n","Epoch [4/10], Loss: 0.5656, Took 1.76 s\n","Epoch [5/10], Loss: 0.5647, Took 1.77 s\n","Epoch [6/10], Loss: 0.5625, Took 1.76 s\n","Epoch [7/10], Loss: 0.5639, Took 1.77 s\n","Epoch [8/10], Loss: 0.562, Took 1.77 s\n","Epoch [9/10], Loss: 0.5619, Took 1.77 s\n","Epoch [10/10], Loss: 0.5615, Took 1.76 s\n","Model saved as 20240518120122_encoder_256em_2l_2h_03dr_10ep.pt\n","3,967,553 total parameters.\n","3,967,553 training parameters.\n","----- Start Training: 256 emb, 2 layers, 4 heads, 0.3 dropout, positional encoding: False, 10 epochs -----\n","Epoch [1/10], Loss: 0.6778, Took 1.81 s\n","Epoch [2/10], Loss: 0.5752, Took 1.81 s\n","Epoch [3/10], Loss: 0.5679, Took 1.81 s\n","Epoch [4/10], Loss: 0.5655, Took 1.81 s\n","Epoch [5/10], Loss: 0.5638, Took 1.81 s\n","Epoch [6/10], Loss: 0.5646, Took 1.81 s\n","Epoch [7/10], Loss: 0.5625, Took 1.81 s\n","Epoch [8/10], Loss: 0.5613, Took 1.81 s\n","Epoch [9/10], Loss: 0.5614, Took 1.81 s\n","Epoch [10/10], Loss: 0.5611, Took 1.81 s\n","Model saved as 20240518120140_encoder_256em_2l_4h_03dr_10ep.pt\n","3,967,553 total parameters.\n","3,967,553 training parameters.\n","----- Start Training: 256 emb, 2 layers, 8 heads, 0.3 dropout, positional encoding: False, 10 epochs -----\n","Epoch [1/10], Loss: 0.6778, Took 2.1 s\n","Epoch [2/10], Loss: 0.5754, Took 2.09 s\n","Epoch [3/10], Loss: 0.5676, Took 2.1 s\n","Epoch [4/10], Loss: 0.565, Took 2.09 s\n","Epoch [5/10], Loss: 0.5636, Took 2.1 s\n","Epoch [6/10], Loss: 0.5638, Took 2.1 s\n","Epoch [7/10], Loss: 0.562, Took 2.09 s\n","Epoch [8/10], Loss: 0.5607, Took 2.07 s\n","Epoch [9/10], Loss: 0.5609, Took 2.07 s\n","Epoch [10/10], Loss: 0.5608, Took 2.07 s\n","Model saved as 20240518120201_encoder_256em_2l_8h_03dr_10ep.pt\n","3,967,553 total parameters.\n","3,967,553 training parameters.\n","----- Start Training: 256 emb, 2 layers, 16 heads, 0.3 dropout, positional encoding: False, 10 epochs -----\n","Epoch [1/10], Loss: 0.6779, Took 2.71 s\n","Epoch [2/10], Loss: 0.5751, Took 2.71 s\n","Epoch [3/10], Loss: 0.5674, Took 2.71 s\n","Epoch [4/10], Loss: 0.5646, Took 2.71 s\n","Epoch [5/10], Loss: 0.5633, Took 2.71 s\n","Epoch [6/10], Loss: 0.5622, Took 2.71 s\n","Epoch [7/10], Loss: 0.5611, Took 2.71 s\n","Epoch [8/10], Loss: 0.5599, Took 2.71 s\n","Epoch [9/10], Loss: 0.5604, Took 2.71 s\n","Epoch [10/10], Loss: 0.5604, Took 2.71 s\n","Model saved as 20240518120228_encoder_256em_2l_16h_03dr_10ep.pt\n","6,597,697 total parameters.\n","6,597,697 training parameters.\n","----- Start Training: 256 emb, 4 layers, 2 heads, 0.3 dropout, positional encoding: False, 10 epochs -----\n","Epoch [1/10], Loss: 0.7492, Took 3.43 s\n","Epoch [2/10], Loss: 0.5751, Took 3.43 s\n","Epoch [3/10], Loss: 0.5667, Took 3.43 s\n","Epoch [4/10], Loss: 0.5645, Took 3.45 s\n","Epoch [5/10], Loss: 0.5633, Took 3.46 s\n","Epoch [6/10], Loss: 0.5613, Took 3.46 s\n","Epoch [7/10], Loss: 0.5617, Took 3.45 s\n","Epoch [8/10], Loss: 0.5621, Took 3.46 s\n","Epoch [9/10], Loss: 0.5627, Took 3.46 s\n","Epoch [10/10], Loss: 0.5624, Took 3.46 s\n","Model saved as 20240518120302_encoder_256em_4l_2h_03dr_10ep.pt\n","6,597,697 total parameters.\n","6,597,697 training parameters.\n","----- Start Training: 256 emb, 4 layers, 4 heads, 0.3 dropout, positional encoding: False, 10 epochs -----\n","Epoch [1/10], Loss: 0.753, Took 3.55 s\n","Epoch [2/10], Loss: 0.5751, Took 3.54 s\n","Epoch [3/10], Loss: 0.5666, Took 3.54 s\n","Epoch [4/10], Loss: 0.5644, Took 3.55 s\n","Epoch [5/10], Loss: 0.5629, Took 3.54 s\n","Epoch [6/10], Loss: 0.5609, Took 3.54 s\n","Epoch [7/10], Loss: 0.5612, Took 3.54 s\n","Epoch [8/10], Loss: 0.5597, Took 3.54 s\n","Epoch [9/10], Loss: 0.5603, Took 3.54 s\n","Epoch [10/10], Loss: 0.5604, Took 3.54 s\n","Model saved as 20240518120338_encoder_256em_4l_4h_03dr_10ep.pt\n","6,597,697 total parameters.\n","6,597,697 training parameters.\n","----- Start Training: 256 emb, 4 layers, 8 heads, 0.3 dropout, positional encoding: False, 10 epochs -----\n","Epoch [1/10], Loss: 0.7542, Took 4.12 s\n","Epoch [2/10], Loss: 0.5752, Took 4.11 s\n","Epoch [3/10], Loss: 0.5665, Took 4.11 s\n","Epoch [4/10], Loss: 0.5643, Took 4.12 s\n","Epoch [5/10], Loss: 0.5625, Took 4.12 s\n","Epoch [6/10], Loss: 0.5608, Took 4.1 s\n","Epoch [7/10], Loss: 0.5611, Took 4.09 s\n","Epoch [8/10], Loss: 0.5595, Took 4.09 s\n","Epoch [9/10], Loss: 0.5602, Took 4.09 s\n","Epoch [10/10], Loss: 0.5604, Took 4.09 s\n","Model saved as 20240518120419_encoder_256em_4l_8h_03dr_10ep.pt\n","6,597,697 total parameters.\n","6,597,697 training parameters.\n","----- Start Training: 256 emb, 4 layers, 16 heads, 0.3 dropout, positional encoding: False, 10 epochs -----\n","Epoch [1/10], Loss: 0.7554, Took 5.37 s\n","Epoch [2/10], Loss: 0.575, Took 5.37 s\n","Epoch [3/10], Loss: 0.5664, Took 5.37 s\n","Epoch [4/10], Loss: 0.5637, Took 5.37 s\n","Epoch [5/10], Loss: 0.5626, Took 5.37 s\n","Epoch [6/10], Loss: 0.5606, Took 5.37 s\n","Epoch [7/10], Loss: 0.5607, Took 5.37 s\n","Epoch [8/10], Loss: 0.5595, Took 5.37 s\n","Epoch [9/10], Loss: 0.5601, Took 5.39 s\n","Epoch [10/10], Loss: 0.56, Took 5.39 s\n","Model saved as 20240518120513_encoder_256em_4l_16h_03dr_10ep.pt\n","11,857,985 total parameters.\n","11,857,985 training parameters.\n","----- Start Training: 256 emb, 8 layers, 2 heads, 0.3 dropout, positional encoding: False, 10 epochs -----\n","Epoch [1/10], Loss: 2.8976, Took 6.85 s\n","Epoch [2/10], Loss: 2.8495, Took 6.85 s\n","Epoch [3/10], Loss: 2.8368, Took 6.85 s\n","Epoch [4/10], Loss: 2.8335, Took 6.85 s\n","Epoch [5/10], Loss: 2.8333, Took 6.85 s\n","Epoch [6/10], Loss: 2.8268, Took 6.85 s\n","Epoch [7/10], Loss: 2.8363, Took 6.86 s\n","Epoch [8/10], Loss: 2.831, Took 6.86 s\n","Epoch [9/10], Loss: 2.8307, Took 6.85 s\n","Epoch [10/10], Loss: 2.8324, Took 6.85 s\n","Model saved as 20240518120621_encoder_256em_8l_2h_03dr_10ep.pt\n","11,857,985 total parameters.\n","11,857,985 training parameters.\n","----- Start Training: 256 emb, 8 layers, 4 heads, 0.3 dropout, positional encoding: False, 10 epochs -----\n","Epoch [1/10], Loss: 2.898, Took 7.02 s\n","Epoch [2/10], Loss: 2.8494, Took 7.02 s\n","Epoch [3/10], Loss: 2.8373, Took 7.03 s\n","Epoch [4/10], Loss: 2.8332, Took 7.03 s\n","Epoch [5/10], Loss: 2.8334, Took 7.03 s\n","Epoch [6/10], Loss: 2.8269, Took 7.02 s\n","Epoch [7/10], Loss: 2.8362, Took 7.03 s\n","Epoch [8/10], Loss: 2.8307, Took 7.0 s\n","Epoch [9/10], Loss: 2.8307, Took 7.0 s\n","Epoch [10/10], Loss: 2.8325, Took 7.0 s\n","Model saved as 20240518120731_encoder_256em_8l_4h_03dr_10ep.pt\n","11,857,985 total parameters.\n","11,857,985 training parameters.\n","----- Start Training: 256 emb, 8 layers, 8 heads, 0.3 dropout, positional encoding: False, 10 epochs -----\n","Epoch [1/10], Loss: 2.8981, Took 8.13 s\n","Epoch [2/10], Loss: 2.8494, Took 8.13 s\n","Epoch [3/10], Loss: 2.8371, Took 8.13 s\n","Epoch [4/10], Loss: 2.8335, Took 8.12 s\n","Epoch [5/10], Loss: 2.8331, Took 8.12 s\n","Epoch [6/10], Loss: 2.8267, Took 8.12 s\n","Epoch [7/10], Loss: 2.8359, Took 8.12 s\n","Epoch [8/10], Loss: 2.8309, Took 8.13 s\n","Epoch [9/10], Loss: 2.8305, Took 8.12 s\n","Epoch [10/10], Loss: 2.8326, Took 8.13 s\n","Model saved as 20240518120853_encoder_256em_8l_8h_03dr_10ep.pt\n","11,857,985 total parameters.\n","11,857,985 training parameters.\n","----- Start Training: 256 emb, 8 layers, 16 heads, 0.3 dropout, positional encoding: False, 10 epochs -----\n","Epoch [1/10], Loss: 2.8981, Took 10.67 s\n","Epoch [2/10], Loss: 2.8493, Took 10.68 s\n","Epoch [3/10], Loss: 2.8375, Took 10.67 s\n","Epoch [4/10], Loss: 2.8336, Took 10.67 s\n","Epoch [5/10], Loss: 2.8332, Took 10.67 s\n","Epoch [6/10], Loss: 2.827, Took 10.66 s\n","Epoch [7/10], Loss: 2.8361, Took 10.7 s\n","Epoch [8/10], Loss: 2.8306, Took 10.71 s\n","Epoch [9/10], Loss: 2.8305, Took 10.71 s\n","Epoch [10/10], Loss: 2.8326, Took 10.7 s\n","Model saved as 20240518121040_encoder_256em_8l_16h_03dr_10ep.pt\n","22,378,561 total parameters.\n","22,378,561 training parameters.\n","----- Start Training: 256 emb, 16 layers, 2 heads, 0.3 dropout, positional encoding: False, 10 epochs -----\n","Epoch [1/10], Loss: 2.899, Took 13.66 s\n","Epoch [2/10], Loss: 2.8493, Took 13.67 s\n","Epoch [3/10], Loss: 2.8371, Took 13.67 s\n","Epoch [4/10], Loss: 2.8335, Took 13.68 s\n","Epoch [5/10], Loss: 2.8332, Took 13.68 s\n","Epoch [6/10], Loss: 2.8269, Took 13.68 s\n","Epoch [7/10], Loss: 2.8361, Took 13.68 s\n","Epoch [8/10], Loss: 2.8307, Took 13.68 s\n","Epoch [9/10], Loss: 2.8306, Took 13.68 s\n","Epoch [10/10], Loss: 2.8326, Took 13.68 s\n","Model saved as 20240518121257_encoder_256em_16l_2h_03dr_10ep.pt\n","22,378,561 total parameters.\n","22,378,561 training parameters.\n","----- Start Training: 256 emb, 16 layers, 4 heads, 0.3 dropout, positional encoding: False, 10 epochs -----\n","Epoch [1/10], Loss: 2.8988, Took 14.03 s\n","Epoch [2/10], Loss: 2.8494, Took 14.03 s\n","Epoch [3/10], Loss: 2.837, Took 14.01 s\n","Epoch [4/10], Loss: 2.8337, Took 14.0 s\n","Epoch [5/10], Loss: 2.8332, Took 14.0 s\n","Epoch [6/10], Loss: 2.8268, Took 14.01 s\n","Epoch [7/10], Loss: 2.8361, Took 14.01 s\n","Epoch [8/10], Loss: 2.8307, Took 14.0 s\n","Epoch [9/10], Loss: 2.8306, Took 14.0 s\n","Epoch [10/10], Loss: 2.8326, Took 14.02 s\n","Model saved as 20240518121517_encoder_256em_16l_4h_03dr_10ep.pt\n","22,378,561 total parameters.\n","22,378,561 training parameters.\n","----- Start Training: 256 emb, 16 layers, 8 heads, 0.3 dropout, positional encoding: False, 10 epochs -----\n","Epoch [1/10], Loss: 2.899, Took 16.25 s\n","Epoch [2/10], Loss: 2.8494, Took 16.24 s\n","Epoch [3/10], Loss: 2.8372, Took 16.26 s\n","Epoch [4/10], Loss: 2.8336, Took 16.24 s\n","Epoch [5/10], Loss: 2.8333, Took 16.27 s\n","Epoch [6/10], Loss: 2.8268, Took 16.28 s\n","Epoch [7/10], Loss: 2.8361, Took 16.28 s\n","Epoch [8/10], Loss: 2.8306, Took 16.28 s\n","Epoch [9/10], Loss: 2.8306, Took 16.29 s\n","Epoch [10/10], Loss: 2.8326, Took 16.28 s\n","Model saved as 20240518121800_encoder_256em_16l_8h_03dr_10ep.pt\n","22,378,561 total parameters.\n","22,378,561 training parameters.\n","----- Start Training: 256 emb, 16 layers, 16 heads, 0.3 dropout, positional encoding: False, 10 epochs -----\n","Epoch [1/10], Loss: 2.8992, Took 21.38 s\n","Epoch [2/10], Loss: 2.8494, Took 21.38 s\n","Epoch [3/10], Loss: 2.8374, Took 21.38 s\n","Epoch [4/10], Loss: 2.8335, Took 21.38 s\n","Epoch [5/10], Loss: 2.8334, Took 21.38 s\n","Epoch [6/10], Loss: 2.8267, Took 21.39 s\n","Epoch [7/10], Loss: 2.8362, Took 21.38 s\n","Epoch [8/10], Loss: 2.8307, Took 21.39 s\n","Epoch [9/10], Loss: 2.8307, Took 21.36 s\n","Epoch [10/10], Loss: 2.8325, Took 21.34 s\n","Model saved as 20240518122134_encoder_256em_16l_16h_03dr_10ep.pt\n"]}],"source":["for NUM_ENCODER_LAYERS in num_encoder_layers:\n","    for NUM_HEADS in num_heads:\n","        train_parameter_model(EMBED_DIM, NUM_ENCODER_LAYERS, NUM_HEADS, DROPOUT, POS_ENC, EPOCHS)"]},{"cell_type":"markdown","metadata":{},"source":["## Training Drosophila.Melanogaster"]},{"cell_type":"code","execution_count":305,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["L채nge train_dataset: 33071\n","L채nge test_dataset: 8100\n"]}],"source":["organism = \"Drosophila.Melanogaster\"\n","min_length = None\n","max_length = 500\n","\n","train_dataset = ml_helper.CodonDataset(organism, \"train\", min_length, max_length, cut_data=True, one_hot_aa=False, data_path=data_path, device=device)\n","print(f\"L채nge train_dataset: {len(train_dataset)}\")\n","test_dataset = ml_helper.CodonDataset(organism, \"test\", min_length, max_length, cut_data=True, one_hot_aa=False, data_path=data_path, device=device)\n","print(f\"L채nge test_dataset: {len(test_dataset)}\")"]},{"cell_type":"code","execution_count":306,"metadata":{},"outputs":[],"source":["EMBED_DIM = 256\n","NUM_ENCODER_LAYERS = 4\n","NUM_HEADS = 4\n","DROPOUT = 0.3\n","POS_ENC = False\n","EPOCHS = 10"]},{"cell_type":"code","execution_count":307,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["6,597,697 total parameters.\n","6,597,697 training parameters.\n","----- Start Training: 256 emb, 4 layers, 4 heads, 0.3 dropout, positional encoding: False, 10 epochs -----\n","Epoch [1/10], Loss: 0.753, Took 3.51 s\n","Epoch [2/10], Loss: 0.5751, Took 3.51 s\n","Epoch [3/10], Loss: 0.5666, Took 3.51 s\n","Epoch [4/10], Loss: 0.5644, Took 3.51 s\n","Epoch [5/10], Loss: 0.5629, Took 3.51 s\n","Epoch [6/10], Loss: 0.5609, Took 3.51 s\n","Epoch [7/10], Loss: 0.5612, Took 3.52 s\n","Epoch [8/10], Loss: 0.5597, Took 3.51 s\n","Epoch [9/10], Loss: 0.5603, Took 3.52 s\n","Epoch [10/10], Loss: 0.5604, Took 3.52 s\n","Model saved as 20240518122826_encoder_256em_4l_4h_03dr_10ep.pt\n"]}],"source":["train_parameter_model(EMBED_DIM, NUM_ENCODER_LAYERS, NUM_HEADS, DROPOUT, POS_ENC, EPOCHS)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":0}
